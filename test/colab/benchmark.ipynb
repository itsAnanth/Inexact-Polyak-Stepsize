{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1ABgpXQB24Ok"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import torch\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.models as models\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DqXnzFmu24Op"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "class IPS(optim.Optimizer):\n",
        "    def __init__(self, model_params, T, lower_bound):\n",
        "\n",
        "        defaults = dict(T=T, lower_bound=lower_bound)\n",
        "\n",
        "        super(IPS, self).__init__(model_params, defaults)\n",
        "\n",
        "        self.best_loss = float('inf')\n",
        "        self.best_params = None\n",
        "\n",
        "\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def step(self, closure=None):\n",
        "\n",
        "\n",
        "        if closure is not None:\n",
        "            with torch.enable_grad():\n",
        "                rtloss = closure()\n",
        "                loss = rtloss.item()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            T = group['T']\n",
        "            l_star = group['lower_bound']\n",
        "\n",
        "            for param in group['params']:\n",
        "                if param.grad is None:\n",
        "                    continue\n",
        "\n",
        "                grad = param.grad.data\n",
        "                grad_norm_sq = torch.sum(grad ** 2) + 1e-8\n",
        "\n",
        "                inexact_step_size = (loss - l_star) / (grad_norm_sq * (T ** 0.5))\n",
        "\n",
        "                # important, since we're using incremental stepsize without clamping gradient explodes\n",
        "                # especially true in earlier steps\n",
        "                inexact_step_size = torch.clamp(inexact_step_size, min=0.0, max=1.0)\n",
        "                param.data.add_(grad, alpha=-inexact_step_size)\n",
        "\n",
        "        # if loss < self.best_loss:\n",
        "        #     self.best_loss = loss\n",
        "        #     self.best_params = [p.clone().detach() for p in self.param_groups[0]['params']]\n",
        "\n",
        "        return rtloss\n",
        "\n",
        "    def load_best_params(self):\n",
        "        if self.best_params:\n",
        "            for param, best_param in zip(self.param_groups[0]['params'], self.best_params):\n",
        "                param.data.copy_(best_param)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JW3HYij124Oq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "\"\"\"\n",
        "    logic\n",
        "\n",
        "    from adam, moment estimates are given by\n",
        "\n",
        "\n",
        "\n",
        "    m_t = beta_1 * m_t-1 + (1 - beta_t) * grad\n",
        "    v_t = beta_2 * v_t-1 + (1 - beta_2) * grad ** 2\n",
        "\n",
        "    with vt maximum tracking,\n",
        "\n",
        "    v_t_max = max(v_t, v_t-1_max)\n",
        "    theta_t = theta_t-1 - (alpha * m_t) / (v_t ** 0.5)\n",
        "\n",
        "\n",
        "    ips = (loss - l*) / (grad_norm_square * (T ** 0.5))\n",
        "    theta_t = theta_t-1 - (ips * grad)\n",
        "\n",
        "    with adam,\n",
        "\n",
        "    TODO: currently, doing layer wise ips, probably should do parameter wise ips. verify it later\n",
        "\n",
        "    ips = (loss - l*) / (grad_norm_square * (T ** 0.5) * (v_t_sum ** 0.5))\n",
        "    theta_t = theta_t-1 - (ips * m_t)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "class AdaIPS_S(optim.Optimizer):\n",
        "    def __init__(self, model_params, lower_bound=0, beta_1=0.9, beta_2=0.999, eps=1e-8, per_param=False):\n",
        "        defaults = dict(lower_bound=lower_bound, beta_1=beta_1, beta_2=beta_2, eps=eps)\n",
        "        super().__init__(model_params, defaults)\n",
        "\n",
        "        print(f\"initialized optimizer with per layer learning rate: {per_param}, no T\")\n",
        "        self.best_loss = float('inf')\n",
        "        self.best_params = None  # List of lists for each param group\n",
        "        self.t = 0\n",
        "        self.per_param = per_param\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def step(self, closure=None):\n",
        "        self.t += 1\n",
        "\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            with torch.enable_grad():\n",
        "                loss = closure()\n",
        "                loss_value = loss.item()\n",
        "        else:\n",
        "            raise ValueError(\"AdaIPS requires closure for loss value\")\n",
        "\n",
        "        current_params = []\n",
        "        for group in self.param_groups:\n",
        "            current_params.append([p.clone().detach() for p in group['params']])\n",
        "        if loss_value < self.best_loss:\n",
        "            self.best_loss = loss_value\n",
        "            self.best_params = current_params\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            l_star = group['lower_bound']\n",
        "            beta_1 = group['beta_1']\n",
        "            beta_2 = group['beta_2']\n",
        "            eps = group['eps']\n",
        "\n",
        "            for param in group['params']:\n",
        "                if param.grad is None:\n",
        "                    continue\n",
        "                grad = param.grad\n",
        "\n",
        "                state = self.state[param]\n",
        "\n",
        "                # Initialize state\n",
        "                if len(state) == 0:\n",
        "                    state['m_t'] = torch.zeros_like(param)\n",
        "                    state['v_t'] = torch.zeros_like(param)\n",
        "                    state['v_t_max'] = torch.zeros_like(param)\n",
        "\n",
        "\n",
        "                m_t = state['m_t']\n",
        "                v_t = state['v_t']\n",
        "                v_t_max = state['v_t_max']\n",
        "\n",
        "                # Update moments\n",
        "\n",
        "                # Update first moment estimate (momentum)\n",
        "                # first moment estimate holds information regarding gradient trends\n",
        "                # ex, if gradient is a ball rolling down a hill then mt holds information like velocity, direction etc\n",
        "                m_t.mul_(beta_1).add_(grad, alpha=1 - beta_1)\n",
        "\n",
        "                # Calculate parameter-wise adaptive T_t\n",
        "                # high vt means gradient has been fluctuating, move slowly\n",
        "                # v_t_hat shows gradient variance (low vt means high confidence, travelling in this direction reduces loss and vice versa)\n",
        "                # high variance means unstable region\n",
        "                # inverse relation, so to prevent overshooting, for large gradient variance small steps\n",
        "                # ex, if gradient is a ball rolling down a hill then vt represents terrain difficulty\n",
        "                v_t.mul_(beta_2).addcmul_(grad, grad, value=1 - beta_2)\n",
        "\n",
        "                v_t_max = torch.maximum(v_t_max, v_t)\n",
        "                # bias correction\n",
        "                m_t_hat = m_t / (1 - beta_1 ** self.t)\n",
        "                v_t_hat = v_t_max / (1 - beta_2 ** self.t)\n",
        "\n",
        "                sum_v_t_hat = v_t_hat.sum()\n",
        "\n",
        "                grad_norm_sq = grad.pow(2).sum().clamp(min=eps)\n",
        "                # param_t = (T0 ** 0.5) * (torch.sqrt(v_t_hat) + eps) if self.per_param else (torch.sqrt(sum_v_t_hat) + eps)\n",
        "\n",
        "                param_t = (torch.sqrt(v_t_hat) + eps) if self.per_param else (torch.sqrt(sum_v_t_hat) + eps)\n",
        "                # did sqrt param_t here, optimization becomes faster because smaller denominator, but becomes more unstable so keep it as it is\n",
        "                denominator = grad_norm_sq * param_t\n",
        "                denominator = denominator.clamp(min=eps)\n",
        "\n",
        "                step_size = (loss_value - l_star) / denominator\n",
        "                step_size = torch.clamp(step_size, min=0.0, max=0.1)\n",
        "\n",
        "                # param.data.add_(m_t_hat, alpha=-step_size)\n",
        "                param.data.add_((m_t_hat * -step_size))\n",
        "\n",
        "\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def load_best_params(self):\n",
        "        if self.best_params is not None:\n",
        "            for group, best_group_params in zip(self.param_groups, self.best_params):\n",
        "                for param, best_param in zip(group['params'], best_group_params):\n",
        "                    param.data.copy_(best_param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8Znjk9OQ24Os"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.transforms import transforms\n",
        "\n",
        "def getData(dataset: str, transform_train, transform_val, batch_size=64):\n",
        "\n",
        "    if not hasattr(torchvision.datasets, dataset):\n",
        "        raise ValueError(\"dataset does not exist\")\n",
        "\n",
        "    data = getattr(torchvision.datasets, dataset)\n",
        "\n",
        "    # Create datasets without transforms initially\n",
        "    full_trainset = data(root='../data', train=True, download=True, transform=None)\n",
        "    testset = data(root='../data', train=False, download=True, transform=transform_val)\n",
        "\n",
        "    train_size = int(0.8 * len(full_trainset))\n",
        "    val_size = len(full_trainset) - train_size\n",
        "\n",
        "    # Split without transforms\n",
        "    train_subset, val_subset = torch.utils.data.random_split(full_trainset, [train_size, val_size])\n",
        "\n",
        "    # Create dataset wrappers that apply transforms\n",
        "    trainset = TransformDataset(train_subset, transform_train)\n",
        "    valset = TransformDataset(val_subset, transform_val)\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
        "    validationloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return trainloader, trainset, testloader, testset, validationloader, valset\n",
        "\n",
        "# Helper class to apply transforms to a subset\n",
        "class TransformDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, subset, transform=None):\n",
        "        self.subset = subset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x, y = self.subset[idx]\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.subset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JYCcNN0j24Os"
      },
      "outputs": [],
      "source": [
        "# Device setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class CIFAR10_CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CIFAR10_CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "        self.t_losses = []\n",
        "        self.v_losses = []\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 8 * 8)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class PretrainedResNet18(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(PretrainedResNet18, self).__init__()\n",
        "        # Load pretrained ResNet18\n",
        "        self.model = resnet18(weights=None)\n",
        "\n",
        "        # Replace the first conv layer to handle CIFAR-10's 32x32 images\n",
        "        # Original ResNet has 7x7 conv with stride 2 for ImageNet's larger images\n",
        "        self.model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "\n",
        "        # Remove the max pooling layer (not needed for smaller images)\n",
        "        self.model.maxpool = nn.Identity()\n",
        "\n",
        "        # Replace the final fully connected layer\n",
        "        in_features = self.model.fc.in_features\n",
        "        self.model.fc = nn.Linear(in_features, num_classes)\n",
        "\n",
        "        self.t_losses = []\n",
        "        self.v_losses = []\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ResNetBlockWithDropout(nn.Module):\n",
        "    \"\"\"Custom BasicBlock with Dropout\"\"\"\n",
        "    def __init__(self, original_block, dropout_rate=0.2):\n",
        "        super().__init__()\n",
        "        self.conv1 = original_block.conv1\n",
        "        self.bn1 = original_block.bn1\n",
        "        self.relu = original_block.relu\n",
        "        self.conv2 = original_block.conv2\n",
        "        self.bn2 = original_block.bn2\n",
        "        self.downsample = original_block.downsample\n",
        "\n",
        "        # Add dropout\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        # Apply dropout after activation\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class ResNetWithDropout(nn.Module):\n",
        "    def __init__(self, num_classes=10, dropout_rate=0.3):\n",
        "        super(ResNetWithDropout, self).__init__()\n",
        "        self.model = resnet18(weights=None)  # Or use `weights=models.ResNet18_Weights.DEFAULT`\n",
        "\n",
        "        # Modify the first conv layer to fit CIFAR-10 (optional)\n",
        "        self.model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.model.maxpool = nn.Identity()  # Remove max pooling for small images\n",
        "\n",
        "        # Replace each BasicBlock with ResNetBlockWithDropout\n",
        "        for name, module in self.model.named_children():\n",
        "            if isinstance(module, nn.Sequential):  # Residual blocks are in nn.Sequential\n",
        "                for block_idx, block in enumerate(module):\n",
        "                    if isinstance(block, models.resnet.BasicBlock):\n",
        "                        module[block_idx] = ResNetBlockWithDropout(block, dropout_rate)\n",
        "\n",
        "        # Add dropout before final fully connected layer\n",
        "        in_features = self.model.fc.in_features\n",
        "        self.model.fc = nn.Sequential(\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(in_features, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "3If54N8VEKN9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5bgd7Ug724Ou"
      },
      "outputs": [],
      "source": [
        "epochs = 50\n",
        "batch_size = 128\n",
        "seed = 42\n",
        "\n",
        "set_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UCaMrnyd24Ou",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "2ab65c82-8092-46eb-8905-07fa2930df7b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "40000"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),  # Randomly crop with padding\n",
        "    transforms.RandomHorizontalFlip(),     # Randomly flip horizontally\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),  # Adjust color properties\n",
        "    transforms.ToTensor(),                 # Convert to tensor\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))  # Normalize with CIFAR-10 mean and std\n",
        "])\n",
        "\n",
        "# Define transforms for validation/testing (no augmentation)\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
        "])\n",
        "trainloader, trainset, testloader, testset, validationloader, valset = getData('CIFAR10', transform_train=transform_train, transform_val=transform_test, batch_size=batch_size)\n",
        "\n",
        "display(len(trainset), len(testset), len(valset))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(model, optimizer, epoch, loss, accuracy, filename, t_losses, v_losses):\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': loss,\n",
        "        'accuracy': accuracy,\n",
        "        't_losses': t_losses,\n",
        "        'v_losses': v_losses\n",
        "    }\n",
        "    torch.save(checkpoint, filename)\n",
        "    print(f\"Checkpoint saved: {filename}\")"
      ],
      "metadata": {
        "id": "EfHEd1UrO0es"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "NSOENtq_24Ov"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, epochs=2):\n",
        "    print(optimizer.__class__.__name__)\n",
        "    print(optimizer)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    t_losses = []\n",
        "    v_losses = []\n",
        "    num_epochs = epochs\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        model.train()\n",
        "        running_loss = 0\n",
        "        for i, (inputs, labels) in enumerate(trainloader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            def closure():\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                return loss\n",
        "\n",
        "            loss = optimizer.step(closure)\n",
        "\n",
        "            print(f'Epoch {epoch+1}, Step {i}, Loss: {loss}')\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            del inputs, labels\n",
        "\n",
        "        t_losses.append(running_loss / len(trainloader))\n",
        "        print(f\"Epoch {epoch+1} end, avg train loss: {running_loss / len(trainloader)}\")\n",
        "\n",
        "        model.eval()  # Set model to evaluation mode\n",
        "        val_running_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():  # No need to track gradients during validation\n",
        "            for v_i, (inputs, labels) in enumerate(validationloader):\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_running_loss += loss.item()\n",
        "\n",
        "                # Calculate accuracy\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "                del inputs, labels, outputs\n",
        "\n",
        "        # Calculate and store validation loss and accuracy\n",
        "        val_loss = val_running_loss / len(validationloader)\n",
        "        v_losses.append(val_loss)\n",
        "        accuracy = 100 * correct / total\n",
        "\n",
        "        print(f\"Epoch {epoch+1} end, avg val loss: {val_loss}, accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "        if (epoch % 10 == 0 and epoch != 0):\n",
        "          save_checkpoint(model, optimizer, epoch+1, loss=val_loss, accuracy=accuracy, filename=f\"{optimizer.__class__.__name__}_{epoch+1}.pth\", t_losses=t_losses, v_losses=v_losses)\n",
        "\n",
        "\n",
        "    model = model.cpu()\n",
        "    model.t_losses = t_losses\n",
        "    model.v_losses = v_losses\n",
        "    torch.cuda.empty_cache()\n",
        "    print(f\"GPU memory allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
        "    print(f\"GPU memory reserved: {torch.cuda.memory_reserved() / 1e9:.2f} GB\")\n",
        "\n",
        "\n",
        "\n",
        "    print(\"Training complete.\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nz9yTMhz24Ov"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "def test(model, testloader):\n",
        "    if testloader is None:\n",
        "        raise ValueError(\"testloader must be provided\")\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Initialize lists to store all predictions and labels\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    # Iterate through batches\n",
        "    for i, (inputs, labels) in enumerate(testloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(inputs)\n",
        "            predictions = torch.argmax(output, dim=1)\n",
        "\n",
        "        # Store batch results\n",
        "        all_predictions.append(predictions.cpu().numpy())\n",
        "        all_labels.append(labels.cpu().numpy())\n",
        "\n",
        "    # Concatenate all batches\n",
        "    all_predictions = np.concatenate(all_predictions)\n",
        "    all_labels = np.concatenate(all_labels)\n",
        "\n",
        "    # Calculate metrics on the entire dataset\n",
        "    accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    precision, recall, fscore, support = precision_recall_fscore_support(all_labels, all_predictions, average='weighted')\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1-score: {fscore:.4f}\")\n",
        "    model.cpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2TuqNr624Ow",
        "outputId": "444e625f-675e-4400-c099-716c589d0655"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 35, Step 44, Loss: 0.25111278891563416\n",
            "Epoch 35, Step 45, Loss: 0.3208291828632355\n",
            "Epoch 35, Step 46, Loss: 0.2901143431663513\n",
            "Epoch 35, Step 47, Loss: 0.4693639874458313\n",
            "Epoch 35, Step 48, Loss: 0.44107985496520996\n",
            "Epoch 35, Step 49, Loss: 0.36627501249313354\n",
            "Epoch 35, Step 50, Loss: 0.22971631586551666\n",
            "Epoch 35, Step 51, Loss: 0.37188878655433655\n",
            "Epoch 35, Step 52, Loss: 0.33290353417396545\n",
            "Epoch 35, Step 53, Loss: 0.1916894018650055\n",
            "Epoch 35, Step 54, Loss: 0.34821465611457825\n",
            "Epoch 35, Step 55, Loss: 0.2927216589450836\n",
            "Epoch 35, Step 56, Loss: 0.21673539280891418\n",
            "Epoch 35, Step 57, Loss: 0.26895442605018616\n",
            "Epoch 35, Step 58, Loss: 0.3338928818702698\n",
            "Epoch 35, Step 59, Loss: 0.3218880593776703\n",
            "Epoch 35, Step 60, Loss: 0.22030624747276306\n",
            "Epoch 35, Step 61, Loss: 0.44652435183525085\n",
            "Epoch 35, Step 62, Loss: 0.26207807660102844\n",
            "Epoch 35, Step 63, Loss: 0.3013114333152771\n",
            "Epoch 35, Step 64, Loss: 0.32219645380973816\n",
            "Epoch 35, Step 65, Loss: 0.3004579246044159\n",
            "Epoch 35, Step 66, Loss: 0.35166579484939575\n",
            "Epoch 35, Step 67, Loss: 0.38807767629623413\n",
            "Epoch 35, Step 68, Loss: 0.27489960193634033\n",
            "Epoch 35, Step 69, Loss: 0.29166173934936523\n",
            "Epoch 35, Step 70, Loss: 0.4360232949256897\n",
            "Epoch 35, Step 71, Loss: 0.36374375224113464\n",
            "Epoch 35, Step 72, Loss: 0.2823954224586487\n",
            "Epoch 35, Step 73, Loss: 0.31982576847076416\n",
            "Epoch 35, Step 74, Loss: 0.26714590191841125\n",
            "Epoch 35, Step 75, Loss: 0.31189149618148804\n",
            "Epoch 35, Step 76, Loss: 0.38282665610313416\n",
            "Epoch 35, Step 77, Loss: 0.3127863109111786\n",
            "Epoch 35, Step 78, Loss: 0.24570345878601074\n",
            "Epoch 35, Step 79, Loss: 0.2463269829750061\n",
            "Epoch 35, Step 80, Loss: 0.38120731711387634\n",
            "Epoch 35, Step 81, Loss: 0.5236793160438538\n",
            "Epoch 35, Step 82, Loss: 0.27935361862182617\n",
            "Epoch 35, Step 83, Loss: 0.3150666058063507\n",
            "Epoch 35, Step 84, Loss: 0.29322463274002075\n",
            "Epoch 35, Step 85, Loss: 0.379142701625824\n",
            "Epoch 35, Step 86, Loss: 0.33265337347984314\n",
            "Epoch 35, Step 87, Loss: 0.30890166759490967\n",
            "Epoch 35, Step 88, Loss: 0.20435664057731628\n",
            "Epoch 35, Step 89, Loss: 0.5103716850280762\n",
            "Epoch 35, Step 90, Loss: 0.34252503514289856\n",
            "Epoch 35, Step 91, Loss: 0.34418222308158875\n",
            "Epoch 35, Step 92, Loss: 0.3906802237033844\n",
            "Epoch 35, Step 93, Loss: 0.3596991300582886\n",
            "Epoch 35, Step 94, Loss: 0.3610438406467438\n",
            "Epoch 35, Step 95, Loss: 0.4819793701171875\n",
            "Epoch 35, Step 96, Loss: 0.43582746386528015\n",
            "Epoch 35, Step 97, Loss: 0.3129348158836365\n",
            "Epoch 35, Step 98, Loss: 0.4332830607891083\n",
            "Epoch 35, Step 99, Loss: 0.24118879437446594\n",
            "Epoch 35, Step 100, Loss: 0.24798136949539185\n",
            "Epoch 35, Step 101, Loss: 0.3235282301902771\n",
            "Epoch 35, Step 102, Loss: 0.46361443400382996\n",
            "Epoch 35, Step 103, Loss: 0.43942150473594666\n",
            "Epoch 35, Step 104, Loss: 0.29853683710098267\n",
            "Epoch 35, Step 105, Loss: 0.3252914547920227\n",
            "Epoch 35, Step 106, Loss: 0.242819681763649\n",
            "Epoch 35, Step 107, Loss: 0.2886967658996582\n",
            "Epoch 35, Step 108, Loss: 0.31332844495773315\n",
            "Epoch 35, Step 109, Loss: 0.3875497281551361\n",
            "Epoch 35, Step 110, Loss: 0.29803091287612915\n",
            "Epoch 35, Step 111, Loss: 0.3751406669616699\n",
            "Epoch 35, Step 112, Loss: 0.41383621096611023\n",
            "Epoch 35, Step 113, Loss: 0.3043196201324463\n",
            "Epoch 35, Step 114, Loss: 0.2301512211561203\n",
            "Epoch 35, Step 115, Loss: 0.3522345721721649\n",
            "Epoch 35, Step 116, Loss: 0.27779123187065125\n",
            "Epoch 35, Step 117, Loss: 0.3406184911727905\n",
            "Epoch 35, Step 118, Loss: 0.3286343812942505\n",
            "Epoch 35, Step 119, Loss: 0.25035059452056885\n",
            "Epoch 35, Step 120, Loss: 0.340088814496994\n",
            "Epoch 35, Step 121, Loss: 0.327278196811676\n",
            "Epoch 35, Step 122, Loss: 0.2496250867843628\n",
            "Epoch 35, Step 123, Loss: 0.30485695600509644\n",
            "Epoch 35, Step 124, Loss: 0.35853883624076843\n",
            "Epoch 35, Step 125, Loss: 0.3624956011772156\n",
            "Epoch 35, Step 126, Loss: 0.3223012685775757\n",
            "Epoch 35, Step 127, Loss: 0.28658589720726013\n",
            "Epoch 35, Step 128, Loss: 0.2918762266635895\n",
            "Epoch 35, Step 129, Loss: 0.2635834515094757\n",
            "Epoch 35, Step 130, Loss: 0.3890625238418579\n",
            "Epoch 35, Step 131, Loss: 0.2844194769859314\n",
            "Epoch 35, Step 132, Loss: 0.29088839888572693\n",
            "Epoch 35, Step 133, Loss: 0.2764812409877777\n",
            "Epoch 35, Step 134, Loss: 0.3641720712184906\n",
            "Epoch 35, Step 135, Loss: 0.40266668796539307\n",
            "Epoch 35, Step 136, Loss: 0.23338542878627777\n",
            "Epoch 35, Step 137, Loss: 0.3790929913520813\n",
            "Epoch 35, Step 138, Loss: 0.4036553204059601\n",
            "Epoch 35, Step 139, Loss: 0.33103758096694946\n",
            "Epoch 35, Step 140, Loss: 0.36825665831565857\n",
            "Epoch 35, Step 141, Loss: 0.20694637298583984\n",
            "Epoch 35, Step 142, Loss: 0.21880419552326202\n",
            "Epoch 35, Step 143, Loss: 0.24486778676509857\n",
            "Epoch 35, Step 144, Loss: 0.43366581201553345\n",
            "Epoch 35, Step 145, Loss: 0.255452036857605\n",
            "Epoch 35, Step 146, Loss: 0.3780128061771393\n",
            "Epoch 35, Step 147, Loss: 0.33904218673706055\n",
            "Epoch 35, Step 148, Loss: 0.48811960220336914\n",
            "Epoch 35, Step 149, Loss: 0.31871429085731506\n",
            "Epoch 35, Step 150, Loss: 0.28168943524360657\n",
            "Epoch 35, Step 151, Loss: 0.32124581933021545\n",
            "Epoch 35, Step 152, Loss: 0.5428766012191772\n",
            "Epoch 35, Step 153, Loss: 0.48980236053466797\n",
            "Epoch 35, Step 154, Loss: 0.39172330498695374\n",
            "Epoch 35, Step 155, Loss: 0.30060014128685\n",
            "Epoch 35, Step 156, Loss: 0.4174421727657318\n",
            "Epoch 35, Step 157, Loss: 0.3217092752456665\n",
            "Epoch 35, Step 158, Loss: 0.32638686895370483\n",
            "Epoch 35, Step 159, Loss: 0.3306494355201721\n",
            "Epoch 35, Step 160, Loss: 0.41190627217292786\n",
            "Epoch 35, Step 161, Loss: 0.20976051688194275\n",
            "Epoch 35, Step 162, Loss: 0.37833526730537415\n",
            "Epoch 35, Step 163, Loss: 0.2307671457529068\n",
            "Epoch 35, Step 164, Loss: 0.36564934253692627\n",
            "Epoch 35, Step 165, Loss: 0.3491255044937134\n",
            "Epoch 35, Step 166, Loss: 0.42370450496673584\n",
            "Epoch 35, Step 167, Loss: 0.29575732350349426\n",
            "Epoch 35, Step 168, Loss: 0.2875770926475525\n",
            "Epoch 35, Step 169, Loss: 0.24817989766597748\n",
            "Epoch 35, Step 170, Loss: 0.35934337973594666\n",
            "Epoch 35, Step 171, Loss: 0.28418996930122375\n",
            "Epoch 35, Step 172, Loss: 0.36225154995918274\n",
            "Epoch 35, Step 173, Loss: 0.25181424617767334\n",
            "Epoch 35, Step 174, Loss: 0.3500494360923767\n",
            "Epoch 35, Step 175, Loss: 0.2949192523956299\n",
            "Epoch 35, Step 176, Loss: 0.36390823125839233\n",
            "Epoch 35, Step 177, Loss: 0.32783880829811096\n",
            "Epoch 35, Step 178, Loss: 0.35441210865974426\n",
            "Epoch 35, Step 179, Loss: 0.21632122993469238\n",
            "Epoch 35, Step 180, Loss: 0.27744683623313904\n",
            "Epoch 35, Step 181, Loss: 0.3236343562602997\n",
            "Epoch 35, Step 182, Loss: 0.38522231578826904\n",
            "Epoch 35, Step 183, Loss: 0.40593743324279785\n",
            "Epoch 35, Step 184, Loss: 0.37332257628440857\n",
            "Epoch 35, Step 185, Loss: 0.32111042737960815\n",
            "Epoch 35, Step 186, Loss: 0.21293246746063232\n",
            "Epoch 35, Step 187, Loss: 0.2900007367134094\n",
            "Epoch 35, Step 188, Loss: 0.3413722813129425\n",
            "Epoch 35, Step 189, Loss: 0.4330384135246277\n",
            "Epoch 35, Step 190, Loss: 0.29995065927505493\n",
            "Epoch 35, Step 191, Loss: 0.367918998003006\n",
            "Epoch 35, Step 192, Loss: 0.23550449311733246\n",
            "Epoch 35, Step 193, Loss: 0.2884818911552429\n",
            "Epoch 35, Step 194, Loss: 0.419425904750824\n",
            "Epoch 35, Step 195, Loss: 0.35250699520111084\n",
            "Epoch 35, Step 196, Loss: 0.39529237151145935\n",
            "Epoch 35, Step 197, Loss: 0.44716861844062805\n",
            "Epoch 35, Step 198, Loss: 0.3260352909564972\n",
            "Epoch 35, Step 199, Loss: 0.31474679708480835\n",
            "Epoch 35, Step 200, Loss: 0.321942538022995\n",
            "Epoch 35, Step 201, Loss: 0.24079371988773346\n",
            "Epoch 35, Step 202, Loss: 0.39574992656707764\n",
            "Epoch 35, Step 203, Loss: 0.29705309867858887\n",
            "Epoch 35, Step 204, Loss: 0.29239222407341003\n",
            "Epoch 35, Step 205, Loss: 0.31863290071487427\n",
            "Epoch 35, Step 206, Loss: 0.43207672238349915\n",
            "Epoch 35, Step 207, Loss: 0.42907923460006714\n",
            "Epoch 35, Step 208, Loss: 0.36551639437675476\n",
            "Epoch 35, Step 209, Loss: 0.40504568815231323\n",
            "Epoch 35, Step 210, Loss: 0.3036697506904602\n",
            "Epoch 35, Step 211, Loss: 0.23375895619392395\n",
            "Epoch 35, Step 212, Loss: 0.32148292660713196\n",
            "Epoch 35, Step 213, Loss: 0.24023698270320892\n",
            "Epoch 35, Step 214, Loss: 0.3916814625263214\n",
            "Epoch 35, Step 215, Loss: 0.353068470954895\n",
            "Epoch 35, Step 216, Loss: 0.43673670291900635\n",
            "Epoch 35, Step 217, Loss: 0.2547529637813568\n",
            "Epoch 35, Step 218, Loss: 0.36987531185150146\n",
            "Epoch 35, Step 219, Loss: 0.2465449720621109\n",
            "Epoch 35, Step 220, Loss: 0.30921676754951477\n",
            "Epoch 35, Step 221, Loss: 0.5052262544631958\n",
            "Epoch 35, Step 222, Loss: 0.3028853237628937\n",
            "Epoch 35, Step 223, Loss: 0.26074114441871643\n",
            "Epoch 35, Step 224, Loss: 0.500505805015564\n",
            "Epoch 35, Step 225, Loss: 0.227731391787529\n",
            "Epoch 35, Step 226, Loss: 0.3038589656352997\n",
            "Epoch 35, Step 227, Loss: 0.3621339201927185\n",
            "Epoch 35, Step 228, Loss: 0.3632858991622925\n",
            "Epoch 35, Step 229, Loss: 0.3128114640712738\n",
            "Epoch 35, Step 230, Loss: 0.3519851863384247\n",
            "Epoch 35, Step 231, Loss: 0.407477468252182\n",
            "Epoch 35, Step 232, Loss: 0.2471238523721695\n",
            "Epoch 35, Step 233, Loss: 0.3539879620075226\n",
            "Epoch 35, Step 234, Loss: 0.24050508439540863\n",
            "Epoch 35, Step 235, Loss: 0.2826642096042633\n",
            "Epoch 35, Step 236, Loss: 0.38683560490608215\n",
            "Epoch 35, Step 237, Loss: 0.3742433488368988\n",
            "Epoch 35, Step 238, Loss: 0.5446709394454956\n",
            "Epoch 35, Step 239, Loss: 0.4492051303386688\n",
            "Epoch 35, Step 240, Loss: 0.2317582070827484\n",
            "Epoch 35, Step 241, Loss: 0.24166566133499146\n",
            "Epoch 35, Step 242, Loss: 0.3114572763442993\n",
            "Epoch 35, Step 243, Loss: 0.3012044429779053\n",
            "Epoch 35, Step 244, Loss: 0.34809720516204834\n",
            "Epoch 35, Step 245, Loss: 0.4173186421394348\n",
            "Epoch 35, Step 246, Loss: 0.3143485486507416\n",
            "Epoch 35, Step 247, Loss: 0.44152218103408813\n",
            "Epoch 35, Step 248, Loss: 0.1968396008014679\n",
            "Epoch 35, Step 249, Loss: 0.3256012499332428\n",
            "Epoch 35, Step 250, Loss: 0.32697513699531555\n",
            "Epoch 35, Step 251, Loss: 0.4518800377845764\n",
            "Epoch 35, Step 252, Loss: 0.31824126839637756\n",
            "Epoch 35, Step 253, Loss: 0.2331112027168274\n",
            "Epoch 35, Step 254, Loss: 0.3092757761478424\n",
            "Epoch 35, Step 255, Loss: 0.37625744938850403\n",
            "Epoch 35, Step 256, Loss: 0.3301456570625305\n",
            "Epoch 35, Step 257, Loss: 0.3603123426437378\n",
            "Epoch 35, Step 258, Loss: 0.5016108155250549\n",
            "Epoch 35, Step 259, Loss: 0.3678876757621765\n",
            "Epoch 35, Step 260, Loss: 0.269969642162323\n",
            "Epoch 35, Step 261, Loss: 0.42691296339035034\n",
            "Epoch 35, Step 262, Loss: 0.31561368703842163\n",
            "Epoch 35, Step 263, Loss: 0.33474043011665344\n",
            "Epoch 35, Step 264, Loss: 0.30593669414520264\n",
            "Epoch 35, Step 265, Loss: 0.2950480282306671\n",
            "Epoch 35, Step 266, Loss: 0.49010688066482544\n",
            "Epoch 35, Step 267, Loss: 0.4122678339481354\n",
            "Epoch 35, Step 268, Loss: 0.37953051924705505\n",
            "Epoch 35, Step 269, Loss: 0.451072096824646\n",
            "Epoch 35, Step 270, Loss: 0.3239515721797943\n",
            "Epoch 35, Step 271, Loss: 0.5566014647483826\n",
            "Epoch 35, Step 272, Loss: 0.3747028708457947\n",
            "Epoch 35, Step 273, Loss: 0.3650130331516266\n",
            "Epoch 35, Step 274, Loss: 0.2679302394390106\n",
            "Epoch 35, Step 275, Loss: 0.2789402902126312\n",
            "Epoch 35, Step 276, Loss: 0.37734657526016235\n",
            "Epoch 35, Step 277, Loss: 0.36849817633628845\n",
            "Epoch 35, Step 278, Loss: 0.2689378559589386\n",
            "Epoch 35, Step 279, Loss: 0.4262460172176361\n",
            "Epoch 35, Step 280, Loss: 0.362571656703949\n",
            "Epoch 35, Step 281, Loss: 0.507110595703125\n",
            "Epoch 35, Step 282, Loss: 0.4377681016921997\n",
            "Epoch 35, Step 283, Loss: 0.3052119314670563\n",
            "Epoch 35, Step 284, Loss: 0.3716350495815277\n",
            "Epoch 35, Step 285, Loss: 0.3538490831851959\n",
            "Epoch 35, Step 286, Loss: 0.3103421926498413\n",
            "Epoch 35, Step 287, Loss: 0.4347606897354126\n",
            "Epoch 35, Step 288, Loss: 0.25791195034980774\n",
            "Epoch 35, Step 289, Loss: 0.26944249868392944\n",
            "Epoch 35, Step 290, Loss: 0.36604583263397217\n",
            "Epoch 35, Step 291, Loss: 0.33224689960479736\n",
            "Epoch 35, Step 292, Loss: 0.2994760572910309\n",
            "Epoch 35, Step 293, Loss: 0.2874925136566162\n",
            "Epoch 35, Step 294, Loss: 0.37759339809417725\n",
            "Epoch 35, Step 295, Loss: 0.4552922546863556\n",
            "Epoch 35, Step 296, Loss: 0.39045023918151855\n",
            "Epoch 35, Step 297, Loss: 0.3789919912815094\n",
            "Epoch 35, Step 298, Loss: 0.4230717420578003\n",
            "Epoch 35, Step 299, Loss: 0.3355008661746979\n",
            "Epoch 35, Step 300, Loss: 0.31981196999549866\n",
            "Epoch 35, Step 301, Loss: 0.4521567225456238\n",
            "Epoch 35, Step 302, Loss: 0.4161568582057953\n",
            "Epoch 35, Step 303, Loss: 0.35192614793777466\n",
            "Epoch 35, Step 304, Loss: 0.46996748447418213\n",
            "Epoch 35, Step 305, Loss: 0.2637137174606323\n",
            "Epoch 35, Step 306, Loss: 0.42650845646858215\n",
            "Epoch 35, Step 307, Loss: 0.38096141815185547\n",
            "Epoch 35, Step 308, Loss: 0.42332521080970764\n",
            "Epoch 35, Step 309, Loss: 0.47443127632141113\n",
            "Epoch 35, Step 310, Loss: 0.35832691192626953\n",
            "Epoch 35, Step 311, Loss: 0.374847948551178\n",
            "Epoch 35, Step 312, Loss: 0.5431839227676392\n",
            "Epoch 35 end, avg train loss: 0.34149388659495516\n",
            "Epoch 35 end, avg val loss: 0.37885958239247525, accuracy: 87.53%\n",
            "Epoch 36, Step 0, Loss: 0.32222262024879456\n",
            "Epoch 36, Step 1, Loss: 0.4275438189506531\n",
            "Epoch 36, Step 2, Loss: 0.2951461374759674\n",
            "Epoch 36, Step 3, Loss: 0.2836572229862213\n",
            "Epoch 36, Step 4, Loss: 0.29390886425971985\n",
            "Epoch 36, Step 5, Loss: 0.2826075553894043\n",
            "Epoch 36, Step 6, Loss: 0.36135008931159973\n",
            "Epoch 36, Step 7, Loss: 0.3307100534439087\n",
            "Epoch 36, Step 8, Loss: 0.27906283736228943\n",
            "Epoch 36, Step 9, Loss: 0.3796868622303009\n",
            "Epoch 36, Step 10, Loss: 0.3727395534515381\n",
            "Epoch 36, Step 11, Loss: 0.32881635427474976\n",
            "Epoch 36, Step 12, Loss: 0.285842627286911\n",
            "Epoch 36, Step 13, Loss: 0.35971587896347046\n",
            "Epoch 36, Step 14, Loss: 0.2067154198884964\n",
            "Epoch 36, Step 15, Loss: 0.3662587106227875\n",
            "Epoch 36, Step 16, Loss: 0.32899272441864014\n",
            "Epoch 36, Step 17, Loss: 0.33404505252838135\n",
            "Epoch 36, Step 18, Loss: 0.3356056809425354\n",
            "Epoch 36, Step 19, Loss: 0.21879900991916656\n",
            "Epoch 36, Step 20, Loss: 0.32847997546195984\n",
            "Epoch 36, Step 21, Loss: 0.29469236731529236\n",
            "Epoch 36, Step 22, Loss: 0.3773011267185211\n",
            "Epoch 36, Step 23, Loss: 0.2921002507209778\n",
            "Epoch 36, Step 24, Loss: 0.5083904266357422\n",
            "Epoch 36, Step 25, Loss: 0.3119993507862091\n",
            "Epoch 36, Step 26, Loss: 0.3997625410556793\n",
            "Epoch 36, Step 27, Loss: 0.31325438618659973\n",
            "Epoch 36, Step 28, Loss: 0.4159018397331238\n",
            "Epoch 36, Step 29, Loss: 0.2992596924304962\n",
            "Epoch 36, Step 30, Loss: 0.4137839078903198\n",
            "Epoch 36, Step 31, Loss: 0.33090367913246155\n",
            "Epoch 36, Step 32, Loss: 0.2751725912094116\n",
            "Epoch 36, Step 33, Loss: 0.4334513545036316\n",
            "Epoch 36, Step 34, Loss: 0.4010452330112457\n",
            "Epoch 36, Step 35, Loss: 0.24732717871665955\n",
            "Epoch 36, Step 36, Loss: 0.2964822053909302\n",
            "Epoch 36, Step 37, Loss: 0.5432573556900024\n",
            "Epoch 36, Step 38, Loss: 0.3305739760398865\n",
            "Epoch 36, Step 39, Loss: 0.43623048067092896\n",
            "Epoch 36, Step 40, Loss: 0.31849899888038635\n",
            "Epoch 36, Step 41, Loss: 0.3587062954902649\n",
            "Epoch 36, Step 42, Loss: 0.30858877301216125\n",
            "Epoch 36, Step 43, Loss: 0.315324991941452\n",
            "Epoch 36, Step 44, Loss: 0.3367125391960144\n",
            "Epoch 36, Step 45, Loss: 0.35420936346054077\n",
            "Epoch 36, Step 46, Loss: 0.3926640748977661\n",
            "Epoch 36, Step 47, Loss: 0.3453441262245178\n",
            "Epoch 36, Step 48, Loss: 0.38730353116989136\n",
            "Epoch 36, Step 49, Loss: 0.38082271814346313\n",
            "Epoch 36, Step 50, Loss: 0.29837557673454285\n",
            "Epoch 36, Step 51, Loss: 0.3160340487957001\n",
            "Epoch 36, Step 52, Loss: 0.3941316306591034\n",
            "Epoch 36, Step 53, Loss: 0.3085147738456726\n",
            "Epoch 36, Step 54, Loss: 0.30993878841400146\n",
            "Epoch 36, Step 55, Loss: 0.30716022849082947\n",
            "Epoch 36, Step 56, Loss: 0.4604564607143402\n",
            "Epoch 36, Step 57, Loss: 0.3329932689666748\n",
            "Epoch 36, Step 58, Loss: 0.3441382050514221\n",
            "Epoch 36, Step 59, Loss: 0.3522953391075134\n",
            "Epoch 36, Step 60, Loss: 0.20186355710029602\n",
            "Epoch 36, Step 61, Loss: 0.4070471525192261\n",
            "Epoch 36, Step 62, Loss: 0.19285982847213745\n",
            "Epoch 36, Step 63, Loss: 0.4343148171901703\n",
            "Epoch 36, Step 64, Loss: 0.23402039706707\n",
            "Epoch 36, Step 65, Loss: 0.3726000487804413\n",
            "Epoch 36, Step 66, Loss: 0.3093656003475189\n",
            "Epoch 36, Step 67, Loss: 0.2062845677137375\n",
            "Epoch 36, Step 68, Loss: 0.2799648642539978\n",
            "Epoch 36, Step 69, Loss: 0.3093574047088623\n",
            "Epoch 36, Step 70, Loss: 0.41958311200141907\n",
            "Epoch 36, Step 71, Loss: 0.3122350573539734\n",
            "Epoch 36, Step 72, Loss: 0.21333014965057373\n",
            "Epoch 36, Step 73, Loss: 0.22034843266010284\n",
            "Epoch 36, Step 74, Loss: 0.35776036977767944\n",
            "Epoch 36, Step 75, Loss: 0.37339580059051514\n",
            "Epoch 36, Step 76, Loss: 0.2632840871810913\n",
            "Epoch 36, Step 77, Loss: 0.35162732005119324\n",
            "Epoch 36, Step 78, Loss: 0.16175149381160736\n",
            "Epoch 36, Step 79, Loss: 0.3412359058856964\n",
            "Epoch 36, Step 80, Loss: 0.23435229063034058\n",
            "Epoch 36, Step 81, Loss: 0.24448193609714508\n",
            "Epoch 36, Step 82, Loss: 0.33737215399742126\n",
            "Epoch 36, Step 83, Loss: 0.310055136680603\n",
            "Epoch 36, Step 84, Loss: 0.3187350332736969\n",
            "Epoch 36, Step 85, Loss: 0.27122020721435547\n",
            "Epoch 36, Step 86, Loss: 0.31463655829429626\n",
            "Epoch 36, Step 87, Loss: 0.2509985864162445\n",
            "Epoch 36, Step 88, Loss: 0.4232175350189209\n",
            "Epoch 36, Step 89, Loss: 0.3872022032737732\n",
            "Epoch 36, Step 90, Loss: 0.28669995069503784\n",
            "Epoch 36, Step 91, Loss: 0.31169748306274414\n",
            "Epoch 36, Step 92, Loss: 0.32624995708465576\n",
            "Epoch 36, Step 93, Loss: 0.2876531779766083\n",
            "Epoch 36, Step 94, Loss: 0.27195215225219727\n",
            "Epoch 36, Step 95, Loss: 0.21348139643669128\n",
            "Epoch 36, Step 96, Loss: 0.3425845503807068\n",
            "Epoch 36, Step 97, Loss: 0.3515858054161072\n",
            "Epoch 36, Step 98, Loss: 0.2761895954608917\n",
            "Epoch 36, Step 99, Loss: 0.3150864541530609\n",
            "Epoch 36, Step 100, Loss: 0.5272369980812073\n",
            "Epoch 36, Step 101, Loss: 0.3441087603569031\n",
            "Epoch 36, Step 102, Loss: 0.19329124689102173\n",
            "Epoch 36, Step 103, Loss: 0.21365569531917572\n",
            "Epoch 36, Step 104, Loss: 0.38342639803886414\n",
            "Epoch 36, Step 105, Loss: 0.4143916964530945\n",
            "Epoch 36, Step 106, Loss: 0.2554498016834259\n",
            "Epoch 36, Step 107, Loss: 0.2603139877319336\n",
            "Epoch 36, Step 108, Loss: 0.4957684278488159\n",
            "Epoch 36, Step 109, Loss: 0.3864038288593292\n",
            "Epoch 36, Step 110, Loss: 0.3251582980155945\n",
            "Epoch 36, Step 111, Loss: 0.1811918467283249\n",
            "Epoch 36, Step 112, Loss: 0.29144173860549927\n",
            "Epoch 36, Step 113, Loss: 0.30796629190444946\n",
            "Epoch 36, Step 114, Loss: 0.245433509349823\n",
            "Epoch 36, Step 115, Loss: 0.3161681890487671\n",
            "Epoch 36, Step 116, Loss: 0.4186133146286011\n",
            "Epoch 36, Step 117, Loss: 0.2145569771528244\n",
            "Epoch 36, Step 118, Loss: 0.3379732370376587\n",
            "Epoch 36, Step 119, Loss: 0.3333192765712738\n",
            "Epoch 36, Step 120, Loss: 0.254331111907959\n",
            "Epoch 36, Step 121, Loss: 0.29636701941490173\n",
            "Epoch 36, Step 122, Loss: 0.35089749097824097\n",
            "Epoch 36, Step 123, Loss: 0.3269422650337219\n",
            "Epoch 36, Step 124, Loss: 0.289584219455719\n",
            "Epoch 36, Step 125, Loss: 0.3081478476524353\n",
            "Epoch 36, Step 126, Loss: 0.2546257972717285\n",
            "Epoch 36, Step 127, Loss: 0.33166152238845825\n",
            "Epoch 36, Step 128, Loss: 0.19001397490501404\n",
            "Epoch 36, Step 129, Loss: 0.40339571237564087\n",
            "Epoch 36, Step 130, Loss: 0.312691330909729\n",
            "Epoch 36, Step 131, Loss: 0.35435807704925537\n",
            "Epoch 36, Step 132, Loss: 0.30462920665740967\n",
            "Epoch 36, Step 133, Loss: 0.4161428213119507\n",
            "Epoch 36, Step 134, Loss: 0.24732577800750732\n",
            "Epoch 36, Step 135, Loss: 0.31875497102737427\n",
            "Epoch 36, Step 136, Loss: 0.4486062824726105\n",
            "Epoch 36, Step 137, Loss: 0.4604329764842987\n",
            "Epoch 36, Step 138, Loss: 0.24765071272850037\n",
            "Epoch 36, Step 139, Loss: 0.3306316137313843\n",
            "Epoch 36, Step 140, Loss: 0.3746272623538971\n",
            "Epoch 36, Step 141, Loss: 0.4467438757419586\n",
            "Epoch 36, Step 142, Loss: 0.25639835000038147\n",
            "Epoch 36, Step 143, Loss: 0.35491111874580383\n",
            "Epoch 36, Step 144, Loss: 0.4218112826347351\n",
            "Epoch 36, Step 145, Loss: 0.34143784642219543\n",
            "Epoch 36, Step 146, Loss: 0.3077765703201294\n",
            "Epoch 36, Step 147, Loss: 0.24398352205753326\n",
            "Epoch 36, Step 148, Loss: 0.43137237429618835\n",
            "Epoch 36, Step 149, Loss: 0.30712220072746277\n",
            "Epoch 36, Step 150, Loss: 0.372079998254776\n",
            "Epoch 36, Step 151, Loss: 0.4789169728755951\n",
            "Epoch 36, Step 152, Loss: 0.3033881187438965\n",
            "Epoch 36, Step 153, Loss: 0.28983810544013977\n",
            "Epoch 36, Step 154, Loss: 0.35861679911613464\n",
            "Epoch 36, Step 155, Loss: 0.2942263185977936\n",
            "Epoch 36, Step 156, Loss: 0.32416635751724243\n",
            "Epoch 36, Step 157, Loss: 0.25614601373672485\n",
            "Epoch 36, Step 158, Loss: 0.337846040725708\n",
            "Epoch 36, Step 159, Loss: 0.3509460687637329\n",
            "Epoch 36, Step 160, Loss: 0.35244691371917725\n",
            "Epoch 36, Step 161, Loss: 0.39249300956726074\n",
            "Epoch 36, Step 162, Loss: 0.2297041267156601\n",
            "Epoch 36, Step 163, Loss: 0.2972451150417328\n",
            "Epoch 36, Step 164, Loss: 0.3049640357494354\n",
            "Epoch 36, Step 165, Loss: 0.4390140175819397\n",
            "Epoch 36, Step 166, Loss: 0.37106266617774963\n",
            "Epoch 36, Step 167, Loss: 0.3134075105190277\n",
            "Epoch 36, Step 168, Loss: 0.2897743880748749\n",
            "Epoch 36, Step 169, Loss: 0.31897827982902527\n",
            "Epoch 36, Step 170, Loss: 0.42542243003845215\n",
            "Epoch 36, Step 171, Loss: 0.5941933989524841\n",
            "Epoch 36, Step 172, Loss: 0.3488028347492218\n",
            "Epoch 36, Step 173, Loss: 0.296627402305603\n",
            "Epoch 36, Step 174, Loss: 0.3240077495574951\n",
            "Epoch 36, Step 175, Loss: 0.27467209100723267\n",
            "Epoch 36, Step 176, Loss: 0.35956308245658875\n",
            "Epoch 36, Step 177, Loss: 0.33704277873039246\n",
            "Epoch 36, Step 178, Loss: 0.2995586097240448\n",
            "Epoch 36, Step 179, Loss: 0.27654793858528137\n",
            "Epoch 36, Step 180, Loss: 0.3650169372558594\n",
            "Epoch 36, Step 181, Loss: 0.221421480178833\n",
            "Epoch 36, Step 182, Loss: 0.2816849946975708\n",
            "Epoch 36, Step 183, Loss: 0.3281157612800598\n",
            "Epoch 36, Step 184, Loss: 0.2993816137313843\n",
            "Epoch 36, Step 185, Loss: 0.4379873275756836\n",
            "Epoch 36, Step 186, Loss: 0.3156852126121521\n",
            "Epoch 36, Step 187, Loss: 0.33941516280174255\n",
            "Epoch 36, Step 188, Loss: 0.20974820852279663\n",
            "Epoch 36, Step 189, Loss: 0.2851046919822693\n",
            "Epoch 36, Step 190, Loss: 0.425401508808136\n",
            "Epoch 36, Step 191, Loss: 0.2144862860441208\n",
            "Epoch 36, Step 192, Loss: 0.416276752948761\n",
            "Epoch 36, Step 193, Loss: 0.33663907647132874\n",
            "Epoch 36, Step 194, Loss: 0.46894949674606323\n",
            "Epoch 36, Step 195, Loss: 0.4553220570087433\n",
            "Epoch 36, Step 196, Loss: 0.33134347200393677\n",
            "Epoch 36, Step 197, Loss: 0.2507459819316864\n",
            "Epoch 36, Step 198, Loss: 0.3979353606700897\n",
            "Epoch 36, Step 199, Loss: 0.4914782643318176\n",
            "Epoch 36, Step 200, Loss: 0.4193460941314697\n",
            "Epoch 36, Step 201, Loss: 0.3910628855228424\n",
            "Epoch 36, Step 202, Loss: 0.2396191656589508\n",
            "Epoch 36, Step 203, Loss: 0.49478092789649963\n",
            "Epoch 36, Step 204, Loss: 0.2721623480319977\n",
            "Epoch 36, Step 205, Loss: 0.2516673803329468\n",
            "Epoch 36, Step 206, Loss: 0.48357370495796204\n",
            "Epoch 36, Step 207, Loss: 0.35176315903663635\n",
            "Epoch 36, Step 208, Loss: 0.3783307671546936\n",
            "Epoch 36, Step 209, Loss: 0.29439154267311096\n",
            "Epoch 36, Step 210, Loss: 0.3103961646556854\n",
            "Epoch 36, Step 211, Loss: 0.29918670654296875\n",
            "Epoch 36, Step 212, Loss: 0.2738243341445923\n",
            "Epoch 36, Step 213, Loss: 0.26301223039627075\n",
            "Epoch 36, Step 214, Loss: 0.328732430934906\n",
            "Epoch 36, Step 215, Loss: 0.321590781211853\n",
            "Epoch 36, Step 216, Loss: 0.3750416040420532\n",
            "Epoch 36, Step 217, Loss: 0.2580239176750183\n",
            "Epoch 36, Step 218, Loss: 0.24927537143230438\n",
            "Epoch 36, Step 219, Loss: 0.38342103362083435\n",
            "Epoch 36, Step 220, Loss: 0.4592457413673401\n",
            "Epoch 36, Step 221, Loss: 0.3701108396053314\n",
            "Epoch 36, Step 222, Loss: 0.2673455774784088\n",
            "Epoch 36, Step 223, Loss: 0.2709890305995941\n",
            "Epoch 36, Step 224, Loss: 0.32434266805648804\n",
            "Epoch 36, Step 225, Loss: 0.3654612600803375\n",
            "Epoch 36, Step 226, Loss: 0.364026814699173\n",
            "Epoch 36, Step 227, Loss: 0.4188867211341858\n",
            "Epoch 36, Step 228, Loss: 0.2761085629463196\n",
            "Epoch 36, Step 229, Loss: 0.30190372467041016\n",
            "Epoch 36, Step 230, Loss: 0.31452736258506775\n",
            "Epoch 36, Step 231, Loss: 0.30700844526290894\n",
            "Epoch 36, Step 232, Loss: 0.4089440703392029\n",
            "Epoch 36, Step 233, Loss: 0.3345188796520233\n",
            "Epoch 36, Step 234, Loss: 0.32808706164360046\n",
            "Epoch 36, Step 235, Loss: 0.32764631509780884\n",
            "Epoch 36, Step 236, Loss: 0.38937801122665405\n",
            "Epoch 36, Step 237, Loss: 0.28733646869659424\n",
            "Epoch 36, Step 238, Loss: 0.30269259214401245\n",
            "Epoch 36, Step 239, Loss: 0.36802637577056885\n",
            "Epoch 36, Step 240, Loss: 0.34124353528022766\n",
            "Epoch 36, Step 241, Loss: 0.2561066746711731\n",
            "Epoch 36, Step 242, Loss: 0.3650122284889221\n",
            "Epoch 36, Step 243, Loss: 0.45290055871009827\n",
            "Epoch 36, Step 244, Loss: 0.3041580319404602\n",
            "Epoch 36, Step 245, Loss: 0.31805095076560974\n",
            "Epoch 36, Step 246, Loss: 0.3975560665130615\n",
            "Epoch 36, Step 247, Loss: 0.3113495111465454\n",
            "Epoch 36, Step 248, Loss: 0.3483336865901947\n",
            "Epoch 36, Step 249, Loss: 0.1970394253730774\n",
            "Epoch 36, Step 250, Loss: 0.3932145833969116\n",
            "Epoch 36, Step 251, Loss: 0.30204567313194275\n",
            "Epoch 36, Step 252, Loss: 0.34572383761405945\n",
            "Epoch 36, Step 253, Loss: 0.2857121229171753\n",
            "Epoch 36, Step 254, Loss: 0.3605421781539917\n",
            "Epoch 36, Step 255, Loss: 0.459879994392395\n",
            "Epoch 36, Step 256, Loss: 0.3213651478290558\n",
            "Epoch 36, Step 257, Loss: 0.43147698044776917\n",
            "Epoch 36, Step 258, Loss: 0.276073694229126\n",
            "Epoch 36, Step 259, Loss: 0.2855050563812256\n",
            "Epoch 36, Step 260, Loss: 0.2699737250804901\n",
            "Epoch 36, Step 261, Loss: 0.2692772448062897\n",
            "Epoch 36, Step 262, Loss: 0.3126496970653534\n",
            "Epoch 36, Step 263, Loss: 0.510780394077301\n",
            "Epoch 36, Step 264, Loss: 0.3172902464866638\n",
            "Epoch 36, Step 265, Loss: 0.29753628373146057\n",
            "Epoch 36, Step 266, Loss: 0.2476395070552826\n",
            "Epoch 36, Step 267, Loss: 0.24242687225341797\n",
            "Epoch 36, Step 268, Loss: 0.31749284267425537\n",
            "Epoch 36, Step 269, Loss: 0.3471960723400116\n",
            "Epoch 36, Step 270, Loss: 0.25245577096939087\n",
            "Epoch 36, Step 271, Loss: 0.3439558744430542\n",
            "Epoch 36, Step 272, Loss: 0.373614639043808\n",
            "Epoch 36, Step 273, Loss: 0.3091147243976593\n",
            "Epoch 36, Step 274, Loss: 0.34173837304115295\n",
            "Epoch 36, Step 275, Loss: 0.2767021059989929\n",
            "Epoch 36, Step 276, Loss: 0.25116634368896484\n",
            "Epoch 36, Step 277, Loss: 0.4505395293235779\n",
            "Epoch 36, Step 278, Loss: 0.3068595230579376\n",
            "Epoch 36, Step 279, Loss: 0.3977760374546051\n",
            "Epoch 36, Step 280, Loss: 0.4159983992576599\n",
            "Epoch 36, Step 281, Loss: 0.32185885310173035\n",
            "Epoch 36, Step 282, Loss: 0.38330480456352234\n",
            "Epoch 36, Step 283, Loss: 0.3725231885910034\n",
            "Epoch 36, Step 284, Loss: 0.2880629599094391\n",
            "Epoch 36, Step 285, Loss: 0.20775087177753448\n",
            "Epoch 36, Step 286, Loss: 0.23805156350135803\n",
            "Epoch 36, Step 287, Loss: 0.31533023715019226\n",
            "Epoch 36, Step 288, Loss: 0.32649654150009155\n",
            "Epoch 36, Step 289, Loss: 0.350786030292511\n",
            "Epoch 36, Step 290, Loss: 0.35815340280532837\n",
            "Epoch 36, Step 291, Loss: 0.2988824248313904\n",
            "Epoch 36, Step 292, Loss: 0.46826836466789246\n",
            "Epoch 36, Step 293, Loss: 0.2079130858182907\n",
            "Epoch 36, Step 294, Loss: 0.40081021189689636\n",
            "Epoch 36, Step 295, Loss: 0.3617234230041504\n",
            "Epoch 36, Step 296, Loss: 0.33915042877197266\n",
            "Epoch 36, Step 297, Loss: 0.36285141110420227\n",
            "Epoch 36, Step 298, Loss: 0.3681705594062805\n",
            "Epoch 36, Step 299, Loss: 0.29184436798095703\n",
            "Epoch 36, Step 300, Loss: 0.3250443935394287\n",
            "Epoch 36, Step 301, Loss: 0.31026574969291687\n",
            "Epoch 36, Step 302, Loss: 0.3276650309562683\n",
            "Epoch 36, Step 303, Loss: 0.3247431218624115\n",
            "Epoch 36, Step 304, Loss: 0.35188835859298706\n",
            "Epoch 36, Step 305, Loss: 0.35996922850608826\n",
            "Epoch 36, Step 306, Loss: 0.40209686756134033\n",
            "Epoch 36, Step 307, Loss: 0.29915186762809753\n",
            "Epoch 36, Step 308, Loss: 0.23511609435081482\n",
            "Epoch 36, Step 309, Loss: 0.3186335563659668\n",
            "Epoch 36, Step 310, Loss: 0.29211583733558655\n",
            "Epoch 36, Step 311, Loss: 0.5020242929458618\n",
            "Epoch 36, Step 312, Loss: 0.3559962809085846\n",
            "Epoch 36 end, avg train loss: 0.33151336409413396\n",
            "Epoch 36 end, avg val loss: 0.36320345914816554, accuracy: 88.03%\n",
            "Epoch 37, Step 0, Loss: 0.301334410905838\n",
            "Epoch 37, Step 1, Loss: 0.31455981731414795\n",
            "Epoch 37, Step 2, Loss: 0.325361967086792\n",
            "Epoch 37, Step 3, Loss: 0.28488853573799133\n",
            "Epoch 37, Step 4, Loss: 0.2238842099905014\n",
            "Epoch 37, Step 5, Loss: 0.3697546124458313\n",
            "Epoch 37, Step 6, Loss: 0.2616105377674103\n",
            "Epoch 37, Step 7, Loss: 0.4537825882434845\n",
            "Epoch 37, Step 8, Loss: 0.4383825659751892\n",
            "Epoch 37, Step 9, Loss: 0.2534329295158386\n",
            "Epoch 37, Step 10, Loss: 0.2571650445461273\n",
            "Epoch 37, Step 11, Loss: 0.3028643727302551\n",
            "Epoch 37, Step 12, Loss: 0.27085572481155396\n",
            "Epoch 37, Step 13, Loss: 0.3360520601272583\n",
            "Epoch 37, Step 14, Loss: 0.28868088126182556\n",
            "Epoch 37, Step 15, Loss: 0.23704800009727478\n",
            "Epoch 37, Step 16, Loss: 0.400604248046875\n",
            "Epoch 37, Step 17, Loss: 0.30420562624931335\n",
            "Epoch 37, Step 18, Loss: 0.25549209117889404\n",
            "Epoch 37, Step 19, Loss: 0.3156655430793762\n",
            "Epoch 37, Step 20, Loss: 0.32387441396713257\n",
            "Epoch 37, Step 21, Loss: 0.34188857674598694\n",
            "Epoch 37, Step 22, Loss: 0.3576052784919739\n",
            "Epoch 37, Step 23, Loss: 0.4276720881462097\n",
            "Epoch 37, Step 24, Loss: 0.17114116251468658\n",
            "Epoch 37, Step 25, Loss: 0.31829410791397095\n",
            "Epoch 37, Step 26, Loss: 0.2904653549194336\n",
            "Epoch 37, Step 27, Loss: 0.2881227433681488\n",
            "Epoch 37, Step 28, Loss: 0.4132738411426544\n",
            "Epoch 37, Step 29, Loss: 0.36060866713523865\n",
            "Epoch 37, Step 30, Loss: 0.21372820436954498\n",
            "Epoch 37, Step 31, Loss: 0.22936707735061646\n",
            "Epoch 37, Step 32, Loss: 0.20865289866924286\n",
            "Epoch 37, Step 33, Loss: 0.4115656018257141\n",
            "Epoch 37, Step 34, Loss: 0.3343677520751953\n",
            "Epoch 37, Step 35, Loss: 0.4649865925312042\n",
            "Epoch 37, Step 36, Loss: 0.4006959795951843\n",
            "Epoch 37, Step 37, Loss: 0.30339109897613525\n",
            "Epoch 37, Step 38, Loss: 0.20405545830726624\n",
            "Epoch 37, Step 39, Loss: 0.399646133184433\n",
            "Epoch 37, Step 40, Loss: 0.363757848739624\n",
            "Epoch 37, Step 41, Loss: 0.21952693164348602\n",
            "Epoch 37, Step 42, Loss: 0.33347436785697937\n",
            "Epoch 37, Step 43, Loss: 0.2557397484779358\n",
            "Epoch 37, Step 44, Loss: 0.23737096786499023\n",
            "Epoch 37, Step 45, Loss: 0.35593029856681824\n",
            "Epoch 37, Step 46, Loss: 0.21929003298282623\n",
            "Epoch 37, Step 47, Loss: 0.31715577840805054\n",
            "Epoch 37, Step 48, Loss: 0.31651219725608826\n",
            "Epoch 37, Step 49, Loss: 0.2523156404495239\n",
            "Epoch 37, Step 50, Loss: 0.21394506096839905\n",
            "Epoch 37, Step 51, Loss: 0.3290077745914459\n",
            "Epoch 37, Step 52, Loss: 0.411601185798645\n",
            "Epoch 37, Step 53, Loss: 0.3087061941623688\n",
            "Epoch 37, Step 54, Loss: 0.24728995561599731\n",
            "Epoch 37, Step 55, Loss: 0.2618941366672516\n",
            "Epoch 37, Step 56, Loss: 0.3072080612182617\n",
            "Epoch 37, Step 57, Loss: 0.310868501663208\n",
            "Epoch 37, Step 58, Loss: 0.3097153604030609\n",
            "Epoch 37, Step 59, Loss: 0.3941970467567444\n",
            "Epoch 37, Step 60, Loss: 0.3658849895000458\n",
            "Epoch 37, Step 61, Loss: 0.3812650740146637\n",
            "Epoch 37, Step 62, Loss: 0.30526816844940186\n",
            "Epoch 37, Step 63, Loss: 0.14127445220947266\n",
            "Epoch 37, Step 64, Loss: 0.29302793741226196\n",
            "Epoch 37, Step 65, Loss: 0.33723369240760803\n",
            "Epoch 37, Step 66, Loss: 0.3452109694480896\n",
            "Epoch 37, Step 67, Loss: 0.4542452096939087\n",
            "Epoch 37, Step 68, Loss: 0.27642104029655457\n",
            "Epoch 37, Step 69, Loss: 0.22176766395568848\n",
            "Epoch 37, Step 70, Loss: 0.3047747015953064\n",
            "Epoch 37, Step 71, Loss: 0.3949788808822632\n",
            "Epoch 37, Step 72, Loss: 0.284193754196167\n",
            "Epoch 37, Step 73, Loss: 0.4205828309059143\n",
            "Epoch 37, Step 74, Loss: 0.31913360953330994\n",
            "Epoch 37, Step 75, Loss: 0.41939911246299744\n",
            "Epoch 37, Step 76, Loss: 0.22604963183403015\n",
            "Epoch 37, Step 77, Loss: 0.23353153467178345\n",
            "Epoch 37, Step 78, Loss: 0.46928903460502625\n",
            "Epoch 37, Step 79, Loss: 0.24119269847869873\n",
            "Epoch 37, Step 80, Loss: 0.3339119851589203\n",
            "Epoch 37, Step 81, Loss: 0.3616011440753937\n",
            "Epoch 37, Step 82, Loss: 0.44512462615966797\n",
            "Epoch 37, Step 83, Loss: 0.29871857166290283\n",
            "Epoch 37, Step 84, Loss: 0.2627588212490082\n",
            "Epoch 37, Step 85, Loss: 0.3713591992855072\n",
            "Epoch 37, Step 86, Loss: 0.1502494066953659\n",
            "Epoch 37, Step 87, Loss: 0.3433148264884949\n",
            "Epoch 37, Step 88, Loss: 0.36026981472969055\n",
            "Epoch 37, Step 89, Loss: 0.30110061168670654\n",
            "Epoch 37, Step 90, Loss: 0.30930057168006897\n",
            "Epoch 37, Step 91, Loss: 0.3050704002380371\n",
            "Epoch 37, Step 92, Loss: 0.20154698193073273\n",
            "Epoch 37, Step 93, Loss: 0.30085888504981995\n",
            "Epoch 37, Step 94, Loss: 0.4150925576686859\n",
            "Epoch 37, Step 95, Loss: 0.4175615906715393\n",
            "Epoch 37, Step 96, Loss: 0.3524553179740906\n",
            "Epoch 37, Step 97, Loss: 0.32357868552207947\n",
            "Epoch 37, Step 98, Loss: 0.30024489760398865\n",
            "Epoch 37, Step 99, Loss: 0.21975192427635193\n",
            "Epoch 37, Step 100, Loss: 0.3461405336856842\n",
            "Epoch 37, Step 101, Loss: 0.41219279170036316\n",
            "Epoch 37, Step 102, Loss: 0.31417375802993774\n",
            "Epoch 37, Step 103, Loss: 0.27915921807289124\n",
            "Epoch 37, Step 104, Loss: 0.24153342843055725\n",
            "Epoch 37, Step 105, Loss: 0.3241371512413025\n",
            "Epoch 37, Step 106, Loss: 0.29896706342697144\n",
            "Epoch 37, Step 107, Loss: 0.21281497180461884\n",
            "Epoch 37, Step 108, Loss: 0.22280317544937134\n",
            "Epoch 37, Step 109, Loss: 0.35146719217300415\n",
            "Epoch 37, Step 110, Loss: 0.39995077252388\n",
            "Epoch 37, Step 111, Loss: 0.2905023396015167\n",
            "Epoch 37, Step 112, Loss: 0.28619396686553955\n",
            "Epoch 37, Step 113, Loss: 0.3656969666481018\n",
            "Epoch 37, Step 114, Loss: 0.34985193610191345\n",
            "Epoch 37, Step 115, Loss: 0.3191407322883606\n",
            "Epoch 37, Step 116, Loss: 0.26875069737434387\n",
            "Epoch 37, Step 117, Loss: 0.322318971157074\n",
            "Epoch 37, Step 118, Loss: 0.36501067876815796\n",
            "Epoch 37, Step 119, Loss: 0.37733227014541626\n",
            "Epoch 37, Step 120, Loss: 0.34187382459640503\n",
            "Epoch 37, Step 121, Loss: 0.329401433467865\n",
            "Epoch 37, Step 122, Loss: 0.41429373621940613\n",
            "Epoch 37, Step 123, Loss: 0.2927112579345703\n",
            "Epoch 37, Step 124, Loss: 0.32416078448295593\n",
            "Epoch 37, Step 125, Loss: 0.23912851512432098\n",
            "Epoch 37, Step 126, Loss: 0.3286284804344177\n",
            "Epoch 37, Step 127, Loss: 0.2502422630786896\n",
            "Epoch 37, Step 128, Loss: 0.21149390935897827\n",
            "Epoch 37, Step 129, Loss: 0.3239108920097351\n",
            "Epoch 37, Step 130, Loss: 0.24388238787651062\n",
            "Epoch 37, Step 131, Loss: 0.39429670572280884\n",
            "Epoch 37, Step 132, Loss: 0.22667564451694489\n",
            "Epoch 37, Step 133, Loss: 0.396700382232666\n",
            "Epoch 37, Step 134, Loss: 0.3882237672805786\n",
            "Epoch 37, Step 135, Loss: 0.3765353560447693\n",
            "Epoch 37, Step 136, Loss: 0.3355911374092102\n",
            "Epoch 37, Step 137, Loss: 0.32692277431488037\n",
            "Epoch 37, Step 138, Loss: 0.33788445591926575\n",
            "Epoch 37, Step 139, Loss: 0.2014140486717224\n",
            "Epoch 37, Step 140, Loss: 0.33557403087615967\n",
            "Epoch 37, Step 141, Loss: 0.3363836109638214\n",
            "Epoch 37, Step 142, Loss: 0.4275001585483551\n",
            "Epoch 37, Step 143, Loss: 0.3124420642852783\n",
            "Epoch 37, Step 144, Loss: 0.3413039445877075\n",
            "Epoch 37, Step 145, Loss: 0.25230127573013306\n",
            "Epoch 37, Step 146, Loss: 0.3808145523071289\n",
            "Epoch 37, Step 147, Loss: 0.450054407119751\n",
            "Epoch 37, Step 148, Loss: 0.27109020948410034\n",
            "Epoch 37, Step 149, Loss: 0.2959652245044708\n",
            "Epoch 37, Step 150, Loss: 0.28777867555618286\n",
            "Epoch 37, Step 151, Loss: 0.4766095280647278\n",
            "Epoch 37, Step 152, Loss: 0.2690970003604889\n",
            "Epoch 37, Step 153, Loss: 0.3157232105731964\n",
            "Epoch 37, Step 154, Loss: 0.3235059380531311\n",
            "Epoch 37, Step 155, Loss: 0.2923390865325928\n",
            "Epoch 37, Step 156, Loss: 0.3036077618598938\n",
            "Epoch 37, Step 157, Loss: 0.3508719503879547\n",
            "Epoch 37, Step 158, Loss: 0.3389908969402313\n",
            "Epoch 37, Step 159, Loss: 0.32342928647994995\n",
            "Epoch 37, Step 160, Loss: 0.2411103993654251\n",
            "Epoch 37, Step 161, Loss: 0.31890010833740234\n",
            "Epoch 37, Step 162, Loss: 0.2276340276002884\n",
            "Epoch 37, Step 163, Loss: 0.43808913230895996\n",
            "Epoch 37, Step 164, Loss: 0.4549378752708435\n",
            "Epoch 37, Step 165, Loss: 0.3594459891319275\n",
            "Epoch 37, Step 166, Loss: 0.2853851914405823\n",
            "Epoch 37, Step 167, Loss: 0.3210853040218353\n",
            "Epoch 37, Step 168, Loss: 0.37059876322746277\n",
            "Epoch 37, Step 169, Loss: 0.2842101752758026\n",
            "Epoch 37, Step 170, Loss: 0.30315256118774414\n",
            "Epoch 37, Step 171, Loss: 0.3679918646812439\n",
            "Epoch 37, Step 172, Loss: 0.4259492754936218\n",
            "Epoch 37, Step 173, Loss: 0.3499617874622345\n",
            "Epoch 37, Step 174, Loss: 0.3347373306751251\n",
            "Epoch 37, Step 175, Loss: 0.31251877546310425\n",
            "Epoch 37, Step 176, Loss: 0.3245273530483246\n",
            "Epoch 37, Step 177, Loss: 0.28830328583717346\n",
            "Epoch 37, Step 178, Loss: 0.37831300497055054\n",
            "Epoch 37, Step 179, Loss: 0.45176079869270325\n",
            "Epoch 37, Step 180, Loss: 0.38303354382514954\n",
            "Epoch 37, Step 181, Loss: 0.3307802081108093\n",
            "Epoch 37, Step 182, Loss: 0.3657405376434326\n",
            "Epoch 37, Step 183, Loss: 0.3411141335964203\n",
            "Epoch 37, Step 184, Loss: 0.27990174293518066\n",
            "Epoch 37, Step 185, Loss: 0.4421820640563965\n",
            "Epoch 37, Step 186, Loss: 0.3281451165676117\n",
            "Epoch 37, Step 187, Loss: 0.31572213768959045\n",
            "Epoch 37, Step 188, Loss: 0.34920522570610046\n",
            "Epoch 37, Step 189, Loss: 0.4324595034122467\n",
            "Epoch 37, Step 190, Loss: 0.32741978764533997\n",
            "Epoch 37, Step 191, Loss: 0.25738614797592163\n",
            "Epoch 37, Step 192, Loss: 0.29390209913253784\n",
            "Epoch 37, Step 193, Loss: 0.27460378408432007\n",
            "Epoch 37, Step 194, Loss: 0.2202569544315338\n",
            "Epoch 37, Step 195, Loss: 0.48328474164009094\n",
            "Epoch 37, Step 196, Loss: 0.31049883365631104\n",
            "Epoch 37, Step 197, Loss: 0.3843720555305481\n",
            "Epoch 37, Step 198, Loss: 0.21671397984027863\n",
            "Epoch 37, Step 199, Loss: 0.5293614864349365\n",
            "Epoch 37, Step 200, Loss: 0.24527916312217712\n",
            "Epoch 37, Step 201, Loss: 0.3474820554256439\n",
            "Epoch 37, Step 202, Loss: 0.3731458783149719\n",
            "Epoch 37, Step 203, Loss: 0.37970954179763794\n",
            "Epoch 37, Step 204, Loss: 0.32660868763923645\n",
            "Epoch 37, Step 205, Loss: 0.2524384558200836\n",
            "Epoch 37, Step 206, Loss: 0.3143077492713928\n",
            "Epoch 37, Step 207, Loss: 0.3165571093559265\n",
            "Epoch 37, Step 208, Loss: 0.24983766674995422\n",
            "Epoch 37, Step 209, Loss: 0.31697630882263184\n",
            "Epoch 37, Step 210, Loss: 0.34484195709228516\n",
            "Epoch 37, Step 211, Loss: 0.34334850311279297\n",
            "Epoch 37, Step 212, Loss: 0.34906259179115295\n",
            "Epoch 37, Step 213, Loss: 0.3675321936607361\n",
            "Epoch 37, Step 214, Loss: 0.2457708716392517\n",
            "Epoch 37, Step 215, Loss: 0.29623255133628845\n",
            "Epoch 37, Step 216, Loss: 0.24955008924007416\n",
            "Epoch 37, Step 217, Loss: 0.44401687383651733\n",
            "Epoch 37, Step 218, Loss: 0.2325695902109146\n",
            "Epoch 37, Step 219, Loss: 0.34387215971946716\n",
            "Epoch 37, Step 220, Loss: 0.30005449056625366\n",
            "Epoch 37, Step 221, Loss: 0.35465309023857117\n",
            "Epoch 37, Step 222, Loss: 0.2679501175880432\n",
            "Epoch 37, Step 223, Loss: 0.30837151408195496\n",
            "Epoch 37, Step 224, Loss: 0.24582965672016144\n",
            "Epoch 37, Step 225, Loss: 0.34441035985946655\n",
            "Epoch 37, Step 226, Loss: 0.3158835768699646\n",
            "Epoch 37, Step 227, Loss: 0.24863585829734802\n",
            "Epoch 37, Step 228, Loss: 0.29002845287323\n",
            "Epoch 37, Step 229, Loss: 0.3009364902973175\n",
            "Epoch 37, Step 230, Loss: 0.23050031065940857\n",
            "Epoch 37, Step 231, Loss: 0.33147284388542175\n",
            "Epoch 37, Step 232, Loss: 0.31102684140205383\n",
            "Epoch 37, Step 233, Loss: 0.3185323476791382\n",
            "Epoch 37, Step 234, Loss: 0.3380703926086426\n",
            "Epoch 37, Step 235, Loss: 0.24762338399887085\n",
            "Epoch 37, Step 236, Loss: 0.2109488844871521\n",
            "Epoch 37, Step 237, Loss: 0.3977873623371124\n",
            "Epoch 37, Step 238, Loss: 0.5000700354576111\n",
            "Epoch 37, Step 239, Loss: 0.3579834997653961\n",
            "Epoch 37, Step 240, Loss: 0.3310694098472595\n",
            "Epoch 37, Step 241, Loss: 0.3688119649887085\n",
            "Epoch 37, Step 242, Loss: 0.3617139756679535\n",
            "Epoch 37, Step 243, Loss: 0.296798437833786\n",
            "Epoch 37, Step 244, Loss: 0.3181923031806946\n",
            "Epoch 37, Step 245, Loss: 0.2037443071603775\n",
            "Epoch 37, Step 246, Loss: 0.35705694556236267\n",
            "Epoch 37, Step 247, Loss: 0.20290657877922058\n",
            "Epoch 37, Step 248, Loss: 0.3850346803665161\n",
            "Epoch 37, Step 249, Loss: 0.31586480140686035\n",
            "Epoch 37, Step 250, Loss: 0.28491100668907166\n",
            "Epoch 37, Step 251, Loss: 0.26147153973579407\n",
            "Epoch 37, Step 252, Loss: 0.3226550817489624\n",
            "Epoch 37, Step 253, Loss: 0.2023507058620453\n",
            "Epoch 37, Step 254, Loss: 0.36243849992752075\n",
            "Epoch 37, Step 255, Loss: 0.3693316876888275\n",
            "Epoch 37, Step 256, Loss: 0.2993507981300354\n",
            "Epoch 37, Step 257, Loss: 0.27072674036026\n",
            "Epoch 37, Step 258, Loss: 0.3611496090888977\n",
            "Epoch 37, Step 259, Loss: 0.2948809266090393\n",
            "Epoch 37, Step 260, Loss: 0.2991872727870941\n",
            "Epoch 37, Step 261, Loss: 0.36740779876708984\n",
            "Epoch 37, Step 262, Loss: 0.3758429288864136\n",
            "Epoch 37, Step 263, Loss: 0.3447662591934204\n",
            "Epoch 37, Step 264, Loss: 0.31825852394104004\n",
            "Epoch 37, Step 265, Loss: 0.40666696429252625\n",
            "Epoch 37, Step 266, Loss: 0.3816099166870117\n",
            "Epoch 37, Step 267, Loss: 0.3722134828567505\n",
            "Epoch 37, Step 268, Loss: 0.19985288381576538\n",
            "Epoch 37, Step 269, Loss: 0.29911211133003235\n",
            "Epoch 37, Step 270, Loss: 0.38224053382873535\n",
            "Epoch 37, Step 271, Loss: 0.26050758361816406\n",
            "Epoch 37, Step 272, Loss: 0.2852417230606079\n",
            "Epoch 37, Step 273, Loss: 0.3295385539531708\n",
            "Epoch 37, Step 274, Loss: 0.27592283487319946\n",
            "Epoch 37, Step 275, Loss: 0.3719862401485443\n",
            "Epoch 37, Step 276, Loss: 0.3830500543117523\n",
            "Epoch 37, Step 277, Loss: 0.25425922870635986\n",
            "Epoch 37, Step 278, Loss: 0.3892686665058136\n",
            "Epoch 37, Step 279, Loss: 0.31000715494155884\n",
            "Epoch 37, Step 280, Loss: 0.277895450592041\n",
            "Epoch 37, Step 281, Loss: 0.4130207300186157\n",
            "Epoch 37, Step 282, Loss: 0.2530950903892517\n",
            "Epoch 37, Step 283, Loss: 0.3059632480144501\n",
            "Epoch 37, Step 284, Loss: 0.32248687744140625\n",
            "Epoch 37, Step 285, Loss: 0.30320972204208374\n",
            "Epoch 37, Step 286, Loss: 0.2586955726146698\n",
            "Epoch 37, Step 287, Loss: 0.2136172503232956\n",
            "Epoch 37, Step 288, Loss: 0.2865741550922394\n",
            "Epoch 37, Step 289, Loss: 0.3082835376262665\n",
            "Epoch 37, Step 290, Loss: 0.25305885076522827\n",
            "Epoch 37, Step 291, Loss: 0.2624191343784332\n",
            "Epoch 37, Step 292, Loss: 0.3755423426628113\n",
            "Epoch 37, Step 293, Loss: 0.2837020456790924\n",
            "Epoch 37, Step 294, Loss: 0.3688081204891205\n",
            "Epoch 37, Step 295, Loss: 0.3209773898124695\n",
            "Epoch 37, Step 296, Loss: 0.5141623020172119\n",
            "Epoch 37, Step 297, Loss: 0.3319459855556488\n",
            "Epoch 37, Step 298, Loss: 0.2689395546913147\n",
            "Epoch 37, Step 299, Loss: 0.36783161759376526\n",
            "Epoch 37, Step 300, Loss: 0.545921266078949\n",
            "Epoch 37, Step 301, Loss: 0.20702487230300903\n",
            "Epoch 37, Step 302, Loss: 0.32234373688697815\n",
            "Epoch 37, Step 303, Loss: 0.39081743359565735\n",
            "Epoch 37, Step 304, Loss: 0.3288082778453827\n",
            "Epoch 37, Step 305, Loss: 0.30268973112106323\n",
            "Epoch 37, Step 306, Loss: 0.27231359481811523\n",
            "Epoch 37, Step 307, Loss: 0.4587811827659607\n",
            "Epoch 37, Step 308, Loss: 0.44407933950424194\n",
            "Epoch 37, Step 309, Loss: 0.3019828498363495\n",
            "Epoch 37, Step 310, Loss: 0.4118114709854126\n",
            "Epoch 37, Step 311, Loss: 0.349302738904953\n",
            "Epoch 37, Step 312, Loss: 0.5072154402732849\n",
            "Epoch 37 end, avg train loss: 0.3224471345210609\n",
            "Epoch 37 end, avg val loss: 0.3761121757045577, accuracy: 87.82%\n",
            "Epoch 38, Step 0, Loss: 0.3333858847618103\n",
            "Epoch 38, Step 1, Loss: 0.3218497037887573\n",
            "Epoch 38, Step 2, Loss: 0.3603663146495819\n",
            "Epoch 38, Step 3, Loss: 0.39120742678642273\n",
            "Epoch 38, Step 4, Loss: 0.1458735316991806\n",
            "Epoch 38, Step 5, Loss: 0.43473130464553833\n",
            "Epoch 38, Step 6, Loss: 0.3400583267211914\n",
            "Epoch 38, Step 7, Loss: 0.3578373193740845\n",
            "Epoch 38, Step 8, Loss: 0.2916242778301239\n",
            "Epoch 38, Step 9, Loss: 0.24540504813194275\n",
            "Epoch 38, Step 10, Loss: 0.35595089197158813\n",
            "Epoch 38, Step 11, Loss: 0.33260858058929443\n",
            "Epoch 38, Step 12, Loss: 0.2608982026576996\n",
            "Epoch 38, Step 13, Loss: 0.27508214116096497\n",
            "Epoch 38, Step 14, Loss: 0.2836456298828125\n",
            "Epoch 38, Step 15, Loss: 0.33253389596939087\n",
            "Epoch 38, Step 16, Loss: 0.23962727189064026\n",
            "Epoch 38, Step 17, Loss: 0.36618345975875854\n",
            "Epoch 38, Step 18, Loss: 0.26784127950668335\n",
            "Epoch 38, Step 19, Loss: 0.2704947590827942\n",
            "Epoch 38, Step 20, Loss: 0.26556363701820374\n",
            "Epoch 38, Step 21, Loss: 0.3497334420681\n",
            "Epoch 38, Step 22, Loss: 0.34971392154693604\n",
            "Epoch 38, Step 23, Loss: 0.29379573464393616\n",
            "Epoch 38, Step 24, Loss: 0.26649209856987\n",
            "Epoch 38, Step 25, Loss: 0.2993212044239044\n",
            "Epoch 38, Step 26, Loss: 0.35352930426597595\n",
            "Epoch 38, Step 27, Loss: 0.3475806713104248\n",
            "Epoch 38, Step 28, Loss: 0.20846162736415863\n",
            "Epoch 38, Step 29, Loss: 0.282576322555542\n",
            "Epoch 38, Step 30, Loss: 0.32022422552108765\n",
            "Epoch 38, Step 31, Loss: 0.24005822837352753\n",
            "Epoch 38, Step 32, Loss: 0.3460942506790161\n",
            "Epoch 38, Step 33, Loss: 0.27912765741348267\n",
            "Epoch 38, Step 34, Loss: 0.38379937410354614\n",
            "Epoch 38, Step 35, Loss: 0.25904566049575806\n",
            "Epoch 38, Step 36, Loss: 0.18841136991977692\n",
            "Epoch 38, Step 37, Loss: 0.2612038254737854\n",
            "Epoch 38, Step 38, Loss: 0.3109270930290222\n",
            "Epoch 38, Step 39, Loss: 0.27623045444488525\n",
            "Epoch 38, Step 40, Loss: 0.3378619849681854\n",
            "Epoch 38, Step 41, Loss: 0.2540370225906372\n",
            "Epoch 38, Step 42, Loss: 0.3505704700946808\n",
            "Epoch 38, Step 43, Loss: 0.3722285032272339\n",
            "Epoch 38, Step 44, Loss: 0.28872522711753845\n",
            "Epoch 38, Step 45, Loss: 0.31456243991851807\n",
            "Epoch 38, Step 46, Loss: 0.3467395007610321\n",
            "Epoch 38, Step 47, Loss: 0.39949434995651245\n",
            "Epoch 38, Step 48, Loss: 0.3978394865989685\n",
            "Epoch 38, Step 49, Loss: 0.27692151069641113\n",
            "Epoch 38, Step 50, Loss: 0.34383103251457214\n",
            "Epoch 38, Step 51, Loss: 0.2319844514131546\n",
            "Epoch 38, Step 52, Loss: 0.3077833950519562\n",
            "Epoch 38, Step 53, Loss: 0.3039209842681885\n",
            "Epoch 38, Step 54, Loss: 0.2901553213596344\n",
            "Epoch 38, Step 55, Loss: 0.37401044368743896\n",
            "Epoch 38, Step 56, Loss: 0.27152466773986816\n",
            "Epoch 38, Step 57, Loss: 0.2021099328994751\n",
            "Epoch 38, Step 58, Loss: 0.27178478240966797\n",
            "Epoch 38, Step 59, Loss: 0.4158436954021454\n",
            "Epoch 38, Step 60, Loss: 0.2494945377111435\n",
            "Epoch 38, Step 61, Loss: 0.342313289642334\n",
            "Epoch 38, Step 62, Loss: 0.28670933842658997\n",
            "Epoch 38, Step 63, Loss: 0.3448719382286072\n",
            "Epoch 38, Step 64, Loss: 0.3085395395755768\n",
            "Epoch 38, Step 65, Loss: 0.2711697518825531\n",
            "Epoch 38, Step 66, Loss: 0.27419188618659973\n",
            "Epoch 38, Step 67, Loss: 0.39093080163002014\n",
            "Epoch 38, Step 68, Loss: 0.3069220781326294\n",
            "Epoch 38, Step 69, Loss: 0.21379344165325165\n",
            "Epoch 38, Step 70, Loss: 0.31729114055633545\n",
            "Epoch 38, Step 71, Loss: 0.2705745995044708\n",
            "Epoch 38, Step 72, Loss: 0.36348333954811096\n",
            "Epoch 38, Step 73, Loss: 0.3411136269569397\n",
            "Epoch 38, Step 74, Loss: 0.36356908082962036\n",
            "Epoch 38, Step 75, Loss: 0.20183555781841278\n",
            "Epoch 38, Step 76, Loss: 0.32048583030700684\n",
            "Epoch 38, Step 77, Loss: 0.26890408992767334\n",
            "Epoch 38, Step 78, Loss: 0.2677677869796753\n",
            "Epoch 38, Step 79, Loss: 0.3357595205307007\n",
            "Epoch 38, Step 80, Loss: 0.3212258517742157\n",
            "Epoch 38, Step 81, Loss: 0.2189662605524063\n",
            "Epoch 38, Step 82, Loss: 0.2590143084526062\n",
            "Epoch 38, Step 83, Loss: 0.3750941753387451\n",
            "Epoch 38, Step 84, Loss: 0.370900958776474\n",
            "Epoch 38, Step 85, Loss: 0.2947219908237457\n",
            "Epoch 38, Step 86, Loss: 0.26898184418678284\n",
            "Epoch 38, Step 87, Loss: 0.27412715554237366\n",
            "Epoch 38, Step 88, Loss: 0.29654234647750854\n",
            "Epoch 38, Step 89, Loss: 0.5260862708091736\n",
            "Epoch 38, Step 90, Loss: 0.26080071926116943\n",
            "Epoch 38, Step 91, Loss: 0.25341108441352844\n",
            "Epoch 38, Step 92, Loss: 0.25268131494522095\n",
            "Epoch 38, Step 93, Loss: 0.23224852979183197\n",
            "Epoch 38, Step 94, Loss: 0.4075357913970947\n",
            "Epoch 38, Step 95, Loss: 0.29828834533691406\n",
            "Epoch 38, Step 96, Loss: 0.21783195436000824\n",
            "Epoch 38, Step 97, Loss: 0.2081937938928604\n",
            "Epoch 38, Step 98, Loss: 0.2482883781194687\n",
            "Epoch 38, Step 99, Loss: 0.2961563766002655\n",
            "Epoch 38, Step 100, Loss: 0.3418068289756775\n",
            "Epoch 38, Step 101, Loss: 0.35073408484458923\n",
            "Epoch 38, Step 102, Loss: 0.3654753267765045\n",
            "Epoch 38, Step 103, Loss: 0.2867336869239807\n",
            "Epoch 38, Step 104, Loss: 0.3524710536003113\n",
            "Epoch 38, Step 105, Loss: 0.240858256816864\n",
            "Epoch 38, Step 106, Loss: 0.3054965138435364\n",
            "Epoch 38, Step 107, Loss: 0.35527554154396057\n",
            "Epoch 38, Step 108, Loss: 0.35933610796928406\n",
            "Epoch 38, Step 109, Loss: 0.3074786961078644\n",
            "Epoch 38, Step 110, Loss: 0.2682463526725769\n",
            "Epoch 38, Step 111, Loss: 0.41319283843040466\n",
            "Epoch 38, Step 112, Loss: 0.18987534940242767\n",
            "Epoch 38, Step 113, Loss: 0.3473953306674957\n",
            "Epoch 38, Step 114, Loss: 0.3046887516975403\n",
            "Epoch 38, Step 115, Loss: 0.379588782787323\n",
            "Epoch 38, Step 116, Loss: 0.3879236578941345\n",
            "Epoch 38, Step 117, Loss: 0.27900925278663635\n",
            "Epoch 38, Step 118, Loss: 0.3142617642879486\n",
            "Epoch 38, Step 119, Loss: 0.23055410385131836\n",
            "Epoch 38, Step 120, Loss: 0.35280895233154297\n",
            "Epoch 38, Step 121, Loss: 0.2753044068813324\n",
            "Epoch 38, Step 122, Loss: 0.2934003472328186\n",
            "Epoch 38, Step 123, Loss: 0.2541729509830475\n",
            "Epoch 38, Step 124, Loss: 0.2957462966442108\n",
            "Epoch 38, Step 125, Loss: 0.23425763845443726\n",
            "Epoch 38, Step 126, Loss: 0.21885783970355988\n",
            "Epoch 38, Step 127, Loss: 0.3569243550300598\n",
            "Epoch 38, Step 128, Loss: 0.307332843542099\n",
            "Epoch 38, Step 129, Loss: 0.37759584188461304\n",
            "Epoch 38, Step 130, Loss: 0.42651066184043884\n",
            "Epoch 38, Step 131, Loss: 0.24121993780136108\n",
            "Epoch 38, Step 132, Loss: 0.34280925989151\n",
            "Epoch 38, Step 133, Loss: 0.3615955412387848\n",
            "Epoch 38, Step 134, Loss: 0.27559763193130493\n",
            "Epoch 38, Step 135, Loss: 0.2504464089870453\n",
            "Epoch 38, Step 136, Loss: 0.4032599925994873\n",
            "Epoch 38, Step 137, Loss: 0.249134823679924\n",
            "Epoch 38, Step 138, Loss: 0.29519346356391907\n",
            "Epoch 38, Step 139, Loss: 0.18759456276893616\n",
            "Epoch 38, Step 140, Loss: 0.3082900941371918\n",
            "Epoch 38, Step 141, Loss: 0.4265006184577942\n",
            "Epoch 38, Step 142, Loss: 0.3631989359855652\n",
            "Epoch 38, Step 143, Loss: 0.2289978563785553\n",
            "Epoch 38, Step 144, Loss: 0.22831350564956665\n",
            "Epoch 38, Step 145, Loss: 0.33159637451171875\n",
            "Epoch 38, Step 146, Loss: 0.31707948446273804\n",
            "Epoch 38, Step 147, Loss: 0.32363855838775635\n",
            "Epoch 38, Step 148, Loss: 0.21826069056987762\n",
            "Epoch 38, Step 149, Loss: 0.28342118859291077\n",
            "Epoch 38, Step 150, Loss: 0.45463529229164124\n",
            "Epoch 38, Step 151, Loss: 0.32366931438446045\n",
            "Epoch 38, Step 152, Loss: 0.2551092803478241\n",
            "Epoch 38, Step 153, Loss: 0.3189326524734497\n",
            "Epoch 38, Step 154, Loss: 0.2889319956302643\n",
            "Epoch 38, Step 155, Loss: 0.2950569689273834\n",
            "Epoch 38, Step 156, Loss: 0.27255454659461975\n",
            "Epoch 38, Step 157, Loss: 0.3782289922237396\n",
            "Epoch 38, Step 158, Loss: 0.3949023485183716\n",
            "Epoch 38, Step 159, Loss: 0.3646259307861328\n",
            "Epoch 38, Step 160, Loss: 0.22884683310985565\n",
            "Epoch 38, Step 161, Loss: 0.24929384887218475\n",
            "Epoch 38, Step 162, Loss: 0.3763766586780548\n",
            "Epoch 38, Step 163, Loss: 0.42942267656326294\n",
            "Epoch 38, Step 164, Loss: 0.23133812844753265\n",
            "Epoch 38, Step 165, Loss: 0.37221667170524597\n",
            "Epoch 38, Step 166, Loss: 0.27225497364997864\n",
            "Epoch 38, Step 167, Loss: 0.3487432897090912\n",
            "Epoch 38, Step 168, Loss: 0.32463008165359497\n",
            "Epoch 38, Step 169, Loss: 0.22942155599594116\n",
            "Epoch 38, Step 170, Loss: 0.24998220801353455\n",
            "Epoch 38, Step 171, Loss: 0.32172247767448425\n",
            "Epoch 38, Step 172, Loss: 0.2211465984582901\n",
            "Epoch 38, Step 173, Loss: 0.2929573655128479\n",
            "Epoch 38, Step 174, Loss: 0.30104660987854004\n",
            "Epoch 38, Step 175, Loss: 0.24045708775520325\n",
            "Epoch 38, Step 176, Loss: 0.2801782786846161\n",
            "Epoch 38, Step 177, Loss: 0.29813677072525024\n",
            "Epoch 38, Step 178, Loss: 0.3073385953903198\n",
            "Epoch 38, Step 179, Loss: 0.39146187901496887\n",
            "Epoch 38, Step 180, Loss: 0.417035847902298\n",
            "Epoch 38, Step 181, Loss: 0.47737690806388855\n",
            "Epoch 38, Step 182, Loss: 0.2716485857963562\n",
            "Epoch 38, Step 183, Loss: 0.2826465964317322\n",
            "Epoch 38, Step 184, Loss: 0.36940956115722656\n",
            "Epoch 38, Step 185, Loss: 0.27881792187690735\n",
            "Epoch 38, Step 186, Loss: 0.21614879369735718\n",
            "Epoch 38, Step 187, Loss: 0.34587863087654114\n",
            "Epoch 38, Step 188, Loss: 0.39069491624832153\n",
            "Epoch 38, Step 189, Loss: 0.3260324001312256\n",
            "Epoch 38, Step 190, Loss: 0.2643425166606903\n",
            "Epoch 38, Step 191, Loss: 0.3324059247970581\n",
            "Epoch 38, Step 192, Loss: 0.2197062075138092\n",
            "Epoch 38, Step 193, Loss: 0.3396340310573578\n",
            "Epoch 38, Step 194, Loss: 0.2893002927303314\n",
            "Epoch 38, Step 195, Loss: 0.4236937165260315\n",
            "Epoch 38, Step 196, Loss: 0.3918370008468628\n",
            "Epoch 38, Step 197, Loss: 0.41173598170280457\n",
            "Epoch 38, Step 198, Loss: 0.27031031250953674\n",
            "Epoch 38, Step 199, Loss: 0.3728351891040802\n",
            "Epoch 38, Step 200, Loss: 0.3890962302684784\n",
            "Epoch 38, Step 201, Loss: 0.321086049079895\n",
            "Epoch 38, Step 202, Loss: 0.35386624932289124\n",
            "Epoch 38, Step 203, Loss: 0.21266070008277893\n",
            "Epoch 38, Step 204, Loss: 0.3285048007965088\n",
            "Epoch 38, Step 205, Loss: 0.2534860670566559\n",
            "Epoch 38, Step 206, Loss: 0.27220070362091064\n",
            "Epoch 38, Step 207, Loss: 0.2542344331741333\n",
            "Epoch 38, Step 208, Loss: 0.3205600678920746\n",
            "Epoch 38, Step 209, Loss: 0.29812362790107727\n",
            "Epoch 38, Step 210, Loss: 0.16526184976100922\n",
            "Epoch 38, Step 211, Loss: 0.3307374119758606\n",
            "Epoch 38, Step 212, Loss: 0.2873094081878662\n",
            "Epoch 38, Step 213, Loss: 0.323119193315506\n",
            "Epoch 38, Step 214, Loss: 0.3591194748878479\n",
            "Epoch 38, Step 215, Loss: 0.17668938636779785\n",
            "Epoch 38, Step 216, Loss: 0.34810522198677063\n",
            "Epoch 38, Step 217, Loss: 0.35429906845092773\n",
            "Epoch 38, Step 218, Loss: 0.26841190457344055\n",
            "Epoch 38, Step 219, Loss: 0.2654350996017456\n",
            "Epoch 38, Step 220, Loss: 0.31042787432670593\n",
            "Epoch 38, Step 221, Loss: 0.24700669944286346\n",
            "Epoch 38, Step 222, Loss: 0.35778898000717163\n",
            "Epoch 38, Step 223, Loss: 0.2671947479248047\n",
            "Epoch 38, Step 224, Loss: 0.36677810549736023\n",
            "Epoch 38, Step 225, Loss: 0.3591858446598053\n",
            "Epoch 38, Step 226, Loss: 0.2636632025241852\n",
            "Epoch 38, Step 227, Loss: 0.34642040729522705\n",
            "Epoch 38, Step 228, Loss: 0.3392128050327301\n",
            "Epoch 38, Step 229, Loss: 0.30208098888397217\n",
            "Epoch 38, Step 230, Loss: 0.34338000416755676\n",
            "Epoch 38, Step 231, Loss: 0.27169284224510193\n",
            "Epoch 38, Step 232, Loss: 0.3289225101470947\n",
            "Epoch 38, Step 233, Loss: 0.24678432941436768\n",
            "Epoch 38, Step 234, Loss: 0.3453483581542969\n",
            "Epoch 38, Step 235, Loss: 0.3402041494846344\n",
            "Epoch 38, Step 236, Loss: 0.3907359540462494\n",
            "Epoch 38, Step 237, Loss: 0.266907274723053\n",
            "Epoch 38, Step 238, Loss: 0.3101159930229187\n",
            "Epoch 38, Step 239, Loss: 0.2944701313972473\n",
            "Epoch 38, Step 240, Loss: 0.2854578197002411\n",
            "Epoch 38, Step 241, Loss: 0.3145655393600464\n",
            "Epoch 38, Step 242, Loss: 0.2903718054294586\n",
            "Epoch 38, Step 243, Loss: 0.37636908888816833\n",
            "Epoch 38, Step 244, Loss: 0.2823696732521057\n",
            "Epoch 38, Step 245, Loss: 0.2916906177997589\n",
            "Epoch 38, Step 246, Loss: 0.2545442283153534\n",
            "Epoch 38, Step 247, Loss: 0.37052634358406067\n",
            "Epoch 38, Step 248, Loss: 0.2672310471534729\n",
            "Epoch 38, Step 249, Loss: 0.28574490547180176\n",
            "Epoch 38, Step 250, Loss: 0.4307319223880768\n",
            "Epoch 38, Step 251, Loss: 0.3356895446777344\n",
            "Epoch 38, Step 252, Loss: 0.3338780701160431\n",
            "Epoch 38, Step 253, Loss: 0.224299818277359\n",
            "Epoch 38, Step 254, Loss: 0.30950841307640076\n",
            "Epoch 38, Step 255, Loss: 0.3937734365463257\n",
            "Epoch 38, Step 256, Loss: 0.22943182289600372\n",
            "Epoch 38, Step 257, Loss: 0.33619269728660583\n",
            "Epoch 38, Step 258, Loss: 0.33595797419548035\n",
            "Epoch 38, Step 259, Loss: 0.28133827447891235\n",
            "Epoch 38, Step 260, Loss: 0.26395782828330994\n",
            "Epoch 38, Step 261, Loss: 0.3521370589733124\n",
            "Epoch 38, Step 262, Loss: 0.328479140996933\n",
            "Epoch 38, Step 263, Loss: 0.2791215479373932\n",
            "Epoch 38, Step 264, Loss: 0.4697433114051819\n",
            "Epoch 38, Step 265, Loss: 0.25832054018974304\n",
            "Epoch 38, Step 266, Loss: 0.3693811893463135\n",
            "Epoch 38, Step 267, Loss: 0.2959608733654022\n",
            "Epoch 38, Step 268, Loss: 0.3745383024215698\n",
            "Epoch 38, Step 269, Loss: 0.30403587222099304\n",
            "Epoch 38, Step 270, Loss: 0.36323925852775574\n",
            "Epoch 38, Step 271, Loss: 0.4048115909099579\n",
            "Epoch 38, Step 272, Loss: 0.30226242542266846\n",
            "Epoch 38, Step 273, Loss: 0.22148354351520538\n",
            "Epoch 38, Step 274, Loss: 0.33816975355148315\n",
            "Epoch 38, Step 275, Loss: 0.34649938344955444\n",
            "Epoch 38, Step 276, Loss: 0.43300655484199524\n",
            "Epoch 38, Step 277, Loss: 0.3065042793750763\n",
            "Epoch 38, Step 278, Loss: 0.33252227306365967\n",
            "Epoch 38, Step 279, Loss: 0.34558767080307007\n",
            "Epoch 38, Step 280, Loss: 0.19287927448749542\n",
            "Epoch 38, Step 281, Loss: 0.23259775340557098\n",
            "Epoch 38, Step 282, Loss: 0.27704960107803345\n",
            "Epoch 38, Step 283, Loss: 0.2891038954257965\n",
            "Epoch 38, Step 284, Loss: 0.3493294417858124\n",
            "Epoch 38, Step 285, Loss: 0.3555501699447632\n",
            "Epoch 38, Step 286, Loss: 0.41906291246414185\n",
            "Epoch 38, Step 287, Loss: 0.40496039390563965\n",
            "Epoch 38, Step 288, Loss: 0.42272478342056274\n",
            "Epoch 38, Step 289, Loss: 0.2995624542236328\n",
            "Epoch 38, Step 290, Loss: 0.27774956822395325\n",
            "Epoch 38, Step 291, Loss: 0.3339281380176544\n",
            "Epoch 38, Step 292, Loss: 0.24141162633895874\n",
            "Epoch 38, Step 293, Loss: 0.3317386209964752\n",
            "Epoch 38, Step 294, Loss: 0.1987752765417099\n",
            "Epoch 38, Step 295, Loss: 0.3295895457267761\n",
            "Epoch 38, Step 296, Loss: 0.2710559666156769\n",
            "Epoch 38, Step 297, Loss: 0.3260151147842407\n",
            "Epoch 38, Step 298, Loss: 0.31715065240859985\n",
            "Epoch 38, Step 299, Loss: 0.2993674874305725\n",
            "Epoch 38, Step 300, Loss: 0.28051966428756714\n",
            "Epoch 38, Step 301, Loss: 0.375949889421463\n",
            "Epoch 38, Step 302, Loss: 0.340372234582901\n",
            "Epoch 38, Step 303, Loss: 0.4455876648426056\n",
            "Epoch 38, Step 304, Loss: 0.40369510650634766\n",
            "Epoch 38, Step 305, Loss: 0.2592686712741852\n",
            "Epoch 38, Step 306, Loss: 0.23694771528244019\n",
            "Epoch 38, Step 307, Loss: 0.3542453646659851\n",
            "Epoch 38, Step 308, Loss: 0.36690446734428406\n",
            "Epoch 38, Step 309, Loss: 0.33272606134414673\n",
            "Epoch 38, Step 310, Loss: 0.29233410954475403\n",
            "Epoch 38, Step 311, Loss: 0.3560718595981598\n",
            "Epoch 38, Step 312, Loss: 0.20353569090366364\n",
            "Epoch 38 end, avg train loss: 0.3108442253864611\n",
            "Epoch 38 end, avg val loss: 0.39430881093574477, accuracy: 87.20%\n",
            "Epoch 39, Step 0, Loss: 0.3099968433380127\n",
            "Epoch 39, Step 1, Loss: 0.4054291546344757\n",
            "Epoch 39, Step 2, Loss: 0.3126322329044342\n",
            "Epoch 39, Step 3, Loss: 0.37464454770088196\n",
            "Epoch 39, Step 4, Loss: 0.30736255645751953\n",
            "Epoch 39, Step 5, Loss: 0.1945853978395462\n",
            "Epoch 39, Step 6, Loss: 0.3345816433429718\n",
            "Epoch 39, Step 7, Loss: 0.24075263738632202\n",
            "Epoch 39, Step 8, Loss: 0.2358931005001068\n",
            "Epoch 39, Step 9, Loss: 0.29875391721725464\n",
            "Epoch 39, Step 10, Loss: 0.31181660294532776\n",
            "Epoch 39, Step 11, Loss: 0.30688536167144775\n",
            "Epoch 39, Step 12, Loss: 0.3570108115673065\n",
            "Epoch 39, Step 13, Loss: 0.22678157687187195\n",
            "Epoch 39, Step 14, Loss: 0.30259984731674194\n",
            "Epoch 39, Step 15, Loss: 0.28895604610443115\n",
            "Epoch 39, Step 16, Loss: 0.1510835736989975\n",
            "Epoch 39, Step 17, Loss: 0.2934063971042633\n",
            "Epoch 39, Step 18, Loss: 0.457936555147171\n",
            "Epoch 39, Step 19, Loss: 0.2754102349281311\n",
            "Epoch 39, Step 20, Loss: 0.2399301528930664\n",
            "Epoch 39, Step 21, Loss: 0.21315978467464447\n",
            "Epoch 39, Step 22, Loss: 0.23156268894672394\n",
            "Epoch 39, Step 23, Loss: 0.26554927229881287\n",
            "Epoch 39, Step 24, Loss: 0.2883104383945465\n",
            "Epoch 39, Step 25, Loss: 0.2859932780265808\n",
            "Epoch 39, Step 26, Loss: 0.2668052017688751\n",
            "Epoch 39, Step 27, Loss: 0.22786782681941986\n",
            "Epoch 39, Step 28, Loss: 0.27315664291381836\n",
            "Epoch 39, Step 29, Loss: 0.30153489112854004\n",
            "Epoch 39, Step 30, Loss: 0.25587254762649536\n",
            "Epoch 39, Step 31, Loss: 0.33148205280303955\n",
            "Epoch 39, Step 32, Loss: 0.2199055701494217\n",
            "Epoch 39, Step 33, Loss: 0.33974334597587585\n",
            "Epoch 39, Step 34, Loss: 0.3441902995109558\n",
            "Epoch 39, Step 35, Loss: 0.242360919713974\n",
            "Epoch 39, Step 36, Loss: 0.33530473709106445\n",
            "Epoch 39, Step 37, Loss: 0.38444700837135315\n",
            "Epoch 39, Step 38, Loss: 0.3283396363258362\n",
            "Epoch 39, Step 39, Loss: 0.34207212924957275\n",
            "Epoch 39, Step 40, Loss: 0.4007488191127777\n",
            "Epoch 39, Step 41, Loss: 0.3366275429725647\n",
            "Epoch 39, Step 42, Loss: 0.34537947177886963\n",
            "Epoch 39, Step 43, Loss: 0.34345006942749023\n",
            "Epoch 39, Step 44, Loss: 0.25526320934295654\n",
            "Epoch 39, Step 45, Loss: 0.28041157126426697\n",
            "Epoch 39, Step 46, Loss: 0.3515112102031708\n",
            "Epoch 39, Step 47, Loss: 0.2878528833389282\n",
            "Epoch 39, Step 48, Loss: 0.2666560411453247\n",
            "Epoch 39, Step 49, Loss: 0.31913796067237854\n",
            "Epoch 39, Step 50, Loss: 0.2731342017650604\n",
            "Epoch 39, Step 51, Loss: 0.35733935236930847\n",
            "Epoch 39, Step 52, Loss: 0.3245178163051605\n",
            "Epoch 39, Step 53, Loss: 0.3172079920768738\n",
            "Epoch 39, Step 54, Loss: 0.3191463351249695\n",
            "Epoch 39, Step 55, Loss: 0.1751568466424942\n",
            "Epoch 39, Step 56, Loss: 0.28465601801872253\n",
            "Epoch 39, Step 57, Loss: 0.2271747589111328\n",
            "Epoch 39, Step 58, Loss: 0.38713306188583374\n",
            "Epoch 39, Step 59, Loss: 0.3641294240951538\n",
            "Epoch 39, Step 60, Loss: 0.3155784606933594\n",
            "Epoch 39, Step 61, Loss: 0.25821617245674133\n",
            "Epoch 39, Step 62, Loss: 0.32913923263549805\n",
            "Epoch 39, Step 63, Loss: 0.28248849511146545\n",
            "Epoch 39, Step 64, Loss: 0.3790113031864166\n",
            "Epoch 39, Step 65, Loss: 0.36674022674560547\n",
            "Epoch 39, Step 66, Loss: 0.2545366585254669\n",
            "Epoch 39, Step 67, Loss: 0.25858139991760254\n",
            "Epoch 39, Step 68, Loss: 0.2716238796710968\n",
            "Epoch 39, Step 69, Loss: 0.44283387064933777\n",
            "Epoch 39, Step 70, Loss: 0.23726379871368408\n",
            "Epoch 39, Step 71, Loss: 0.3212282955646515\n",
            "Epoch 39, Step 72, Loss: 0.23757819831371307\n",
            "Epoch 39, Step 73, Loss: 0.4108814597129822\n",
            "Epoch 39, Step 74, Loss: 0.4304294288158417\n",
            "Epoch 39, Step 75, Loss: 0.2914949953556061\n",
            "Epoch 39, Step 76, Loss: 0.4060458540916443\n",
            "Epoch 39, Step 77, Loss: 0.25727036595344543\n",
            "Epoch 39, Step 78, Loss: 0.4222598671913147\n",
            "Epoch 39, Step 79, Loss: 0.31032708287239075\n",
            "Epoch 39, Step 80, Loss: 0.3241170644760132\n",
            "Epoch 39, Step 81, Loss: 0.21421922743320465\n",
            "Epoch 39, Step 82, Loss: 0.4185604155063629\n",
            "Epoch 39, Step 83, Loss: 0.347657710313797\n",
            "Epoch 39, Step 84, Loss: 0.2890821099281311\n",
            "Epoch 39, Step 85, Loss: 0.20425578951835632\n",
            "Epoch 39, Step 86, Loss: 0.30335256457328796\n",
            "Epoch 39, Step 87, Loss: 0.27945655584335327\n",
            "Epoch 39, Step 88, Loss: 0.40170058608055115\n",
            "Epoch 39, Step 89, Loss: 0.2601222097873688\n",
            "Epoch 39, Step 90, Loss: 0.3240070939064026\n",
            "Epoch 39, Step 91, Loss: 0.4353504180908203\n",
            "Epoch 39, Step 92, Loss: 0.36558032035827637\n",
            "Epoch 39, Step 93, Loss: 0.37794673442840576\n",
            "Epoch 39, Step 94, Loss: 0.37389522790908813\n",
            "Epoch 39, Step 95, Loss: 0.27241820096969604\n",
            "Epoch 39, Step 96, Loss: 0.42517566680908203\n",
            "Epoch 39, Step 97, Loss: 0.30184030532836914\n",
            "Epoch 39, Step 98, Loss: 0.3356102705001831\n",
            "Epoch 39, Step 99, Loss: 0.34101158380508423\n",
            "Epoch 39, Step 100, Loss: 0.3537052273750305\n",
            "Epoch 39, Step 101, Loss: 0.31805750727653503\n",
            "Epoch 39, Step 102, Loss: 0.3799514174461365\n",
            "Epoch 39, Step 103, Loss: 0.257585346698761\n",
            "Epoch 39, Step 104, Loss: 0.37067675590515137\n",
            "Epoch 39, Step 105, Loss: 0.25317105650901794\n",
            "Epoch 39, Step 106, Loss: 0.2631005048751831\n",
            "Epoch 39, Step 107, Loss: 0.18711338937282562\n",
            "Epoch 39, Step 108, Loss: 0.2426915466785431\n",
            "Epoch 39, Step 109, Loss: 0.2561302185058594\n",
            "Epoch 39, Step 110, Loss: 0.3105950951576233\n",
            "Epoch 39, Step 111, Loss: 0.3648434281349182\n",
            "Epoch 39, Step 112, Loss: 0.38817259669303894\n",
            "Epoch 39, Step 113, Loss: 0.333808571100235\n",
            "Epoch 39, Step 114, Loss: 0.4086540937423706\n",
            "Epoch 39, Step 115, Loss: 0.2243289202451706\n",
            "Epoch 39, Step 116, Loss: 0.32234033942222595\n",
            "Epoch 39, Step 117, Loss: 0.2623804211616516\n",
            "Epoch 39, Step 118, Loss: 0.2565382421016693\n",
            "Epoch 39, Step 119, Loss: 0.3615401089191437\n",
            "Epoch 39, Step 120, Loss: 0.30968156456947327\n",
            "Epoch 39, Step 121, Loss: 0.27844229340553284\n",
            "Epoch 39, Step 122, Loss: 0.3228822350502014\n",
            "Epoch 39, Step 123, Loss: 0.5009138584136963\n",
            "Epoch 39, Step 124, Loss: 0.21485206484794617\n",
            "Epoch 39, Step 125, Loss: 0.28785887360572815\n",
            "Epoch 39, Step 126, Loss: 0.3010506331920624\n",
            "Epoch 39, Step 127, Loss: 0.3398664891719818\n",
            "Epoch 39, Step 128, Loss: 0.24417874217033386\n",
            "Epoch 39, Step 129, Loss: 0.3011261522769928\n",
            "Epoch 39, Step 130, Loss: 0.27451008558273315\n",
            "Epoch 39, Step 131, Loss: 0.33287906646728516\n",
            "Epoch 39, Step 132, Loss: 0.46126943826675415\n",
            "Epoch 39, Step 133, Loss: 0.2701950967311859\n",
            "Epoch 39, Step 134, Loss: 0.1441349983215332\n",
            "Epoch 39, Step 135, Loss: 0.4503543972969055\n",
            "Epoch 39, Step 136, Loss: 0.2648162245750427\n",
            "Epoch 39, Step 137, Loss: 0.2844144105911255\n",
            "Epoch 39, Step 138, Loss: 0.26755577325820923\n",
            "Epoch 39, Step 139, Loss: 0.27348771691322327\n",
            "Epoch 39, Step 140, Loss: 0.3683684170246124\n",
            "Epoch 39, Step 141, Loss: 0.14059647917747498\n",
            "Epoch 39, Step 142, Loss: 0.35076001286506653\n",
            "Epoch 39, Step 143, Loss: 0.24797362089157104\n",
            "Epoch 39, Step 144, Loss: 0.33872702717781067\n",
            "Epoch 39, Step 145, Loss: 0.22514981031417847\n",
            "Epoch 39, Step 146, Loss: 0.34061214327812195\n",
            "Epoch 39, Step 147, Loss: 0.18467789888381958\n",
            "Epoch 39, Step 148, Loss: 0.2888208031654358\n",
            "Epoch 39, Step 149, Loss: 0.28542032837867737\n",
            "Epoch 39, Step 150, Loss: 0.38256359100341797\n",
            "Epoch 39, Step 151, Loss: 0.37930211424827576\n",
            "Epoch 39, Step 152, Loss: 0.27180445194244385\n",
            "Epoch 39, Step 153, Loss: 0.36077162623405457\n",
            "Epoch 39, Step 154, Loss: 0.31831759214401245\n",
            "Epoch 39, Step 155, Loss: 0.23783977329730988\n",
            "Epoch 39, Step 156, Loss: 0.32313135266304016\n",
            "Epoch 39, Step 157, Loss: 0.22935433685779572\n",
            "Epoch 39, Step 158, Loss: 0.32655954360961914\n",
            "Epoch 39, Step 159, Loss: 0.22797787189483643\n",
            "Epoch 39, Step 160, Loss: 0.4059622287750244\n",
            "Epoch 39, Step 161, Loss: 0.3821648955345154\n",
            "Epoch 39, Step 162, Loss: 0.31004777550697327\n",
            "Epoch 39, Step 163, Loss: 0.3781769871711731\n",
            "Epoch 39, Step 164, Loss: 0.19282840192317963\n",
            "Epoch 39, Step 165, Loss: 0.2625955641269684\n",
            "Epoch 39, Step 166, Loss: 0.30004972219467163\n",
            "Epoch 39, Step 167, Loss: 0.30593299865722656\n",
            "Epoch 39, Step 168, Loss: 0.3503868579864502\n",
            "Epoch 39, Step 169, Loss: 0.21854394674301147\n",
            "Epoch 39, Step 170, Loss: 0.24311423301696777\n",
            "Epoch 39, Step 171, Loss: 0.29739412665367126\n",
            "Epoch 39, Step 172, Loss: 0.36167845129966736\n",
            "Epoch 39, Step 173, Loss: 0.3193681836128235\n",
            "Epoch 39, Step 174, Loss: 0.2899620532989502\n",
            "Epoch 39, Step 175, Loss: 0.2903527617454529\n",
            "Epoch 39, Step 176, Loss: 0.2910398244857788\n",
            "Epoch 39, Step 177, Loss: 0.30348294973373413\n",
            "Epoch 39, Step 178, Loss: 0.18376480042934418\n",
            "Epoch 39, Step 179, Loss: 0.2455093413591385\n",
            "Epoch 39, Step 180, Loss: 0.40961527824401855\n",
            "Epoch 39, Step 181, Loss: 0.358841210603714\n",
            "Epoch 39, Step 182, Loss: 0.4142270088195801\n",
            "Epoch 39, Step 183, Loss: 0.34049898386001587\n",
            "Epoch 39, Step 184, Loss: 0.27120906114578247\n",
            "Epoch 39, Step 185, Loss: 0.3627239465713501\n",
            "Epoch 39, Step 186, Loss: 0.3073596656322479\n",
            "Epoch 39, Step 187, Loss: 0.2535257041454315\n",
            "Epoch 39, Step 188, Loss: 0.3126637041568756\n",
            "Epoch 39, Step 189, Loss: 0.2902654707431793\n",
            "Epoch 39, Step 190, Loss: 0.29253464937210083\n",
            "Epoch 39, Step 191, Loss: 0.33142754435539246\n",
            "Epoch 39, Step 192, Loss: 0.24363791942596436\n",
            "Epoch 39, Step 193, Loss: 0.3355049788951874\n",
            "Epoch 39, Step 194, Loss: 0.16586396098136902\n",
            "Epoch 39, Step 195, Loss: 0.2951681315898895\n",
            "Epoch 39, Step 196, Loss: 0.3175106644630432\n",
            "Epoch 39, Step 197, Loss: 0.1557454615831375\n",
            "Epoch 39, Step 198, Loss: 0.3712822496891022\n",
            "Epoch 39, Step 199, Loss: 0.3159075677394867\n",
            "Epoch 39, Step 200, Loss: 0.44544222950935364\n",
            "Epoch 39, Step 201, Loss: 0.35974887013435364\n",
            "Epoch 39, Step 202, Loss: 0.3419942855834961\n",
            "Epoch 39, Step 203, Loss: 0.4902036488056183\n",
            "Epoch 39, Step 204, Loss: 0.261016845703125\n",
            "Epoch 39, Step 205, Loss: 0.2702678442001343\n",
            "Epoch 39, Step 206, Loss: 0.37919145822525024\n",
            "Epoch 39, Step 207, Loss: 0.28446635603904724\n",
            "Epoch 39, Step 208, Loss: 0.37080666422843933\n",
            "Epoch 39, Step 209, Loss: 0.2531335651874542\n",
            "Epoch 39, Step 210, Loss: 0.3485803008079529\n",
            "Epoch 39, Step 211, Loss: 0.43372103571891785\n",
            "Epoch 39, Step 212, Loss: 0.3364067077636719\n",
            "Epoch 39, Step 213, Loss: 0.15759190917015076\n",
            "Epoch 39, Step 214, Loss: 0.32852786779403687\n",
            "Epoch 39, Step 215, Loss: 0.20804843306541443\n",
            "Epoch 39, Step 216, Loss: 0.3576816916465759\n",
            "Epoch 39, Step 217, Loss: 0.33982613682746887\n",
            "Epoch 39, Step 218, Loss: 0.2493932843208313\n",
            "Epoch 39, Step 219, Loss: 0.23687878251075745\n",
            "Epoch 39, Step 220, Loss: 0.2707389295101166\n",
            "Epoch 39, Step 221, Loss: 0.3692907691001892\n",
            "Epoch 39, Step 222, Loss: 0.3215077519416809\n",
            "Epoch 39, Step 223, Loss: 0.4100857675075531\n",
            "Epoch 39, Step 224, Loss: 0.35972851514816284\n",
            "Epoch 39, Step 225, Loss: 0.3045943081378937\n",
            "Epoch 39, Step 226, Loss: 0.38209986686706543\n",
            "Epoch 39, Step 227, Loss: 0.2372850924730301\n",
            "Epoch 39, Step 228, Loss: 0.364851713180542\n",
            "Epoch 39, Step 229, Loss: 0.2563415467739105\n",
            "Epoch 39, Step 230, Loss: 0.5448295474052429\n",
            "Epoch 39, Step 231, Loss: 0.3724353313446045\n",
            "Epoch 39, Step 232, Loss: 0.3028796315193176\n",
            "Epoch 39, Step 233, Loss: 0.2353084683418274\n",
            "Epoch 39, Step 234, Loss: 0.2883327305316925\n",
            "Epoch 39, Step 235, Loss: 0.3253414034843445\n",
            "Epoch 39, Step 236, Loss: 0.3744153380393982\n",
            "Epoch 39, Step 237, Loss: 0.23464763164520264\n",
            "Epoch 39, Step 238, Loss: 0.3948897123336792\n",
            "Epoch 39, Step 239, Loss: 0.3003876507282257\n",
            "Epoch 39, Step 240, Loss: 0.3173134922981262\n",
            "Epoch 39, Step 241, Loss: 0.30740344524383545\n",
            "Epoch 39, Step 242, Loss: 0.30754271149635315\n",
            "Epoch 39, Step 243, Loss: 0.1892814189195633\n",
            "Epoch 39, Step 244, Loss: 0.3309597671031952\n",
            "Epoch 39, Step 245, Loss: 0.4445579946041107\n",
            "Epoch 39, Step 246, Loss: 0.3069011867046356\n",
            "Epoch 39, Step 247, Loss: 0.24331822991371155\n",
            "Epoch 39, Step 248, Loss: 0.3365943133831024\n",
            "Epoch 39, Step 249, Loss: 0.32437705993652344\n",
            "Epoch 39, Step 250, Loss: 0.3687700629234314\n",
            "Epoch 39, Step 251, Loss: 0.3702906370162964\n",
            "Epoch 39, Step 252, Loss: 0.2785223722457886\n",
            "Epoch 39, Step 253, Loss: 0.3449340760707855\n",
            "Epoch 39, Step 254, Loss: 0.25601711869239807\n",
            "Epoch 39, Step 255, Loss: 0.26125943660736084\n",
            "Epoch 39, Step 256, Loss: 0.26973390579223633\n",
            "Epoch 39, Step 257, Loss: 0.3003213703632355\n",
            "Epoch 39, Step 258, Loss: 0.3206179141998291\n",
            "Epoch 39, Step 259, Loss: 0.2827034592628479\n",
            "Epoch 39, Step 260, Loss: 0.3804449737071991\n",
            "Epoch 39, Step 261, Loss: 0.24945636093616486\n",
            "Epoch 39, Step 262, Loss: 0.39534273743629456\n",
            "Epoch 39, Step 263, Loss: 0.4406771659851074\n",
            "Epoch 39, Step 264, Loss: 0.3587965965270996\n",
            "Epoch 39, Step 265, Loss: 0.3565906882286072\n",
            "Epoch 39, Step 266, Loss: 0.22136814892292023\n",
            "Epoch 39, Step 267, Loss: 0.3171025514602661\n",
            "Epoch 39, Step 268, Loss: 0.34717121720314026\n",
            "Epoch 39, Step 269, Loss: 0.4454399347305298\n",
            "Epoch 39, Step 270, Loss: 0.21618202328681946\n",
            "Epoch 39, Step 271, Loss: 0.3708515167236328\n",
            "Epoch 39, Step 272, Loss: 0.2859243154525757\n",
            "Epoch 39, Step 273, Loss: 0.36878305673599243\n",
            "Epoch 39, Step 274, Loss: 0.24202364683151245\n",
            "Epoch 39, Step 275, Loss: 0.25842592120170593\n",
            "Epoch 39, Step 276, Loss: 0.35207363963127136\n",
            "Epoch 39, Step 277, Loss: 0.19547903537750244\n",
            "Epoch 39, Step 278, Loss: 0.3455270528793335\n",
            "Epoch 39, Step 279, Loss: 0.4139285087585449\n",
            "Epoch 39, Step 280, Loss: 0.39874547719955444\n",
            "Epoch 39, Step 281, Loss: 0.2711828052997589\n",
            "Epoch 39, Step 282, Loss: 0.4177253246307373\n",
            "Epoch 39, Step 283, Loss: 0.3724212944507599\n",
            "Epoch 39, Step 284, Loss: 0.16693677008152008\n",
            "Epoch 39, Step 285, Loss: 0.1761608123779297\n",
            "Epoch 39, Step 286, Loss: 0.4195946455001831\n",
            "Epoch 39, Step 287, Loss: 0.2845335900783539\n",
            "Epoch 39, Step 288, Loss: 0.22384031116962433\n",
            "Epoch 39, Step 289, Loss: 0.270795077085495\n",
            "Epoch 39, Step 290, Loss: 0.24332691729068756\n",
            "Epoch 39, Step 291, Loss: 0.31132280826568604\n",
            "Epoch 39, Step 292, Loss: 0.2633364498615265\n",
            "Epoch 39, Step 293, Loss: 0.3394712209701538\n",
            "Epoch 39, Step 294, Loss: 0.3692489266395569\n",
            "Epoch 39, Step 295, Loss: 0.259128600358963\n",
            "Epoch 39, Step 296, Loss: 0.37386852502822876\n",
            "Epoch 39, Step 297, Loss: 0.31864500045776367\n",
            "Epoch 39, Step 298, Loss: 0.3796224296092987\n",
            "Epoch 39, Step 299, Loss: 0.21791885793209076\n",
            "Epoch 39, Step 300, Loss: 0.2506955862045288\n",
            "Epoch 39, Step 301, Loss: 0.33026835322380066\n",
            "Epoch 39, Step 302, Loss: 0.39432549476623535\n",
            "Epoch 39, Step 303, Loss: 0.26976656913757324\n",
            "Epoch 39, Step 304, Loss: 0.30956995487213135\n",
            "Epoch 39, Step 305, Loss: 0.3398458659648895\n",
            "Epoch 39, Step 306, Loss: 0.2691941559314728\n",
            "Epoch 39, Step 307, Loss: 0.3073047995567322\n",
            "Epoch 39, Step 308, Loss: 0.21725596487522125\n",
            "Epoch 39, Step 309, Loss: 0.42031678557395935\n",
            "Epoch 39, Step 310, Loss: 0.3756721019744873\n",
            "Epoch 39, Step 311, Loss: 0.3855694532394409\n",
            "Epoch 39, Step 312, Loss: 0.1828540563583374\n",
            "Epoch 39 end, avg train loss: 0.3102315584310708\n",
            "Epoch 39 end, avg val loss: 0.3627126033924803, accuracy: 88.50%\n",
            "Epoch 40, Step 0, Loss: 0.2506554126739502\n",
            "Epoch 40, Step 1, Loss: 0.31748166680336\n",
            "Epoch 40, Step 2, Loss: 0.280224084854126\n",
            "Epoch 40, Step 3, Loss: 0.21898575127124786\n",
            "Epoch 40, Step 4, Loss: 0.2801319658756256\n",
            "Epoch 40, Step 5, Loss: 0.27453547716140747\n",
            "Epoch 40, Step 6, Loss: 0.36330607533454895\n",
            "Epoch 40, Step 7, Loss: 0.34044700860977173\n",
            "Epoch 40, Step 8, Loss: 0.2611914277076721\n",
            "Epoch 40, Step 9, Loss: 0.19059060513973236\n",
            "Epoch 40, Step 10, Loss: 0.25791075825691223\n",
            "Epoch 40, Step 11, Loss: 0.278891384601593\n",
            "Epoch 40, Step 12, Loss: 0.25895261764526367\n",
            "Epoch 40, Step 13, Loss: 0.24860456585884094\n",
            "Epoch 40, Step 14, Loss: 0.2911163866519928\n",
            "Epoch 40, Step 15, Loss: 0.3642677366733551\n",
            "Epoch 40, Step 16, Loss: 0.3287423849105835\n",
            "Epoch 40, Step 17, Loss: 0.2608979046344757\n",
            "Epoch 40, Step 18, Loss: 0.22294896841049194\n",
            "Epoch 40, Step 19, Loss: 0.33300915360450745\n",
            "Epoch 40, Step 20, Loss: 0.28120195865631104\n",
            "Epoch 40, Step 21, Loss: 0.2168886810541153\n",
            "Epoch 40, Step 22, Loss: 0.2562526762485504\n",
            "Epoch 40, Step 23, Loss: 0.27781611680984497\n",
            "Epoch 40, Step 24, Loss: 0.3521220088005066\n",
            "Epoch 40, Step 25, Loss: 0.2365334928035736\n",
            "Epoch 40, Step 26, Loss: 0.29595279693603516\n",
            "Epoch 40, Step 27, Loss: 0.18175756931304932\n",
            "Epoch 40, Step 28, Loss: 0.29478177428245544\n",
            "Epoch 40, Step 29, Loss: 0.212537482380867\n",
            "Epoch 40, Step 30, Loss: 0.23285844922065735\n",
            "Epoch 40, Step 31, Loss: 0.26486602425575256\n",
            "Epoch 40, Step 32, Loss: 0.31518813967704773\n",
            "Epoch 40, Step 33, Loss: 0.29187479615211487\n",
            "Epoch 40, Step 34, Loss: 0.3315654993057251\n",
            "Epoch 40, Step 35, Loss: 0.32356908917427063\n",
            "Epoch 40, Step 36, Loss: 0.38008737564086914\n",
            "Epoch 40, Step 37, Loss: 0.3460344672203064\n",
            "Epoch 40, Step 38, Loss: 0.3986167907714844\n",
            "Epoch 40, Step 39, Loss: 0.25428271293640137\n",
            "Epoch 40, Step 40, Loss: 0.21496199071407318\n",
            "Epoch 40, Step 41, Loss: 0.19539397954940796\n",
            "Epoch 40, Step 42, Loss: 0.2905467450618744\n",
            "Epoch 40, Step 43, Loss: 0.21422138810157776\n",
            "Epoch 40, Step 44, Loss: 0.3467165529727936\n",
            "Epoch 40, Step 45, Loss: 0.2653008699417114\n",
            "Epoch 40, Step 46, Loss: 0.36890310049057007\n",
            "Epoch 40, Step 47, Loss: 0.31789031624794006\n",
            "Epoch 40, Step 48, Loss: 0.28724661469459534\n",
            "Epoch 40, Step 49, Loss: 0.23449592292308807\n",
            "Epoch 40, Step 50, Loss: 0.4086759090423584\n",
            "Epoch 40, Step 51, Loss: 0.3097343146800995\n",
            "Epoch 40, Step 52, Loss: 0.36552396416664124\n",
            "Epoch 40, Step 53, Loss: 0.22765427827835083\n",
            "Epoch 40, Step 54, Loss: 0.32489311695098877\n",
            "Epoch 40, Step 55, Loss: 0.23203539848327637\n",
            "Epoch 40, Step 56, Loss: 0.26505181193351746\n",
            "Epoch 40, Step 57, Loss: 0.29154765605926514\n",
            "Epoch 40, Step 58, Loss: 0.2545865774154663\n",
            "Epoch 40, Step 59, Loss: 0.36626163125038147\n",
            "Epoch 40, Step 60, Loss: 0.20921342074871063\n",
            "Epoch 40, Step 61, Loss: 0.2727503776550293\n",
            "Epoch 40, Step 62, Loss: 0.3439115285873413\n",
            "Epoch 40, Step 63, Loss: 0.3662565350532532\n",
            "Epoch 40, Step 64, Loss: 0.32548224925994873\n",
            "Epoch 40, Step 65, Loss: 0.38835200667381287\n",
            "Epoch 40, Step 66, Loss: 0.3217999041080475\n",
            "Epoch 40, Step 67, Loss: 0.20245873928070068\n",
            "Epoch 40, Step 68, Loss: 0.23707151412963867\n",
            "Epoch 40, Step 69, Loss: 0.17958059906959534\n",
            "Epoch 40, Step 70, Loss: 0.40433329343795776\n",
            "Epoch 40, Step 71, Loss: 0.3466316759586334\n",
            "Epoch 40, Step 72, Loss: 0.3280961215496063\n",
            "Epoch 40, Step 73, Loss: 0.37415266036987305\n",
            "Epoch 40, Step 74, Loss: 0.1930823028087616\n",
            "Epoch 40, Step 75, Loss: 0.30923986434936523\n",
            "Epoch 40, Step 76, Loss: 0.22780689597129822\n",
            "Epoch 40, Step 77, Loss: 0.3034995496273041\n",
            "Epoch 40, Step 78, Loss: 0.36761996150016785\n",
            "Epoch 40, Step 79, Loss: 0.37539002299308777\n",
            "Epoch 40, Step 80, Loss: 0.26347652077674866\n",
            "Epoch 40, Step 81, Loss: 0.29885098338127136\n",
            "Epoch 40, Step 82, Loss: 0.37209928035736084\n",
            "Epoch 40, Step 83, Loss: 0.30247944593429565\n",
            "Epoch 40, Step 84, Loss: 0.24978622794151306\n",
            "Epoch 40, Step 85, Loss: 0.2674747705459595\n",
            "Epoch 40, Step 86, Loss: 0.33348003029823303\n",
            "Epoch 40, Step 87, Loss: 0.39803168177604675\n",
            "Epoch 40, Step 88, Loss: 0.31149062514305115\n",
            "Epoch 40, Step 89, Loss: 0.28852832317352295\n",
            "Epoch 40, Step 90, Loss: 0.43927907943725586\n",
            "Epoch 40, Step 91, Loss: 0.2980814278125763\n",
            "Epoch 40, Step 92, Loss: 0.44928115606307983\n",
            "Epoch 40, Step 93, Loss: 0.21136708557605743\n",
            "Epoch 40, Step 94, Loss: 0.34701886773109436\n",
            "Epoch 40, Step 95, Loss: 0.29361534118652344\n",
            "Epoch 40, Step 96, Loss: 0.3808118402957916\n",
            "Epoch 40, Step 97, Loss: 0.2651236057281494\n",
            "Epoch 40, Step 98, Loss: 0.2990095019340515\n",
            "Epoch 40, Step 99, Loss: 0.48530298471450806\n",
            "Epoch 40, Step 100, Loss: 0.29664888978004456\n",
            "Epoch 40, Step 101, Loss: 0.35238051414489746\n",
            "Epoch 40, Step 102, Loss: 0.21407058835029602\n",
            "Epoch 40, Step 103, Loss: 0.2508787214756012\n",
            "Epoch 40, Step 104, Loss: 0.36898693442344666\n",
            "Epoch 40, Step 105, Loss: 0.337929368019104\n",
            "Epoch 40, Step 106, Loss: 0.31946077942848206\n",
            "Epoch 40, Step 107, Loss: 0.4835616648197174\n",
            "Epoch 40, Step 108, Loss: 0.3649939000606537\n",
            "Epoch 40, Step 109, Loss: 0.3489264249801636\n",
            "Epoch 40, Step 110, Loss: 0.28970229625701904\n",
            "Epoch 40, Step 111, Loss: 0.3601648211479187\n",
            "Epoch 40, Step 112, Loss: 0.29819080233573914\n",
            "Epoch 40, Step 113, Loss: 0.24888530373573303\n",
            "Epoch 40, Step 114, Loss: 0.23968671262264252\n",
            "Epoch 40, Step 115, Loss: 0.19602927565574646\n",
            "Epoch 40, Step 116, Loss: 0.3238634467124939\n",
            "Epoch 40, Step 117, Loss: 0.25196120142936707\n",
            "Epoch 40, Step 118, Loss: 0.3639155924320221\n",
            "Epoch 40, Step 119, Loss: 0.2965872287750244\n",
            "Epoch 40, Step 120, Loss: 0.25385352969169617\n",
            "Epoch 40, Step 121, Loss: 0.37308546900749207\n",
            "Epoch 40, Step 122, Loss: 0.344316691160202\n",
            "Epoch 40, Step 123, Loss: 0.28329598903656006\n",
            "Epoch 40, Step 124, Loss: 0.28121837973594666\n",
            "Epoch 40, Step 125, Loss: 0.2882521450519562\n",
            "Epoch 40, Step 126, Loss: 0.36695340275764465\n",
            "Epoch 40, Step 127, Loss: 0.3224211633205414\n",
            "Epoch 40, Step 128, Loss: 0.2995296120643616\n",
            "Epoch 40, Step 129, Loss: 0.21681798994541168\n",
            "Epoch 40, Step 130, Loss: 0.3025325834751129\n",
            "Epoch 40, Step 131, Loss: 0.31475046277046204\n",
            "Epoch 40, Step 132, Loss: 0.3016285300254822\n",
            "Epoch 40, Step 133, Loss: 0.3392718732357025\n",
            "Epoch 40, Step 134, Loss: 0.28581252694129944\n",
            "Epoch 40, Step 135, Loss: 0.3097030818462372\n",
            "Epoch 40, Step 136, Loss: 0.282349169254303\n",
            "Epoch 40, Step 137, Loss: 0.317862331867218\n",
            "Epoch 40, Step 138, Loss: 0.33791473507881165\n",
            "Epoch 40, Step 139, Loss: 0.2799167335033417\n",
            "Epoch 40, Step 140, Loss: 0.30756500363349915\n",
            "Epoch 40, Step 141, Loss: 0.33343833684921265\n",
            "Epoch 40, Step 142, Loss: 0.27327990531921387\n",
            "Epoch 40, Step 143, Loss: 0.33261197805404663\n",
            "Epoch 40, Step 144, Loss: 0.30872222781181335\n",
            "Epoch 40, Step 145, Loss: 0.40933874249458313\n",
            "Epoch 40, Step 146, Loss: 0.2899373769760132\n",
            "Epoch 40, Step 147, Loss: 0.3074139952659607\n",
            "Epoch 40, Step 148, Loss: 0.29554012417793274\n",
            "Epoch 40, Step 149, Loss: 0.3125230669975281\n",
            "Epoch 40, Step 150, Loss: 0.38301247358322144\n",
            "Epoch 40, Step 151, Loss: 0.3525979816913605\n",
            "Epoch 40, Step 152, Loss: 0.18621887266635895\n",
            "Epoch 40, Step 153, Loss: 0.2345353066921234\n",
            "Epoch 40, Step 154, Loss: 0.3973037600517273\n",
            "Epoch 40, Step 155, Loss: 0.24226988852024078\n",
            "Epoch 40, Step 156, Loss: 0.37229353189468384\n",
            "Epoch 40, Step 157, Loss: 0.36641058325767517\n",
            "Epoch 40, Step 158, Loss: 0.34508216381073\n",
            "Epoch 40, Step 159, Loss: 0.24009937047958374\n",
            "Epoch 40, Step 160, Loss: 0.3772449791431427\n",
            "Epoch 40, Step 161, Loss: 0.3191332221031189\n",
            "Epoch 40, Step 162, Loss: 0.44127410650253296\n",
            "Epoch 40, Step 163, Loss: 0.26782694458961487\n",
            "Epoch 40, Step 164, Loss: 0.23467792570590973\n",
            "Epoch 40, Step 165, Loss: 0.3419293463230133\n",
            "Epoch 40, Step 166, Loss: 0.3062594532966614\n",
            "Epoch 40, Step 167, Loss: 0.2415512204170227\n",
            "Epoch 40, Step 168, Loss: 0.25233858823776245\n",
            "Epoch 40, Step 169, Loss: 0.32862621545791626\n",
            "Epoch 40, Step 170, Loss: 0.33335351943969727\n",
            "Epoch 40, Step 171, Loss: 0.2873470187187195\n",
            "Epoch 40, Step 172, Loss: 0.30534088611602783\n",
            "Epoch 40, Step 173, Loss: 0.34614798426628113\n",
            "Epoch 40, Step 174, Loss: 0.4028782248497009\n",
            "Epoch 40, Step 175, Loss: 0.21678803861141205\n",
            "Epoch 40, Step 176, Loss: 0.4161686301231384\n",
            "Epoch 40, Step 177, Loss: 0.3679690659046173\n",
            "Epoch 40, Step 178, Loss: 0.5184134244918823\n",
            "Epoch 40, Step 179, Loss: 0.32832327485084534\n",
            "Epoch 40, Step 180, Loss: 0.29329490661621094\n",
            "Epoch 40, Step 181, Loss: 0.27871665358543396\n",
            "Epoch 40, Step 182, Loss: 0.30203914642333984\n",
            "Epoch 40, Step 183, Loss: 0.22086074948310852\n",
            "Epoch 40, Step 184, Loss: 0.31436026096343994\n",
            "Epoch 40, Step 185, Loss: 0.2130444198846817\n",
            "Epoch 40, Step 186, Loss: 0.31934863328933716\n",
            "Epoch 40, Step 187, Loss: 0.32784950733184814\n",
            "Epoch 40, Step 188, Loss: 0.264906108379364\n",
            "Epoch 40, Step 189, Loss: 0.29354530572891235\n",
            "Epoch 40, Step 190, Loss: 0.4604111909866333\n",
            "Epoch 40, Step 191, Loss: 0.4087480902671814\n",
            "Epoch 40, Step 192, Loss: 0.26772403717041016\n",
            "Epoch 40, Step 193, Loss: 0.2842760980129242\n",
            "Epoch 40, Step 194, Loss: 0.3142082989215851\n",
            "Epoch 40, Step 195, Loss: 0.264542818069458\n",
            "Epoch 40, Step 196, Loss: 0.3976864218711853\n",
            "Epoch 40, Step 197, Loss: 0.31174197793006897\n",
            "Epoch 40, Step 198, Loss: 0.4179019331932068\n",
            "Epoch 40, Step 199, Loss: 0.3075658977031708\n",
            "Epoch 40, Step 200, Loss: 0.30276623368263245\n",
            "Epoch 40, Step 201, Loss: 0.1836697906255722\n",
            "Epoch 40, Step 202, Loss: 0.31571510434150696\n",
            "Epoch 40, Step 203, Loss: 0.3585171699523926\n",
            "Epoch 40, Step 204, Loss: 0.46127042174339294\n",
            "Epoch 40, Step 205, Loss: 0.2514646649360657\n",
            "Epoch 40, Step 206, Loss: 0.3802943825721741\n",
            "Epoch 40, Step 207, Loss: 0.2932412326335907\n",
            "Epoch 40, Step 208, Loss: 0.3403699994087219\n",
            "Epoch 40, Step 209, Loss: 0.3232363760471344\n",
            "Epoch 40, Step 210, Loss: 0.3174981474876404\n",
            "Epoch 40, Step 211, Loss: 0.3820232152938843\n",
            "Epoch 40, Step 212, Loss: 0.38728293776512146\n",
            "Epoch 40, Step 213, Loss: 0.3517152965068817\n",
            "Epoch 40, Step 214, Loss: 0.31843626499176025\n",
            "Epoch 40, Step 215, Loss: 0.27527472376823425\n",
            "Epoch 40, Step 216, Loss: 0.203738272190094\n",
            "Epoch 40, Step 217, Loss: 0.47804558277130127\n",
            "Epoch 40, Step 218, Loss: 0.37954920530319214\n",
            "Epoch 40, Step 219, Loss: 0.3806150555610657\n",
            "Epoch 40, Step 220, Loss: 0.45896217226982117\n",
            "Epoch 40, Step 221, Loss: 0.2867051362991333\n",
            "Epoch 40, Step 222, Loss: 0.20957137644290924\n",
            "Epoch 40, Step 223, Loss: 0.24299019575119019\n",
            "Epoch 40, Step 224, Loss: 0.29256874322891235\n",
            "Epoch 40, Step 225, Loss: 0.24566134810447693\n",
            "Epoch 40, Step 226, Loss: 0.28828081488609314\n",
            "Epoch 40, Step 227, Loss: 0.2636912167072296\n",
            "Epoch 40, Step 228, Loss: 0.33724480867385864\n",
            "Epoch 40, Step 229, Loss: 0.23391249775886536\n",
            "Epoch 40, Step 230, Loss: 0.4675277769565582\n",
            "Epoch 40, Step 231, Loss: 0.27114003896713257\n",
            "Epoch 40, Step 232, Loss: 0.3260188698768616\n",
            "Epoch 40, Step 233, Loss: 0.2334827184677124\n",
            "Epoch 40, Step 234, Loss: 0.3290300667285919\n",
            "Epoch 40, Step 235, Loss: 0.3057650327682495\n",
            "Epoch 40, Step 236, Loss: 0.38569873571395874\n",
            "Epoch 40, Step 237, Loss: 0.2834312319755554\n",
            "Epoch 40, Step 238, Loss: 0.3756164014339447\n",
            "Epoch 40, Step 239, Loss: 0.24437227845191956\n",
            "Epoch 40, Step 240, Loss: 0.20013593137264252\n",
            "Epoch 40, Step 241, Loss: 0.41943123936653137\n",
            "Epoch 40, Step 242, Loss: 0.4113197326660156\n",
            "Epoch 40, Step 243, Loss: 0.22954246401786804\n",
            "Epoch 40, Step 244, Loss: 0.2700473964214325\n",
            "Epoch 40, Step 245, Loss: 0.42836788296699524\n",
            "Epoch 40, Step 246, Loss: 0.39086705446243286\n",
            "Epoch 40, Step 247, Loss: 0.22059988975524902\n",
            "Epoch 40, Step 248, Loss: 0.20412366092205048\n",
            "Epoch 40, Step 249, Loss: 0.1846664994955063\n",
            "Epoch 40, Step 250, Loss: 0.2792928218841553\n",
            "Epoch 40, Step 251, Loss: 0.26091867685317993\n",
            "Epoch 40, Step 252, Loss: 0.29788097739219666\n",
            "Epoch 40, Step 253, Loss: 0.35842981934547424\n",
            "Epoch 40, Step 254, Loss: 0.30646976828575134\n",
            "Epoch 40, Step 255, Loss: 0.3283274471759796\n",
            "Epoch 40, Step 256, Loss: 0.3032003939151764\n",
            "Epoch 40, Step 257, Loss: 0.24208536744117737\n",
            "Epoch 40, Step 258, Loss: 0.28418779373168945\n",
            "Epoch 40, Step 259, Loss: 0.30512672662734985\n",
            "Epoch 40, Step 260, Loss: 0.21423658728599548\n",
            "Epoch 40, Step 261, Loss: 0.2317420393228531\n",
            "Epoch 40, Step 262, Loss: 0.20246797800064087\n",
            "Epoch 40, Step 263, Loss: 0.3247847855091095\n",
            "Epoch 40, Step 264, Loss: 0.24596743285655975\n",
            "Epoch 40, Step 265, Loss: 0.39815476536750793\n",
            "Epoch 40, Step 266, Loss: 0.36554914712905884\n",
            "Epoch 40, Step 267, Loss: 0.36584600806236267\n",
            "Epoch 40, Step 268, Loss: 0.32863762974739075\n",
            "Epoch 40, Step 269, Loss: 0.24857039749622345\n",
            "Epoch 40, Step 270, Loss: 0.17380709946155548\n",
            "Epoch 40, Step 271, Loss: 0.2233663648366928\n",
            "Epoch 40, Step 272, Loss: 0.28774523735046387\n",
            "Epoch 40, Step 273, Loss: 0.3865254521369934\n",
            "Epoch 40, Step 274, Loss: 0.39378222823143005\n",
            "Epoch 40, Step 275, Loss: 0.2979196012020111\n",
            "Epoch 40, Step 276, Loss: 0.3452676832675934\n",
            "Epoch 40, Step 277, Loss: 0.27518993616104126\n",
            "Epoch 40, Step 278, Loss: 0.25094762444496155\n",
            "Epoch 40, Step 279, Loss: 0.2976348400115967\n",
            "Epoch 40, Step 280, Loss: 0.3280373513698578\n",
            "Epoch 40, Step 281, Loss: 0.26628267765045166\n",
            "Epoch 40, Step 282, Loss: 0.2656462490558624\n",
            "Epoch 40, Step 283, Loss: 0.40924426913261414\n",
            "Epoch 40, Step 284, Loss: 0.21473132073879242\n",
            "Epoch 40, Step 285, Loss: 0.2947395443916321\n",
            "Epoch 40, Step 286, Loss: 0.46370819211006165\n",
            "Epoch 40, Step 287, Loss: 0.28003185987472534\n",
            "Epoch 40, Step 288, Loss: 0.22070997953414917\n",
            "Epoch 40, Step 289, Loss: 0.3242465555667877\n",
            "Epoch 40, Step 290, Loss: 0.2622014582157135\n",
            "Epoch 40, Step 291, Loss: 0.23297207057476044\n",
            "Epoch 40, Step 292, Loss: 0.23862257599830627\n",
            "Epoch 40, Step 293, Loss: 0.4357706308364868\n",
            "Epoch 40, Step 294, Loss: 0.26961371302604675\n",
            "Epoch 40, Step 295, Loss: 0.3188304901123047\n",
            "Epoch 40, Step 296, Loss: 0.3191443383693695\n",
            "Epoch 40, Step 297, Loss: 0.26460766792297363\n",
            "Epoch 40, Step 298, Loss: 0.3927255868911743\n",
            "Epoch 40, Step 299, Loss: 0.3420019745826721\n",
            "Epoch 40, Step 300, Loss: 0.3382849395275116\n",
            "Epoch 40, Step 301, Loss: 0.25874388217926025\n",
            "Epoch 40, Step 302, Loss: 0.40827706456184387\n",
            "Epoch 40, Step 303, Loss: 0.3149798810482025\n",
            "Epoch 40, Step 304, Loss: 0.31619301438331604\n",
            "Epoch 40, Step 305, Loss: 0.3469681739807129\n",
            "Epoch 40, Step 306, Loss: 0.27524611353874207\n",
            "Epoch 40, Step 307, Loss: 0.28811973333358765\n",
            "Epoch 40, Step 308, Loss: 0.26903653144836426\n",
            "Epoch 40, Step 309, Loss: 0.21313989162445068\n",
            "Epoch 40, Step 310, Loss: 0.2716867923736572\n",
            "Epoch 40, Step 311, Loss: 0.30997562408447266\n",
            "Epoch 40, Step 312, Loss: 0.3656257390975952\n",
            "Epoch 40 end, avg train loss: 0.30653423408921154\n",
            "Epoch 40 end, avg val loss: 0.373139320106446, accuracy: 88.05%\n",
            "Epoch 41, Step 0, Loss: 0.3268231749534607\n",
            "Epoch 41, Step 1, Loss: 0.3015070855617523\n",
            "Epoch 41, Step 2, Loss: 0.34759581089019775\n",
            "Epoch 41, Step 3, Loss: 0.35840940475463867\n",
            "Epoch 41, Step 4, Loss: 0.3095833659172058\n",
            "Epoch 41, Step 5, Loss: 0.29934263229370117\n",
            "Epoch 41, Step 6, Loss: 0.26376402378082275\n",
            "Epoch 41, Step 7, Loss: 0.2666732370853424\n",
            "Epoch 41, Step 8, Loss: 0.16707301139831543\n",
            "Epoch 41, Step 9, Loss: 0.26495277881622314\n",
            "Epoch 41, Step 10, Loss: 0.30014440417289734\n",
            "Epoch 41, Step 11, Loss: 0.2016131579875946\n",
            "Epoch 41, Step 12, Loss: 0.3486700654029846\n",
            "Epoch 41, Step 13, Loss: 0.27577415108680725\n",
            "Epoch 41, Step 14, Loss: 0.25454023480415344\n",
            "Epoch 41, Step 15, Loss: 0.39816486835479736\n",
            "Epoch 41, Step 16, Loss: 0.2716258764266968\n",
            "Epoch 41, Step 17, Loss: 0.38999679684638977\n",
            "Epoch 41, Step 18, Loss: 0.3286384344100952\n",
            "Epoch 41, Step 19, Loss: 0.24527211487293243\n",
            "Epoch 41, Step 20, Loss: 0.30677568912506104\n",
            "Epoch 41, Step 21, Loss: 0.19139617681503296\n",
            "Epoch 41, Step 22, Loss: 0.2877489924430847\n",
            "Epoch 41, Step 23, Loss: 0.29149436950683594\n",
            "Epoch 41, Step 24, Loss: 0.4302382469177246\n",
            "Epoch 41, Step 25, Loss: 0.22363057732582092\n",
            "Epoch 41, Step 26, Loss: 0.2506372034549713\n",
            "Epoch 41, Step 27, Loss: 0.28377145528793335\n",
            "Epoch 41, Step 28, Loss: 0.21406333148479462\n",
            "Epoch 41, Step 29, Loss: 0.21068011224269867\n",
            "Epoch 41, Step 30, Loss: 0.30893900990486145\n",
            "Epoch 41, Step 31, Loss: 0.16957135498523712\n",
            "Epoch 41, Step 32, Loss: 0.20479847490787506\n",
            "Epoch 41, Step 33, Loss: 0.3590438663959503\n",
            "Epoch 41, Step 34, Loss: 0.24753300845623016\n",
            "Epoch 41, Step 35, Loss: 0.15870879590511322\n",
            "Epoch 41, Step 36, Loss: 0.31490010023117065\n",
            "Epoch 41, Step 37, Loss: 0.2845715582370758\n",
            "Epoch 41, Step 38, Loss: 0.22571872174739838\n",
            "Epoch 41, Step 39, Loss: 0.33834171295166016\n",
            "Epoch 41, Step 40, Loss: 0.31329503655433655\n",
            "Epoch 41, Step 41, Loss: 0.2692985534667969\n",
            "Epoch 41, Step 42, Loss: 0.3451194763183594\n",
            "Epoch 41, Step 43, Loss: 0.32348912954330444\n",
            "Epoch 41, Step 44, Loss: 0.32955503463745117\n",
            "Epoch 41, Step 45, Loss: 0.2614113390445709\n",
            "Epoch 41, Step 46, Loss: 0.3066462576389313\n",
            "Epoch 41, Step 47, Loss: 0.23034700751304626\n",
            "Epoch 41, Step 48, Loss: 0.23436033725738525\n",
            "Epoch 41, Step 49, Loss: 0.2849826216697693\n",
            "Epoch 41, Step 50, Loss: 0.3296060264110565\n",
            "Epoch 41, Step 51, Loss: 0.17163828015327454\n",
            "Epoch 41, Step 52, Loss: 0.28614550828933716\n",
            "Epoch 41, Step 53, Loss: 0.3009348511695862\n",
            "Epoch 41, Step 54, Loss: 0.26234129071235657\n",
            "Epoch 41, Step 55, Loss: 0.20863935351371765\n",
            "Epoch 41, Step 56, Loss: 0.2528015673160553\n",
            "Epoch 41, Step 57, Loss: 0.2876199185848236\n",
            "Epoch 41, Step 58, Loss: 0.2515959143638611\n",
            "Epoch 41, Step 59, Loss: 0.24697500467300415\n",
            "Epoch 41, Step 60, Loss: 0.34546196460723877\n",
            "Epoch 41, Step 61, Loss: 0.3764271140098572\n",
            "Epoch 41, Step 62, Loss: 0.25918057560920715\n",
            "Epoch 41, Step 63, Loss: 0.28833290934562683\n",
            "Epoch 41, Step 64, Loss: 0.36211466789245605\n",
            "Epoch 41, Step 65, Loss: 0.30972036719322205\n",
            "Epoch 41, Step 66, Loss: 0.3720768094062805\n",
            "Epoch 41, Step 67, Loss: 0.251327782869339\n",
            "Epoch 41, Step 68, Loss: 0.28956592082977295\n",
            "Epoch 41, Step 69, Loss: 0.3533446192741394\n",
            "Epoch 41, Step 70, Loss: 0.25050997734069824\n",
            "Epoch 41, Step 71, Loss: 0.27399352192878723\n",
            "Epoch 41, Step 72, Loss: 0.3934086263179779\n",
            "Epoch 41, Step 73, Loss: 0.3271191120147705\n",
            "Epoch 41, Step 74, Loss: 0.2850700914859772\n",
            "Epoch 41, Step 75, Loss: 0.35781535506248474\n",
            "Epoch 41, Step 76, Loss: 0.27744603157043457\n",
            "Epoch 41, Step 77, Loss: 0.271466463804245\n",
            "Epoch 41, Step 78, Loss: 0.4568658769130707\n",
            "Epoch 41, Step 79, Loss: 0.3069925308227539\n",
            "Epoch 41, Step 80, Loss: 0.3035110533237457\n",
            "Epoch 41, Step 81, Loss: 0.22026897966861725\n",
            "Epoch 41, Step 82, Loss: 0.31794673204421997\n",
            "Epoch 41, Step 83, Loss: 0.1385936737060547\n",
            "Epoch 41, Step 84, Loss: 0.28818079829216003\n",
            "Epoch 41, Step 85, Loss: 0.29950207471847534\n",
            "Epoch 41, Step 86, Loss: 0.22685633599758148\n",
            "Epoch 41, Step 87, Loss: 0.3331563174724579\n",
            "Epoch 41, Step 88, Loss: 0.3264508545398712\n",
            "Epoch 41, Step 89, Loss: 0.22564804553985596\n",
            "Epoch 41, Step 90, Loss: 0.3056418001651764\n",
            "Epoch 41, Step 91, Loss: 0.31773683428764343\n",
            "Epoch 41, Step 92, Loss: 0.2936595678329468\n",
            "Epoch 41, Step 93, Loss: 0.26911768317222595\n",
            "Epoch 41, Step 94, Loss: 0.18805812299251556\n",
            "Epoch 41, Step 95, Loss: 0.2240993082523346\n",
            "Epoch 41, Step 96, Loss: 0.21034063398838043\n",
            "Epoch 41, Step 97, Loss: 0.23703938722610474\n",
            "Epoch 41, Step 98, Loss: 0.3314405679702759\n",
            "Epoch 41, Step 99, Loss: 0.38193121552467346\n",
            "Epoch 41, Step 100, Loss: 0.1987462043762207\n",
            "Epoch 41, Step 101, Loss: 0.4034118950366974\n",
            "Epoch 41, Step 102, Loss: 0.34843194484710693\n",
            "Epoch 41, Step 103, Loss: 0.2610331177711487\n",
            "Epoch 41, Step 104, Loss: 0.30682501196861267\n",
            "Epoch 41, Step 105, Loss: 0.21579746901988983\n",
            "Epoch 41, Step 106, Loss: 0.19892753660678864\n",
            "Epoch 41, Step 107, Loss: 0.27810367941856384\n",
            "Epoch 41, Step 108, Loss: 0.23225775361061096\n",
            "Epoch 41, Step 109, Loss: 0.21795977652072906\n",
            "Epoch 41, Step 110, Loss: 0.3617790639400482\n",
            "Epoch 41, Step 111, Loss: 0.3046090006828308\n",
            "Epoch 41, Step 112, Loss: 0.4393983781337738\n",
            "Epoch 41, Step 113, Loss: 0.17022177577018738\n",
            "Epoch 41, Step 114, Loss: 0.3096503019332886\n",
            "Epoch 41, Step 115, Loss: 0.37065091729164124\n",
            "Epoch 41, Step 116, Loss: 0.2642884850502014\n",
            "Epoch 41, Step 117, Loss: 0.3036074638366699\n",
            "Epoch 41, Step 118, Loss: 0.2871539890766144\n",
            "Epoch 41, Step 119, Loss: 0.3565523326396942\n",
            "Epoch 41, Step 120, Loss: 0.29728275537490845\n",
            "Epoch 41, Step 121, Loss: 0.22252607345581055\n",
            "Epoch 41, Step 122, Loss: 0.4079461097717285\n",
            "Epoch 41, Step 123, Loss: 0.2862353026866913\n",
            "Epoch 41, Step 124, Loss: 0.35166236758232117\n",
            "Epoch 41, Step 125, Loss: 0.27306872606277466\n",
            "Epoch 41, Step 126, Loss: 0.41584938764572144\n",
            "Epoch 41, Step 127, Loss: 0.35235878825187683\n",
            "Epoch 41, Step 128, Loss: 0.2901307940483093\n",
            "Epoch 41, Step 129, Loss: 0.26252079010009766\n",
            "Epoch 41, Step 130, Loss: 0.21117626130580902\n",
            "Epoch 41, Step 131, Loss: 0.30298182368278503\n",
            "Epoch 41, Step 132, Loss: 0.20486849546432495\n",
            "Epoch 41, Step 133, Loss: 0.32444509863853455\n",
            "Epoch 41, Step 134, Loss: 0.23317867517471313\n",
            "Epoch 41, Step 135, Loss: 0.44396212697029114\n",
            "Epoch 41, Step 136, Loss: 0.3092655837535858\n",
            "Epoch 41, Step 137, Loss: 0.28827622532844543\n",
            "Epoch 41, Step 138, Loss: 0.26138418912887573\n",
            "Epoch 41, Step 139, Loss: 0.29351410269737244\n",
            "Epoch 41, Step 140, Loss: 0.31559547781944275\n",
            "Epoch 41, Step 141, Loss: 0.281349778175354\n",
            "Epoch 41, Step 142, Loss: 0.23674847185611725\n",
            "Epoch 41, Step 143, Loss: 0.28476864099502563\n",
            "Epoch 41, Step 144, Loss: 0.467818945646286\n",
            "Epoch 41, Step 145, Loss: 0.32671722769737244\n",
            "Epoch 41, Step 146, Loss: 0.3573368191719055\n",
            "Epoch 41, Step 147, Loss: 0.38123589754104614\n",
            "Epoch 41, Step 148, Loss: 0.3705650866031647\n",
            "Epoch 41, Step 149, Loss: 0.45714473724365234\n",
            "Epoch 41, Step 150, Loss: 0.40914082527160645\n",
            "Epoch 41, Step 151, Loss: 0.3317579925060272\n",
            "Epoch 41, Step 152, Loss: 0.2736051082611084\n",
            "Epoch 41, Step 153, Loss: 0.2715948820114136\n",
            "Epoch 41, Step 154, Loss: 0.21475650370121002\n",
            "Epoch 41, Step 155, Loss: 0.32697761058807373\n",
            "Epoch 41, Step 156, Loss: 0.256799578666687\n",
            "Epoch 41, Step 157, Loss: 0.35515087842941284\n",
            "Epoch 41, Step 158, Loss: 0.2588920593261719\n",
            "Epoch 41, Step 159, Loss: 0.20468805730342865\n",
            "Epoch 41, Step 160, Loss: 0.21290390193462372\n",
            "Epoch 41, Step 161, Loss: 0.23891715705394745\n",
            "Epoch 41, Step 162, Loss: 0.31282731890678406\n",
            "Epoch 41, Step 163, Loss: 0.2666495144367218\n",
            "Epoch 41, Step 164, Loss: 0.283894419670105\n",
            "Epoch 41, Step 165, Loss: 0.2961236238479614\n",
            "Epoch 41, Step 166, Loss: 0.2435167282819748\n",
            "Epoch 41, Step 167, Loss: 0.22716058790683746\n",
            "Epoch 41, Step 168, Loss: 0.21957777440547943\n",
            "Epoch 41, Step 169, Loss: 0.29053795337677\n",
            "Epoch 41, Step 170, Loss: 0.3005494177341461\n",
            "Epoch 41, Step 171, Loss: 0.34915491938591003\n",
            "Epoch 41, Step 172, Loss: 0.3296287953853607\n",
            "Epoch 41, Step 173, Loss: 0.311804860830307\n",
            "Epoch 41, Step 174, Loss: 0.3390563428401947\n",
            "Epoch 41, Step 175, Loss: 0.339690238237381\n",
            "Epoch 41, Step 176, Loss: 0.34213829040527344\n",
            "Epoch 41, Step 177, Loss: 0.2513219714164734\n",
            "Epoch 41, Step 178, Loss: 0.3166223466396332\n",
            "Epoch 41, Step 179, Loss: 0.3546595573425293\n",
            "Epoch 41, Step 180, Loss: 0.3170204162597656\n",
            "Epoch 41, Step 181, Loss: 0.22114154696464539\n",
            "Epoch 41, Step 182, Loss: 0.2290230542421341\n",
            "Epoch 41, Step 183, Loss: 0.27227506041526794\n",
            "Epoch 41, Step 184, Loss: 0.3305608630180359\n",
            "Epoch 41, Step 185, Loss: 0.27067700028419495\n",
            "Epoch 41, Step 186, Loss: 0.2804150879383087\n",
            "Epoch 41, Step 187, Loss: 0.303729385137558\n",
            "Epoch 41, Step 188, Loss: 0.25581374764442444\n",
            "Epoch 41, Step 189, Loss: 0.23613740503787994\n",
            "Epoch 41, Step 190, Loss: 0.22352643311023712\n",
            "Epoch 41, Step 191, Loss: 0.33144906163215637\n",
            "Epoch 41, Step 192, Loss: 0.24577198922634125\n",
            "Epoch 41, Step 193, Loss: 0.27160024642944336\n",
            "Epoch 41, Step 194, Loss: 0.1609141230583191\n",
            "Epoch 41, Step 195, Loss: 0.24676711857318878\n",
            "Epoch 41, Step 196, Loss: 0.35641759634017944\n",
            "Epoch 41, Step 197, Loss: 0.45389047265052795\n",
            "Epoch 41, Step 198, Loss: 0.2711191177368164\n",
            "Epoch 41, Step 199, Loss: 0.15468920767307281\n",
            "Epoch 41, Step 200, Loss: 0.4148103892803192\n",
            "Epoch 41, Step 201, Loss: 0.19349104166030884\n",
            "Epoch 41, Step 202, Loss: 0.3082719147205353\n",
            "Epoch 41, Step 203, Loss: 0.23325613141059875\n",
            "Epoch 41, Step 204, Loss: 0.3006168007850647\n",
            "Epoch 41, Step 205, Loss: 0.2534249424934387\n",
            "Epoch 41, Step 206, Loss: 0.3892255127429962\n",
            "Epoch 41, Step 207, Loss: 0.42755958437919617\n",
            "Epoch 41, Step 208, Loss: 0.34734299778938293\n",
            "Epoch 41, Step 209, Loss: 0.3768957853317261\n",
            "Epoch 41, Step 210, Loss: 0.39594030380249023\n",
            "Epoch 41, Step 211, Loss: 0.3740905523300171\n",
            "Epoch 41, Step 212, Loss: 0.358447402715683\n",
            "Epoch 41, Step 213, Loss: 0.28434082865715027\n",
            "Epoch 41, Step 214, Loss: 0.22607505321502686\n",
            "Epoch 41, Step 215, Loss: 0.26514625549316406\n",
            "Epoch 41, Step 216, Loss: 0.25366953015327454\n",
            "Epoch 41, Step 217, Loss: 0.26414862275123596\n",
            "Epoch 41, Step 218, Loss: 0.39471563696861267\n",
            "Epoch 41, Step 219, Loss: 0.20731346309185028\n",
            "Epoch 41, Step 220, Loss: 0.35035616159439087\n",
            "Epoch 41, Step 221, Loss: 0.42497164011001587\n",
            "Epoch 41, Step 222, Loss: 0.22590146958827972\n",
            "Epoch 41, Step 223, Loss: 0.320036917924881\n",
            "Epoch 41, Step 224, Loss: 0.2867429554462433\n",
            "Epoch 41, Step 225, Loss: 0.39161649346351624\n",
            "Epoch 41, Step 226, Loss: 0.27202966809272766\n",
            "Epoch 41, Step 227, Loss: 0.2994251251220703\n",
            "Epoch 41, Step 228, Loss: 0.390640527009964\n",
            "Epoch 41, Step 229, Loss: 0.3603675365447998\n",
            "Epoch 41, Step 230, Loss: 0.2458706498146057\n",
            "Epoch 41, Step 231, Loss: 0.24552176892757416\n",
            "Epoch 41, Step 232, Loss: 0.1930842250585556\n",
            "Epoch 41, Step 233, Loss: 0.3502480089664459\n",
            "Epoch 41, Step 234, Loss: 0.21497099101543427\n",
            "Epoch 41, Step 235, Loss: 0.273703396320343\n",
            "Epoch 41, Step 236, Loss: 0.2649049162864685\n",
            "Epoch 41, Step 237, Loss: 0.26178982853889465\n",
            "Epoch 41, Step 238, Loss: 0.34030598402023315\n",
            "Epoch 41, Step 239, Loss: 0.22054624557495117\n",
            "Epoch 41, Step 240, Loss: 0.24196775257587433\n",
            "Epoch 41, Step 241, Loss: 0.3998361825942993\n",
            "Epoch 41, Step 242, Loss: 0.3085700571537018\n",
            "Epoch 41, Step 243, Loss: 0.39149317145347595\n",
            "Epoch 41, Step 244, Loss: 0.32158324122428894\n",
            "Epoch 41, Step 245, Loss: 0.20702247321605682\n",
            "Epoch 41, Step 246, Loss: 0.31588730216026306\n",
            "Epoch 41, Step 247, Loss: 0.20648880302906036\n",
            "Epoch 41, Step 248, Loss: 0.281453400850296\n",
            "Epoch 41, Step 249, Loss: 0.22562415897846222\n",
            "Epoch 41, Step 250, Loss: 0.36636975407600403\n",
            "Epoch 41, Step 251, Loss: 0.26438578963279724\n",
            "Epoch 41, Step 252, Loss: 0.18761886656284332\n",
            "Epoch 41, Step 253, Loss: 0.3283027410507202\n",
            "Epoch 41, Step 254, Loss: 0.33760303258895874\n",
            "Epoch 41, Step 255, Loss: 0.17266036570072174\n",
            "Epoch 41, Step 256, Loss: 0.15651258826255798\n",
            "Epoch 41, Step 257, Loss: 0.23549796640872955\n",
            "Epoch 41, Step 258, Loss: 0.24683794379234314\n",
            "Epoch 41, Step 259, Loss: 0.4009503126144409\n",
            "Epoch 41, Step 260, Loss: 0.26330122351646423\n",
            "Epoch 41, Step 261, Loss: 0.27785971760749817\n",
            "Epoch 41, Step 262, Loss: 0.45530110597610474\n",
            "Epoch 41, Step 263, Loss: 0.3779142200946808\n",
            "Epoch 41, Step 264, Loss: 0.3886958062648773\n",
            "Epoch 41, Step 265, Loss: 0.2029745727777481\n",
            "Epoch 41, Step 266, Loss: 0.2339968979358673\n",
            "Epoch 41, Step 267, Loss: 0.25176000595092773\n",
            "Epoch 41, Step 268, Loss: 0.22781075537204742\n",
            "Epoch 41, Step 269, Loss: 0.3136865198612213\n",
            "Epoch 41, Step 270, Loss: 0.23613341152668\n",
            "Epoch 41, Step 271, Loss: 0.29141002893447876\n",
            "Epoch 41, Step 272, Loss: 0.34100550413131714\n",
            "Epoch 41, Step 273, Loss: 0.3161517083644867\n",
            "Epoch 41, Step 274, Loss: 0.3043360114097595\n",
            "Epoch 41, Step 275, Loss: 0.23793217539787292\n",
            "Epoch 41, Step 276, Loss: 0.3698839247226715\n",
            "Epoch 41, Step 277, Loss: 0.4830038249492645\n",
            "Epoch 41, Step 278, Loss: 0.3255918025970459\n",
            "Epoch 41, Step 279, Loss: 0.22740603983402252\n",
            "Epoch 41, Step 280, Loss: 0.21587340533733368\n",
            "Epoch 41, Step 281, Loss: 0.34350109100341797\n",
            "Epoch 41, Step 282, Loss: 0.3049085736274719\n",
            "Epoch 41, Step 283, Loss: 0.4288681745529175\n",
            "Epoch 41, Step 284, Loss: 0.22114934027194977\n",
            "Epoch 41, Step 285, Loss: 0.28428125381469727\n",
            "Epoch 41, Step 286, Loss: 0.41910895705223083\n",
            "Epoch 41, Step 287, Loss: 0.2221190333366394\n",
            "Epoch 41, Step 288, Loss: 0.3069334626197815\n",
            "Epoch 41, Step 289, Loss: 0.3701024055480957\n",
            "Epoch 41, Step 290, Loss: 0.32327574491500854\n",
            "Epoch 41, Step 291, Loss: 0.35679709911346436\n",
            "Epoch 41, Step 292, Loss: 0.3324958086013794\n",
            "Epoch 41, Step 293, Loss: 0.3923974633216858\n",
            "Epoch 41, Step 294, Loss: 0.3069162666797638\n",
            "Epoch 41, Step 295, Loss: 0.24296149611473083\n",
            "Epoch 41, Step 296, Loss: 0.3665606677532196\n",
            "Epoch 41, Step 297, Loss: 0.27481770515441895\n",
            "Epoch 41, Step 298, Loss: 0.2980714440345764\n",
            "Epoch 41, Step 299, Loss: 0.33209455013275146\n",
            "Epoch 41, Step 300, Loss: 0.2508222162723541\n",
            "Epoch 41, Step 301, Loss: 0.21156072616577148\n",
            "Epoch 41, Step 302, Loss: 0.33719688653945923\n",
            "Epoch 41, Step 303, Loss: 0.19370557367801666\n",
            "Epoch 41, Step 304, Loss: 0.3312729001045227\n",
            "Epoch 41, Step 305, Loss: 0.2928902804851532\n",
            "Epoch 41, Step 306, Loss: 0.1983761191368103\n",
            "Epoch 41, Step 307, Loss: 0.26867714524269104\n",
            "Epoch 41, Step 308, Loss: 0.36639106273651123\n",
            "Epoch 41, Step 309, Loss: 0.23803028464317322\n",
            "Epoch 41, Step 310, Loss: 0.30378955602645874\n",
            "Epoch 41, Step 311, Loss: 0.2601942718029022\n",
            "Epoch 41, Step 312, Loss: 0.2151041477918625\n",
            "Epoch 41 end, avg train loss: 0.29331371483330526\n",
            "Epoch 41 end, avg val loss: 0.3613561740781687, accuracy: 88.47%\n",
            "Checkpoint saved: AdaIPS_S_41.pth\n",
            "Epoch 42, Step 0, Loss: 0.24799245595932007\n",
            "Epoch 42, Step 1, Loss: 0.26252493262290955\n",
            "Epoch 42, Step 2, Loss: 0.239296555519104\n",
            "Epoch 42, Step 3, Loss: 0.29243043065071106\n",
            "Epoch 42, Step 4, Loss: 0.31103894114494324\n",
            "Epoch 42, Step 5, Loss: 0.375088632106781\n",
            "Epoch 42, Step 6, Loss: 0.26324015855789185\n",
            "Epoch 42, Step 7, Loss: 0.26607173681259155\n",
            "Epoch 42, Step 8, Loss: 0.20272867381572723\n",
            "Epoch 42, Step 9, Loss: 0.27153000235557556\n",
            "Epoch 42, Step 10, Loss: 0.34275344014167786\n",
            "Epoch 42, Step 11, Loss: 0.3926449716091156\n",
            "Epoch 42, Step 12, Loss: 0.24485720694065094\n",
            "Epoch 42, Step 13, Loss: 0.3541407585144043\n",
            "Epoch 42, Step 14, Loss: 0.3187987804412842\n",
            "Epoch 42, Step 15, Loss: 0.31276553869247437\n",
            "Epoch 42, Step 16, Loss: 0.3674997389316559\n",
            "Epoch 42, Step 17, Loss: 0.33937183022499084\n",
            "Epoch 42, Step 18, Loss: 0.27855128049850464\n",
            "Epoch 42, Step 19, Loss: 0.36377817392349243\n",
            "Epoch 42, Step 20, Loss: 0.323199063539505\n",
            "Epoch 42, Step 21, Loss: 0.4581061601638794\n",
            "Epoch 42, Step 22, Loss: 0.29041898250579834\n",
            "Epoch 42, Step 23, Loss: 0.164080411195755\n",
            "Epoch 42, Step 24, Loss: 0.24708852171897888\n",
            "Epoch 42, Step 25, Loss: 0.31812208890914917\n",
            "Epoch 42, Step 26, Loss: 0.24826458096504211\n",
            "Epoch 42, Step 27, Loss: 0.22582615911960602\n",
            "Epoch 42, Step 28, Loss: 0.2495230734348297\n",
            "Epoch 42, Step 29, Loss: 0.2090417742729187\n",
            "Epoch 42, Step 30, Loss: 0.2213590443134308\n",
            "Epoch 42, Step 31, Loss: 0.38167643547058105\n",
            "Epoch 42, Step 32, Loss: 0.2772425413131714\n",
            "Epoch 42, Step 33, Loss: 0.3442568778991699\n",
            "Epoch 42, Step 34, Loss: 0.2674645185470581\n",
            "Epoch 42, Step 35, Loss: 0.2805686295032501\n",
            "Epoch 42, Step 36, Loss: 0.3983735740184784\n",
            "Epoch 42, Step 37, Loss: 0.33532196283340454\n",
            "Epoch 42, Step 38, Loss: 0.2532299757003784\n",
            "Epoch 42, Step 39, Loss: 0.34048664569854736\n",
            "Epoch 42, Step 40, Loss: 0.33827725052833557\n",
            "Epoch 42, Step 41, Loss: 0.27475857734680176\n",
            "Epoch 42, Step 42, Loss: 0.2357235848903656\n",
            "Epoch 42, Step 43, Loss: 0.3135993480682373\n",
            "Epoch 42, Step 44, Loss: 0.16018150746822357\n",
            "Epoch 42, Step 45, Loss: 0.32995548844337463\n",
            "Epoch 42, Step 46, Loss: 0.2408757507801056\n",
            "Epoch 42, Step 47, Loss: 0.3741471469402313\n",
            "Epoch 42, Step 48, Loss: 0.3448532223701477\n",
            "Epoch 42, Step 49, Loss: 0.28170761466026306\n",
            "Epoch 42, Step 50, Loss: 0.21694634854793549\n",
            "Epoch 42, Step 51, Loss: 0.36677980422973633\n",
            "Epoch 42, Step 52, Loss: 0.23357202112674713\n",
            "Epoch 42, Step 53, Loss: 0.283832311630249\n",
            "Epoch 42, Step 54, Loss: 0.2292269915342331\n",
            "Epoch 42, Step 55, Loss: 0.16025115549564362\n",
            "Epoch 42, Step 56, Loss: 0.23933979868888855\n",
            "Epoch 42, Step 57, Loss: 0.27085208892822266\n",
            "Epoch 42, Step 58, Loss: 0.2527945637702942\n",
            "Epoch 42, Step 59, Loss: 0.30986300110816956\n",
            "Epoch 42, Step 60, Loss: 0.3361969292163849\n",
            "Epoch 42, Step 61, Loss: 0.288457989692688\n",
            "Epoch 42, Step 62, Loss: 0.2281697541475296\n",
            "Epoch 42, Step 63, Loss: 0.3329014480113983\n",
            "Epoch 42, Step 64, Loss: 0.22361403703689575\n",
            "Epoch 42, Step 65, Loss: 0.24426932632923126\n",
            "Epoch 42, Step 66, Loss: 0.32201671600341797\n",
            "Epoch 42, Step 67, Loss: 0.37264183163642883\n",
            "Epoch 42, Step 68, Loss: 0.25673362612724304\n",
            "Epoch 42, Step 69, Loss: 0.2600824534893036\n",
            "Epoch 42, Step 70, Loss: 0.3695944845676422\n",
            "Epoch 42, Step 71, Loss: 0.3051531910896301\n",
            "Epoch 42, Step 72, Loss: 0.2586669623851776\n",
            "Epoch 42, Step 73, Loss: 0.2706846594810486\n",
            "Epoch 42, Step 74, Loss: 0.25827550888061523\n",
            "Epoch 42, Step 75, Loss: 0.2672291696071625\n",
            "Epoch 42, Step 76, Loss: 0.37338152527809143\n",
            "Epoch 42, Step 77, Loss: 0.15614274144172668\n",
            "Epoch 42, Step 78, Loss: 0.19748252630233765\n",
            "Epoch 42, Step 79, Loss: 0.3055986166000366\n",
            "Epoch 42, Step 80, Loss: 0.28118976950645447\n",
            "Epoch 42, Step 81, Loss: 0.1985384076833725\n",
            "Epoch 42, Step 82, Loss: 0.215717613697052\n",
            "Epoch 42, Step 83, Loss: 0.3668045401573181\n",
            "Epoch 42, Step 84, Loss: 0.3926657736301422\n",
            "Epoch 42, Step 85, Loss: 0.2729194164276123\n",
            "Epoch 42, Step 86, Loss: 0.20395289361476898\n",
            "Epoch 42, Step 87, Loss: 0.2618527412414551\n",
            "Epoch 42, Step 88, Loss: 0.3316425681114197\n",
            "Epoch 42, Step 89, Loss: 0.19090062379837036\n",
            "Epoch 42, Step 90, Loss: 0.3031266927719116\n",
            "Epoch 42, Step 91, Loss: 0.2586294412612915\n",
            "Epoch 42, Step 92, Loss: 0.2528243958950043\n",
            "Epoch 42, Step 93, Loss: 0.2482534795999527\n",
            "Epoch 42, Step 94, Loss: 0.18371018767356873\n",
            "Epoch 42, Step 95, Loss: 0.32882723212242126\n",
            "Epoch 42, Step 96, Loss: 0.3531762361526489\n",
            "Epoch 42, Step 97, Loss: 0.4370807707309723\n",
            "Epoch 42, Step 98, Loss: 0.19671331346035004\n",
            "Epoch 42, Step 99, Loss: 0.2768527567386627\n",
            "Epoch 42, Step 100, Loss: 0.22389845550060272\n",
            "Epoch 42, Step 101, Loss: 0.28267601132392883\n",
            "Epoch 42, Step 102, Loss: 0.2333718091249466\n",
            "Epoch 42, Step 103, Loss: 0.289277046918869\n",
            "Epoch 42, Step 104, Loss: 0.2430734485387802\n",
            "Epoch 42, Step 105, Loss: 0.24785850942134857\n",
            "Epoch 42, Step 106, Loss: 0.34670504927635193\n",
            "Epoch 42, Step 107, Loss: 0.2661077678203583\n",
            "Epoch 42, Step 108, Loss: 0.29751408100128174\n",
            "Epoch 42, Step 109, Loss: 0.3376045525074005\n",
            "Epoch 42, Step 110, Loss: 0.2512056529521942\n",
            "Epoch 42, Step 111, Loss: 0.28441378474235535\n",
            "Epoch 42, Step 112, Loss: 0.26889559626579285\n",
            "Epoch 42, Step 113, Loss: 0.361105740070343\n",
            "Epoch 42, Step 114, Loss: 0.23413163423538208\n",
            "Epoch 42, Step 115, Loss: 0.23891811072826385\n",
            "Epoch 42, Step 116, Loss: 0.22847673296928406\n",
            "Epoch 42, Step 117, Loss: 0.3121103048324585\n",
            "Epoch 42, Step 118, Loss: 0.3436419367790222\n",
            "Epoch 42, Step 119, Loss: 0.2912050783634186\n",
            "Epoch 42, Step 120, Loss: 0.3748379349708557\n",
            "Epoch 42, Step 121, Loss: 0.32212451100349426\n",
            "Epoch 42, Step 122, Loss: 0.29434892535209656\n",
            "Epoch 42, Step 123, Loss: 0.32387641072273254\n",
            "Epoch 42, Step 124, Loss: 0.1747608184814453\n",
            "Epoch 42, Step 125, Loss: 0.2586374282836914\n",
            "Epoch 42, Step 126, Loss: 0.24034889042377472\n",
            "Epoch 42, Step 127, Loss: 0.31754395365715027\n",
            "Epoch 42, Step 128, Loss: 0.2906261682510376\n",
            "Epoch 42, Step 129, Loss: 0.3745131492614746\n",
            "Epoch 42, Step 130, Loss: 0.37978702783584595\n",
            "Epoch 42, Step 131, Loss: 0.35907605290412903\n",
            "Epoch 42, Step 132, Loss: 0.27895277738571167\n",
            "Epoch 42, Step 133, Loss: 0.2515582740306854\n",
            "Epoch 42, Step 134, Loss: 0.28929734230041504\n",
            "Epoch 42, Step 135, Loss: 0.451651930809021\n",
            "Epoch 42, Step 136, Loss: 0.2635543644428253\n",
            "Epoch 42, Step 137, Loss: 0.35293254256248474\n",
            "Epoch 42, Step 138, Loss: 0.1540241539478302\n",
            "Epoch 42, Step 139, Loss: 0.14394046366214752\n",
            "Epoch 42, Step 140, Loss: 0.3316915035247803\n",
            "Epoch 42, Step 141, Loss: 0.29939401149749756\n",
            "Epoch 42, Step 142, Loss: 0.2970581352710724\n",
            "Epoch 42, Step 143, Loss: 0.40652915835380554\n",
            "Epoch 42, Step 144, Loss: 0.16738227009773254\n",
            "Epoch 42, Step 145, Loss: 0.28685715794563293\n",
            "Epoch 42, Step 146, Loss: 0.26707935333251953\n",
            "Epoch 42, Step 147, Loss: 0.2058843970298767\n",
            "Epoch 42, Step 148, Loss: 0.25786662101745605\n",
            "Epoch 42, Step 149, Loss: 0.24600818753242493\n",
            "Epoch 42, Step 150, Loss: 0.3110053241252899\n",
            "Epoch 42, Step 151, Loss: 0.3347848355770111\n",
            "Epoch 42, Step 152, Loss: 0.27019575238227844\n",
            "Epoch 42, Step 153, Loss: 0.28328225016593933\n",
            "Epoch 42, Step 154, Loss: 0.33214271068573\n",
            "Epoch 42, Step 155, Loss: 0.23287981748580933\n",
            "Epoch 42, Step 156, Loss: 0.2839416563510895\n",
            "Epoch 42, Step 157, Loss: 0.3498587906360626\n",
            "Epoch 42, Step 158, Loss: 0.29454028606414795\n",
            "Epoch 42, Step 159, Loss: 0.21991971135139465\n",
            "Epoch 42, Step 160, Loss: 0.2716931700706482\n",
            "Epoch 42, Step 161, Loss: 0.28948071599006653\n",
            "Epoch 42, Step 162, Loss: 0.29853174090385437\n",
            "Epoch 42, Step 163, Loss: 0.2016381174325943\n",
            "Epoch 42, Step 164, Loss: 0.27947837114334106\n",
            "Epoch 42, Step 165, Loss: 0.20643289387226105\n",
            "Epoch 42, Step 166, Loss: 0.2088288962841034\n",
            "Epoch 42, Step 167, Loss: 0.2969992458820343\n",
            "Epoch 42, Step 168, Loss: 0.3016400933265686\n",
            "Epoch 42, Step 169, Loss: 0.3513020873069763\n",
            "Epoch 42, Step 170, Loss: 0.3043923079967499\n",
            "Epoch 42, Step 171, Loss: 0.41020524501800537\n",
            "Epoch 42, Step 172, Loss: 0.15441419184207916\n",
            "Epoch 42, Step 173, Loss: 0.30019786953926086\n",
            "Epoch 42, Step 174, Loss: 0.17566661536693573\n",
            "Epoch 42, Step 175, Loss: 0.27750593423843384\n",
            "Epoch 42, Step 176, Loss: 0.36552196741104126\n",
            "Epoch 42, Step 177, Loss: 0.3137472867965698\n",
            "Epoch 42, Step 178, Loss: 0.3528379499912262\n",
            "Epoch 42, Step 179, Loss: 0.41187018156051636\n",
            "Epoch 42, Step 180, Loss: 0.19957022368907928\n",
            "Epoch 42, Step 181, Loss: 0.19626978039741516\n",
            "Epoch 42, Step 182, Loss: 0.2680759131908417\n",
            "Epoch 42, Step 183, Loss: 0.21972794830799103\n",
            "Epoch 42, Step 184, Loss: 0.22615931928157806\n",
            "Epoch 42, Step 185, Loss: 0.3388284742832184\n",
            "Epoch 42, Step 186, Loss: 0.3273123800754547\n",
            "Epoch 42, Step 187, Loss: 0.3751339614391327\n",
            "Epoch 42, Step 188, Loss: 0.31082746386528015\n",
            "Epoch 42, Step 189, Loss: 0.24441483616828918\n",
            "Epoch 42, Step 190, Loss: 0.15418003499507904\n",
            "Epoch 42, Step 191, Loss: 0.22051066160202026\n",
            "Epoch 42, Step 192, Loss: 0.3068103492259979\n",
            "Epoch 42, Step 193, Loss: 0.32428228855133057\n",
            "Epoch 42, Step 194, Loss: 0.23398315906524658\n",
            "Epoch 42, Step 195, Loss: 0.30757883191108704\n",
            "Epoch 42, Step 196, Loss: 0.2523709237575531\n",
            "Epoch 42, Step 197, Loss: 0.3896638751029968\n",
            "Epoch 42, Step 198, Loss: 0.2575412094593048\n",
            "Epoch 42, Step 199, Loss: 0.2489764243364334\n",
            "Epoch 42, Step 200, Loss: 0.24952350556850433\n",
            "Epoch 42, Step 201, Loss: 0.2915549874305725\n",
            "Epoch 42, Step 202, Loss: 0.3303074538707733\n",
            "Epoch 42, Step 203, Loss: 0.2455497533082962\n",
            "Epoch 42, Step 204, Loss: 0.22147828340530396\n",
            "Epoch 42, Step 205, Loss: 0.27713537216186523\n",
            "Epoch 42, Step 206, Loss: 0.2639464735984802\n",
            "Epoch 42, Step 207, Loss: 0.3103102445602417\n",
            "Epoch 42, Step 208, Loss: 0.2188982218503952\n",
            "Epoch 42, Step 209, Loss: 0.17888915538787842\n",
            "Epoch 42, Step 210, Loss: 0.2630537152290344\n",
            "Epoch 42, Step 211, Loss: 0.3578677177429199\n",
            "Epoch 42, Step 212, Loss: 0.3228912949562073\n",
            "Epoch 42, Step 213, Loss: 0.23625300824642181\n",
            "Epoch 42, Step 214, Loss: 0.13962364196777344\n",
            "Epoch 42, Step 215, Loss: 0.284199059009552\n",
            "Epoch 42, Step 216, Loss: 0.3554143011569977\n",
            "Epoch 42, Step 217, Loss: 0.23644760251045227\n",
            "Epoch 42, Step 218, Loss: 0.3501586616039276\n",
            "Epoch 42, Step 219, Loss: 0.4069517254829407\n",
            "Epoch 42, Step 220, Loss: 0.23000288009643555\n",
            "Epoch 42, Step 221, Loss: 0.43074846267700195\n",
            "Epoch 42, Step 222, Loss: 0.16470400989055634\n",
            "Epoch 42, Step 223, Loss: 0.23287072777748108\n",
            "Epoch 42, Step 224, Loss: 0.31480181217193604\n",
            "Epoch 42, Step 225, Loss: 0.328525573015213\n",
            "Epoch 42, Step 226, Loss: 0.29113373160362244\n",
            "Epoch 42, Step 227, Loss: 0.2829465866088867\n",
            "Epoch 42, Step 228, Loss: 0.2810329496860504\n",
            "Epoch 42, Step 229, Loss: 0.19165204465389252\n",
            "Epoch 42, Step 230, Loss: 0.20137867331504822\n",
            "Epoch 42, Step 231, Loss: 0.3812270760536194\n",
            "Epoch 42, Step 232, Loss: 0.3356902003288269\n",
            "Epoch 42, Step 233, Loss: 0.24071714282035828\n",
            "Epoch 42, Step 234, Loss: 0.26885417103767395\n",
            "Epoch 42, Step 235, Loss: 0.2622912526130676\n",
            "Epoch 42, Step 236, Loss: 0.3314211964607239\n",
            "Epoch 42, Step 237, Loss: 0.3552626073360443\n",
            "Epoch 42, Step 238, Loss: 0.28028297424316406\n",
            "Epoch 42, Step 239, Loss: 0.3040338158607483\n",
            "Epoch 42, Step 240, Loss: 0.2387363314628601\n",
            "Epoch 42, Step 241, Loss: 0.24292004108428955\n",
            "Epoch 42, Step 242, Loss: 0.19410675764083862\n",
            "Epoch 42, Step 243, Loss: 0.2651009261608124\n",
            "Epoch 42, Step 244, Loss: 0.27151137590408325\n",
            "Epoch 42, Step 245, Loss: 0.2948864996433258\n",
            "Epoch 42, Step 246, Loss: 0.28659868240356445\n",
            "Epoch 42, Step 247, Loss: 0.1985684335231781\n",
            "Epoch 42, Step 248, Loss: 0.32783034443855286\n",
            "Epoch 42, Step 249, Loss: 0.4167196452617645\n",
            "Epoch 42, Step 250, Loss: 0.2786446809768677\n",
            "Epoch 42, Step 251, Loss: 0.2560938894748688\n",
            "Epoch 42, Step 252, Loss: 0.3457551598548889\n",
            "Epoch 42, Step 253, Loss: 0.35031282901763916\n",
            "Epoch 42, Step 254, Loss: 0.2871820628643036\n",
            "Epoch 42, Step 255, Loss: 0.23302210867404938\n",
            "Epoch 42, Step 256, Loss: 0.3151284158229828\n",
            "Epoch 42, Step 257, Loss: 0.26069721579551697\n",
            "Epoch 42, Step 258, Loss: 0.26000547409057617\n",
            "Epoch 42, Step 259, Loss: 0.2523055374622345\n",
            "Epoch 42, Step 260, Loss: 0.2270876169204712\n",
            "Epoch 42, Step 261, Loss: 0.2408498078584671\n",
            "Epoch 42, Step 262, Loss: 0.2618219554424286\n",
            "Epoch 42, Step 263, Loss: 0.3455545902252197\n",
            "Epoch 42, Step 264, Loss: 0.34849798679351807\n",
            "Epoch 42, Step 265, Loss: 0.2502809762954712\n",
            "Epoch 42, Step 266, Loss: 0.23526746034622192\n",
            "Epoch 42, Step 267, Loss: 0.29292431473731995\n",
            "Epoch 42, Step 268, Loss: 0.2835330069065094\n",
            "Epoch 42, Step 269, Loss: 0.2433791160583496\n",
            "Epoch 42, Step 270, Loss: 0.28963175415992737\n",
            "Epoch 42, Step 271, Loss: 0.2900872528553009\n",
            "Epoch 42, Step 272, Loss: 0.38858872652053833\n",
            "Epoch 42, Step 273, Loss: 0.3406587243080139\n",
            "Epoch 42, Step 274, Loss: 0.43144670128822327\n",
            "Epoch 42, Step 275, Loss: 0.27502647042274475\n",
            "Epoch 42, Step 276, Loss: 0.3058655261993408\n",
            "Epoch 42, Step 277, Loss: 0.433608740568161\n",
            "Epoch 42, Step 278, Loss: 0.26914119720458984\n",
            "Epoch 42, Step 279, Loss: 0.31127142906188965\n",
            "Epoch 42, Step 280, Loss: 0.25251439213752747\n",
            "Epoch 42, Step 281, Loss: 0.18291980028152466\n",
            "Epoch 42, Step 282, Loss: 0.3070876896381378\n",
            "Epoch 42, Step 283, Loss: 0.247223898768425\n",
            "Epoch 42, Step 284, Loss: 0.3707628846168518\n",
            "Epoch 42, Step 285, Loss: 0.3203750550746918\n",
            "Epoch 42, Step 286, Loss: 0.281504362821579\n",
            "Epoch 42, Step 287, Loss: 0.1928754299879074\n",
            "Epoch 42, Step 288, Loss: 0.2512151598930359\n",
            "Epoch 42, Step 289, Loss: 0.38169369101524353\n",
            "Epoch 42, Step 290, Loss: 0.19602172076702118\n",
            "Epoch 42, Step 291, Loss: 0.28960084915161133\n",
            "Epoch 42, Step 292, Loss: 0.25678205490112305\n",
            "Epoch 42, Step 293, Loss: 0.2883892059326172\n",
            "Epoch 42, Step 294, Loss: 0.3253312110900879\n",
            "Epoch 42, Step 295, Loss: 0.3239075243473053\n",
            "Epoch 42, Step 296, Loss: 0.38001325726509094\n",
            "Epoch 42, Step 297, Loss: 0.26160120964050293\n",
            "Epoch 42, Step 298, Loss: 0.22250640392303467\n",
            "Epoch 42, Step 299, Loss: 0.2731667160987854\n",
            "Epoch 42, Step 300, Loss: 0.24890877306461334\n",
            "Epoch 42, Step 301, Loss: 0.3192487955093384\n",
            "Epoch 42, Step 302, Loss: 0.3114587664604187\n",
            "Epoch 42, Step 303, Loss: 0.3788047432899475\n",
            "Epoch 42, Step 304, Loss: 0.3684607446193695\n",
            "Epoch 42, Step 305, Loss: 0.42315202951431274\n",
            "Epoch 42, Step 306, Loss: 0.29085418581962585\n",
            "Epoch 42, Step 307, Loss: 0.2870829999446869\n",
            "Epoch 42, Step 308, Loss: 0.34031563997268677\n",
            "Epoch 42, Step 309, Loss: 0.23141241073608398\n",
            "Epoch 42, Step 310, Loss: 0.2871391475200653\n",
            "Epoch 42, Step 311, Loss: 0.35974356532096863\n",
            "Epoch 42, Step 312, Loss: 0.3951546251773834\n",
            "Epoch 42 end, avg train loss: 0.28623119891642\n",
            "Epoch 42 end, avg val loss: 0.3558379988881606, accuracy: 88.56%\n",
            "Epoch 43, Step 0, Loss: 0.3444131016731262\n",
            "Epoch 43, Step 1, Loss: 0.22051659226417542\n",
            "Epoch 43, Step 2, Loss: 0.2171051800251007\n",
            "Epoch 43, Step 3, Loss: 0.31250110268592834\n",
            "Epoch 43, Step 4, Loss: 0.2206999659538269\n",
            "Epoch 43, Step 5, Loss: 0.2596268951892853\n",
            "Epoch 43, Step 6, Loss: 0.2926855981349945\n",
            "Epoch 43, Step 7, Loss: 0.24730725586414337\n",
            "Epoch 43, Step 8, Loss: 0.22200176119804382\n",
            "Epoch 43, Step 9, Loss: 0.28948891162872314\n",
            "Epoch 43, Step 10, Loss: 0.33068764209747314\n",
            "Epoch 43, Step 11, Loss: 0.32180070877075195\n",
            "Epoch 43, Step 12, Loss: 0.383929967880249\n",
            "Epoch 43, Step 13, Loss: 0.3238173723220825\n",
            "Epoch 43, Step 14, Loss: 0.20108649134635925\n",
            "Epoch 43, Step 15, Loss: 0.24162322282791138\n",
            "Epoch 43, Step 16, Loss: 0.36020898818969727\n",
            "Epoch 43, Step 17, Loss: 0.2864198386669159\n",
            "Epoch 43, Step 18, Loss: 0.23326486349105835\n",
            "Epoch 43, Step 19, Loss: 0.23587718605995178\n",
            "Epoch 43, Step 20, Loss: 0.3357696533203125\n",
            "Epoch 43, Step 21, Loss: 0.2894255816936493\n",
            "Epoch 43, Step 22, Loss: 0.2413809895515442\n",
            "Epoch 43, Step 23, Loss: 0.19768919050693512\n",
            "Epoch 43, Step 24, Loss: 0.3693699240684509\n",
            "Epoch 43, Step 25, Loss: 0.22889408469200134\n",
            "Epoch 43, Step 26, Loss: 0.2729840874671936\n",
            "Epoch 43, Step 27, Loss: 0.2703981399536133\n",
            "Epoch 43, Step 28, Loss: 0.2535088360309601\n",
            "Epoch 43, Step 29, Loss: 0.2246788889169693\n",
            "Epoch 43, Step 30, Loss: 0.22169607877731323\n",
            "Epoch 43, Step 31, Loss: 0.34235256910324097\n",
            "Epoch 43, Step 32, Loss: 0.3708493113517761\n",
            "Epoch 43, Step 33, Loss: 0.2046731561422348\n",
            "Epoch 43, Step 34, Loss: 0.34536299109458923\n",
            "Epoch 43, Step 35, Loss: 0.28854283690452576\n",
            "Epoch 43, Step 36, Loss: 0.3708655536174774\n",
            "Epoch 43, Step 37, Loss: 0.24183882772922516\n",
            "Epoch 43, Step 38, Loss: 0.17123182117938995\n",
            "Epoch 43, Step 39, Loss: 0.25644755363464355\n",
            "Epoch 43, Step 40, Loss: 0.321329802274704\n",
            "Epoch 43, Step 41, Loss: 0.2431909143924713\n",
            "Epoch 43, Step 42, Loss: 0.301229327917099\n",
            "Epoch 43, Step 43, Loss: 0.385370671749115\n",
            "Epoch 43, Step 44, Loss: 0.33519184589385986\n",
            "Epoch 43, Step 45, Loss: 0.25710663199424744\n",
            "Epoch 43, Step 46, Loss: 0.1435893028974533\n",
            "Epoch 43, Step 47, Loss: 0.27756598591804504\n",
            "Epoch 43, Step 48, Loss: 0.30813977122306824\n",
            "Epoch 43, Step 49, Loss: 0.21311143040657043\n",
            "Epoch 43, Step 50, Loss: 0.2710438370704651\n",
            "Epoch 43, Step 51, Loss: 0.4592369794845581\n",
            "Epoch 43, Step 52, Loss: 0.2985268533229828\n",
            "Epoch 43, Step 53, Loss: 0.2845281660556793\n",
            "Epoch 43, Step 54, Loss: 0.24033933877944946\n",
            "Epoch 43, Step 55, Loss: 0.18729574978351593\n",
            "Epoch 43, Step 56, Loss: 0.27828168869018555\n",
            "Epoch 43, Step 57, Loss: 0.2663480043411255\n",
            "Epoch 43, Step 58, Loss: 0.27088961005210876\n",
            "Epoch 43, Step 59, Loss: 0.2860167324542999\n",
            "Epoch 43, Step 60, Loss: 0.26782453060150146\n",
            "Epoch 43, Step 61, Loss: 0.2570524215698242\n",
            "Epoch 43, Step 62, Loss: 0.4949893057346344\n",
            "Epoch 43, Step 63, Loss: 0.26505962014198303\n",
            "Epoch 43, Step 64, Loss: 0.2642659842967987\n",
            "Epoch 43, Step 65, Loss: 0.23480574786663055\n",
            "Epoch 43, Step 66, Loss: 0.30500149726867676\n",
            "Epoch 43, Step 67, Loss: 0.19453050196170807\n",
            "Epoch 43, Step 68, Loss: 0.27353721857070923\n",
            "Epoch 43, Step 69, Loss: 0.2726353108882904\n",
            "Epoch 43, Step 70, Loss: 0.26303979754447937\n",
            "Epoch 43, Step 71, Loss: 0.18343374133110046\n",
            "Epoch 43, Step 72, Loss: 0.2119036316871643\n",
            "Epoch 43, Step 73, Loss: 0.36308643221855164\n",
            "Epoch 43, Step 74, Loss: 0.2880210876464844\n",
            "Epoch 43, Step 75, Loss: 0.2929171621799469\n",
            "Epoch 43, Step 76, Loss: 0.21213547885417938\n",
            "Epoch 43, Step 77, Loss: 0.30435216426849365\n",
            "Epoch 43, Step 78, Loss: 0.24400152266025543\n",
            "Epoch 43, Step 79, Loss: 0.25946488976478577\n",
            "Epoch 43, Step 80, Loss: 0.2700999975204468\n",
            "Epoch 43, Step 81, Loss: 0.4017331600189209\n",
            "Epoch 43, Step 82, Loss: 0.4238426983356476\n",
            "Epoch 43, Step 83, Loss: 0.24046263098716736\n",
            "Epoch 43, Step 84, Loss: 0.211906298995018\n",
            "Epoch 43, Step 85, Loss: 0.22229410707950592\n",
            "Epoch 43, Step 86, Loss: 0.24002191424369812\n",
            "Epoch 43, Step 87, Loss: 0.25448161363601685\n",
            "Epoch 43, Step 88, Loss: 0.28814923763275146\n",
            "Epoch 43, Step 89, Loss: 0.3634568154811859\n",
            "Epoch 43, Step 90, Loss: 0.37259596586227417\n",
            "Epoch 43, Step 91, Loss: 0.32374218106269836\n",
            "Epoch 43, Step 92, Loss: 0.2888250946998596\n",
            "Epoch 43, Step 93, Loss: 0.2356194406747818\n",
            "Epoch 43, Step 94, Loss: 0.2517406642436981\n",
            "Epoch 43, Step 95, Loss: 0.29843267798423767\n",
            "Epoch 43, Step 96, Loss: 0.3246263861656189\n",
            "Epoch 43, Step 97, Loss: 0.2992401123046875\n",
            "Epoch 43, Step 98, Loss: 0.25081053376197815\n",
            "Epoch 43, Step 99, Loss: 0.2630133330821991\n",
            "Epoch 43, Step 100, Loss: 0.18827208876609802\n",
            "Epoch 43, Step 101, Loss: 0.30853813886642456\n",
            "Epoch 43, Step 102, Loss: 0.313637375831604\n",
            "Epoch 43, Step 103, Loss: 0.3320584297180176\n",
            "Epoch 43, Step 104, Loss: 0.3277129828929901\n",
            "Epoch 43, Step 105, Loss: 0.19304190576076508\n",
            "Epoch 43, Step 106, Loss: 0.29216286540031433\n",
            "Epoch 43, Step 107, Loss: 0.4605892300605774\n",
            "Epoch 43, Step 108, Loss: 0.24194058775901794\n",
            "Epoch 43, Step 109, Loss: 0.36854687333106995\n",
            "Epoch 43, Step 110, Loss: 0.2918849587440491\n",
            "Epoch 43, Step 111, Loss: 0.24782389402389526\n",
            "Epoch 43, Step 112, Loss: 0.19299079477787018\n",
            "Epoch 43, Step 113, Loss: 0.3113868236541748\n",
            "Epoch 43, Step 114, Loss: 0.23439811170101166\n",
            "Epoch 43, Step 115, Loss: 0.27305424213409424\n",
            "Epoch 43, Step 116, Loss: 0.19438037276268005\n",
            "Epoch 43, Step 117, Loss: 0.24505269527435303\n",
            "Epoch 43, Step 118, Loss: 0.26565951108932495\n",
            "Epoch 43, Step 119, Loss: 0.4293956160545349\n",
            "Epoch 43, Step 120, Loss: 0.24769577383995056\n",
            "Epoch 43, Step 121, Loss: 0.2851693034172058\n",
            "Epoch 43, Step 122, Loss: 0.3324810564517975\n",
            "Epoch 43, Step 123, Loss: 0.30919238924980164\n",
            "Epoch 43, Step 124, Loss: 0.28733885288238525\n",
            "Epoch 43, Step 125, Loss: 0.23937220871448517\n",
            "Epoch 43, Step 126, Loss: 0.2538300156593323\n",
            "Epoch 43, Step 127, Loss: 0.22283002734184265\n",
            "Epoch 43, Step 128, Loss: 0.3233107626438141\n",
            "Epoch 43, Step 129, Loss: 0.20486359298229218\n",
            "Epoch 43, Step 130, Loss: 0.16846276819705963\n",
            "Epoch 43, Step 131, Loss: 0.2909078598022461\n",
            "Epoch 43, Step 132, Loss: 0.31282761693000793\n",
            "Epoch 43, Step 133, Loss: 0.3785133957862854\n",
            "Epoch 43, Step 134, Loss: 0.31961342692375183\n",
            "Epoch 43, Step 135, Loss: 0.3047519326210022\n",
            "Epoch 43, Step 136, Loss: 0.14495660364627838\n",
            "Epoch 43, Step 137, Loss: 0.15172113478183746\n",
            "Epoch 43, Step 138, Loss: 0.21810653805732727\n",
            "Epoch 43, Step 139, Loss: 0.23317886888980865\n",
            "Epoch 43, Step 140, Loss: 0.28691911697387695\n",
            "Epoch 43, Step 141, Loss: 0.21257588267326355\n",
            "Epoch 43, Step 142, Loss: 0.2677944004535675\n",
            "Epoch 43, Step 143, Loss: 0.2941412925720215\n",
            "Epoch 43, Step 144, Loss: 0.1993783414363861\n",
            "Epoch 43, Step 145, Loss: 0.29408520460128784\n",
            "Epoch 43, Step 146, Loss: 0.35111385583877563\n",
            "Epoch 43, Step 147, Loss: 0.2980630695819855\n",
            "Epoch 43, Step 148, Loss: 0.23525972664356232\n",
            "Epoch 43, Step 149, Loss: 0.2244645059108734\n",
            "Epoch 43, Step 150, Loss: 0.32872679829597473\n",
            "Epoch 43, Step 151, Loss: 0.22654367983341217\n",
            "Epoch 43, Step 152, Loss: 0.2993718683719635\n",
            "Epoch 43, Step 153, Loss: 0.2765217125415802\n",
            "Epoch 43, Step 154, Loss: 0.29912257194519043\n",
            "Epoch 43, Step 155, Loss: 0.21529726684093475\n",
            "Epoch 43, Step 156, Loss: 0.2855849862098694\n",
            "Epoch 43, Step 157, Loss: 0.3946496844291687\n",
            "Epoch 43, Step 158, Loss: 0.3051070272922516\n",
            "Epoch 43, Step 159, Loss: 0.24033084511756897\n",
            "Epoch 43, Step 160, Loss: 0.2835265100002289\n",
            "Epoch 43, Step 161, Loss: 0.3094753921031952\n",
            "Epoch 43, Step 162, Loss: 0.361596018075943\n",
            "Epoch 43, Step 163, Loss: 0.2842880189418793\n",
            "Epoch 43, Step 164, Loss: 0.30045297741889954\n",
            "Epoch 43, Step 165, Loss: 0.17668768763542175\n",
            "Epoch 43, Step 166, Loss: 0.2479727566242218\n",
            "Epoch 43, Step 167, Loss: 0.2145955115556717\n",
            "Epoch 43, Step 168, Loss: 0.24542094767093658\n",
            "Epoch 43, Step 169, Loss: 0.38228240609169006\n",
            "Epoch 43, Step 170, Loss: 0.30829161405563354\n",
            "Epoch 43, Step 171, Loss: 0.23446024954319\n",
            "Epoch 43, Step 172, Loss: 0.22510792315006256\n",
            "Epoch 43, Step 173, Loss: 0.2352990359067917\n",
            "Epoch 43, Step 174, Loss: 0.28777024149894714\n",
            "Epoch 43, Step 175, Loss: 0.1900397092103958\n",
            "Epoch 43, Step 176, Loss: 0.2400950789451599\n",
            "Epoch 43, Step 177, Loss: 0.33188143372535706\n",
            "Epoch 43, Step 178, Loss: 0.2919002175331116\n",
            "Epoch 43, Step 179, Loss: 0.2758197486400604\n",
            "Epoch 43, Step 180, Loss: 0.30762264132499695\n",
            "Epoch 43, Step 181, Loss: 0.26910993456840515\n",
            "Epoch 43, Step 182, Loss: 0.30626755952835083\n",
            "Epoch 43, Step 183, Loss: 0.39390820264816284\n",
            "Epoch 43, Step 184, Loss: 0.2739279866218567\n",
            "Epoch 43, Step 185, Loss: 0.30596819519996643\n",
            "Epoch 43, Step 186, Loss: 0.18769404292106628\n",
            "Epoch 43, Step 187, Loss: 0.22515806555747986\n",
            "Epoch 43, Step 188, Loss: 0.24713972210884094\n",
            "Epoch 43, Step 189, Loss: 0.18174713850021362\n",
            "Epoch 43, Step 190, Loss: 0.27821874618530273\n",
            "Epoch 43, Step 191, Loss: 0.28722941875457764\n",
            "Epoch 43, Step 192, Loss: 0.26252245903015137\n",
            "Epoch 43, Step 193, Loss: 0.2922039330005646\n",
            "Epoch 43, Step 194, Loss: 0.279316782951355\n",
            "Epoch 43, Step 195, Loss: 0.43308618664741516\n",
            "Epoch 43, Step 196, Loss: 0.3033960163593292\n",
            "Epoch 43, Step 197, Loss: 0.3077406883239746\n",
            "Epoch 43, Step 198, Loss: 0.2604363262653351\n",
            "Epoch 43, Step 199, Loss: 0.37956058979034424\n",
            "Epoch 43, Step 200, Loss: 0.35799744725227356\n",
            "Epoch 43, Step 201, Loss: 0.28294622898101807\n",
            "Epoch 43, Step 202, Loss: 0.30970486998558044\n",
            "Epoch 43, Step 203, Loss: 0.2687588334083557\n",
            "Epoch 43, Step 204, Loss: 0.27485859394073486\n",
            "Epoch 43, Step 205, Loss: 0.205605149269104\n",
            "Epoch 43, Step 206, Loss: 0.2007797360420227\n",
            "Epoch 43, Step 207, Loss: 0.27921298146247864\n",
            "Epoch 43, Step 208, Loss: 0.25097382068634033\n",
            "Epoch 43, Step 209, Loss: 0.32352688908576965\n",
            "Epoch 43, Step 210, Loss: 0.24066196382045746\n",
            "Epoch 43, Step 211, Loss: 0.3530796766281128\n",
            "Epoch 43, Step 212, Loss: 0.2465600073337555\n",
            "Epoch 43, Step 213, Loss: 0.2103429138660431\n",
            "Epoch 43, Step 214, Loss: 0.2743823528289795\n",
            "Epoch 43, Step 215, Loss: 0.22438156604766846\n",
            "Epoch 43, Step 216, Loss: 0.3053053319454193\n",
            "Epoch 43, Step 217, Loss: 0.21435627341270447\n",
            "Epoch 43, Step 218, Loss: 0.189255490899086\n",
            "Epoch 43, Step 219, Loss: 0.2860069274902344\n",
            "Epoch 43, Step 220, Loss: 0.22425846755504608\n",
            "Epoch 43, Step 221, Loss: 0.29580843448638916\n",
            "Epoch 43, Step 222, Loss: 0.19328166544437408\n",
            "Epoch 43, Step 223, Loss: 0.37307751178741455\n",
            "Epoch 43, Step 224, Loss: 0.2263161689043045\n",
            "Epoch 43, Step 225, Loss: 0.30113449692726135\n",
            "Epoch 43, Step 226, Loss: 0.21286819875240326\n",
            "Epoch 43, Step 227, Loss: 0.23480719327926636\n",
            "Epoch 43, Step 228, Loss: 0.2689571976661682\n",
            "Epoch 43, Step 229, Loss: 0.430820494890213\n",
            "Epoch 43, Step 230, Loss: 0.30443042516708374\n",
            "Epoch 43, Step 231, Loss: 0.32986170053482056\n",
            "Epoch 43, Step 232, Loss: 0.3338358700275421\n",
            "Epoch 43, Step 233, Loss: 0.2726319432258606\n",
            "Epoch 43, Step 234, Loss: 0.2897781729698181\n",
            "Epoch 43, Step 235, Loss: 0.3309839367866516\n",
            "Epoch 43, Step 236, Loss: 0.3743096590042114\n",
            "Epoch 43, Step 237, Loss: 0.23740743100643158\n",
            "Epoch 43, Step 238, Loss: 0.24955201148986816\n",
            "Epoch 43, Step 239, Loss: 0.325200617313385\n",
            "Epoch 43, Step 240, Loss: 0.34693199396133423\n",
            "Epoch 43, Step 241, Loss: 0.34265419840812683\n",
            "Epoch 43, Step 242, Loss: 0.2867978811264038\n",
            "Epoch 43, Step 243, Loss: 0.27343472838401794\n",
            "Epoch 43, Step 244, Loss: 0.47594332695007324\n",
            "Epoch 43, Step 245, Loss: 0.2075972557067871\n",
            "Epoch 43, Step 246, Loss: 0.27487993240356445\n",
            "Epoch 43, Step 247, Loss: 0.2467949539422989\n",
            "Epoch 43, Step 248, Loss: 0.379935085773468\n",
            "Epoch 43, Step 249, Loss: 0.333317369222641\n",
            "Epoch 43, Step 250, Loss: 0.2480897158384323\n",
            "Epoch 43, Step 251, Loss: 0.2368285357952118\n",
            "Epoch 43, Step 252, Loss: 0.3755466341972351\n",
            "Epoch 43, Step 253, Loss: 0.2037849873304367\n",
            "Epoch 43, Step 254, Loss: 0.2812623679637909\n",
            "Epoch 43, Step 255, Loss: 0.30924156308174133\n",
            "Epoch 43, Step 256, Loss: 0.25982949137687683\n",
            "Epoch 43, Step 257, Loss: 0.2701623737812042\n",
            "Epoch 43, Step 258, Loss: 0.24137702584266663\n",
            "Epoch 43, Step 259, Loss: 0.30826064944267273\n",
            "Epoch 43, Step 260, Loss: 0.2039046585559845\n",
            "Epoch 43, Step 261, Loss: 0.1828751266002655\n",
            "Epoch 43, Step 262, Loss: 0.30288904905319214\n",
            "Epoch 43, Step 263, Loss: 0.25494199991226196\n",
            "Epoch 43, Step 264, Loss: 0.29743891954421997\n",
            "Epoch 43, Step 265, Loss: 0.3335486948490143\n",
            "Epoch 43, Step 266, Loss: 0.3010876774787903\n",
            "Epoch 43, Step 267, Loss: 0.3574446141719818\n",
            "Epoch 43, Step 268, Loss: 0.3187412619590759\n",
            "Epoch 43, Step 269, Loss: 0.26977330446243286\n",
            "Epoch 43, Step 270, Loss: 0.24955610930919647\n",
            "Epoch 43, Step 271, Loss: 0.23380595445632935\n",
            "Epoch 43, Step 272, Loss: 0.26671692728996277\n",
            "Epoch 43, Step 273, Loss: 0.3209565579891205\n",
            "Epoch 43, Step 274, Loss: 0.17109887301921844\n",
            "Epoch 43, Step 275, Loss: 0.5257459878921509\n",
            "Epoch 43, Step 276, Loss: 0.31646528840065\n",
            "Epoch 43, Step 277, Loss: 0.20308434963226318\n",
            "Epoch 43, Step 278, Loss: 0.2576618790626526\n",
            "Epoch 43, Step 279, Loss: 0.2708798944950104\n",
            "Epoch 43, Step 280, Loss: 0.3146309554576874\n",
            "Epoch 43, Step 281, Loss: 0.3772347867488861\n",
            "Epoch 43, Step 282, Loss: 0.3638123571872711\n",
            "Epoch 43, Step 283, Loss: 0.27864736318588257\n",
            "Epoch 43, Step 284, Loss: 0.32512861490249634\n",
            "Epoch 43, Step 285, Loss: 0.3274581730365753\n",
            "Epoch 43, Step 286, Loss: 0.286981999874115\n",
            "Epoch 43, Step 287, Loss: 0.21767854690551758\n",
            "Epoch 43, Step 288, Loss: 0.1573835164308548\n",
            "Epoch 43, Step 289, Loss: 0.31826651096343994\n",
            "Epoch 43, Step 290, Loss: 0.1651696264743805\n",
            "Epoch 43, Step 291, Loss: 0.23480096459388733\n",
            "Epoch 43, Step 292, Loss: 0.28753480315208435\n",
            "Epoch 43, Step 293, Loss: 0.2938915193080902\n",
            "Epoch 43, Step 294, Loss: 0.14917035400867462\n",
            "Epoch 43, Step 295, Loss: 0.27577221393585205\n",
            "Epoch 43, Step 296, Loss: 0.34711506962776184\n",
            "Epoch 43, Step 297, Loss: 0.276332825422287\n",
            "Epoch 43, Step 298, Loss: 0.26522427797317505\n",
            "Epoch 43, Step 299, Loss: 0.2304917275905609\n",
            "Epoch 43, Step 300, Loss: 0.23118425905704498\n",
            "Epoch 43, Step 301, Loss: 0.31456008553504944\n",
            "Epoch 43, Step 302, Loss: 0.3141928017139435\n",
            "Epoch 43, Step 303, Loss: 0.34598323702812195\n",
            "Epoch 43, Step 304, Loss: 0.30914491415023804\n",
            "Epoch 43, Step 305, Loss: 0.25650739669799805\n",
            "Epoch 43, Step 306, Loss: 0.23374837636947632\n",
            "Epoch 43, Step 307, Loss: 0.3113377094268799\n",
            "Epoch 43, Step 308, Loss: 0.3130326569080353\n",
            "Epoch 43, Step 309, Loss: 0.29410988092422485\n",
            "Epoch 43, Step 310, Loss: 0.39542949199676514\n",
            "Epoch 43, Step 311, Loss: 0.3587140440940857\n",
            "Epoch 43, Step 312, Loss: 0.26637065410614014\n",
            "Epoch 43 end, avg train loss: 0.280258074831277\n",
            "Epoch 43 end, avg val loss: 0.37344471827338016, accuracy: 87.81%\n",
            "Epoch 44, Step 0, Loss: 0.2596437931060791\n",
            "Epoch 44, Step 1, Loss: 0.32657337188720703\n",
            "Epoch 44, Step 2, Loss: 0.2666100263595581\n",
            "Epoch 44, Step 3, Loss: 0.2917354106903076\n",
            "Epoch 44, Step 4, Loss: 0.21911969780921936\n",
            "Epoch 44, Step 5, Loss: 0.32766449451446533\n",
            "Epoch 44, Step 6, Loss: 0.23942893743515015\n",
            "Epoch 44, Step 7, Loss: 0.3329198658466339\n",
            "Epoch 44, Step 8, Loss: 0.2231873720884323\n",
            "Epoch 44, Step 9, Loss: 0.2705319821834564\n",
            "Epoch 44, Step 10, Loss: 0.26106786727905273\n",
            "Epoch 44, Step 11, Loss: 0.2007165253162384\n",
            "Epoch 44, Step 12, Loss: 0.3148251473903656\n",
            "Epoch 44, Step 13, Loss: 0.21279695630073547\n",
            "Epoch 44, Step 14, Loss: 0.3221385180950165\n",
            "Epoch 44, Step 15, Loss: 0.43050017952919006\n",
            "Epoch 44, Step 16, Loss: 0.33321475982666016\n",
            "Epoch 44, Step 17, Loss: 0.23386181890964508\n",
            "Epoch 44, Step 18, Loss: 0.26355475187301636\n",
            "Epoch 44, Step 19, Loss: 0.24769966304302216\n",
            "Epoch 44, Step 20, Loss: 0.22824572026729584\n",
            "Epoch 44, Step 21, Loss: 0.3130015730857849\n",
            "Epoch 44, Step 22, Loss: 0.3490005135536194\n",
            "Epoch 44, Step 23, Loss: 0.3054819405078888\n",
            "Epoch 44, Step 24, Loss: 0.27625706791877747\n",
            "Epoch 44, Step 25, Loss: 0.3442324101924896\n",
            "Epoch 44, Step 26, Loss: 0.37251555919647217\n",
            "Epoch 44, Step 27, Loss: 0.24524949491024017\n",
            "Epoch 44, Step 28, Loss: 0.2745060324668884\n",
            "Epoch 44, Step 29, Loss: 0.26859650015830994\n",
            "Epoch 44, Step 30, Loss: 0.18307679891586304\n",
            "Epoch 44, Step 31, Loss: 0.40665876865386963\n",
            "Epoch 44, Step 32, Loss: 0.24449896812438965\n",
            "Epoch 44, Step 33, Loss: 0.23302005231380463\n",
            "Epoch 44, Step 34, Loss: 0.24081678688526154\n",
            "Epoch 44, Step 35, Loss: 0.3119148313999176\n",
            "Epoch 44, Step 36, Loss: 0.2406608909368515\n",
            "Epoch 44, Step 37, Loss: 0.3148620128631592\n",
            "Epoch 44, Step 38, Loss: 0.19131925702095032\n",
            "Epoch 44, Step 39, Loss: 0.2697114050388336\n",
            "Epoch 44, Step 40, Loss: 0.2836921811103821\n",
            "Epoch 44, Step 41, Loss: 0.393360435962677\n",
            "Epoch 44, Step 42, Loss: 0.3050180971622467\n",
            "Epoch 44, Step 43, Loss: 0.28083816170692444\n",
            "Epoch 44, Step 44, Loss: 0.22924098372459412\n",
            "Epoch 44, Step 45, Loss: 0.19626536965370178\n",
            "Epoch 44, Step 46, Loss: 0.3166171610355377\n",
            "Epoch 44, Step 47, Loss: 0.3277585506439209\n",
            "Epoch 44, Step 48, Loss: 0.3642388582229614\n",
            "Epoch 44, Step 49, Loss: 0.21550576388835907\n",
            "Epoch 44, Step 50, Loss: 0.23779714107513428\n",
            "Epoch 44, Step 51, Loss: 0.28248775005340576\n",
            "Epoch 44, Step 52, Loss: 0.27448317408561707\n",
            "Epoch 44, Step 53, Loss: 0.29585087299346924\n",
            "Epoch 44, Step 54, Loss: 0.27257123589515686\n",
            "Epoch 44, Step 55, Loss: 0.3464089334011078\n",
            "Epoch 44, Step 56, Loss: 0.38147175312042236\n",
            "Epoch 44, Step 57, Loss: 0.23268333077430725\n",
            "Epoch 44, Step 58, Loss: 0.2346459925174713\n",
            "Epoch 44, Step 59, Loss: 0.204351007938385\n",
            "Epoch 44, Step 60, Loss: 0.24543629586696625\n",
            "Epoch 44, Step 61, Loss: 0.3180094361305237\n",
            "Epoch 44, Step 62, Loss: 0.3255181610584259\n",
            "Epoch 44, Step 63, Loss: 0.24090006947517395\n",
            "Epoch 44, Step 64, Loss: 0.3294511139392853\n",
            "Epoch 44, Step 65, Loss: 0.16102194786071777\n",
            "Epoch 44, Step 66, Loss: 0.22239966690540314\n",
            "Epoch 44, Step 67, Loss: 0.2931607663631439\n",
            "Epoch 44, Step 68, Loss: 0.20886965095996857\n",
            "Epoch 44, Step 69, Loss: 0.23411236703395844\n",
            "Epoch 44, Step 70, Loss: 0.2908334732055664\n",
            "Epoch 44, Step 71, Loss: 0.34875068068504333\n",
            "Epoch 44, Step 72, Loss: 0.3235898017883301\n",
            "Epoch 44, Step 73, Loss: 0.3234369158744812\n",
            "Epoch 44, Step 74, Loss: 0.17306028306484222\n",
            "Epoch 44, Step 75, Loss: 0.28919556736946106\n",
            "Epoch 44, Step 76, Loss: 0.3200311064720154\n",
            "Epoch 44, Step 77, Loss: 0.14482539892196655\n",
            "Epoch 44, Step 78, Loss: 0.30813899636268616\n",
            "Epoch 44, Step 79, Loss: 0.2989492118358612\n",
            "Epoch 44, Step 80, Loss: 0.22829581797122955\n",
            "Epoch 44, Step 81, Loss: 0.34710055589675903\n",
            "Epoch 44, Step 82, Loss: 0.28289085626602173\n",
            "Epoch 44, Step 83, Loss: 0.2476615458726883\n",
            "Epoch 44, Step 84, Loss: 0.2877177298069\n",
            "Epoch 44, Step 85, Loss: 0.31192612648010254\n",
            "Epoch 44, Step 86, Loss: 0.2868187427520752\n",
            "Epoch 44, Step 87, Loss: 0.2702585756778717\n",
            "Epoch 44, Step 88, Loss: 0.3424188494682312\n",
            "Epoch 44, Step 89, Loss: 0.2998231053352356\n",
            "Epoch 44, Step 90, Loss: 0.27709442377090454\n",
            "Epoch 44, Step 91, Loss: 0.1761242151260376\n",
            "Epoch 44, Step 92, Loss: 0.23741407692432404\n",
            "Epoch 44, Step 93, Loss: 0.228839710354805\n",
            "Epoch 44, Step 94, Loss: 0.2171756476163864\n",
            "Epoch 44, Step 95, Loss: 0.27015239000320435\n",
            "Epoch 44, Step 96, Loss: 0.29496845602989197\n",
            "Epoch 44, Step 97, Loss: 0.3143705725669861\n",
            "Epoch 44, Step 98, Loss: 0.4083840250968933\n",
            "Epoch 44, Step 99, Loss: 0.2607981860637665\n",
            "Epoch 44, Step 100, Loss: 0.3619443476200104\n",
            "Epoch 44, Step 101, Loss: 0.2355213314294815\n",
            "Epoch 44, Step 102, Loss: 0.1842927485704422\n",
            "Epoch 44, Step 103, Loss: 0.2575375437736511\n",
            "Epoch 44, Step 104, Loss: 0.3043800890445709\n",
            "Epoch 44, Step 105, Loss: 0.24302126467227936\n",
            "Epoch 44, Step 106, Loss: 0.3428301215171814\n",
            "Epoch 44, Step 107, Loss: 0.23808243870735168\n",
            "Epoch 44, Step 108, Loss: 0.21257007122039795\n",
            "Epoch 44, Step 109, Loss: 0.30449554324150085\n",
            "Epoch 44, Step 110, Loss: 0.3427661061286926\n",
            "Epoch 44, Step 111, Loss: 0.1881842315196991\n",
            "Epoch 44, Step 112, Loss: 0.254642128944397\n",
            "Epoch 44, Step 113, Loss: 0.18772825598716736\n",
            "Epoch 44, Step 114, Loss: 0.24416929483413696\n",
            "Epoch 44, Step 115, Loss: 0.3465108573436737\n",
            "Epoch 44, Step 116, Loss: 0.2808515727519989\n",
            "Epoch 44, Step 117, Loss: 0.2391817569732666\n",
            "Epoch 44, Step 118, Loss: 0.314005583524704\n",
            "Epoch 44, Step 119, Loss: 0.28055572509765625\n",
            "Epoch 44, Step 120, Loss: 0.21058408915996552\n",
            "Epoch 44, Step 121, Loss: 0.2999545931816101\n",
            "Epoch 44, Step 122, Loss: 0.3401629626750946\n",
            "Epoch 44, Step 123, Loss: 0.19917862117290497\n",
            "Epoch 44, Step 124, Loss: 0.3601030707359314\n",
            "Epoch 44, Step 125, Loss: 0.2590094804763794\n",
            "Epoch 44, Step 126, Loss: 0.38464322686195374\n",
            "Epoch 44, Step 127, Loss: 0.21715009212493896\n",
            "Epoch 44, Step 128, Loss: 0.3420877456665039\n",
            "Epoch 44, Step 129, Loss: 0.24399900436401367\n",
            "Epoch 44, Step 130, Loss: 0.2897487282752991\n",
            "Epoch 44, Step 131, Loss: 0.39227068424224854\n",
            "Epoch 44, Step 132, Loss: 0.2654087245464325\n",
            "Epoch 44, Step 133, Loss: 0.3754517436027527\n",
            "Epoch 44, Step 134, Loss: 0.23830120265483856\n",
            "Epoch 44, Step 135, Loss: 0.3231552839279175\n",
            "Epoch 44, Step 136, Loss: 0.27658015489578247\n",
            "Epoch 44, Step 137, Loss: 0.2874985635280609\n",
            "Epoch 44, Step 138, Loss: 0.20404258370399475\n",
            "Epoch 44, Step 139, Loss: 0.14030256867408752\n",
            "Epoch 44, Step 140, Loss: 0.179357647895813\n",
            "Epoch 44, Step 141, Loss: 0.2058345377445221\n",
            "Epoch 44, Step 142, Loss: 0.3351813852787018\n",
            "Epoch 44, Step 143, Loss: 0.29560068249702454\n",
            "Epoch 44, Step 144, Loss: 0.2837473154067993\n",
            "Epoch 44, Step 145, Loss: 0.22646474838256836\n",
            "Epoch 44, Step 146, Loss: 0.2836252748966217\n",
            "Epoch 44, Step 147, Loss: 0.1358150690793991\n",
            "Epoch 44, Step 148, Loss: 0.1843927800655365\n",
            "Epoch 44, Step 149, Loss: 0.2483735978603363\n",
            "Epoch 44, Step 150, Loss: 0.2835727035999298\n",
            "Epoch 44, Step 151, Loss: 0.37004634737968445\n",
            "Epoch 44, Step 152, Loss: 0.2607957422733307\n",
            "Epoch 44, Step 153, Loss: 0.2680225372314453\n",
            "Epoch 44, Step 154, Loss: 0.31972360610961914\n",
            "Epoch 44, Step 155, Loss: 0.2379777431488037\n",
            "Epoch 44, Step 156, Loss: 0.2753003239631653\n",
            "Epoch 44, Step 157, Loss: 0.24964949488639832\n",
            "Epoch 44, Step 158, Loss: 0.2525445222854614\n",
            "Epoch 44, Step 159, Loss: 0.28383442759513855\n",
            "Epoch 44, Step 160, Loss: 0.3169148564338684\n",
            "Epoch 44, Step 161, Loss: 0.31153619289398193\n",
            "Epoch 44, Step 162, Loss: 0.2801596522331238\n",
            "Epoch 44, Step 163, Loss: 0.3287661373615265\n",
            "Epoch 44, Step 164, Loss: 0.2661437392234802\n",
            "Epoch 44, Step 165, Loss: 0.31137263774871826\n",
            "Epoch 44, Step 166, Loss: 0.3110254406929016\n",
            "Epoch 44, Step 167, Loss: 0.2895861268043518\n",
            "Epoch 44, Step 168, Loss: 0.2524820864200592\n",
            "Epoch 44, Step 169, Loss: 0.2838784456253052\n",
            "Epoch 44, Step 170, Loss: 0.23072537779808044\n",
            "Epoch 44, Step 171, Loss: 0.21234475076198578\n",
            "Epoch 44, Step 172, Loss: 0.32642677426338196\n",
            "Epoch 44, Step 173, Loss: 0.31724825501441956\n",
            "Epoch 44, Step 174, Loss: 0.21387003362178802\n",
            "Epoch 44, Step 175, Loss: 0.21703654527664185\n",
            "Epoch 44, Step 176, Loss: 0.2097478061914444\n",
            "Epoch 44, Step 177, Loss: 0.26045259833335876\n",
            "Epoch 44, Step 178, Loss: 0.2716626822948456\n",
            "Epoch 44, Step 179, Loss: 0.17936241626739502\n",
            "Epoch 44, Step 180, Loss: 0.35228902101516724\n",
            "Epoch 44, Step 181, Loss: 0.233333021402359\n",
            "Epoch 44, Step 182, Loss: 0.28156670928001404\n",
            "Epoch 44, Step 183, Loss: 0.21123488247394562\n",
            "Epoch 44, Step 184, Loss: 0.29452821612358093\n",
            "Epoch 44, Step 185, Loss: 0.30486464500427246\n",
            "Epoch 44, Step 186, Loss: 0.2772136628627777\n",
            "Epoch 44, Step 187, Loss: 0.19460712373256683\n",
            "Epoch 44, Step 188, Loss: 0.2916269302368164\n",
            "Epoch 44, Step 189, Loss: 0.21925446391105652\n",
            "Epoch 44, Step 190, Loss: 0.12708310782909393\n",
            "Epoch 44, Step 191, Loss: 0.37690475583076477\n",
            "Epoch 44, Step 192, Loss: 0.2510496973991394\n",
            "Epoch 44, Step 193, Loss: 0.26468557119369507\n",
            "Epoch 44, Step 194, Loss: 0.21515868604183197\n",
            "Epoch 44, Step 195, Loss: 0.24035099148750305\n",
            "Epoch 44, Step 196, Loss: 0.17867590487003326\n",
            "Epoch 44, Step 197, Loss: 0.25540462136268616\n",
            "Epoch 44, Step 198, Loss: 0.2766169607639313\n",
            "Epoch 44, Step 199, Loss: 0.228088840842247\n",
            "Epoch 44, Step 200, Loss: 0.21812957525253296\n",
            "Epoch 44, Step 201, Loss: 0.23364490270614624\n",
            "Epoch 44, Step 202, Loss: 0.2568005323410034\n",
            "Epoch 44, Step 203, Loss: 0.21874266862869263\n",
            "Epoch 44, Step 204, Loss: 0.20072397589683533\n",
            "Epoch 44, Step 205, Loss: 0.27126574516296387\n",
            "Epoch 44, Step 206, Loss: 0.2588571310043335\n",
            "Epoch 44, Step 207, Loss: 0.14788569509983063\n",
            "Epoch 44, Step 208, Loss: 0.24846741557121277\n",
            "Epoch 44, Step 209, Loss: 0.39902356266975403\n",
            "Epoch 44, Step 210, Loss: 0.30923616886138916\n",
            "Epoch 44, Step 211, Loss: 0.15867821872234344\n",
            "Epoch 44, Step 212, Loss: 0.3063267767429352\n",
            "Epoch 44, Step 213, Loss: 0.34253573417663574\n",
            "Epoch 44, Step 214, Loss: 0.21104709804058075\n",
            "Epoch 44, Step 215, Loss: 0.23575459420681\n",
            "Epoch 44, Step 216, Loss: 0.3055543005466461\n",
            "Epoch 44, Step 217, Loss: 0.2688944935798645\n",
            "Epoch 44, Step 218, Loss: 0.2125399261713028\n",
            "Epoch 44, Step 219, Loss: 0.22128532826900482\n",
            "Epoch 44, Step 220, Loss: 0.33630695939064026\n",
            "Epoch 44, Step 221, Loss: 0.2105085551738739\n",
            "Epoch 44, Step 222, Loss: 0.27911943197250366\n",
            "Epoch 44, Step 223, Loss: 0.3588559031486511\n",
            "Epoch 44, Step 224, Loss: 0.29517829418182373\n",
            "Epoch 44, Step 225, Loss: 0.31814733147621155\n",
            "Epoch 44, Step 226, Loss: 0.23490314185619354\n",
            "Epoch 44, Step 227, Loss: 0.24866041541099548\n",
            "Epoch 44, Step 228, Loss: 0.2728104889392853\n",
            "Epoch 44, Step 229, Loss: 0.22191911935806274\n",
            "Epoch 44, Step 230, Loss: 0.2718660235404968\n",
            "Epoch 44, Step 231, Loss: 0.40277421474456787\n",
            "Epoch 44, Step 232, Loss: 0.3729681074619293\n",
            "Epoch 44, Step 233, Loss: 0.2987620234489441\n",
            "Epoch 44, Step 234, Loss: 0.2498374730348587\n",
            "Epoch 44, Step 235, Loss: 0.3186255395412445\n",
            "Epoch 44, Step 236, Loss: 0.24135294556617737\n",
            "Epoch 44, Step 237, Loss: 0.30330362915992737\n",
            "Epoch 44, Step 238, Loss: 0.22801119089126587\n",
            "Epoch 44, Step 239, Loss: 0.2940124571323395\n",
            "Epoch 44, Step 240, Loss: 0.34284213185310364\n",
            "Epoch 44, Step 241, Loss: 0.3746277689933777\n",
            "Epoch 44, Step 242, Loss: 0.26594778895378113\n",
            "Epoch 44, Step 243, Loss: 0.35903212428092957\n",
            "Epoch 44, Step 244, Loss: 0.2853960394859314\n",
            "Epoch 44, Step 245, Loss: 0.2496921271085739\n",
            "Epoch 44, Step 246, Loss: 0.295382559299469\n",
            "Epoch 44, Step 247, Loss: 0.36575111746788025\n",
            "Epoch 44, Step 248, Loss: 0.36425164341926575\n",
            "Epoch 44, Step 249, Loss: 0.26464414596557617\n",
            "Epoch 44, Step 250, Loss: 0.46130725741386414\n",
            "Epoch 44, Step 251, Loss: 0.19549503922462463\n",
            "Epoch 44, Step 252, Loss: 0.244104266166687\n",
            "Epoch 44, Step 253, Loss: 0.23965823650360107\n",
            "Epoch 44, Step 254, Loss: 0.3648548424243927\n",
            "Epoch 44, Step 255, Loss: 0.21078579127788544\n",
            "Epoch 44, Step 256, Loss: 0.214230477809906\n",
            "Epoch 44, Step 257, Loss: 0.4109111726284027\n",
            "Epoch 44, Step 258, Loss: 0.24614132940769196\n",
            "Epoch 44, Step 259, Loss: 0.30713868141174316\n",
            "Epoch 44, Step 260, Loss: 0.2730523943901062\n",
            "Epoch 44, Step 261, Loss: 0.2176731824874878\n",
            "Epoch 44, Step 262, Loss: 0.23807556927204132\n",
            "Epoch 44, Step 263, Loss: 0.21534207463264465\n",
            "Epoch 44, Step 264, Loss: 0.23625101149082184\n",
            "Epoch 44, Step 265, Loss: 0.346073716878891\n",
            "Epoch 44, Step 266, Loss: 0.3187800347805023\n",
            "Epoch 44, Step 267, Loss: 0.35692906379699707\n",
            "Epoch 44, Step 268, Loss: 0.4087408185005188\n",
            "Epoch 44, Step 269, Loss: 0.2774412930011749\n",
            "Epoch 44, Step 270, Loss: 0.2628541886806488\n",
            "Epoch 44, Step 271, Loss: 0.2470260113477707\n",
            "Epoch 44, Step 272, Loss: 0.26042360067367554\n",
            "Epoch 44, Step 273, Loss: 0.19838698208332062\n",
            "Epoch 44, Step 274, Loss: 0.467265784740448\n",
            "Epoch 44, Step 275, Loss: 0.2390824556350708\n",
            "Epoch 44, Step 276, Loss: 0.22248831391334534\n",
            "Epoch 44, Step 277, Loss: 0.28126126527786255\n",
            "Epoch 44, Step 278, Loss: 0.2097834348678589\n",
            "Epoch 44, Step 279, Loss: 0.3274551033973694\n",
            "Epoch 44, Step 280, Loss: 0.4040796756744385\n",
            "Epoch 44, Step 281, Loss: 0.32843324542045593\n",
            "Epoch 44, Step 282, Loss: 0.15523989498615265\n",
            "Epoch 44, Step 283, Loss: 0.3143863081932068\n",
            "Epoch 44, Step 284, Loss: 0.3224083185195923\n",
            "Epoch 44, Step 285, Loss: 0.2698633670806885\n",
            "Epoch 44, Step 286, Loss: 0.33435702323913574\n",
            "Epoch 44, Step 287, Loss: 0.23935121297836304\n",
            "Epoch 44, Step 288, Loss: 0.41300544142723083\n",
            "Epoch 44, Step 289, Loss: 0.33109670877456665\n",
            "Epoch 44, Step 290, Loss: 0.2737951874732971\n",
            "Epoch 44, Step 291, Loss: 0.2703263461589813\n",
            "Epoch 44, Step 292, Loss: 0.332631915807724\n",
            "Epoch 44, Step 293, Loss: 0.24579046666622162\n",
            "Epoch 44, Step 294, Loss: 0.308538556098938\n",
            "Epoch 44, Step 295, Loss: 0.20335114002227783\n",
            "Epoch 44, Step 296, Loss: 0.37302812933921814\n",
            "Epoch 44, Step 297, Loss: 0.24250131845474243\n",
            "Epoch 44, Step 298, Loss: 0.31687450408935547\n",
            "Epoch 44, Step 299, Loss: 0.35475194454193115\n",
            "Epoch 44, Step 300, Loss: 0.3439946174621582\n",
            "Epoch 44, Step 301, Loss: 0.2991660237312317\n",
            "Epoch 44, Step 302, Loss: 0.23702169954776764\n",
            "Epoch 44, Step 303, Loss: 0.2884930968284607\n",
            "Epoch 44, Step 304, Loss: 0.31275516748428345\n",
            "Epoch 44, Step 305, Loss: 0.26031795144081116\n",
            "Epoch 44, Step 306, Loss: 0.21196117997169495\n",
            "Epoch 44, Step 307, Loss: 0.27942711114883423\n",
            "Epoch 44, Step 308, Loss: 0.34479954838752747\n",
            "Epoch 44, Step 309, Loss: 0.2956695556640625\n",
            "Epoch 44, Step 310, Loss: 0.35539746284484863\n",
            "Epoch 44, Step 311, Loss: 0.2954941391944885\n",
            "Epoch 44, Step 312, Loss: 0.5746504068374634\n",
            "Epoch 44 end, avg train loss: 0.2782668708898008\n",
            "Epoch 44 end, avg val loss: 0.35706819990013217, accuracy: 88.72%\n",
            "Epoch 45, Step 0, Loss: 0.145034059882164\n",
            "Epoch 45, Step 1, Loss: 0.2906831204891205\n",
            "Epoch 45, Step 2, Loss: 0.21684642136096954\n",
            "Epoch 45, Step 3, Loss: 0.29546040296554565\n",
            "Epoch 45, Step 4, Loss: 0.22041460871696472\n",
            "Epoch 45, Step 5, Loss: 0.3815176784992218\n",
            "Epoch 45, Step 6, Loss: 0.30026549100875854\n",
            "Epoch 45, Step 7, Loss: 0.26153212785720825\n",
            "Epoch 45, Step 8, Loss: 0.2450769543647766\n",
            "Epoch 45, Step 9, Loss: 0.2386707067489624\n",
            "Epoch 45, Step 10, Loss: 0.16450965404510498\n",
            "Epoch 45, Step 11, Loss: 0.23211845755577087\n",
            "Epoch 45, Step 12, Loss: 0.3164123594760895\n",
            "Epoch 45, Step 13, Loss: 0.19468915462493896\n",
            "Epoch 45, Step 14, Loss: 0.30289024114608765\n",
            "Epoch 45, Step 15, Loss: 0.2798624634742737\n",
            "Epoch 45, Step 16, Loss: 0.1654098927974701\n",
            "Epoch 45, Step 17, Loss: 0.4059271514415741\n",
            "Epoch 45, Step 18, Loss: 0.31702616810798645\n",
            "Epoch 45, Step 19, Loss: 0.2208733707666397\n",
            "Epoch 45, Step 20, Loss: 0.2467462122440338\n",
            "Epoch 45, Step 21, Loss: 0.32471761107444763\n",
            "Epoch 45, Step 22, Loss: 0.24321028590202332\n",
            "Epoch 45, Step 23, Loss: 0.2983343005180359\n",
            "Epoch 45, Step 24, Loss: 0.28338927030563354\n",
            "Epoch 45, Step 25, Loss: 0.28357744216918945\n",
            "Epoch 45, Step 26, Loss: 0.29813310503959656\n",
            "Epoch 45, Step 27, Loss: 0.21220198273658752\n",
            "Epoch 45, Step 28, Loss: 0.18083405494689941\n",
            "Epoch 45, Step 29, Loss: 0.2595115602016449\n",
            "Epoch 45, Step 30, Loss: 0.2815309166908264\n",
            "Epoch 45, Step 31, Loss: 0.28669092059135437\n",
            "Epoch 45, Step 32, Loss: 0.4188806414604187\n",
            "Epoch 45, Step 33, Loss: 0.17278242111206055\n",
            "Epoch 45, Step 34, Loss: 0.214005246758461\n",
            "Epoch 45, Step 35, Loss: 0.22491371631622314\n",
            "Epoch 45, Step 36, Loss: 0.21313878893852234\n",
            "Epoch 45, Step 37, Loss: 0.2970825731754303\n",
            "Epoch 45, Step 38, Loss: 0.2672668397426605\n",
            "Epoch 45, Step 39, Loss: 0.22459976375102997\n",
            "Epoch 45, Step 40, Loss: 0.23328523337841034\n",
            "Epoch 45, Step 41, Loss: 0.24633462727069855\n",
            "Epoch 45, Step 42, Loss: 0.23855376243591309\n",
            "Epoch 45, Step 43, Loss: 0.23350374400615692\n",
            "Epoch 45, Step 44, Loss: 0.21114319562911987\n",
            "Epoch 45, Step 45, Loss: 0.37177574634552\n",
            "Epoch 45, Step 46, Loss: 0.22369875013828278\n",
            "Epoch 45, Step 47, Loss: 0.3219671845436096\n",
            "Epoch 45, Step 48, Loss: 0.33597686886787415\n",
            "Epoch 45, Step 49, Loss: 0.24634277820587158\n",
            "Epoch 45, Step 50, Loss: 0.32180488109588623\n",
            "Epoch 45, Step 51, Loss: 0.2564285397529602\n",
            "Epoch 45, Step 52, Loss: 0.286869078874588\n",
            "Epoch 45, Step 53, Loss: 0.33040741086006165\n",
            "Epoch 45, Step 54, Loss: 0.27256327867507935\n",
            "Epoch 45, Step 55, Loss: 0.22823557257652283\n",
            "Epoch 45, Step 56, Loss: 0.1607881635427475\n",
            "Epoch 45, Step 57, Loss: 0.1649511456489563\n",
            "Epoch 45, Step 58, Loss: 0.17562462389469147\n",
            "Epoch 45, Step 59, Loss: 0.191055029630661\n",
            "Epoch 45, Step 60, Loss: 0.30492591857910156\n",
            "Epoch 45, Step 61, Loss: 0.3181479573249817\n",
            "Epoch 45, Step 62, Loss: 0.22563141584396362\n",
            "Epoch 45, Step 63, Loss: 0.26674526929855347\n",
            "Epoch 45, Step 64, Loss: 0.324268102645874\n",
            "Epoch 45, Step 65, Loss: 0.2203691452741623\n",
            "Epoch 45, Step 66, Loss: 0.44727927446365356\n",
            "Epoch 45, Step 67, Loss: 0.2397017925977707\n",
            "Epoch 45, Step 68, Loss: 0.2525288164615631\n",
            "Epoch 45, Step 69, Loss: 0.39126619696617126\n",
            "Epoch 45, Step 70, Loss: 0.22338776290416718\n",
            "Epoch 45, Step 71, Loss: 0.28702908754348755\n",
            "Epoch 45, Step 72, Loss: 0.29136085510253906\n",
            "Epoch 45, Step 73, Loss: 0.2934452295303345\n",
            "Epoch 45, Step 74, Loss: 0.2037496417760849\n",
            "Epoch 45, Step 75, Loss: 0.15269781649112701\n",
            "Epoch 45, Step 76, Loss: 0.23654067516326904\n",
            "Epoch 45, Step 77, Loss: 0.2994466722011566\n",
            "Epoch 45, Step 78, Loss: 0.2439160794019699\n",
            "Epoch 45, Step 79, Loss: 0.2612331509590149\n",
            "Epoch 45, Step 80, Loss: 0.49661731719970703\n",
            "Epoch 45, Step 81, Loss: 0.36240026354789734\n",
            "Epoch 45, Step 82, Loss: 0.3818110525608063\n",
            "Epoch 45, Step 83, Loss: 0.12673382461071014\n",
            "Epoch 45, Step 84, Loss: 0.3111097812652588\n",
            "Epoch 45, Step 85, Loss: 0.17418256402015686\n",
            "Epoch 45, Step 86, Loss: 0.27997514605522156\n",
            "Epoch 45, Step 87, Loss: 0.1982085257768631\n",
            "Epoch 45, Step 88, Loss: 0.23287995159626007\n",
            "Epoch 45, Step 89, Loss: 0.21282057464122772\n",
            "Epoch 45, Step 90, Loss: 0.29089823365211487\n",
            "Epoch 45, Step 91, Loss: 0.35739192366600037\n",
            "Epoch 45, Step 92, Loss: 0.4113699197769165\n",
            "Epoch 45, Step 93, Loss: 0.27921220660209656\n",
            "Epoch 45, Step 94, Loss: 0.3320414125919342\n",
            "Epoch 45, Step 95, Loss: 0.19918113946914673\n",
            "Epoch 45, Step 96, Loss: 0.1726253777742386\n",
            "Epoch 45, Step 97, Loss: 0.278887003660202\n",
            "Epoch 45, Step 98, Loss: 0.4105698764324188\n",
            "Epoch 45, Step 99, Loss: 0.22166964411735535\n",
            "Epoch 45, Step 100, Loss: 0.25021010637283325\n",
            "Epoch 45, Step 101, Loss: 0.3045368790626526\n",
            "Epoch 45, Step 102, Loss: 0.2768179774284363\n",
            "Epoch 45, Step 103, Loss: 0.17790570855140686\n",
            "Epoch 45, Step 104, Loss: 0.20800523459911346\n",
            "Epoch 45, Step 105, Loss: 0.20053301751613617\n",
            "Epoch 45, Step 106, Loss: 0.19469688832759857\n",
            "Epoch 45, Step 107, Loss: 0.19156569242477417\n",
            "Epoch 45, Step 108, Loss: 0.17981421947479248\n",
            "Epoch 45, Step 109, Loss: 0.30808743834495544\n",
            "Epoch 45, Step 110, Loss: 0.1880781203508377\n",
            "Epoch 45, Step 111, Loss: 0.2991892099380493\n",
            "Epoch 45, Step 112, Loss: 0.2922024130821228\n",
            "Epoch 45, Step 113, Loss: 0.17565011978149414\n",
            "Epoch 45, Step 114, Loss: 0.3002171814441681\n",
            "Epoch 45, Step 115, Loss: 0.3257065415382385\n",
            "Epoch 45, Step 116, Loss: 0.22427794337272644\n",
            "Epoch 45, Step 117, Loss: 0.3400934040546417\n",
            "Epoch 45, Step 118, Loss: 0.3568004071712494\n",
            "Epoch 45, Step 119, Loss: 0.3034316301345825\n",
            "Epoch 45, Step 120, Loss: 0.269941121339798\n",
            "Epoch 45, Step 121, Loss: 0.27982357144355774\n",
            "Epoch 45, Step 122, Loss: 0.24815219640731812\n",
            "Epoch 45, Step 123, Loss: 0.2998749613761902\n",
            "Epoch 45, Step 124, Loss: 0.24123352766036987\n",
            "Epoch 45, Step 125, Loss: 0.2511494755744934\n",
            "Epoch 45, Step 126, Loss: 0.3221771717071533\n",
            "Epoch 45, Step 127, Loss: 0.2761855721473694\n",
            "Epoch 45, Step 128, Loss: 0.23468823730945587\n",
            "Epoch 45, Step 129, Loss: 0.24072404205799103\n",
            "Epoch 45, Step 130, Loss: 0.3886323869228363\n",
            "Epoch 45, Step 131, Loss: 0.28683361411094666\n",
            "Epoch 45, Step 132, Loss: 0.39627566933631897\n",
            "Epoch 45, Step 133, Loss: 0.3487122654914856\n",
            "Epoch 45, Step 134, Loss: 0.2700320780277252\n",
            "Epoch 45, Step 135, Loss: 0.23736312985420227\n",
            "Epoch 45, Step 136, Loss: 0.33605098724365234\n",
            "Epoch 45, Step 137, Loss: 0.22095029056072235\n",
            "Epoch 45, Step 138, Loss: 0.23496218025684357\n",
            "Epoch 45, Step 139, Loss: 0.35682186484336853\n",
            "Epoch 45, Step 140, Loss: 0.2343096286058426\n",
            "Epoch 45, Step 141, Loss: 0.31268081068992615\n",
            "Epoch 45, Step 142, Loss: 0.4662572741508484\n",
            "Epoch 45, Step 143, Loss: 0.24481339752674103\n",
            "Epoch 45, Step 144, Loss: 0.17701096832752228\n",
            "Epoch 45, Step 145, Loss: 0.33809149265289307\n",
            "Epoch 45, Step 146, Loss: 0.22286686301231384\n",
            "Epoch 45, Step 147, Loss: 0.30374038219451904\n",
            "Epoch 45, Step 148, Loss: 0.26101991534233093\n",
            "Epoch 45, Step 149, Loss: 0.3166466951370239\n",
            "Epoch 45, Step 150, Loss: 0.25983676314353943\n",
            "Epoch 45, Step 151, Loss: 0.28900396823883057\n",
            "Epoch 45, Step 152, Loss: 0.2393094152212143\n",
            "Epoch 45, Step 153, Loss: 0.30173981189727783\n",
            "Epoch 45, Step 154, Loss: 0.2571137845516205\n",
            "Epoch 45, Step 155, Loss: 0.2630850672721863\n",
            "Epoch 45, Step 156, Loss: 0.3828648626804352\n",
            "Epoch 45, Step 157, Loss: 0.26293104887008667\n",
            "Epoch 45, Step 158, Loss: 0.3408392071723938\n",
            "Epoch 45, Step 159, Loss: 0.4865700602531433\n",
            "Epoch 45, Step 160, Loss: 0.19437365233898163\n",
            "Epoch 45, Step 161, Loss: 0.1987374722957611\n",
            "Epoch 45, Step 162, Loss: 0.3265106678009033\n",
            "Epoch 45, Step 163, Loss: 0.2057206928730011\n",
            "Epoch 45, Step 164, Loss: 0.2895289957523346\n",
            "Epoch 45, Step 165, Loss: 0.35504841804504395\n",
            "Epoch 45, Step 166, Loss: 0.42149457335472107\n",
            "Epoch 45, Step 167, Loss: 0.30249783396720886\n",
            "Epoch 45, Step 168, Loss: 0.3477245569229126\n",
            "Epoch 45, Step 169, Loss: 0.42443931102752686\n",
            "Epoch 45, Step 170, Loss: 0.2603066563606262\n",
            "Epoch 45, Step 171, Loss: 0.2700045704841614\n",
            "Epoch 45, Step 172, Loss: 0.27841341495513916\n",
            "Epoch 45, Step 173, Loss: 0.16305974125862122\n",
            "Epoch 45, Step 174, Loss: 0.21216098964214325\n",
            "Epoch 45, Step 175, Loss: 0.27069100737571716\n",
            "Epoch 45, Step 176, Loss: 0.273280531167984\n",
            "Epoch 45, Step 177, Loss: 0.2667907774448395\n",
            "Epoch 45, Step 178, Loss: 0.24967747926712036\n",
            "Epoch 45, Step 179, Loss: 0.18160253763198853\n",
            "Epoch 45, Step 180, Loss: 0.36840662360191345\n",
            "Epoch 45, Step 181, Loss: 0.35307958722114563\n",
            "Epoch 45, Step 182, Loss: 0.2387479543685913\n",
            "Epoch 45, Step 183, Loss: 0.3119449317455292\n",
            "Epoch 45, Step 184, Loss: 0.21923430263996124\n",
            "Epoch 45, Step 185, Loss: 0.3717966377735138\n",
            "Epoch 45, Step 186, Loss: 0.27489838004112244\n",
            "Epoch 45, Step 187, Loss: 0.3295605182647705\n",
            "Epoch 45, Step 188, Loss: 0.2576069235801697\n",
            "Epoch 45, Step 189, Loss: 0.2813185155391693\n",
            "Epoch 45, Step 190, Loss: 0.3859223425388336\n",
            "Epoch 45, Step 191, Loss: 0.2729358971118927\n",
            "Epoch 45, Step 192, Loss: 0.2040659487247467\n",
            "Epoch 45, Step 193, Loss: 0.19331583380699158\n",
            "Epoch 45, Step 194, Loss: 0.3276427984237671\n",
            "Epoch 45, Step 195, Loss: 0.30813246965408325\n",
            "Epoch 45, Step 196, Loss: 0.271027535200119\n",
            "Epoch 45, Step 197, Loss: 0.30865129828453064\n",
            "Epoch 45, Step 198, Loss: 0.23658856749534607\n",
            "Epoch 45, Step 199, Loss: 0.29185858368873596\n",
            "Epoch 45, Step 200, Loss: 0.32580724358558655\n",
            "Epoch 45, Step 201, Loss: 0.1648484170436859\n",
            "Epoch 45, Step 202, Loss: 0.2242548167705536\n",
            "Epoch 45, Step 203, Loss: 0.2609144151210785\n",
            "Epoch 45, Step 204, Loss: 0.2898411154747009\n",
            "Epoch 45, Step 205, Loss: 0.24026033282279968\n",
            "Epoch 45, Step 206, Loss: 0.14860276877880096\n",
            "Epoch 45, Step 207, Loss: 0.23237872123718262\n",
            "Epoch 45, Step 208, Loss: 0.24692849814891815\n",
            "Epoch 45, Step 209, Loss: 0.3121822476387024\n",
            "Epoch 45, Step 210, Loss: 0.26466473937034607\n",
            "Epoch 45, Step 211, Loss: 0.32518836855888367\n",
            "Epoch 45, Step 212, Loss: 0.25024718046188354\n",
            "Epoch 45, Step 213, Loss: 0.3303258717060089\n",
            "Epoch 45, Step 214, Loss: 0.23951157927513123\n",
            "Epoch 45, Step 215, Loss: 0.35468149185180664\n",
            "Epoch 45, Step 216, Loss: 0.27692750096321106\n",
            "Epoch 45, Step 217, Loss: 0.31227779388427734\n",
            "Epoch 45, Step 218, Loss: 0.3840729296207428\n",
            "Epoch 45, Step 219, Loss: 0.2646371126174927\n",
            "Epoch 45, Step 220, Loss: 0.2769942581653595\n",
            "Epoch 45, Step 221, Loss: 0.2823479473590851\n",
            "Epoch 45, Step 222, Loss: 0.27122917771339417\n",
            "Epoch 45, Step 223, Loss: 0.3244164288043976\n",
            "Epoch 45, Step 224, Loss: 0.2760728895664215\n",
            "Epoch 45, Step 225, Loss: 0.2609018385410309\n",
            "Epoch 45, Step 226, Loss: 0.25288164615631104\n",
            "Epoch 45, Step 227, Loss: 0.2444232553243637\n",
            "Epoch 45, Step 228, Loss: 0.3115719258785248\n",
            "Epoch 45, Step 229, Loss: 0.270678848028183\n",
            "Epoch 45, Step 230, Loss: 0.2392578423023224\n",
            "Epoch 45, Step 231, Loss: 0.250813752412796\n",
            "Epoch 45, Step 232, Loss: 0.2971557080745697\n",
            "Epoch 45, Step 233, Loss: 0.29666876792907715\n",
            "Epoch 45, Step 234, Loss: 0.2198459655046463\n",
            "Epoch 45, Step 235, Loss: 0.25588151812553406\n",
            "Epoch 45, Step 236, Loss: 0.33350372314453125\n",
            "Epoch 45, Step 237, Loss: 0.22458681464195251\n",
            "Epoch 45, Step 238, Loss: 0.3116315007209778\n",
            "Epoch 45, Step 239, Loss: 0.2949925661087036\n",
            "Epoch 45, Step 240, Loss: 0.25369709730148315\n",
            "Epoch 45, Step 241, Loss: 0.28338488936424255\n",
            "Epoch 45, Step 242, Loss: 0.2719356417655945\n",
            "Epoch 45, Step 243, Loss: 0.461254358291626\n",
            "Epoch 45, Step 244, Loss: 0.17386724054813385\n",
            "Epoch 45, Step 245, Loss: 0.23066094517707825\n",
            "Epoch 45, Step 246, Loss: 0.26455822587013245\n",
            "Epoch 45, Step 247, Loss: 0.27448326349258423\n",
            "Epoch 45, Step 248, Loss: 0.22099316120147705\n",
            "Epoch 45, Step 249, Loss: 0.26408278942108154\n",
            "Epoch 45, Step 250, Loss: 0.18918423354625702\n",
            "Epoch 45, Step 251, Loss: 0.22643408179283142\n",
            "Epoch 45, Step 252, Loss: 0.18085451424121857\n",
            "Epoch 45, Step 253, Loss: 0.26847022771835327\n",
            "Epoch 45, Step 254, Loss: 0.3093195855617523\n",
            "Epoch 45, Step 255, Loss: 0.21436215937137604\n",
            "Epoch 45, Step 256, Loss: 0.331354558467865\n",
            "Epoch 45, Step 257, Loss: 0.22478149831295013\n",
            "Epoch 45, Step 258, Loss: 0.26551806926727295\n",
            "Epoch 45, Step 259, Loss: 0.21144096553325653\n",
            "Epoch 45, Step 260, Loss: 0.33921968936920166\n",
            "Epoch 45, Step 261, Loss: 0.2817402482032776\n",
            "Epoch 45, Step 262, Loss: 0.22829215228557587\n",
            "Epoch 45, Step 263, Loss: 0.3574884533882141\n",
            "Epoch 45, Step 264, Loss: 0.20554876327514648\n",
            "Epoch 45, Step 265, Loss: 0.3492533564567566\n",
            "Epoch 45, Step 266, Loss: 0.22833159565925598\n",
            "Epoch 45, Step 267, Loss: 0.3911077380180359\n",
            "Epoch 45, Step 268, Loss: 0.1796238124370575\n",
            "Epoch 45, Step 269, Loss: 0.24863667786121368\n",
            "Epoch 45, Step 270, Loss: 0.35014185309410095\n",
            "Epoch 45, Step 271, Loss: 0.24629226326942444\n",
            "Epoch 45, Step 272, Loss: 0.32013434171676636\n",
            "Epoch 45, Step 273, Loss: 0.2948589622974396\n",
            "Epoch 45, Step 274, Loss: 0.2546335756778717\n",
            "Epoch 45, Step 275, Loss: 0.2445177286863327\n",
            "Epoch 45, Step 276, Loss: 0.38370728492736816\n",
            "Epoch 45, Step 277, Loss: 0.18843118846416473\n",
            "Epoch 45, Step 278, Loss: 0.32133379578590393\n",
            "Epoch 45, Step 279, Loss: 0.17822924256324768\n",
            "Epoch 45, Step 280, Loss: 0.37797537446022034\n",
            "Epoch 45, Step 281, Loss: 0.2743934392929077\n",
            "Epoch 45, Step 282, Loss: 0.30683547258377075\n",
            "Epoch 45, Step 283, Loss: 0.3028617203235626\n",
            "Epoch 45, Step 284, Loss: 0.16054844856262207\n",
            "Epoch 45, Step 285, Loss: 0.27043718099594116\n",
            "Epoch 45, Step 286, Loss: 0.2858125865459442\n",
            "Epoch 45, Step 287, Loss: 0.22334742546081543\n",
            "Epoch 45, Step 288, Loss: 0.27468904852867126\n",
            "Epoch 45, Step 289, Loss: 0.29207709431648254\n",
            "Epoch 45, Step 290, Loss: 0.3368697166442871\n",
            "Epoch 45, Step 291, Loss: 0.1987648606300354\n",
            "Epoch 45, Step 292, Loss: 0.30193477869033813\n",
            "Epoch 45, Step 293, Loss: 0.31300029158592224\n",
            "Epoch 45, Step 294, Loss: 0.22779010236263275\n",
            "Epoch 45, Step 295, Loss: 0.3137240409851074\n",
            "Epoch 45, Step 296, Loss: 0.2534518241882324\n",
            "Epoch 45, Step 297, Loss: 0.2945912778377533\n",
            "Epoch 45, Step 298, Loss: 0.23218649625778198\n",
            "Epoch 45, Step 299, Loss: 0.26582270860671997\n",
            "Epoch 45, Step 300, Loss: 0.3500916361808777\n",
            "Epoch 45, Step 301, Loss: 0.32931578159332275\n",
            "Epoch 45, Step 302, Loss: 0.26194894313812256\n",
            "Epoch 45, Step 303, Loss: 0.3113836944103241\n",
            "Epoch 45, Step 304, Loss: 0.2008729875087738\n",
            "Epoch 45, Step 305, Loss: 0.1808994859457016\n",
            "Epoch 45, Step 306, Loss: 0.2809656262397766\n",
            "Epoch 45, Step 307, Loss: 0.2967331111431122\n",
            "Epoch 45, Step 308, Loss: 0.27013924717903137\n",
            "Epoch 45, Step 309, Loss: 0.2707008123397827\n",
            "Epoch 45, Step 310, Loss: 0.326349675655365\n",
            "Epoch 45, Step 311, Loss: 0.32388171553611755\n",
            "Epoch 45, Step 312, Loss: 0.37249353528022766\n",
            "Epoch 45 end, avg train loss: 0.27389689989554616\n",
            "Epoch 45 end, avg val loss: 0.36448920131484164, accuracy: 88.73%\n",
            "Epoch 46, Step 0, Loss: 0.36788931488990784\n",
            "Epoch 46, Step 1, Loss: 0.2466743141412735\n",
            "Epoch 46, Step 2, Loss: 0.25264406204223633\n",
            "Epoch 46, Step 3, Loss: 0.25823265314102173\n",
            "Epoch 46, Step 4, Loss: 0.2391405999660492\n",
            "Epoch 46, Step 5, Loss: 0.2804703712463379\n",
            "Epoch 46, Step 6, Loss: 0.3738935589790344\n",
            "Epoch 46, Step 7, Loss: 0.16768890619277954\n",
            "Epoch 46, Step 8, Loss: 0.3752334713935852\n",
            "Epoch 46, Step 9, Loss: 0.18775101006031036\n",
            "Epoch 46, Step 10, Loss: 0.18417154252529144\n",
            "Epoch 46, Step 11, Loss: 0.20013147592544556\n",
            "Epoch 46, Step 12, Loss: 0.3275299072265625\n",
            "Epoch 46, Step 13, Loss: 0.17881092429161072\n",
            "Epoch 46, Step 14, Loss: 0.1579974740743637\n",
            "Epoch 46, Step 15, Loss: 0.43941590189933777\n",
            "Epoch 46, Step 16, Loss: 0.23277024924755096\n",
            "Epoch 46, Step 17, Loss: 0.30981969833374023\n",
            "Epoch 46, Step 18, Loss: 0.2723805606365204\n",
            "Epoch 46, Step 19, Loss: 0.21390487253665924\n",
            "Epoch 46, Step 20, Loss: 0.19875575602054596\n",
            "Epoch 46, Step 21, Loss: 0.268598347902298\n",
            "Epoch 46, Step 22, Loss: 0.24665765464305878\n",
            "Epoch 46, Step 23, Loss: 0.27329230308532715\n",
            "Epoch 46, Step 24, Loss: 0.2620787024497986\n",
            "Epoch 46, Step 25, Loss: 0.24786654114723206\n",
            "Epoch 46, Step 26, Loss: 0.3095149099826813\n",
            "Epoch 46, Step 27, Loss: 0.322566419839859\n",
            "Epoch 46, Step 28, Loss: 0.30758053064346313\n",
            "Epoch 46, Step 29, Loss: 0.24503642320632935\n",
            "Epoch 46, Step 30, Loss: 0.3707669973373413\n",
            "Epoch 46, Step 31, Loss: 0.2582656443119049\n",
            "Epoch 46, Step 32, Loss: 0.4109213948249817\n",
            "Epoch 46, Step 33, Loss: 0.3168209195137024\n",
            "Epoch 46, Step 34, Loss: 0.25367170572280884\n",
            "Epoch 46, Step 35, Loss: 0.21488012373447418\n",
            "Epoch 46, Step 36, Loss: 0.29548102617263794\n",
            "Epoch 46, Step 37, Loss: 0.22186289727687836\n",
            "Epoch 46, Step 38, Loss: 0.2639288902282715\n",
            "Epoch 46, Step 39, Loss: 0.36043623089790344\n",
            "Epoch 46, Step 40, Loss: 0.2763020694255829\n",
            "Epoch 46, Step 41, Loss: 0.35839349031448364\n",
            "Epoch 46, Step 42, Loss: 0.2773611843585968\n",
            "Epoch 46, Step 43, Loss: 0.2222823053598404\n",
            "Epoch 46, Step 44, Loss: 0.2234933078289032\n",
            "Epoch 46, Step 45, Loss: 0.18671385943889618\n",
            "Epoch 46, Step 46, Loss: 0.32060539722442627\n",
            "Epoch 46, Step 47, Loss: 0.18673665821552277\n",
            "Epoch 46, Step 48, Loss: 0.24753552675247192\n",
            "Epoch 46, Step 49, Loss: 0.21157774329185486\n",
            "Epoch 46, Step 50, Loss: 0.29855799674987793\n",
            "Epoch 46, Step 51, Loss: 0.4094965159893036\n",
            "Epoch 46, Step 52, Loss: 0.20886404812335968\n",
            "Epoch 46, Step 53, Loss: 0.2663528025150299\n",
            "Epoch 46, Step 54, Loss: 0.3127841353416443\n",
            "Epoch 46, Step 55, Loss: 0.41340434551239014\n",
            "Epoch 46, Step 56, Loss: 0.23212075233459473\n",
            "Epoch 46, Step 57, Loss: 0.3040600121021271\n",
            "Epoch 46, Step 58, Loss: 0.15934500098228455\n",
            "Epoch 46, Step 59, Loss: 0.2509353756904602\n",
            "Epoch 46, Step 60, Loss: 0.22249680757522583\n",
            "Epoch 46, Step 61, Loss: 0.3684762716293335\n",
            "Epoch 46, Step 62, Loss: 0.27658942341804504\n",
            "Epoch 46, Step 63, Loss: 0.13555248081684113\n",
            "Epoch 46, Step 64, Loss: 0.37939223647117615\n",
            "Epoch 46, Step 65, Loss: 0.2958804965019226\n",
            "Epoch 46, Step 66, Loss: 0.2881115972995758\n",
            "Epoch 46, Step 67, Loss: 0.25423410534858704\n",
            "Epoch 46, Step 68, Loss: 0.23888935148715973\n",
            "Epoch 46, Step 69, Loss: 0.27967748045921326\n",
            "Epoch 46, Step 70, Loss: 0.18347150087356567\n",
            "Epoch 46, Step 71, Loss: 0.2834928035736084\n",
            "Epoch 46, Step 72, Loss: 0.29521363973617554\n",
            "Epoch 46, Step 73, Loss: 0.2738104462623596\n",
            "Epoch 46, Step 74, Loss: 0.2709078788757324\n",
            "Epoch 46, Step 75, Loss: 0.3235274851322174\n",
            "Epoch 46, Step 76, Loss: 0.25291764736175537\n",
            "Epoch 46, Step 77, Loss: 0.21792419254779816\n",
            "Epoch 46, Step 78, Loss: 0.2995499074459076\n",
            "Epoch 46, Step 79, Loss: 0.25066033005714417\n",
            "Epoch 46, Step 80, Loss: 0.17354026436805725\n",
            "Epoch 46, Step 81, Loss: 0.21274302899837494\n",
            "Epoch 46, Step 82, Loss: 0.25336942076683044\n",
            "Epoch 46, Step 83, Loss: 0.2641094923019409\n",
            "Epoch 46, Step 84, Loss: 0.32972168922424316\n",
            "Epoch 46, Step 85, Loss: 0.21835213899612427\n",
            "Epoch 46, Step 86, Loss: 0.3363898992538452\n",
            "Epoch 46, Step 87, Loss: 0.3517756164073944\n",
            "Epoch 46, Step 88, Loss: 0.19735072553157806\n",
            "Epoch 46, Step 89, Loss: 0.20393171906471252\n",
            "Epoch 46, Step 90, Loss: 0.2356511354446411\n",
            "Epoch 46, Step 91, Loss: 0.3226025402545929\n",
            "Epoch 46, Step 92, Loss: 0.20535939931869507\n",
            "Epoch 46, Step 93, Loss: 0.31140056252479553\n",
            "Epoch 46, Step 94, Loss: 0.38920858502388\n",
            "Epoch 46, Step 95, Loss: 0.3175341784954071\n",
            "Epoch 46, Step 96, Loss: 0.234488844871521\n",
            "Epoch 46, Step 97, Loss: 0.14339332282543182\n",
            "Epoch 46, Step 98, Loss: 0.33109691739082336\n",
            "Epoch 46, Step 99, Loss: 0.24738122522830963\n",
            "Epoch 46, Step 100, Loss: 0.39558231830596924\n",
            "Epoch 46, Step 101, Loss: 0.21461334824562073\n",
            "Epoch 46, Step 102, Loss: 0.3495003283023834\n",
            "Epoch 46, Step 103, Loss: 0.2770359516143799\n",
            "Epoch 46, Step 104, Loss: 0.20668095350265503\n",
            "Epoch 46, Step 105, Loss: 0.2547597885131836\n",
            "Epoch 46, Step 106, Loss: 0.2110585868358612\n",
            "Epoch 46, Step 107, Loss: 0.4287149906158447\n",
            "Epoch 46, Step 108, Loss: 0.24589212238788605\n",
            "Epoch 46, Step 109, Loss: 0.2136414647102356\n",
            "Epoch 46, Step 110, Loss: 0.22324855625629425\n",
            "Epoch 46, Step 111, Loss: 0.17432323098182678\n",
            "Epoch 46, Step 112, Loss: 0.23886393010616302\n",
            "Epoch 46, Step 113, Loss: 0.2964722812175751\n",
            "Epoch 46, Step 114, Loss: 0.21957385540008545\n",
            "Epoch 46, Step 115, Loss: 0.1519722193479538\n",
            "Epoch 46, Step 116, Loss: 0.2574808895587921\n",
            "Epoch 46, Step 117, Loss: 0.21274229884147644\n",
            "Epoch 46, Step 118, Loss: 0.16725584864616394\n",
            "Epoch 46, Step 119, Loss: 0.25355806946754456\n",
            "Epoch 46, Step 120, Loss: 0.29788216948509216\n",
            "Epoch 46, Step 121, Loss: 0.2324231117963791\n",
            "Epoch 46, Step 122, Loss: 0.4361572563648224\n",
            "Epoch 46, Step 123, Loss: 0.26744455099105835\n",
            "Epoch 46, Step 124, Loss: 0.20915928483009338\n",
            "Epoch 46, Step 125, Loss: 0.23050817847251892\n",
            "Epoch 46, Step 126, Loss: 0.24398736655712128\n",
            "Epoch 46, Step 127, Loss: 0.27625441551208496\n",
            "Epoch 46, Step 128, Loss: 0.21734879910945892\n",
            "Epoch 46, Step 129, Loss: 0.37224143743515015\n",
            "Epoch 46, Step 130, Loss: 0.22066500782966614\n",
            "Epoch 46, Step 131, Loss: 0.21340212225914001\n",
            "Epoch 46, Step 132, Loss: 0.2053394317626953\n",
            "Epoch 46, Step 133, Loss: 0.24731233716011047\n",
            "Epoch 46, Step 134, Loss: 0.30073803663253784\n",
            "Epoch 46, Step 135, Loss: 0.24506822228431702\n",
            "Epoch 46, Step 136, Loss: 0.26275500655174255\n",
            "Epoch 46, Step 137, Loss: 0.2526701092720032\n",
            "Epoch 46, Step 138, Loss: 0.2161918431520462\n",
            "Epoch 46, Step 139, Loss: 0.3233965039253235\n",
            "Epoch 46, Step 140, Loss: 0.26344600319862366\n",
            "Epoch 46, Step 141, Loss: 0.28222692012786865\n",
            "Epoch 46, Step 142, Loss: 0.32197535037994385\n",
            "Epoch 46, Step 143, Loss: 0.315102756023407\n",
            "Epoch 46, Step 144, Loss: 0.3985219895839691\n",
            "Epoch 46, Step 145, Loss: 0.27839452028274536\n",
            "Epoch 46, Step 146, Loss: 0.3203224241733551\n",
            "Epoch 46, Step 147, Loss: 0.2478518933057785\n",
            "Epoch 46, Step 148, Loss: 0.3264053463935852\n",
            "Epoch 46, Step 149, Loss: 0.2903748154640198\n",
            "Epoch 46, Step 150, Loss: 0.326299786567688\n",
            "Epoch 46, Step 151, Loss: 0.24564124643802643\n",
            "Epoch 46, Step 152, Loss: 0.2524105906486511\n",
            "Epoch 46, Step 153, Loss: 0.19498613476753235\n",
            "Epoch 46, Step 154, Loss: 0.2878096103668213\n",
            "Epoch 46, Step 155, Loss: 0.2865128219127655\n",
            "Epoch 46, Step 156, Loss: 0.31483694911003113\n",
            "Epoch 46, Step 157, Loss: 0.471386581659317\n",
            "Epoch 46, Step 158, Loss: 0.1660858690738678\n",
            "Epoch 46, Step 159, Loss: 0.29811206459999084\n",
            "Epoch 46, Step 160, Loss: 0.23873595893383026\n",
            "Epoch 46, Step 161, Loss: 0.38284850120544434\n",
            "Epoch 46, Step 162, Loss: 0.2926810681819916\n",
            "Epoch 46, Step 163, Loss: 0.26507365703582764\n",
            "Epoch 46, Step 164, Loss: 0.4057927131652832\n",
            "Epoch 46, Step 165, Loss: 0.26757603883743286\n",
            "Epoch 46, Step 166, Loss: 0.18063753843307495\n",
            "Epoch 46, Step 167, Loss: 0.23058710992336273\n",
            "Epoch 46, Step 168, Loss: 0.23775605857372284\n",
            "Epoch 46, Step 169, Loss: 0.3328823745250702\n",
            "Epoch 46, Step 170, Loss: 0.15560704469680786\n",
            "Epoch 46, Step 171, Loss: 0.269523948431015\n",
            "Epoch 46, Step 172, Loss: 0.38018444180488586\n",
            "Epoch 46, Step 173, Loss: 0.1987273097038269\n",
            "Epoch 46, Step 174, Loss: 0.18774662911891937\n",
            "Epoch 46, Step 175, Loss: 0.294021874666214\n",
            "Epoch 46, Step 176, Loss: 0.3142825961112976\n",
            "Epoch 46, Step 177, Loss: 0.32985422015190125\n",
            "Epoch 46, Step 178, Loss: 0.3056826889514923\n",
            "Epoch 46, Step 179, Loss: 0.2955784797668457\n",
            "Epoch 46, Step 180, Loss: 0.27619901299476624\n",
            "Epoch 46, Step 181, Loss: 0.29727038741111755\n",
            "Epoch 46, Step 182, Loss: 0.3380592167377472\n",
            "Epoch 46, Step 183, Loss: 0.23913778364658356\n",
            "Epoch 46, Step 184, Loss: 0.29327619075775146\n",
            "Epoch 46, Step 185, Loss: 0.2719452977180481\n",
            "Epoch 46, Step 186, Loss: 0.3363803029060364\n",
            "Epoch 46, Step 187, Loss: 0.23118163645267487\n",
            "Epoch 46, Step 188, Loss: 0.26229315996170044\n",
            "Epoch 46, Step 189, Loss: 0.22558537125587463\n",
            "Epoch 46, Step 190, Loss: 0.32430729269981384\n",
            "Epoch 46, Step 191, Loss: 0.27204927802085876\n",
            "Epoch 46, Step 192, Loss: 0.28677916526794434\n",
            "Epoch 46, Step 193, Loss: 0.31769490242004395\n",
            "Epoch 46, Step 194, Loss: 0.1604463756084442\n",
            "Epoch 46, Step 195, Loss: 0.23282207548618317\n",
            "Epoch 46, Step 196, Loss: 0.34507855772972107\n",
            "Epoch 46, Step 197, Loss: 0.22071948647499084\n",
            "Epoch 46, Step 198, Loss: 0.23274655640125275\n",
            "Epoch 46, Step 199, Loss: 0.2927320599555969\n",
            "Epoch 46, Step 200, Loss: 0.3628961145877838\n",
            "Epoch 46, Step 201, Loss: 0.29621103405952454\n",
            "Epoch 46, Step 202, Loss: 0.3845519423484802\n",
            "Epoch 46, Step 203, Loss: 0.19394026696681976\n",
            "Epoch 46, Step 204, Loss: 0.22078131139278412\n",
            "Epoch 46, Step 205, Loss: 0.21219691634178162\n",
            "Epoch 46, Step 206, Loss: 0.33793869614601135\n",
            "Epoch 46, Step 207, Loss: 0.2196415662765503\n",
            "Epoch 46, Step 208, Loss: 0.28490927815437317\n",
            "Epoch 46, Step 209, Loss: 0.4263577461242676\n",
            "Epoch 46, Step 210, Loss: 0.38836097717285156\n",
            "Epoch 46, Step 211, Loss: 0.21806871891021729\n",
            "Epoch 46, Step 212, Loss: 0.2731633186340332\n",
            "Epoch 46, Step 213, Loss: 0.29689744114875793\n",
            "Epoch 46, Step 214, Loss: 0.285965234041214\n",
            "Epoch 46, Step 215, Loss: 0.2639137804508209\n",
            "Epoch 46, Step 216, Loss: 0.2942339777946472\n",
            "Epoch 46, Step 217, Loss: 0.3678937554359436\n",
            "Epoch 46, Step 218, Loss: 0.27580374479293823\n",
            "Epoch 46, Step 219, Loss: 0.15498092770576477\n",
            "Epoch 46, Step 220, Loss: 0.3289228677749634\n",
            "Epoch 46, Step 221, Loss: 0.28246986865997314\n",
            "Epoch 46, Step 222, Loss: 0.24196571111679077\n",
            "Epoch 46, Step 223, Loss: 0.22693562507629395\n",
            "Epoch 46, Step 224, Loss: 0.22764791548252106\n",
            "Epoch 46, Step 225, Loss: 0.1725752204656601\n",
            "Epoch 46, Step 226, Loss: 0.20441049337387085\n",
            "Epoch 46, Step 227, Loss: 0.17165647447109222\n",
            "Epoch 46, Step 228, Loss: 0.25233548879623413\n",
            "Epoch 46, Step 229, Loss: 0.38209813833236694\n",
            "Epoch 46, Step 230, Loss: 0.24990013241767883\n",
            "Epoch 46, Step 231, Loss: 0.2975992262363434\n",
            "Epoch 46, Step 232, Loss: 0.21142645180225372\n",
            "Epoch 46, Step 233, Loss: 0.30937328934669495\n",
            "Epoch 46, Step 234, Loss: 0.19312673807144165\n",
            "Epoch 46, Step 235, Loss: 0.22605133056640625\n",
            "Epoch 46, Step 236, Loss: 0.15532267093658447\n",
            "Epoch 46, Step 237, Loss: 0.39136558771133423\n",
            "Epoch 46, Step 238, Loss: 0.23092634975910187\n",
            "Epoch 46, Step 239, Loss: 0.23752276599407196\n",
            "Epoch 46, Step 240, Loss: 0.3008926510810852\n",
            "Epoch 46, Step 241, Loss: 0.3322192430496216\n",
            "Epoch 46, Step 242, Loss: 0.34203824400901794\n",
            "Epoch 46, Step 243, Loss: 0.35576507449150085\n",
            "Epoch 46, Step 244, Loss: 0.24489723145961761\n",
            "Epoch 46, Step 245, Loss: 0.3305746912956238\n",
            "Epoch 46, Step 246, Loss: 0.29591524600982666\n",
            "Epoch 46, Step 247, Loss: 0.35647013783454895\n",
            "Epoch 46, Step 248, Loss: 0.25170210003852844\n",
            "Epoch 46, Step 249, Loss: 0.23950231075286865\n",
            "Epoch 46, Step 250, Loss: 0.29427796602249146\n",
            "Epoch 46, Step 251, Loss: 0.23678717017173767\n",
            "Epoch 46, Step 252, Loss: 0.3976348638534546\n",
            "Epoch 46, Step 253, Loss: 0.26364338397979736\n",
            "Epoch 46, Step 254, Loss: 0.1736980378627777\n",
            "Epoch 46, Step 255, Loss: 0.22615200281143188\n",
            "Epoch 46, Step 256, Loss: 0.31730061769485474\n",
            "Epoch 46, Step 257, Loss: 0.34824350476264954\n",
            "Epoch 46, Step 258, Loss: 0.1966625601053238\n",
            "Epoch 46, Step 259, Loss: 0.16309969127178192\n",
            "Epoch 46, Step 260, Loss: 0.16514605283737183\n",
            "Epoch 46, Step 261, Loss: 0.34247270226478577\n",
            "Epoch 46, Step 262, Loss: 0.20672300457954407\n",
            "Epoch 46, Step 263, Loss: 0.2149210423231125\n",
            "Epoch 46, Step 264, Loss: 0.169007807970047\n",
            "Epoch 46, Step 265, Loss: 0.18987634778022766\n",
            "Epoch 46, Step 266, Loss: 0.17853467166423798\n",
            "Epoch 46, Step 267, Loss: 0.3070639967918396\n",
            "Epoch 46, Step 268, Loss: 0.2837071418762207\n",
            "Epoch 46, Step 269, Loss: 0.21616187691688538\n",
            "Epoch 46, Step 270, Loss: 0.17808546125888824\n",
            "Epoch 46, Step 271, Loss: 0.2647190988063812\n",
            "Epoch 46, Step 272, Loss: 0.15625014901161194\n",
            "Epoch 46, Step 273, Loss: 0.3750379979610443\n",
            "Epoch 46, Step 274, Loss: 0.34372609853744507\n",
            "Epoch 46, Step 275, Loss: 0.26622456312179565\n",
            "Epoch 46, Step 276, Loss: 0.1922115832567215\n",
            "Epoch 46, Step 277, Loss: 0.34296879172325134\n",
            "Epoch 46, Step 278, Loss: 0.35879573225975037\n",
            "Epoch 46, Step 279, Loss: 0.3078508973121643\n",
            "Epoch 46, Step 280, Loss: 0.19433775544166565\n",
            "Epoch 46, Step 281, Loss: 0.22750037908554077\n",
            "Epoch 46, Step 282, Loss: 0.35593706369400024\n",
            "Epoch 46, Step 283, Loss: 0.22624535858631134\n",
            "Epoch 46, Step 284, Loss: 0.2118753045797348\n",
            "Epoch 46, Step 285, Loss: 0.18298090994358063\n",
            "Epoch 46, Step 286, Loss: 0.18307159841060638\n",
            "Epoch 46, Step 287, Loss: 0.2577332556247711\n",
            "Epoch 46, Step 288, Loss: 0.32918640971183777\n",
            "Epoch 46, Step 289, Loss: 0.1591554880142212\n",
            "Epoch 46, Step 290, Loss: 0.25905242562294006\n",
            "Epoch 46, Step 291, Loss: 0.18080152571201324\n",
            "Epoch 46, Step 292, Loss: 0.24947324395179749\n",
            "Epoch 46, Step 293, Loss: 0.328893780708313\n",
            "Epoch 46, Step 294, Loss: 0.2981884181499481\n",
            "Epoch 46, Step 295, Loss: 0.24495695531368256\n",
            "Epoch 46, Step 296, Loss: 0.17983855307102203\n",
            "Epoch 46, Step 297, Loss: 0.2732883393764496\n",
            "Epoch 46, Step 298, Loss: 0.2772405445575714\n",
            "Epoch 46, Step 299, Loss: 0.29731693863868713\n",
            "Epoch 46, Step 300, Loss: 0.2882072329521179\n",
            "Epoch 46, Step 301, Loss: 0.18747064471244812\n",
            "Epoch 46, Step 302, Loss: 0.14031565189361572\n",
            "Epoch 46, Step 303, Loss: 0.28296589851379395\n",
            "Epoch 46, Step 304, Loss: 0.25277891755104065\n",
            "Epoch 46, Step 305, Loss: 0.2267402857542038\n",
            "Epoch 46, Step 306, Loss: 0.27189528942108154\n",
            "Epoch 46, Step 307, Loss: 0.22441676259040833\n",
            "Epoch 46, Step 308, Loss: 0.22836613655090332\n",
            "Epoch 46, Step 309, Loss: 0.26243823766708374\n",
            "Epoch 46, Step 310, Loss: 0.2751302123069763\n",
            "Epoch 46, Step 311, Loss: 0.1528853476047516\n",
            "Epoch 46, Step 312, Loss: 0.35063183307647705\n",
            "Epoch 46 end, avg train loss: 0.2673110396336443\n",
            "Epoch 46 end, avg val loss: 0.3408434640003156, accuracy: 89.59%\n",
            "Epoch 47, Step 0, Loss: 0.30843448638916016\n",
            "Epoch 47, Step 1, Loss: 0.2231227308511734\n",
            "Epoch 47, Step 2, Loss: 0.2194334715604782\n",
            "Epoch 47, Step 3, Loss: 0.12078943103551865\n",
            "Epoch 47, Step 4, Loss: 0.2548525035381317\n",
            "Epoch 47, Step 5, Loss: 0.20142751932144165\n",
            "Epoch 47, Step 6, Loss: 0.20304861664772034\n",
            "Epoch 47, Step 7, Loss: 0.15570910274982452\n",
            "Epoch 47, Step 8, Loss: 0.2267867773771286\n",
            "Epoch 47, Step 9, Loss: 0.23460346460342407\n",
            "Epoch 47, Step 10, Loss: 0.2990778386592865\n",
            "Epoch 47, Step 11, Loss: 0.3174406886100769\n",
            "Epoch 47, Step 12, Loss: 0.35967597365379333\n",
            "Epoch 47, Step 13, Loss: 0.13968199491500854\n",
            "Epoch 47, Step 14, Loss: 0.26825186610221863\n",
            "Epoch 47, Step 15, Loss: 0.25935113430023193\n",
            "Epoch 47, Step 16, Loss: 0.27529752254486084\n",
            "Epoch 47, Step 17, Loss: 0.1965027004480362\n",
            "Epoch 47, Step 18, Loss: 0.20936621725559235\n",
            "Epoch 47, Step 19, Loss: 0.2535915970802307\n",
            "Epoch 47, Step 20, Loss: 0.30106085538864136\n",
            "Epoch 47, Step 21, Loss: 0.1405823528766632\n",
            "Epoch 47, Step 22, Loss: 0.2573257088661194\n",
            "Epoch 47, Step 23, Loss: 0.23843501508235931\n",
            "Epoch 47, Step 24, Loss: 0.317680686712265\n",
            "Epoch 47, Step 25, Loss: 0.258791983127594\n",
            "Epoch 47, Step 26, Loss: 0.2080816626548767\n",
            "Epoch 47, Step 27, Loss: 0.23769673705101013\n",
            "Epoch 47, Step 28, Loss: 0.24946902692317963\n",
            "Epoch 47, Step 29, Loss: 0.21741916239261627\n",
            "Epoch 47, Step 30, Loss: 0.24897123873233795\n",
            "Epoch 47, Step 31, Loss: 0.31500545144081116\n",
            "Epoch 47, Step 32, Loss: 0.23821865022182465\n",
            "Epoch 47, Step 33, Loss: 0.22828690707683563\n",
            "Epoch 47, Step 34, Loss: 0.3023827075958252\n",
            "Epoch 47, Step 35, Loss: 0.1531452089548111\n",
            "Epoch 47, Step 36, Loss: 0.18695369362831116\n",
            "Epoch 47, Step 37, Loss: 0.286376953125\n",
            "Epoch 47, Step 38, Loss: 0.33841320872306824\n",
            "Epoch 47, Step 39, Loss: 0.275760680437088\n",
            "Epoch 47, Step 40, Loss: 0.2882811427116394\n",
            "Epoch 47, Step 41, Loss: 0.27474072575569153\n",
            "Epoch 47, Step 42, Loss: 0.27441713213920593\n",
            "Epoch 47, Step 43, Loss: 0.18366816639900208\n",
            "Epoch 47, Step 44, Loss: 0.29164671897888184\n",
            "Epoch 47, Step 45, Loss: 0.20326758921146393\n",
            "Epoch 47, Step 46, Loss: 0.30986151099205017\n",
            "Epoch 47, Step 47, Loss: 0.28124287724494934\n",
            "Epoch 47, Step 48, Loss: 0.21520701050758362\n",
            "Epoch 47, Step 49, Loss: 0.3169303834438324\n",
            "Epoch 47, Step 50, Loss: 0.30685386061668396\n",
            "Epoch 47, Step 51, Loss: 0.27203506231307983\n",
            "Epoch 47, Step 52, Loss: 0.22405125200748444\n",
            "Epoch 47, Step 53, Loss: 0.21596871316432953\n",
            "Epoch 47, Step 54, Loss: 0.2095891237258911\n",
            "Epoch 47, Step 55, Loss: 0.37624692916870117\n",
            "Epoch 47, Step 56, Loss: 0.2168857604265213\n",
            "Epoch 47, Step 57, Loss: 0.33259886503219604\n",
            "Epoch 47, Step 58, Loss: 0.15212173759937286\n",
            "Epoch 47, Step 59, Loss: 0.21601161360740662\n",
            "Epoch 47, Step 60, Loss: 0.20627081394195557\n",
            "Epoch 47, Step 61, Loss: 0.2702794373035431\n",
            "Epoch 47, Step 62, Loss: 0.16077418625354767\n",
            "Epoch 47, Step 63, Loss: 0.19625689089298248\n",
            "Epoch 47, Step 64, Loss: 0.23914684355258942\n",
            "Epoch 47, Step 65, Loss: 0.3007412552833557\n",
            "Epoch 47, Step 66, Loss: 0.2682562470436096\n",
            "Epoch 47, Step 67, Loss: 0.2428932636976242\n",
            "Epoch 47, Step 68, Loss: 0.3490787148475647\n",
            "Epoch 47, Step 69, Loss: 0.24665474891662598\n",
            "Epoch 47, Step 70, Loss: 0.2550274431705475\n",
            "Epoch 47, Step 71, Loss: 0.22259071469306946\n",
            "Epoch 47, Step 72, Loss: 0.2252638041973114\n",
            "Epoch 47, Step 73, Loss: 0.29037851095199585\n",
            "Epoch 47, Step 74, Loss: 0.27479299902915955\n",
            "Epoch 47, Step 75, Loss: 0.42971187829971313\n",
            "Epoch 47, Step 76, Loss: 0.2637019157409668\n",
            "Epoch 47, Step 77, Loss: 0.19837161898612976\n",
            "Epoch 47, Step 78, Loss: 0.29890209436416626\n",
            "Epoch 47, Step 79, Loss: 0.2698593735694885\n",
            "Epoch 47, Step 80, Loss: 0.25714215636253357\n",
            "Epoch 47, Step 81, Loss: 0.2614127993583679\n",
            "Epoch 47, Step 82, Loss: 0.33826786279678345\n",
            "Epoch 47, Step 83, Loss: 0.3707805573940277\n",
            "Epoch 47, Step 84, Loss: 0.1837645322084427\n",
            "Epoch 47, Step 85, Loss: 0.2733306288719177\n",
            "Epoch 47, Step 86, Loss: 0.32134103775024414\n",
            "Epoch 47, Step 87, Loss: 0.3838549852371216\n",
            "Epoch 47, Step 88, Loss: 0.37923717498779297\n",
            "Epoch 47, Step 89, Loss: 0.203015998005867\n",
            "Epoch 47, Step 90, Loss: 0.1609969139099121\n",
            "Epoch 47, Step 91, Loss: 0.23576226830482483\n",
            "Epoch 47, Step 92, Loss: 0.24423526227474213\n",
            "Epoch 47, Step 93, Loss: 0.21229296922683716\n",
            "Epoch 47, Step 94, Loss: 0.2755059003829956\n",
            "Epoch 47, Step 95, Loss: 0.26185962557792664\n",
            "Epoch 47, Step 96, Loss: 0.29333001375198364\n",
            "Epoch 47, Step 97, Loss: 0.25549349188804626\n",
            "Epoch 47, Step 98, Loss: 0.3074268400669098\n",
            "Epoch 47, Step 99, Loss: 0.219838485121727\n",
            "Epoch 47, Step 100, Loss: 0.1855287402868271\n",
            "Epoch 47, Step 101, Loss: 0.17874811589717865\n",
            "Epoch 47, Step 102, Loss: 0.16926580667495728\n",
            "Epoch 47, Step 103, Loss: 0.172135591506958\n",
            "Epoch 47, Step 104, Loss: 0.31312188506126404\n",
            "Epoch 47, Step 105, Loss: 0.2928944528102875\n",
            "Epoch 47, Step 106, Loss: 0.36909133195877075\n",
            "Epoch 47, Step 107, Loss: 0.2704506516456604\n",
            "Epoch 47, Step 108, Loss: 0.19733071327209473\n",
            "Epoch 47, Step 109, Loss: 0.3490363359451294\n",
            "Epoch 47, Step 110, Loss: 0.2648182213306427\n",
            "Epoch 47, Step 111, Loss: 0.30153152346611023\n",
            "Epoch 47, Step 112, Loss: 0.4497230052947998\n",
            "Epoch 47, Step 113, Loss: 0.33284881711006165\n",
            "Epoch 47, Step 114, Loss: 0.3255155086517334\n",
            "Epoch 47, Step 115, Loss: 0.23023296892642975\n",
            "Epoch 47, Step 116, Loss: 0.305389404296875\n",
            "Epoch 47, Step 117, Loss: 0.2086416631937027\n",
            "Epoch 47, Step 118, Loss: 0.3117825388908386\n",
            "Epoch 47, Step 119, Loss: 0.34284165501594543\n",
            "Epoch 47, Step 120, Loss: 0.22314617037773132\n",
            "Epoch 47, Step 121, Loss: 0.28406602144241333\n",
            "Epoch 47, Step 122, Loss: 0.17249548435211182\n",
            "Epoch 47, Step 123, Loss: 0.19311970472335815\n",
            "Epoch 47, Step 124, Loss: 0.23761969804763794\n",
            "Epoch 47, Step 125, Loss: 0.2657274603843689\n",
            "Epoch 47, Step 126, Loss: 0.2586747407913208\n",
            "Epoch 47, Step 127, Loss: 0.2926393449306488\n",
            "Epoch 47, Step 128, Loss: 0.3664563298225403\n",
            "Epoch 47, Step 129, Loss: 0.21077056229114532\n",
            "Epoch 47, Step 130, Loss: 0.2538541257381439\n",
            "Epoch 47, Step 131, Loss: 0.14809617400169373\n",
            "Epoch 47, Step 132, Loss: 0.1528441607952118\n",
            "Epoch 47, Step 133, Loss: 0.24954001605510712\n",
            "Epoch 47, Step 134, Loss: 0.19462627172470093\n",
            "Epoch 47, Step 135, Loss: 0.3419870138168335\n",
            "Epoch 47, Step 136, Loss: 0.18196675181388855\n",
            "Epoch 47, Step 137, Loss: 0.2980697751045227\n",
            "Epoch 47, Step 138, Loss: 0.2724810242652893\n",
            "Epoch 47, Step 139, Loss: 0.18037936091423035\n",
            "Epoch 47, Step 140, Loss: 0.1944170743227005\n",
            "Epoch 47, Step 141, Loss: 0.2460724413394928\n",
            "Epoch 47, Step 142, Loss: 0.26318126916885376\n",
            "Epoch 47, Step 143, Loss: 0.2643837630748749\n",
            "Epoch 47, Step 144, Loss: 0.17196610569953918\n",
            "Epoch 47, Step 145, Loss: 0.10502515733242035\n",
            "Epoch 47, Step 146, Loss: 0.3512609601020813\n",
            "Epoch 47, Step 147, Loss: 0.282987117767334\n",
            "Epoch 47, Step 148, Loss: 0.31456881761550903\n",
            "Epoch 47, Step 149, Loss: 0.18416745960712433\n",
            "Epoch 47, Step 150, Loss: 0.5454175472259521\n",
            "Epoch 47, Step 151, Loss: 0.2036047875881195\n",
            "Epoch 47, Step 152, Loss: 0.33457788825035095\n",
            "Epoch 47, Step 153, Loss: 0.3443756401538849\n",
            "Epoch 47, Step 154, Loss: 0.25162193179130554\n",
            "Epoch 47, Step 155, Loss: 0.1646079123020172\n",
            "Epoch 47, Step 156, Loss: 0.2227177768945694\n",
            "Epoch 47, Step 157, Loss: 0.2121201604604721\n",
            "Epoch 47, Step 158, Loss: 0.25726231932640076\n",
            "Epoch 47, Step 159, Loss: 0.21876730024814606\n",
            "Epoch 47, Step 160, Loss: 0.2689310312271118\n",
            "Epoch 47, Step 161, Loss: 0.24729517102241516\n",
            "Epoch 47, Step 162, Loss: 0.17585235834121704\n",
            "Epoch 47, Step 163, Loss: 0.22215794026851654\n",
            "Epoch 47, Step 164, Loss: 0.25132715702056885\n",
            "Epoch 47, Step 165, Loss: 0.2902956008911133\n",
            "Epoch 47, Step 166, Loss: 0.24987953901290894\n",
            "Epoch 47, Step 167, Loss: 0.2399282157421112\n",
            "Epoch 47, Step 168, Loss: 0.241672545671463\n",
            "Epoch 47, Step 169, Loss: 0.32431575655937195\n",
            "Epoch 47, Step 170, Loss: 0.2127152383327484\n",
            "Epoch 47, Step 171, Loss: 0.20003147423267365\n",
            "Epoch 47, Step 172, Loss: 0.23150628805160522\n",
            "Epoch 47, Step 173, Loss: 0.20491833984851837\n",
            "Epoch 47, Step 174, Loss: 0.17772872745990753\n",
            "Epoch 47, Step 175, Loss: 0.24896427989006042\n",
            "Epoch 47, Step 176, Loss: 0.16926443576812744\n",
            "Epoch 47, Step 177, Loss: 0.25465869903564453\n",
            "Epoch 47, Step 178, Loss: 0.25553521513938904\n",
            "Epoch 47, Step 179, Loss: 0.33691659569740295\n",
            "Epoch 47, Step 180, Loss: 0.35260066390037537\n",
            "Epoch 47, Step 181, Loss: 0.22985431551933289\n",
            "Epoch 47, Step 182, Loss: 0.24380198121070862\n",
            "Epoch 47, Step 183, Loss: 0.22157436609268188\n",
            "Epoch 47, Step 184, Loss: 0.15294967591762543\n",
            "Epoch 47, Step 185, Loss: 0.13772079348564148\n",
            "Epoch 47, Step 186, Loss: 0.3138083219528198\n",
            "Epoch 47, Step 187, Loss: 0.18821151554584503\n",
            "Epoch 47, Step 188, Loss: 0.38521742820739746\n",
            "Epoch 47, Step 189, Loss: 0.24541635811328888\n",
            "Epoch 47, Step 190, Loss: 0.28569602966308594\n",
            "Epoch 47, Step 191, Loss: 0.2361030876636505\n",
            "Epoch 47, Step 192, Loss: 0.21176394820213318\n",
            "Epoch 47, Step 193, Loss: 0.20731620490550995\n",
            "Epoch 47, Step 194, Loss: 0.20920448005199432\n",
            "Epoch 47, Step 195, Loss: 0.43105366826057434\n",
            "Epoch 47, Step 196, Loss: 0.32556644082069397\n",
            "Epoch 47, Step 197, Loss: 0.31200316548347473\n",
            "Epoch 47, Step 198, Loss: 0.31866714358329773\n",
            "Epoch 47, Step 199, Loss: 0.29624420404434204\n",
            "Epoch 47, Step 200, Loss: 0.31079840660095215\n",
            "Epoch 47, Step 201, Loss: 0.2397240400314331\n",
            "Epoch 47, Step 202, Loss: 0.28529465198516846\n",
            "Epoch 47, Step 203, Loss: 0.22016093134880066\n",
            "Epoch 47, Step 204, Loss: 0.40476369857788086\n",
            "Epoch 47, Step 205, Loss: 0.25209009647369385\n",
            "Epoch 47, Step 206, Loss: 0.3797553479671478\n",
            "Epoch 47, Step 207, Loss: 0.27317193150520325\n",
            "Epoch 47, Step 208, Loss: 0.1433103084564209\n",
            "Epoch 47, Step 209, Loss: 0.2034498155117035\n",
            "Epoch 47, Step 210, Loss: 0.21548627316951752\n",
            "Epoch 47, Step 211, Loss: 0.2319898158311844\n",
            "Epoch 47, Step 212, Loss: 0.1904599815607071\n",
            "Epoch 47, Step 213, Loss: 0.19097508490085602\n",
            "Epoch 47, Step 214, Loss: 0.32815834879875183\n",
            "Epoch 47, Step 215, Loss: 0.32577550411224365\n",
            "Epoch 47, Step 216, Loss: 0.2938991189002991\n",
            "Epoch 47, Step 217, Loss: 0.2380656898021698\n",
            "Epoch 47, Step 218, Loss: 0.3606387674808502\n",
            "Epoch 47, Step 219, Loss: 0.3045530915260315\n",
            "Epoch 47, Step 220, Loss: 0.31075286865234375\n",
            "Epoch 47, Step 221, Loss: 0.24021956324577332\n",
            "Epoch 47, Step 222, Loss: 0.2570599913597107\n",
            "Epoch 47, Step 223, Loss: 0.21172013878822327\n",
            "Epoch 47, Step 224, Loss: 0.30045491456985474\n",
            "Epoch 47, Step 225, Loss: 0.25582873821258545\n",
            "Epoch 47, Step 226, Loss: 0.3709053099155426\n",
            "Epoch 47, Step 227, Loss: 0.3549047112464905\n",
            "Epoch 47, Step 228, Loss: 0.2594090700149536\n",
            "Epoch 47, Step 229, Loss: 0.28427374362945557\n",
            "Epoch 47, Step 230, Loss: 0.3511905372142792\n",
            "Epoch 47, Step 231, Loss: 0.23454143106937408\n",
            "Epoch 47, Step 232, Loss: 0.3451625108718872\n",
            "Epoch 47, Step 233, Loss: 0.29215729236602783\n",
            "Epoch 47, Step 234, Loss: 0.33270254731178284\n",
            "Epoch 47, Step 235, Loss: 0.2550355792045593\n",
            "Epoch 47, Step 236, Loss: 0.22788628935813904\n",
            "Epoch 47, Step 237, Loss: 0.4387015402317047\n",
            "Epoch 47, Step 238, Loss: 0.2795235216617584\n",
            "Epoch 47, Step 239, Loss: 0.2125813513994217\n",
            "Epoch 47, Step 240, Loss: 0.23273074626922607\n",
            "Epoch 47, Step 241, Loss: 0.2818179130554199\n",
            "Epoch 47, Step 242, Loss: 0.25716063380241394\n",
            "Epoch 47, Step 243, Loss: 0.46986761689186096\n",
            "Epoch 47, Step 244, Loss: 0.2701583802700043\n",
            "Epoch 47, Step 245, Loss: 0.2086481899023056\n",
            "Epoch 47, Step 246, Loss: 0.4373129904270172\n",
            "Epoch 47, Step 247, Loss: 0.3035791218280792\n",
            "Epoch 47, Step 248, Loss: 0.18312008678913116\n",
            "Epoch 47, Step 249, Loss: 0.2760796546936035\n",
            "Epoch 47, Step 250, Loss: 0.26456645131111145\n",
            "Epoch 47, Step 251, Loss: 0.22921505570411682\n",
            "Epoch 47, Step 252, Loss: 0.2561698853969574\n",
            "Epoch 47, Step 253, Loss: 0.24902310967445374\n",
            "Epoch 47, Step 254, Loss: 0.192618727684021\n",
            "Epoch 47, Step 255, Loss: 0.29090046882629395\n",
            "Epoch 47, Step 256, Loss: 0.2531069815158844\n",
            "Epoch 47, Step 257, Loss: 0.32923609018325806\n",
            "Epoch 47, Step 258, Loss: 0.2756989598274231\n",
            "Epoch 47, Step 259, Loss: 0.24738946557044983\n",
            "Epoch 47, Step 260, Loss: 0.2608413100242615\n",
            "Epoch 47, Step 261, Loss: 0.3863215744495392\n",
            "Epoch 47, Step 262, Loss: 0.19501492381095886\n",
            "Epoch 47, Step 263, Loss: 0.28750866651535034\n",
            "Epoch 47, Step 264, Loss: 0.28561651706695557\n",
            "Epoch 47, Step 265, Loss: 0.14504283666610718\n",
            "Epoch 47, Step 266, Loss: 0.3105800151824951\n",
            "Epoch 47, Step 267, Loss: 0.39125949144363403\n",
            "Epoch 47, Step 268, Loss: 0.3240044116973877\n",
            "Epoch 47, Step 269, Loss: 0.31163516640663147\n",
            "Epoch 47, Step 270, Loss: 0.18086904287338257\n",
            "Epoch 47, Step 271, Loss: 0.28123781085014343\n",
            "Epoch 47, Step 272, Loss: 0.3635098338127136\n",
            "Epoch 47, Step 273, Loss: 0.22342291474342346\n",
            "Epoch 47, Step 274, Loss: 0.26026466488838196\n",
            "Epoch 47, Step 275, Loss: 0.21239516139030457\n",
            "Epoch 47, Step 276, Loss: 0.339919775724411\n",
            "Epoch 47, Step 277, Loss: 0.17011700570583344\n",
            "Epoch 47, Step 278, Loss: 0.3167281150817871\n",
            "Epoch 47, Step 279, Loss: 0.19222994148731232\n",
            "Epoch 47, Step 280, Loss: 0.19725188612937927\n",
            "Epoch 47, Step 281, Loss: 0.22182822227478027\n",
            "Epoch 47, Step 282, Loss: 0.23914211988449097\n",
            "Epoch 47, Step 283, Loss: 0.19512860476970673\n",
            "Epoch 47, Step 284, Loss: 0.1309002786874771\n",
            "Epoch 47, Step 285, Loss: 0.23425042629241943\n",
            "Epoch 47, Step 286, Loss: 0.35615894198417664\n",
            "Epoch 47, Step 287, Loss: 0.34562504291534424\n",
            "Epoch 47, Step 288, Loss: 0.2818087041378021\n",
            "Epoch 47, Step 289, Loss: 0.22881658375263214\n",
            "Epoch 47, Step 290, Loss: 0.3191472291946411\n",
            "Epoch 47, Step 291, Loss: 0.3088478744029999\n",
            "Epoch 47, Step 292, Loss: 0.30472445487976074\n",
            "Epoch 47, Step 293, Loss: 0.2561964988708496\n",
            "Epoch 47, Step 294, Loss: 0.2862984538078308\n",
            "Epoch 47, Step 295, Loss: 0.26599210500717163\n",
            "Epoch 47, Step 296, Loss: 0.21499039232730865\n",
            "Epoch 47, Step 297, Loss: 0.341776579618454\n",
            "Epoch 47, Step 298, Loss: 0.20268389582633972\n",
            "Epoch 47, Step 299, Loss: 0.24987341463565826\n",
            "Epoch 47, Step 300, Loss: 0.26554518938064575\n",
            "Epoch 47, Step 301, Loss: 0.23554731905460358\n",
            "Epoch 47, Step 302, Loss: 0.234813392162323\n",
            "Epoch 47, Step 303, Loss: 0.20781219005584717\n",
            "Epoch 47, Step 304, Loss: 0.29062801599502563\n",
            "Epoch 47, Step 305, Loss: 0.24389143288135529\n",
            "Epoch 47, Step 306, Loss: 0.20356687903404236\n",
            "Epoch 47, Step 307, Loss: 0.26541975140571594\n",
            "Epoch 47, Step 308, Loss: 0.1748856008052826\n",
            "Epoch 47, Step 309, Loss: 0.2517390847206116\n",
            "Epoch 47, Step 310, Loss: 0.27312126755714417\n",
            "Epoch 47, Step 311, Loss: 0.1689278781414032\n",
            "Epoch 47, Step 312, Loss: 0.20380081236362457\n",
            "Epoch 47 end, avg train loss: 0.2603285166259391\n",
            "Epoch 47 end, avg val loss: 0.33058096260964115, accuracy: 89.62%\n",
            "Epoch 48, Step 0, Loss: 0.1626773476600647\n",
            "Epoch 48, Step 1, Loss: 0.2505224943161011\n",
            "Epoch 48, Step 2, Loss: 0.23925212025642395\n",
            "Epoch 48, Step 3, Loss: 0.36562415957450867\n",
            "Epoch 48, Step 4, Loss: 0.298394113779068\n",
            "Epoch 48, Step 5, Loss: 0.14128002524375916\n",
            "Epoch 48, Step 6, Loss: 0.23272612690925598\n",
            "Epoch 48, Step 7, Loss: 0.2818378508090973\n",
            "Epoch 48, Step 8, Loss: 0.26092401146888733\n",
            "Epoch 48, Step 9, Loss: 0.28773757815361023\n",
            "Epoch 48, Step 10, Loss: 0.23719018697738647\n",
            "Epoch 48, Step 11, Loss: 0.22837702929973602\n",
            "Epoch 48, Step 12, Loss: 0.18721966445446014\n",
            "Epoch 48, Step 13, Loss: 0.2785155773162842\n",
            "Epoch 48, Step 14, Loss: 0.2051808387041092\n",
            "Epoch 48, Step 15, Loss: 0.19835712015628815\n",
            "Epoch 48, Step 16, Loss: 0.22019122540950775\n",
            "Epoch 48, Step 17, Loss: 0.19123438000679016\n",
            "Epoch 48, Step 18, Loss: 0.1522381454706192\n",
            "Epoch 48, Step 19, Loss: 0.2685646712779999\n",
            "Epoch 48, Step 20, Loss: 0.2159559726715088\n",
            "Epoch 48, Step 21, Loss: 0.2590845823287964\n",
            "Epoch 48, Step 22, Loss: 0.24975159764289856\n",
            "Epoch 48, Step 23, Loss: 0.24573281407356262\n",
            "Epoch 48, Step 24, Loss: 0.30665847659111023\n",
            "Epoch 48, Step 25, Loss: 0.24949370324611664\n",
            "Epoch 48, Step 26, Loss: 0.20311646163463593\n",
            "Epoch 48, Step 27, Loss: 0.2629372477531433\n",
            "Epoch 48, Step 28, Loss: 0.22418610751628876\n",
            "Epoch 48, Step 29, Loss: 0.2544512450695038\n",
            "Epoch 48, Step 30, Loss: 0.1763085126876831\n",
            "Epoch 48, Step 31, Loss: 0.3172796964645386\n",
            "Epoch 48, Step 32, Loss: 0.23424647748470306\n",
            "Epoch 48, Step 33, Loss: 0.26855120062828064\n",
            "Epoch 48, Step 34, Loss: 0.29928603768348694\n",
            "Epoch 48, Step 35, Loss: 0.29387879371643066\n",
            "Epoch 48, Step 36, Loss: 0.29241234064102173\n",
            "Epoch 48, Step 37, Loss: 0.14503486454486847\n",
            "Epoch 48, Step 38, Loss: 0.2158627212047577\n",
            "Epoch 48, Step 39, Loss: 0.27315762639045715\n",
            "Epoch 48, Step 40, Loss: 0.1497892439365387\n",
            "Epoch 48, Step 41, Loss: 0.12569491565227509\n",
            "Epoch 48, Step 42, Loss: 0.18299500644207\n",
            "Epoch 48, Step 43, Loss: 0.230684295296669\n",
            "Epoch 48, Step 44, Loss: 0.1874401718378067\n",
            "Epoch 48, Step 45, Loss: 0.2079172432422638\n",
            "Epoch 48, Step 46, Loss: 0.22154471278190613\n",
            "Epoch 48, Step 47, Loss: 0.24676087498664856\n",
            "Epoch 48, Step 48, Loss: 0.17505568265914917\n",
            "Epoch 48, Step 49, Loss: 0.36453279852867126\n",
            "Epoch 48, Step 50, Loss: 0.2444155216217041\n",
            "Epoch 48, Step 51, Loss: 0.3128945529460907\n",
            "Epoch 48, Step 52, Loss: 0.34146830439567566\n",
            "Epoch 48, Step 53, Loss: 0.18784721195697784\n",
            "Epoch 48, Step 54, Loss: 0.19413350522518158\n",
            "Epoch 48, Step 55, Loss: 0.23281621932983398\n",
            "Epoch 48, Step 56, Loss: 0.15652675926685333\n",
            "Epoch 48, Step 57, Loss: 0.3016226589679718\n",
            "Epoch 48, Step 58, Loss: 0.18820244073867798\n",
            "Epoch 48, Step 59, Loss: 0.14262516796588898\n",
            "Epoch 48, Step 60, Loss: 0.3775884509086609\n",
            "Epoch 48, Step 61, Loss: 0.2235492467880249\n",
            "Epoch 48, Step 62, Loss: 0.25999510288238525\n",
            "Epoch 48, Step 63, Loss: 0.27758240699768066\n",
            "Epoch 48, Step 64, Loss: 0.17079904675483704\n",
            "Epoch 48, Step 65, Loss: 0.2674492597579956\n",
            "Epoch 48, Step 66, Loss: 0.2522411048412323\n",
            "Epoch 48, Step 67, Loss: 0.26557639241218567\n",
            "Epoch 48, Step 68, Loss: 0.23762167990207672\n",
            "Epoch 48, Step 69, Loss: 0.3762211501598358\n",
            "Epoch 48, Step 70, Loss: 0.23967769742012024\n",
            "Epoch 48, Step 71, Loss: 0.22881095111370087\n",
            "Epoch 48, Step 72, Loss: 0.2768743634223938\n",
            "Epoch 48, Step 73, Loss: 0.2691841125488281\n",
            "Epoch 48, Step 74, Loss: 0.2781512439250946\n",
            "Epoch 48, Step 75, Loss: 0.19962471723556519\n",
            "Epoch 48, Step 76, Loss: 0.22435623407363892\n",
            "Epoch 48, Step 77, Loss: 0.2155764102935791\n",
            "Epoch 48, Step 78, Loss: 0.3669023811817169\n",
            "Epoch 48, Step 79, Loss: 0.298774778842926\n",
            "Epoch 48, Step 80, Loss: 0.2612167298793793\n",
            "Epoch 48, Step 81, Loss: 0.25823870301246643\n",
            "Epoch 48, Step 82, Loss: 0.25706201791763306\n",
            "Epoch 48, Step 83, Loss: 0.25498971343040466\n",
            "Epoch 48, Step 84, Loss: 0.24719387292861938\n",
            "Epoch 48, Step 85, Loss: 0.3014166057109833\n",
            "Epoch 48, Step 86, Loss: 0.3738647401332855\n",
            "Epoch 48, Step 87, Loss: 0.3057399392127991\n",
            "Epoch 48, Step 88, Loss: 0.1623189002275467\n",
            "Epoch 48, Step 89, Loss: 0.29466739296913147\n",
            "Epoch 48, Step 90, Loss: 0.19252577424049377\n",
            "Epoch 48, Step 91, Loss: 0.24526704847812653\n",
            "Epoch 48, Step 92, Loss: 0.26815515756607056\n",
            "Epoch 48, Step 93, Loss: 0.3011317849159241\n",
            "Epoch 48, Step 94, Loss: 0.16643905639648438\n",
            "Epoch 48, Step 95, Loss: 0.24519576132297516\n",
            "Epoch 48, Step 96, Loss: 0.2391757071018219\n",
            "Epoch 48, Step 97, Loss: 0.19749604165554047\n",
            "Epoch 48, Step 98, Loss: 0.2395831197500229\n",
            "Epoch 48, Step 99, Loss: 0.23863518238067627\n",
            "Epoch 48, Step 100, Loss: 0.21017275750637054\n",
            "Epoch 48, Step 101, Loss: 0.25194862484931946\n",
            "Epoch 48, Step 102, Loss: 0.25641563534736633\n",
            "Epoch 48, Step 103, Loss: 0.13010375201702118\n",
            "Epoch 48, Step 104, Loss: 0.2274530827999115\n",
            "Epoch 48, Step 105, Loss: 0.22929176688194275\n",
            "Epoch 48, Step 106, Loss: 0.3296469449996948\n",
            "Epoch 48, Step 107, Loss: 0.19922597706317902\n",
            "Epoch 48, Step 108, Loss: 0.3074827492237091\n",
            "Epoch 48, Step 109, Loss: 0.2241089791059494\n",
            "Epoch 48, Step 110, Loss: 0.3647077679634094\n",
            "Epoch 48, Step 111, Loss: 0.306440144777298\n",
            "Epoch 48, Step 112, Loss: 0.226320281624794\n",
            "Epoch 48, Step 113, Loss: 0.29035666584968567\n",
            "Epoch 48, Step 114, Loss: 0.27571895718574524\n",
            "Epoch 48, Step 115, Loss: 0.19525398313999176\n",
            "Epoch 48, Step 116, Loss: 0.21012479066848755\n",
            "Epoch 48, Step 117, Loss: 0.20199425518512726\n",
            "Epoch 48, Step 118, Loss: 0.21204034984111786\n",
            "Epoch 48, Step 119, Loss: 0.33739376068115234\n",
            "Epoch 48, Step 120, Loss: 0.24595697224140167\n",
            "Epoch 48, Step 121, Loss: 0.2728536128997803\n",
            "Epoch 48, Step 122, Loss: 0.28949201107025146\n",
            "Epoch 48, Step 123, Loss: 0.25152692198753357\n",
            "Epoch 48, Step 124, Loss: 0.33360937237739563\n",
            "Epoch 48, Step 125, Loss: 0.421947181224823\n",
            "Epoch 48, Step 126, Loss: 0.34414783120155334\n",
            "Epoch 48, Step 127, Loss: 0.22701485455036163\n",
            "Epoch 48, Step 128, Loss: 0.24354852735996246\n",
            "Epoch 48, Step 129, Loss: 0.24519020318984985\n",
            "Epoch 48, Step 130, Loss: 0.19367147982120514\n",
            "Epoch 48, Step 131, Loss: 0.24477840960025787\n",
            "Epoch 48, Step 132, Loss: 0.2686411440372467\n",
            "Epoch 48, Step 133, Loss: 0.2850126624107361\n",
            "Epoch 48, Step 134, Loss: 0.20171426236629486\n",
            "Epoch 48, Step 135, Loss: 0.23714737594127655\n",
            "Epoch 48, Step 136, Loss: 0.22985057532787323\n",
            "Epoch 48, Step 137, Loss: 0.24499034881591797\n",
            "Epoch 48, Step 138, Loss: 0.2744448184967041\n",
            "Epoch 48, Step 139, Loss: 0.3362545073032379\n",
            "Epoch 48, Step 140, Loss: 0.38416558504104614\n",
            "Epoch 48, Step 141, Loss: 0.13952383399009705\n",
            "Epoch 48, Step 142, Loss: 0.2369219958782196\n",
            "Epoch 48, Step 143, Loss: 0.2251826822757721\n",
            "Epoch 48, Step 144, Loss: 0.3814240097999573\n",
            "Epoch 48, Step 145, Loss: 0.2509865164756775\n",
            "Epoch 48, Step 146, Loss: 0.2143610417842865\n",
            "Epoch 48, Step 147, Loss: 0.29605668783187866\n",
            "Epoch 48, Step 148, Loss: 0.14768892526626587\n",
            "Epoch 48, Step 149, Loss: 0.19943813979625702\n",
            "Epoch 48, Step 150, Loss: 0.24049365520477295\n",
            "Epoch 48, Step 151, Loss: 0.2371463179588318\n",
            "Epoch 48, Step 152, Loss: 0.31028953194618225\n",
            "Epoch 48, Step 153, Loss: 0.3128441870212555\n",
            "Epoch 48, Step 154, Loss: 0.27835580706596375\n",
            "Epoch 48, Step 155, Loss: 0.3528091013431549\n",
            "Epoch 48, Step 156, Loss: 0.1789940744638443\n",
            "Epoch 48, Step 157, Loss: 0.23405194282531738\n",
            "Epoch 48, Step 158, Loss: 0.33399656414985657\n",
            "Epoch 48, Step 159, Loss: 0.2120026797056198\n",
            "Epoch 48, Step 160, Loss: 0.20504771173000336\n",
            "Epoch 48, Step 161, Loss: 0.2942882478237152\n",
            "Epoch 48, Step 162, Loss: 0.29192566871643066\n",
            "Epoch 48, Step 163, Loss: 0.17895594239234924\n",
            "Epoch 48, Step 164, Loss: 0.28583571314811707\n",
            "Epoch 48, Step 165, Loss: 0.19936205446720123\n",
            "Epoch 48, Step 166, Loss: 0.31096237897872925\n",
            "Epoch 48, Step 167, Loss: 0.3021325170993805\n",
            "Epoch 48, Step 168, Loss: 0.2642001509666443\n",
            "Epoch 48, Step 169, Loss: 0.3222520053386688\n",
            "Epoch 48, Step 170, Loss: 0.2983960509300232\n",
            "Epoch 48, Step 171, Loss: 0.2388288527727127\n",
            "Epoch 48, Step 172, Loss: 0.14930878579616547\n",
            "Epoch 48, Step 173, Loss: 0.2512340843677521\n",
            "Epoch 48, Step 174, Loss: 0.2765040695667267\n",
            "Epoch 48, Step 175, Loss: 0.17768466472625732\n",
            "Epoch 48, Step 176, Loss: 0.27280303835868835\n",
            "Epoch 48, Step 177, Loss: 0.2854381501674652\n",
            "Epoch 48, Step 178, Loss: 0.4263131022453308\n",
            "Epoch 48, Step 179, Loss: 0.26214414834976196\n",
            "Epoch 48, Step 180, Loss: 0.203856959939003\n",
            "Epoch 48, Step 181, Loss: 0.20995663106441498\n",
            "Epoch 48, Step 182, Loss: 0.22993555665016174\n",
            "Epoch 48, Step 183, Loss: 0.30137816071510315\n",
            "Epoch 48, Step 184, Loss: 0.26629936695098877\n",
            "Epoch 48, Step 185, Loss: 0.22627229988574982\n",
            "Epoch 48, Step 186, Loss: 0.25210535526275635\n",
            "Epoch 48, Step 187, Loss: 0.18913356959819794\n",
            "Epoch 48, Step 188, Loss: 0.20106330513954163\n",
            "Epoch 48, Step 189, Loss: 0.20975397527217865\n",
            "Epoch 48, Step 190, Loss: 0.27049869298934937\n",
            "Epoch 48, Step 191, Loss: 0.14422398805618286\n",
            "Epoch 48, Step 192, Loss: 0.28457221388816833\n",
            "Epoch 48, Step 193, Loss: 0.18098032474517822\n",
            "Epoch 48, Step 194, Loss: 0.25371596217155457\n",
            "Epoch 48, Step 195, Loss: 0.2828001081943512\n",
            "Epoch 48, Step 196, Loss: 0.19920527935028076\n",
            "Epoch 48, Step 197, Loss: 0.20259450376033783\n",
            "Epoch 48, Step 198, Loss: 0.3722970485687256\n",
            "Epoch 48, Step 199, Loss: 0.25933513045310974\n",
            "Epoch 48, Step 200, Loss: 0.22326251864433289\n",
            "Epoch 48, Step 201, Loss: 0.27428966760635376\n",
            "Epoch 48, Step 202, Loss: 0.18678155541419983\n",
            "Epoch 48, Step 203, Loss: 0.27725866436958313\n",
            "Epoch 48, Step 204, Loss: 0.19555293023586273\n",
            "Epoch 48, Step 205, Loss: 0.22841326892375946\n",
            "Epoch 48, Step 206, Loss: 0.3946695327758789\n",
            "Epoch 48, Step 207, Loss: 0.28409379720687866\n",
            "Epoch 48, Step 208, Loss: 0.2500118017196655\n",
            "Epoch 48, Step 209, Loss: 0.28686997294425964\n",
            "Epoch 48, Step 210, Loss: 0.13503211736679077\n",
            "Epoch 48, Step 211, Loss: 0.16441914439201355\n",
            "Epoch 48, Step 212, Loss: 0.2330567091703415\n",
            "Epoch 48, Step 213, Loss: 0.22530962526798248\n",
            "Epoch 48, Step 214, Loss: 0.3603234589099884\n",
            "Epoch 48, Step 215, Loss: 0.33969148993492126\n",
            "Epoch 48, Step 216, Loss: 0.22931921482086182\n",
            "Epoch 48, Step 217, Loss: 0.29810744524002075\n",
            "Epoch 48, Step 218, Loss: 0.40546533465385437\n",
            "Epoch 48, Step 219, Loss: 0.1739424467086792\n",
            "Epoch 48, Step 220, Loss: 0.1975785195827484\n",
            "Epoch 48, Step 221, Loss: 0.2720065414905548\n",
            "Epoch 48, Step 222, Loss: 0.22385118901729584\n",
            "Epoch 48, Step 223, Loss: 0.17516422271728516\n",
            "Epoch 48, Step 224, Loss: 0.30193179845809937\n",
            "Epoch 48, Step 225, Loss: 0.35200318694114685\n",
            "Epoch 48, Step 226, Loss: 0.21184830367565155\n",
            "Epoch 48, Step 227, Loss: 0.3084281384944916\n",
            "Epoch 48, Step 228, Loss: 0.2314790040254593\n",
            "Epoch 48, Step 229, Loss: 0.30007076263427734\n",
            "Epoch 48, Step 230, Loss: 0.20454615354537964\n",
            "Epoch 48, Step 231, Loss: 0.20986685156822205\n",
            "Epoch 48, Step 232, Loss: 0.2820238769054413\n",
            "Epoch 48, Step 233, Loss: 0.27626845240592957\n",
            "Epoch 48, Step 234, Loss: 0.30117473006248474\n",
            "Epoch 48, Step 235, Loss: 0.158416748046875\n",
            "Epoch 48, Step 236, Loss: 0.2536136507987976\n",
            "Epoch 48, Step 237, Loss: 0.3178442120552063\n",
            "Epoch 48, Step 238, Loss: 0.345293790102005\n",
            "Epoch 48, Step 239, Loss: 0.2550699710845947\n",
            "Epoch 48, Step 240, Loss: 0.27057090401649475\n",
            "Epoch 48, Step 241, Loss: 0.24672657251358032\n",
            "Epoch 48, Step 242, Loss: 0.3100039064884186\n",
            "Epoch 48, Step 243, Loss: 0.26372039318084717\n",
            "Epoch 48, Step 244, Loss: 0.2406187504529953\n",
            "Epoch 48, Step 245, Loss: 0.2737670838832855\n",
            "Epoch 48, Step 246, Loss: 0.24477724730968475\n",
            "Epoch 48, Step 247, Loss: 0.20730306208133698\n",
            "Epoch 48, Step 248, Loss: 0.304404616355896\n",
            "Epoch 48, Step 249, Loss: 0.2962093651294708\n",
            "Epoch 48, Step 250, Loss: 0.25505441427230835\n",
            "Epoch 48, Step 251, Loss: 0.266623318195343\n",
            "Epoch 48, Step 252, Loss: 0.25472700595855713\n",
            "Epoch 48, Step 253, Loss: 0.2544877529144287\n",
            "Epoch 48, Step 254, Loss: 0.3141387104988098\n",
            "Epoch 48, Step 255, Loss: 0.26105454564094543\n",
            "Epoch 48, Step 256, Loss: 0.17958638072013855\n",
            "Epoch 48, Step 257, Loss: 0.22521810233592987\n",
            "Epoch 48, Step 258, Loss: 0.2727140486240387\n",
            "Epoch 48, Step 259, Loss: 0.29330015182495117\n",
            "Epoch 48, Step 260, Loss: 0.18374283611774445\n",
            "Epoch 48, Step 261, Loss: 0.21084895730018616\n",
            "Epoch 48, Step 262, Loss: 0.1843886375427246\n",
            "Epoch 48, Step 263, Loss: 0.43590065836906433\n",
            "Epoch 48, Step 264, Loss: 0.21804147958755493\n",
            "Epoch 48, Step 265, Loss: 0.26733991503715515\n",
            "Epoch 48, Step 266, Loss: 0.2082308530807495\n",
            "Epoch 48, Step 267, Loss: 0.21156245470046997\n",
            "Epoch 48, Step 268, Loss: 0.2713288962841034\n",
            "Epoch 48, Step 269, Loss: 0.19155435264110565\n",
            "Epoch 48, Step 270, Loss: 0.3691069185733795\n",
            "Epoch 48, Step 271, Loss: 0.27545440196990967\n",
            "Epoch 48, Step 272, Loss: 0.2935415506362915\n",
            "Epoch 48, Step 273, Loss: 0.21629613637924194\n",
            "Epoch 48, Step 274, Loss: 0.3612353205680847\n",
            "Epoch 48, Step 275, Loss: 0.2611352205276489\n",
            "Epoch 48, Step 276, Loss: 0.3628896474838257\n",
            "Epoch 48, Step 277, Loss: 0.2003459930419922\n",
            "Epoch 48, Step 278, Loss: 0.15937626361846924\n",
            "Epoch 48, Step 279, Loss: 0.21022933721542358\n",
            "Epoch 48, Step 280, Loss: 0.20882388949394226\n",
            "Epoch 48, Step 281, Loss: 0.18369416892528534\n",
            "Epoch 48, Step 282, Loss: 0.2439621537923813\n",
            "Epoch 48, Step 283, Loss: 0.24823834002017975\n",
            "Epoch 48, Step 284, Loss: 0.23359866440296173\n",
            "Epoch 48, Step 285, Loss: 0.2725137174129486\n",
            "Epoch 48, Step 286, Loss: 0.1766837239265442\n",
            "Epoch 48, Step 287, Loss: 0.2570347785949707\n",
            "Epoch 48, Step 288, Loss: 0.27649950981140137\n",
            "Epoch 48, Step 289, Loss: 0.2862483561038971\n",
            "Epoch 48, Step 290, Loss: 0.16559165716171265\n",
            "Epoch 48, Step 291, Loss: 0.1885274201631546\n",
            "Epoch 48, Step 292, Loss: 0.25960734486579895\n",
            "Epoch 48, Step 293, Loss: 0.19630099833011627\n",
            "Epoch 48, Step 294, Loss: 0.28203943371772766\n",
            "Epoch 48, Step 295, Loss: 0.21079489588737488\n",
            "Epoch 48, Step 296, Loss: 0.22241869568824768\n",
            "Epoch 48, Step 297, Loss: 0.2156038135290146\n",
            "Epoch 48, Step 298, Loss: 0.2533935606479645\n",
            "Epoch 48, Step 299, Loss: 0.298391729593277\n",
            "Epoch 48, Step 300, Loss: 0.21109932661056519\n",
            "Epoch 48, Step 301, Loss: 0.3283190131187439\n",
            "Epoch 48, Step 302, Loss: 0.36024320125579834\n",
            "Epoch 48, Step 303, Loss: 0.24215364456176758\n",
            "Epoch 48, Step 304, Loss: 0.18949931859970093\n",
            "Epoch 48, Step 305, Loss: 0.3884013295173645\n",
            "Epoch 48, Step 306, Loss: 0.16307014226913452\n",
            "Epoch 48, Step 307, Loss: 0.3346160650253296\n",
            "Epoch 48, Step 308, Loss: 0.2723633646965027\n",
            "Epoch 48, Step 309, Loss: 0.349418044090271\n",
            "Epoch 48, Step 310, Loss: 0.2621319591999054\n",
            "Epoch 48, Step 311, Loss: 0.23410874605178833\n",
            "Epoch 48, Step 312, Loss: 0.27097591757774353\n",
            "Epoch 48 end, avg train loss: 0.25228072093508114\n",
            "Epoch 48 end, avg val loss: 0.3474127955829041, accuracy: 89.28%\n",
            "Epoch 49, Step 0, Loss: 0.21999293565750122\n",
            "Epoch 49, Step 1, Loss: 0.20123757421970367\n",
            "Epoch 49, Step 2, Loss: 0.2315734475851059\n",
            "Epoch 49, Step 3, Loss: 0.3170856535434723\n",
            "Epoch 49, Step 4, Loss: 0.18116505444049835\n",
            "Epoch 49, Step 5, Loss: 0.2627178728580475\n",
            "Epoch 49, Step 6, Loss: 0.22971218824386597\n",
            "Epoch 49, Step 7, Loss: 0.22241979837417603\n",
            "Epoch 49, Step 8, Loss: 0.38569313287734985\n",
            "Epoch 49, Step 9, Loss: 0.20301324129104614\n",
            "Epoch 49, Step 10, Loss: 0.38462138175964355\n",
            "Epoch 49, Step 11, Loss: 0.350673109292984\n",
            "Epoch 49, Step 12, Loss: 0.22054935991764069\n",
            "Epoch 49, Step 13, Loss: 0.24333226680755615\n",
            "Epoch 49, Step 14, Loss: 0.26739269495010376\n",
            "Epoch 49, Step 15, Loss: 0.24125121533870697\n",
            "Epoch 49, Step 16, Loss: 0.23571868240833282\n",
            "Epoch 49, Step 17, Loss: 0.28694695234298706\n",
            "Epoch 49, Step 18, Loss: 0.33679264783859253\n",
            "Epoch 49, Step 19, Loss: 0.23719976842403412\n",
            "Epoch 49, Step 20, Loss: 0.21172228455543518\n",
            "Epoch 49, Step 21, Loss: 0.26344284415245056\n",
            "Epoch 49, Step 22, Loss: 0.26732030510902405\n",
            "Epoch 49, Step 23, Loss: 0.23149944841861725\n",
            "Epoch 49, Step 24, Loss: 0.16974100470542908\n",
            "Epoch 49, Step 25, Loss: 0.29517656564712524\n",
            "Epoch 49, Step 26, Loss: 0.2715223431587219\n",
            "Epoch 49, Step 27, Loss: 0.28448665142059326\n",
            "Epoch 49, Step 28, Loss: 0.34730058908462524\n",
            "Epoch 49, Step 29, Loss: 0.2719985246658325\n",
            "Epoch 49, Step 30, Loss: 0.27543362975120544\n",
            "Epoch 49, Step 31, Loss: 0.27883100509643555\n",
            "Epoch 49, Step 32, Loss: 0.26390403509140015\n",
            "Epoch 49, Step 33, Loss: 0.24178749322891235\n",
            "Epoch 49, Step 34, Loss: 0.1809748411178589\n",
            "Epoch 49, Step 35, Loss: 0.25803712010383606\n",
            "Epoch 49, Step 36, Loss: 0.24580013751983643\n",
            "Epoch 49, Step 37, Loss: 0.3519350290298462\n",
            "Epoch 49, Step 38, Loss: 0.26887619495391846\n",
            "Epoch 49, Step 39, Loss: 0.3195670247077942\n",
            "Epoch 49, Step 40, Loss: 0.20053982734680176\n",
            "Epoch 49, Step 41, Loss: 0.17462226748466492\n",
            "Epoch 49, Step 42, Loss: 0.3186371922492981\n",
            "Epoch 49, Step 43, Loss: 0.22028498351573944\n",
            "Epoch 49, Step 44, Loss: 0.2128414511680603\n",
            "Epoch 49, Step 45, Loss: 0.2617587149143219\n",
            "Epoch 49, Step 46, Loss: 0.16718828678131104\n",
            "Epoch 49, Step 47, Loss: 0.2964187562465668\n",
            "Epoch 49, Step 48, Loss: 0.23389199376106262\n",
            "Epoch 49, Step 49, Loss: 0.20876732468605042\n",
            "Epoch 49, Step 50, Loss: 0.246874138712883\n",
            "Epoch 49, Step 51, Loss: 0.20696285367012024\n",
            "Epoch 49, Step 52, Loss: 0.1987309753894806\n",
            "Epoch 49, Step 53, Loss: 0.2984734773635864\n",
            "Epoch 49, Step 54, Loss: 0.23556993901729584\n",
            "Epoch 49, Step 55, Loss: 0.20893722772598267\n",
            "Epoch 49, Step 56, Loss: 0.24929632246494293\n",
            "Epoch 49, Step 57, Loss: 0.21883313357830048\n",
            "Epoch 49, Step 58, Loss: 0.3009366989135742\n",
            "Epoch 49, Step 59, Loss: 0.23131637275218964\n",
            "Epoch 49, Step 60, Loss: 0.16802391409873962\n",
            "Epoch 49, Step 61, Loss: 0.24038846790790558\n",
            "Epoch 49, Step 62, Loss: 0.40318918228149414\n",
            "Epoch 49, Step 63, Loss: 0.35501518845558167\n",
            "Epoch 49, Step 64, Loss: 0.16268055140972137\n",
            "Epoch 49, Step 65, Loss: 0.22167004644870758\n",
            "Epoch 49, Step 66, Loss: 0.17682261765003204\n",
            "Epoch 49, Step 67, Loss: 0.21503691375255585\n",
            "Epoch 49, Step 68, Loss: 0.2664593458175659\n",
            "Epoch 49, Step 69, Loss: 0.17197799682617188\n",
            "Epoch 49, Step 70, Loss: 0.1656026840209961\n",
            "Epoch 49, Step 71, Loss: 0.34978166222572327\n",
            "Epoch 49, Step 72, Loss: 0.19308696687221527\n",
            "Epoch 49, Step 73, Loss: 0.28423646092414856\n",
            "Epoch 49, Step 74, Loss: 0.3456709384918213\n",
            "Epoch 49, Step 75, Loss: 0.22288744151592255\n",
            "Epoch 49, Step 76, Loss: 0.27349603176116943\n",
            "Epoch 49, Step 77, Loss: 0.22616246342658997\n",
            "Epoch 49, Step 78, Loss: 0.2786671221256256\n",
            "Epoch 49, Step 79, Loss: 0.2391914576292038\n",
            "Epoch 49, Step 80, Loss: 0.20763641595840454\n",
            "Epoch 49, Step 81, Loss: 0.32512515783309937\n",
            "Epoch 49, Step 82, Loss: 0.2610730826854706\n",
            "Epoch 49, Step 83, Loss: 0.250706285238266\n",
            "Epoch 49, Step 84, Loss: 0.20496338605880737\n",
            "Epoch 49, Step 85, Loss: 0.26153838634490967\n",
            "Epoch 49, Step 86, Loss: 0.13811039924621582\n",
            "Epoch 49, Step 87, Loss: 0.25608769059181213\n",
            "Epoch 49, Step 88, Loss: 0.17792436480522156\n",
            "Epoch 49, Step 89, Loss: 0.2239798754453659\n",
            "Epoch 49, Step 90, Loss: 0.21019533276557922\n",
            "Epoch 49, Step 91, Loss: 0.43526899814605713\n",
            "Epoch 49, Step 92, Loss: 0.20892420411109924\n",
            "Epoch 49, Step 93, Loss: 0.21028953790664673\n",
            "Epoch 49, Step 94, Loss: 0.1979505568742752\n",
            "Epoch 49, Step 95, Loss: 0.19275160133838654\n",
            "Epoch 49, Step 96, Loss: 0.10179030150175095\n",
            "Epoch 49, Step 97, Loss: 0.16818855702877045\n",
            "Epoch 49, Step 98, Loss: 0.23399995267391205\n",
            "Epoch 49, Step 99, Loss: 0.2133771777153015\n",
            "Epoch 49, Step 100, Loss: 0.3579135835170746\n",
            "Epoch 49, Step 101, Loss: 0.16519854962825775\n",
            "Epoch 49, Step 102, Loss: 0.2728859484195709\n",
            "Epoch 49, Step 103, Loss: 0.18983155488967896\n",
            "Epoch 49, Step 104, Loss: 0.3012308180332184\n",
            "Epoch 49, Step 105, Loss: 0.12465109676122665\n",
            "Epoch 49, Step 106, Loss: 0.24588432908058167\n",
            "Epoch 49, Step 107, Loss: 0.20556770265102386\n",
            "Epoch 49, Step 108, Loss: 0.37600216269493103\n",
            "Epoch 49, Step 109, Loss: 0.19704902172088623\n",
            "Epoch 49, Step 110, Loss: 0.4391133189201355\n",
            "Epoch 49, Step 111, Loss: 0.2504642605781555\n",
            "Epoch 49, Step 112, Loss: 0.2218560427427292\n",
            "Epoch 49, Step 113, Loss: 0.1937292218208313\n",
            "Epoch 49, Step 114, Loss: 0.16825248301029205\n",
            "Epoch 49, Step 115, Loss: 0.17244109511375427\n",
            "Epoch 49, Step 116, Loss: 0.1917666643857956\n",
            "Epoch 49, Step 117, Loss: 0.2081620842218399\n",
            "Epoch 49, Step 118, Loss: 0.2161686271429062\n",
            "Epoch 49, Step 119, Loss: 0.280859112739563\n",
            "Epoch 49, Step 120, Loss: 0.24198682606220245\n",
            "Epoch 49, Step 121, Loss: 0.251281201839447\n",
            "Epoch 49, Step 122, Loss: 0.23426857590675354\n",
            "Epoch 49, Step 123, Loss: 0.3833177983760834\n",
            "Epoch 49, Step 124, Loss: 0.23946921527385712\n",
            "Epoch 49, Step 125, Loss: 0.267337828874588\n",
            "Epoch 49, Step 126, Loss: 0.2444319874048233\n",
            "Epoch 49, Step 127, Loss: 0.21204672753810883\n",
            "Epoch 49, Step 128, Loss: 0.19460248947143555\n",
            "Epoch 49, Step 129, Loss: 0.2027180939912796\n",
            "Epoch 49, Step 130, Loss: 0.30789318680763245\n",
            "Epoch 49, Step 131, Loss: 0.25480854511260986\n",
            "Epoch 49, Step 132, Loss: 0.25558680295944214\n",
            "Epoch 49, Step 133, Loss: 0.3335924744606018\n",
            "Epoch 49, Step 134, Loss: 0.2333747148513794\n",
            "Epoch 49, Step 135, Loss: 0.2291831225156784\n",
            "Epoch 49, Step 136, Loss: 0.3644416928291321\n",
            "Epoch 49, Step 137, Loss: 0.2686350345611572\n",
            "Epoch 49, Step 138, Loss: 0.29047539830207825\n",
            "Epoch 49, Step 139, Loss: 0.15776962041854858\n",
            "Epoch 49, Step 140, Loss: 0.25581249594688416\n",
            "Epoch 49, Step 141, Loss: 0.18895021080970764\n",
            "Epoch 49, Step 142, Loss: 0.2305920273065567\n",
            "Epoch 49, Step 143, Loss: 0.2457258552312851\n",
            "Epoch 49, Step 144, Loss: 0.2298642247915268\n",
            "Epoch 49, Step 145, Loss: 0.2646178901195526\n",
            "Epoch 49, Step 146, Loss: 0.21731705963611603\n",
            "Epoch 49, Step 147, Loss: 0.25610795617103577\n",
            "Epoch 49, Step 148, Loss: 0.2800576686859131\n",
            "Epoch 49, Step 149, Loss: 0.13876941800117493\n",
            "Epoch 49, Step 150, Loss: 0.2568342685699463\n",
            "Epoch 49, Step 151, Loss: 0.32130271196365356\n",
            "Epoch 49, Step 152, Loss: 0.24301324784755707\n",
            "Epoch 49, Step 153, Loss: 0.17246612906455994\n",
            "Epoch 49, Step 154, Loss: 0.2417289912700653\n",
            "Epoch 49, Step 155, Loss: 0.1948160082101822\n",
            "Epoch 49, Step 156, Loss: 0.3122662305831909\n",
            "Epoch 49, Step 157, Loss: 0.21665363013744354\n",
            "Epoch 49, Step 158, Loss: 0.35257965326309204\n",
            "Epoch 49, Step 159, Loss: 0.24143539369106293\n",
            "Epoch 49, Step 160, Loss: 0.29183536767959595\n",
            "Epoch 49, Step 161, Loss: 0.21785548329353333\n",
            "Epoch 49, Step 162, Loss: 0.23350368440151215\n",
            "Epoch 49, Step 163, Loss: 0.2382194995880127\n",
            "Epoch 49, Step 164, Loss: 0.21226628124713898\n",
            "Epoch 49, Step 165, Loss: 0.2738175690174103\n",
            "Epoch 49, Step 166, Loss: 0.24565286934375763\n",
            "Epoch 49, Step 167, Loss: 0.28876444697380066\n",
            "Epoch 49, Step 168, Loss: 0.27528804540634155\n",
            "Epoch 49, Step 169, Loss: 0.5013062357902527\n",
            "Epoch 49, Step 170, Loss: 0.26210013031959534\n",
            "Epoch 49, Step 171, Loss: 0.2344720959663391\n",
            "Epoch 49, Step 172, Loss: 0.26152756810188293\n",
            "Epoch 49, Step 173, Loss: 0.29392457008361816\n",
            "Epoch 49, Step 174, Loss: 0.23228338360786438\n",
            "Epoch 49, Step 175, Loss: 0.1744309365749359\n",
            "Epoch 49, Step 176, Loss: 0.14046001434326172\n",
            "Epoch 49, Step 177, Loss: 0.17523598670959473\n",
            "Epoch 49, Step 178, Loss: 0.2840297222137451\n",
            "Epoch 49, Step 179, Loss: 0.18848319351673126\n",
            "Epoch 49, Step 180, Loss: 0.21907368302345276\n",
            "Epoch 49, Step 181, Loss: 0.21471169590950012\n",
            "Epoch 49, Step 182, Loss: 0.1833580732345581\n",
            "Epoch 49, Step 183, Loss: 0.16677425801753998\n",
            "Epoch 49, Step 184, Loss: 0.28541770577430725\n",
            "Epoch 49, Step 185, Loss: 0.3242553472518921\n",
            "Epoch 49, Step 186, Loss: 0.39865463972091675\n",
            "Epoch 49, Step 187, Loss: 0.16025355458259583\n",
            "Epoch 49, Step 188, Loss: 0.28701165318489075\n",
            "Epoch 49, Step 189, Loss: 0.37528195977211\n",
            "Epoch 49, Step 190, Loss: 0.2017107456922531\n",
            "Epoch 49, Step 191, Loss: 0.28892526030540466\n",
            "Epoch 49, Step 192, Loss: 0.32305780053138733\n",
            "Epoch 49, Step 193, Loss: 0.1204725056886673\n",
            "Epoch 49, Step 194, Loss: 0.25115272402763367\n",
            "Epoch 49, Step 195, Loss: 0.17101313173770905\n",
            "Epoch 49, Step 196, Loss: 0.25703954696655273\n",
            "Epoch 49, Step 197, Loss: 0.1667805165052414\n",
            "Epoch 49, Step 198, Loss: 0.18478907644748688\n",
            "Epoch 49, Step 199, Loss: 0.23181064426898956\n",
            "Epoch 49, Step 200, Loss: 0.17407581210136414\n",
            "Epoch 49, Step 201, Loss: 0.30678310990333557\n",
            "Epoch 49, Step 202, Loss: 0.19573423266410828\n",
            "Epoch 49, Step 203, Loss: 0.2518693804740906\n",
            "Epoch 49, Step 204, Loss: 0.2587510347366333\n",
            "Epoch 49, Step 205, Loss: 0.23957574367523193\n",
            "Epoch 49, Step 206, Loss: 0.2693007290363312\n",
            "Epoch 49, Step 207, Loss: 0.28565990924835205\n",
            "Epoch 49, Step 208, Loss: 0.15264298021793365\n",
            "Epoch 49, Step 209, Loss: 0.15189164876937866\n",
            "Epoch 49, Step 210, Loss: 0.19672061502933502\n",
            "Epoch 49, Step 211, Loss: 0.20189566910266876\n",
            "Epoch 49, Step 212, Loss: 0.24167253077030182\n",
            "Epoch 49, Step 213, Loss: 0.2727857530117035\n",
            "Epoch 49, Step 214, Loss: 0.21598787605762482\n",
            "Epoch 49, Step 215, Loss: 0.2381761521100998\n",
            "Epoch 49, Step 216, Loss: 0.34604302048683167\n",
            "Epoch 49, Step 217, Loss: 0.20805950462818146\n",
            "Epoch 49, Step 218, Loss: 0.2473699450492859\n",
            "Epoch 49, Step 219, Loss: 0.2940904200077057\n",
            "Epoch 49, Step 220, Loss: 0.3066931664943695\n",
            "Epoch 49, Step 221, Loss: 0.2735545039176941\n",
            "Epoch 49, Step 222, Loss: 0.17461073398590088\n",
            "Epoch 49, Step 223, Loss: 0.292930543422699\n",
            "Epoch 49, Step 224, Loss: 0.1442425698041916\n",
            "Epoch 49, Step 225, Loss: 0.2204633355140686\n",
            "Epoch 49, Step 226, Loss: 0.2865658104419708\n",
            "Epoch 49, Step 227, Loss: 0.2767919600009918\n",
            "Epoch 49, Step 228, Loss: 0.31442588567733765\n",
            "Epoch 49, Step 229, Loss: 0.24586907029151917\n",
            "Epoch 49, Step 230, Loss: 0.23512262105941772\n",
            "Epoch 49, Step 231, Loss: 0.35033729672431946\n",
            "Epoch 49, Step 232, Loss: 0.2414168268442154\n",
            "Epoch 49, Step 233, Loss: 0.3285205662250519\n",
            "Epoch 49, Step 234, Loss: 0.2611023187637329\n",
            "Epoch 49, Step 235, Loss: 0.3159485459327698\n",
            "Epoch 49, Step 236, Loss: 0.22378547489643097\n",
            "Epoch 49, Step 237, Loss: 0.25852400064468384\n",
            "Epoch 49, Step 238, Loss: 0.27062350511550903\n",
            "Epoch 49, Step 239, Loss: 0.19288870692253113\n",
            "Epoch 49, Step 240, Loss: 0.24313437938690186\n",
            "Epoch 49, Step 241, Loss: 0.3028965890407562\n",
            "Epoch 49, Step 242, Loss: 0.22341643273830414\n",
            "Epoch 49, Step 243, Loss: 0.2815954387187958\n",
            "Epoch 49, Step 244, Loss: 0.2577248513698578\n",
            "Epoch 49, Step 245, Loss: 0.289154589176178\n",
            "Epoch 49, Step 246, Loss: 0.1733224093914032\n",
            "Epoch 49, Step 247, Loss: 0.3512243628501892\n",
            "Epoch 49, Step 248, Loss: 0.1915467083454132\n",
            "Epoch 49, Step 249, Loss: 0.27382341027259827\n",
            "Epoch 49, Step 250, Loss: 0.2121661901473999\n",
            "Epoch 49, Step 251, Loss: 0.33597487211227417\n",
            "Epoch 49, Step 252, Loss: 0.21948941051959991\n",
            "Epoch 49, Step 253, Loss: 0.2397257685661316\n",
            "Epoch 49, Step 254, Loss: 0.3015536069869995\n",
            "Epoch 49, Step 255, Loss: 0.2462097704410553\n",
            "Epoch 49, Step 256, Loss: 0.21814674139022827\n",
            "Epoch 49, Step 257, Loss: 0.35322874784469604\n",
            "Epoch 49, Step 258, Loss: 0.254959374666214\n",
            "Epoch 49, Step 259, Loss: 0.23394331336021423\n",
            "Epoch 49, Step 260, Loss: 0.32901614904403687\n",
            "Epoch 49, Step 261, Loss: 0.17564092576503754\n",
            "Epoch 49, Step 262, Loss: 0.259594589471817\n",
            "Epoch 49, Step 263, Loss: 0.15025699138641357\n",
            "Epoch 49, Step 264, Loss: 0.23980355262756348\n",
            "Epoch 49, Step 265, Loss: 0.26376861333847046\n",
            "Epoch 49, Step 266, Loss: 0.17254222929477692\n",
            "Epoch 49, Step 267, Loss: 0.37180963158607483\n",
            "Epoch 49, Step 268, Loss: 0.21884743869304657\n",
            "Epoch 49, Step 269, Loss: 0.2566492557525635\n",
            "Epoch 49, Step 270, Loss: 0.22829167544841766\n",
            "Epoch 49, Step 271, Loss: 0.29408368468284607\n",
            "Epoch 49, Step 272, Loss: 0.15078939497470856\n",
            "Epoch 49, Step 273, Loss: 0.2592751979827881\n",
            "Epoch 49, Step 274, Loss: 0.2969144582748413\n",
            "Epoch 49, Step 275, Loss: 0.16249068081378937\n",
            "Epoch 49, Step 276, Loss: 0.22171254456043243\n",
            "Epoch 49, Step 277, Loss: 0.2815432548522949\n",
            "Epoch 49, Step 278, Loss: 0.2657584249973297\n",
            "Epoch 49, Step 279, Loss: 0.2604356110095978\n",
            "Epoch 49, Step 280, Loss: 0.25720155239105225\n",
            "Epoch 49, Step 281, Loss: 0.22042010724544525\n",
            "Epoch 49, Step 282, Loss: 0.20265817642211914\n",
            "Epoch 49, Step 283, Loss: 0.2106950581073761\n",
            "Epoch 49, Step 284, Loss: 0.23739364743232727\n",
            "Epoch 49, Step 285, Loss: 0.2334650754928589\n",
            "Epoch 49, Step 286, Loss: 0.2341151386499405\n",
            "Epoch 49, Step 287, Loss: 0.21615642309188843\n",
            "Epoch 49, Step 288, Loss: 0.19153371453285217\n",
            "Epoch 49, Step 289, Loss: 0.29373717308044434\n",
            "Epoch 49, Step 290, Loss: 0.24154192209243774\n",
            "Epoch 49, Step 291, Loss: 0.27228012681007385\n",
            "Epoch 49, Step 292, Loss: 0.18005289137363434\n",
            "Epoch 49, Step 293, Loss: 0.16655012965202332\n",
            "Epoch 49, Step 294, Loss: 0.17460644245147705\n",
            "Epoch 49, Step 295, Loss: 0.2850884199142456\n",
            "Epoch 49, Step 296, Loss: 0.1411934345960617\n",
            "Epoch 49, Step 297, Loss: 0.19565033912658691\n",
            "Epoch 49, Step 298, Loss: 0.24260567128658295\n",
            "Epoch 49, Step 299, Loss: 0.2288426011800766\n",
            "Epoch 49, Step 300, Loss: 0.3245406150817871\n",
            "Epoch 49, Step 301, Loss: 0.17603978514671326\n",
            "Epoch 49, Step 302, Loss: 0.24884483218193054\n",
            "Epoch 49, Step 303, Loss: 0.2274925857782364\n",
            "Epoch 49, Step 304, Loss: 0.3581809401512146\n",
            "Epoch 49, Step 305, Loss: 0.23955927789211273\n",
            "Epoch 49, Step 306, Loss: 0.3503069579601288\n",
            "Epoch 49, Step 307, Loss: 0.22674351930618286\n",
            "Epoch 49, Step 308, Loss: 0.2853773534297943\n",
            "Epoch 49, Step 309, Loss: 0.24887952208518982\n",
            "Epoch 49, Step 310, Loss: 0.1754753440618515\n",
            "Epoch 49, Step 311, Loss: 0.319730669260025\n",
            "Epoch 49, Step 312, Loss: 0.2082759141921997\n",
            "Epoch 49 end, avg train loss: 0.24656427649263377\n",
            "Epoch 49 end, avg val loss: 0.348903855568246, accuracy: 88.90%\n",
            "Epoch 50, Step 0, Loss: 0.11302978545427322\n",
            "Epoch 50, Step 1, Loss: 0.28418079018592834\n",
            "Epoch 50, Step 2, Loss: 0.28778237104415894\n",
            "Epoch 50, Step 3, Loss: 0.23383715748786926\n",
            "Epoch 50, Step 4, Loss: 0.22409550845623016\n",
            "Epoch 50, Step 5, Loss: 0.2713255286216736\n",
            "Epoch 50, Step 6, Loss: 0.16693015396595\n",
            "Epoch 50, Step 7, Loss: 0.23126761615276337\n",
            "Epoch 50, Step 8, Loss: 0.3631564676761627\n",
            "Epoch 50, Step 9, Loss: 0.28754669427871704\n",
            "Epoch 50, Step 10, Loss: 0.21524418890476227\n",
            "Epoch 50, Step 11, Loss: 0.32712921500205994\n",
            "Epoch 50, Step 12, Loss: 0.2652435302734375\n",
            "Epoch 50, Step 13, Loss: 0.2474772036075592\n",
            "Epoch 50, Step 14, Loss: 0.18936604261398315\n",
            "Epoch 50, Step 15, Loss: 0.3884700834751129\n",
            "Epoch 50, Step 16, Loss: 0.2548920810222626\n",
            "Epoch 50, Step 17, Loss: 0.1453302949666977\n",
            "Epoch 50, Step 18, Loss: 0.17178253829479218\n",
            "Epoch 50, Step 19, Loss: 0.3844330608844757\n",
            "Epoch 50, Step 20, Loss: 0.1282728761434555\n",
            "Epoch 50, Step 21, Loss: 0.2958909869194031\n",
            "Epoch 50, Step 22, Loss: 0.3706011176109314\n",
            "Epoch 50, Step 23, Loss: 0.19879907369613647\n",
            "Epoch 50, Step 24, Loss: 0.22522662580013275\n",
            "Epoch 50, Step 25, Loss: 0.18406590819358826\n",
            "Epoch 50, Step 26, Loss: 0.22634708881378174\n",
            "Epoch 50, Step 27, Loss: 0.21435703337192535\n",
            "Epoch 50, Step 28, Loss: 0.307420939207077\n",
            "Epoch 50, Step 29, Loss: 0.17637602984905243\n",
            "Epoch 50, Step 30, Loss: 0.3417726457118988\n",
            "Epoch 50, Step 31, Loss: 0.3175378441810608\n",
            "Epoch 50, Step 32, Loss: 0.20732103288173676\n",
            "Epoch 50, Step 33, Loss: 0.21656769514083862\n",
            "Epoch 50, Step 34, Loss: 0.22133751213550568\n",
            "Epoch 50, Step 35, Loss: 0.24244971573352814\n",
            "Epoch 50, Step 36, Loss: 0.3094117045402527\n",
            "Epoch 50, Step 37, Loss: 0.1337563842535019\n",
            "Epoch 50, Step 38, Loss: 0.2985380291938782\n",
            "Epoch 50, Step 39, Loss: 0.2124229520559311\n",
            "Epoch 50, Step 40, Loss: 0.2522070109844208\n",
            "Epoch 50, Step 41, Loss: 0.24475136399269104\n",
            "Epoch 50, Step 42, Loss: 0.29887330532073975\n",
            "Epoch 50, Step 43, Loss: 0.3046647012233734\n",
            "Epoch 50, Step 44, Loss: 0.21333114802837372\n",
            "Epoch 50, Step 45, Loss: 0.19590972363948822\n",
            "Epoch 50, Step 46, Loss: 0.14015179872512817\n",
            "Epoch 50, Step 47, Loss: 0.17373353242874146\n",
            "Epoch 50, Step 48, Loss: 0.20094475150108337\n",
            "Epoch 50, Step 49, Loss: 0.28940659761428833\n",
            "Epoch 50, Step 50, Loss: 0.21613258123397827\n",
            "Epoch 50, Step 51, Loss: 0.23963527381420135\n",
            "Epoch 50, Step 52, Loss: 0.23446254432201385\n",
            "Epoch 50, Step 53, Loss: 0.2697933614253998\n",
            "Epoch 50, Step 54, Loss: 0.30839475989341736\n",
            "Epoch 50, Step 55, Loss: 0.1680530309677124\n",
            "Epoch 50, Step 56, Loss: 0.24944931268692017\n",
            "Epoch 50, Step 57, Loss: 0.26117560267448425\n",
            "Epoch 50, Step 58, Loss: 0.20463399589061737\n",
            "Epoch 50, Step 59, Loss: 0.17761607468128204\n",
            "Epoch 50, Step 60, Loss: 0.23163482546806335\n",
            "Epoch 50, Step 61, Loss: 0.20617081224918365\n",
            "Epoch 50, Step 62, Loss: 0.2658306062221527\n",
            "Epoch 50, Step 63, Loss: 0.17517654597759247\n",
            "Epoch 50, Step 64, Loss: 0.2501027286052704\n",
            "Epoch 50, Step 65, Loss: 0.3072826564311981\n",
            "Epoch 50, Step 66, Loss: 0.21589618921279907\n",
            "Epoch 50, Step 67, Loss: 0.23373836278915405\n",
            "Epoch 50, Step 68, Loss: 0.28094005584716797\n",
            "Epoch 50, Step 69, Loss: 0.2170075625181198\n",
            "Epoch 50, Step 70, Loss: 0.2296055257320404\n",
            "Epoch 50, Step 71, Loss: 0.21237094700336456\n",
            "Epoch 50, Step 72, Loss: 0.24201421439647675\n",
            "Epoch 50, Step 73, Loss: 0.26005324721336365\n",
            "Epoch 50, Step 74, Loss: 0.2339862585067749\n",
            "Epoch 50, Step 75, Loss: 0.22290605306625366\n",
            "Epoch 50, Step 76, Loss: 0.21472972631454468\n",
            "Epoch 50, Step 77, Loss: 0.27413448691368103\n",
            "Epoch 50, Step 78, Loss: 0.28124862909317017\n",
            "Epoch 50, Step 79, Loss: 0.24257993698120117\n",
            "Epoch 50, Step 80, Loss: 0.2249831110239029\n",
            "Epoch 50, Step 81, Loss: 0.2133811116218567\n",
            "Epoch 50, Step 82, Loss: 0.15237456560134888\n",
            "Epoch 50, Step 83, Loss: 0.17457179725170135\n",
            "Epoch 50, Step 84, Loss: 0.29147645831108093\n",
            "Epoch 50, Step 85, Loss: 0.22450457513332367\n",
            "Epoch 50, Step 86, Loss: 0.2960205376148224\n",
            "Epoch 50, Step 87, Loss: 0.22732359170913696\n",
            "Epoch 50, Step 88, Loss: 0.1616133600473404\n",
            "Epoch 50, Step 89, Loss: 0.19673213362693787\n",
            "Epoch 50, Step 90, Loss: 0.2843078374862671\n",
            "Epoch 50, Step 91, Loss: 0.2735464870929718\n",
            "Epoch 50, Step 92, Loss: 0.21362335979938507\n",
            "Epoch 50, Step 93, Loss: 0.19859379529953003\n",
            "Epoch 50, Step 94, Loss: 0.20478588342666626\n",
            "Epoch 50, Step 95, Loss: 0.3410510718822479\n",
            "Epoch 50, Step 96, Loss: 0.16144296526908875\n",
            "Epoch 50, Step 97, Loss: 0.2576743960380554\n",
            "Epoch 50, Step 98, Loss: 0.2009296417236328\n",
            "Epoch 50, Step 99, Loss: 0.24554769694805145\n",
            "Epoch 50, Step 100, Loss: 0.2998909652233124\n",
            "Epoch 50, Step 101, Loss: 0.17371973395347595\n",
            "Epoch 50, Step 102, Loss: 0.24668143689632416\n",
            "Epoch 50, Step 103, Loss: 0.17198003828525543\n",
            "Epoch 50, Step 104, Loss: 0.2036355882883072\n",
            "Epoch 50, Step 105, Loss: 0.25907400250434875\n",
            "Epoch 50, Step 106, Loss: 0.3064292371273041\n",
            "Epoch 50, Step 107, Loss: 0.24886049330234528\n",
            "Epoch 50, Step 108, Loss: 0.15256786346435547\n",
            "Epoch 50, Step 109, Loss: 0.31510815024375916\n",
            "Epoch 50, Step 110, Loss: 0.1696038842201233\n",
            "Epoch 50, Step 111, Loss: 0.18975184857845306\n",
            "Epoch 50, Step 112, Loss: 0.25765547156333923\n",
            "Epoch 50, Step 113, Loss: 0.2645436227321625\n",
            "Epoch 50, Step 114, Loss: 0.26875603199005127\n",
            "Epoch 50, Step 115, Loss: 0.20876918733119965\n",
            "Epoch 50, Step 116, Loss: 0.2873324155807495\n",
            "Epoch 50, Step 117, Loss: 0.1762649565935135\n",
            "Epoch 50, Step 118, Loss: 0.19248276948928833\n",
            "Epoch 50, Step 119, Loss: 0.2548067569732666\n",
            "Epoch 50, Step 120, Loss: 0.2175225466489792\n",
            "Epoch 50, Step 121, Loss: 0.17748117446899414\n",
            "Epoch 50, Step 122, Loss: 0.2927640378475189\n",
            "Epoch 50, Step 123, Loss: 0.23613497614860535\n",
            "Epoch 50, Step 124, Loss: 0.27281633019447327\n",
            "Epoch 50, Step 125, Loss: 0.2487204521894455\n",
            "Epoch 50, Step 126, Loss: 0.20695386826992035\n",
            "Epoch 50, Step 127, Loss: 0.29308298230171204\n",
            "Epoch 50, Step 128, Loss: 0.16671571135520935\n",
            "Epoch 50, Step 129, Loss: 0.26842767000198364\n",
            "Epoch 50, Step 130, Loss: 0.1870318055152893\n",
            "Epoch 50, Step 131, Loss: 0.2028992474079132\n",
            "Epoch 50, Step 132, Loss: 0.25420835614204407\n",
            "Epoch 50, Step 133, Loss: 0.18826957046985626\n",
            "Epoch 50, Step 134, Loss: 0.251618355512619\n",
            "Epoch 50, Step 135, Loss: 0.2360144406557083\n",
            "Epoch 50, Step 136, Loss: 0.25076887011528015\n",
            "Epoch 50, Step 137, Loss: 0.23414944112300873\n",
            "Epoch 50, Step 138, Loss: 0.25859367847442627\n",
            "Epoch 50, Step 139, Loss: 0.17417308688163757\n",
            "Epoch 50, Step 140, Loss: 0.30471962690353394\n",
            "Epoch 50, Step 141, Loss: 0.3242562413215637\n",
            "Epoch 50, Step 142, Loss: 0.17667701840400696\n",
            "Epoch 50, Step 143, Loss: 0.2266993522644043\n",
            "Epoch 50, Step 144, Loss: 0.2289564162492752\n",
            "Epoch 50, Step 145, Loss: 0.26415199041366577\n",
            "Epoch 50, Step 146, Loss: 0.1993470937013626\n",
            "Epoch 50, Step 147, Loss: 0.18378318846225739\n",
            "Epoch 50, Step 148, Loss: 0.2620168626308441\n",
            "Epoch 50, Step 149, Loss: 0.2174399048089981\n",
            "Epoch 50, Step 150, Loss: 0.2591986060142517\n",
            "Epoch 50, Step 151, Loss: 0.32397574186325073\n",
            "Epoch 50, Step 152, Loss: 0.2025592178106308\n",
            "Epoch 50, Step 153, Loss: 0.13526777923107147\n",
            "Epoch 50, Step 154, Loss: 0.20459617674350739\n",
            "Epoch 50, Step 155, Loss: 0.2654852271080017\n",
            "Epoch 50, Step 156, Loss: 0.16047249734401703\n",
            "Epoch 50, Step 157, Loss: 0.22032037377357483\n",
            "Epoch 50, Step 158, Loss: 0.36522534489631653\n",
            "Epoch 50, Step 159, Loss: 0.31514376401901245\n",
            "Epoch 50, Step 160, Loss: 0.19350585341453552\n",
            "Epoch 50, Step 161, Loss: 0.19256463646888733\n",
            "Epoch 50, Step 162, Loss: 0.2162066102027893\n",
            "Epoch 50, Step 163, Loss: 0.20379051566123962\n",
            "Epoch 50, Step 164, Loss: 0.22889769077301025\n",
            "Epoch 50, Step 165, Loss: 0.17243221402168274\n",
            "Epoch 50, Step 166, Loss: 0.31947895884513855\n",
            "Epoch 50, Step 167, Loss: 0.1773083657026291\n",
            "Epoch 50, Step 168, Loss: 0.20038244128227234\n",
            "Epoch 50, Step 169, Loss: 0.15504597127437592\n",
            "Epoch 50, Step 170, Loss: 0.25271034240722656\n",
            "Epoch 50, Step 171, Loss: 0.24167199432849884\n",
            "Epoch 50, Step 172, Loss: 0.2900308072566986\n",
            "Epoch 50, Step 173, Loss: 0.20644164085388184\n",
            "Epoch 50, Step 174, Loss: 0.18274155259132385\n",
            "Epoch 50, Step 175, Loss: 0.29534417390823364\n",
            "Epoch 50, Step 176, Loss: 0.30940738320350647\n",
            "Epoch 50, Step 177, Loss: 0.18305309116840363\n",
            "Epoch 50, Step 178, Loss: 0.2545458972454071\n",
            "Epoch 50, Step 179, Loss: 0.35949844121932983\n",
            "Epoch 50, Step 180, Loss: 0.12654158473014832\n",
            "Epoch 50, Step 181, Loss: 0.25402310490608215\n",
            "Epoch 50, Step 182, Loss: 0.2604599595069885\n",
            "Epoch 50, Step 183, Loss: 0.22303567826747894\n",
            "Epoch 50, Step 184, Loss: 0.35318827629089355\n",
            "Epoch 50, Step 185, Loss: 0.3134467303752899\n",
            "Epoch 50, Step 186, Loss: 0.21311591565608978\n",
            "Epoch 50, Step 187, Loss: 0.28714311122894287\n",
            "Epoch 50, Step 188, Loss: 0.2562638521194458\n",
            "Epoch 50, Step 189, Loss: 0.3072589039802551\n",
            "Epoch 50, Step 190, Loss: 0.25990334153175354\n",
            "Epoch 50, Step 191, Loss: 0.17998385429382324\n",
            "Epoch 50, Step 192, Loss: 0.17820903658866882\n",
            "Epoch 50, Step 193, Loss: 0.330183744430542\n",
            "Epoch 50, Step 194, Loss: 0.3678632080554962\n",
            "Epoch 50, Step 195, Loss: 0.185125932097435\n",
            "Epoch 50, Step 196, Loss: 0.2665379047393799\n",
            "Epoch 50, Step 197, Loss: 0.3299960494041443\n",
            "Epoch 50, Step 198, Loss: 0.35412970185279846\n",
            "Epoch 50, Step 199, Loss: 0.27105268836021423\n",
            "Epoch 50, Step 200, Loss: 0.20857557654380798\n",
            "Epoch 50, Step 201, Loss: 0.21854528784751892\n",
            "Epoch 50, Step 202, Loss: 0.2654249370098114\n",
            "Epoch 50, Step 203, Loss: 0.2429429292678833\n",
            "Epoch 50, Step 204, Loss: 0.2866111695766449\n",
            "Epoch 50, Step 205, Loss: 0.19791486859321594\n",
            "Epoch 50, Step 206, Loss: 0.2589469850063324\n",
            "Epoch 50, Step 207, Loss: 0.27482566237449646\n",
            "Epoch 50, Step 208, Loss: 0.19820642471313477\n",
            "Epoch 50, Step 209, Loss: 0.31887128949165344\n",
            "Epoch 50, Step 210, Loss: 0.32981637120246887\n",
            "Epoch 50, Step 211, Loss: 0.30833977460861206\n",
            "Epoch 50, Step 212, Loss: 0.17857545614242554\n",
            "Epoch 50, Step 213, Loss: 0.3623904287815094\n",
            "Epoch 50, Step 214, Loss: 0.3334609866142273\n",
            "Epoch 50, Step 215, Loss: 0.21259291470050812\n",
            "Epoch 50, Step 216, Loss: 0.1658352166414261\n",
            "Epoch 50, Step 217, Loss: 0.3467884063720703\n",
            "Epoch 50, Step 218, Loss: 0.2732917368412018\n",
            "Epoch 50, Step 219, Loss: 0.29138311743736267\n",
            "Epoch 50, Step 220, Loss: 0.2635723054409027\n",
            "Epoch 50, Step 221, Loss: 0.21440057456493378\n",
            "Epoch 50, Step 222, Loss: 0.31204095482826233\n",
            "Epoch 50, Step 223, Loss: 0.26442456245422363\n",
            "Epoch 50, Step 224, Loss: 0.23310774564743042\n",
            "Epoch 50, Step 225, Loss: 0.23503385484218597\n",
            "Epoch 50, Step 226, Loss: 0.25509101152420044\n",
            "Epoch 50, Step 227, Loss: 0.19410277903079987\n",
            "Epoch 50, Step 228, Loss: 0.19533789157867432\n",
            "Epoch 50, Step 229, Loss: 0.17426609992980957\n",
            "Epoch 50, Step 230, Loss: 0.15060439705848694\n",
            "Epoch 50, Step 231, Loss: 0.21763737499713898\n",
            "Epoch 50, Step 232, Loss: 0.29118767380714417\n",
            "Epoch 50, Step 233, Loss: 0.23694002628326416\n",
            "Epoch 50, Step 234, Loss: 0.19353148341178894\n",
            "Epoch 50, Step 235, Loss: 0.13273985683918\n",
            "Epoch 50, Step 236, Loss: 0.19839544594287872\n",
            "Epoch 50, Step 237, Loss: 0.26311519742012024\n",
            "Epoch 50, Step 238, Loss: 0.3636798560619354\n",
            "Epoch 50, Step 239, Loss: 0.25872284173965454\n",
            "Epoch 50, Step 240, Loss: 0.22670620679855347\n",
            "Epoch 50, Step 241, Loss: 0.1847618967294693\n",
            "Epoch 50, Step 242, Loss: 0.24173197150230408\n",
            "Epoch 50, Step 243, Loss: 0.21374818682670593\n",
            "Epoch 50, Step 244, Loss: 0.26709917187690735\n",
            "Epoch 50, Step 245, Loss: 0.269221693277359\n",
            "Epoch 50, Step 246, Loss: 0.15595634281635284\n",
            "Epoch 50, Step 247, Loss: 0.24594838917255402\n",
            "Epoch 50, Step 248, Loss: 0.2778526544570923\n",
            "Epoch 50, Step 249, Loss: 0.3032234013080597\n",
            "Epoch 50, Step 250, Loss: 0.2838062047958374\n",
            "Epoch 50, Step 251, Loss: 0.3131718933582306\n",
            "Epoch 50, Step 252, Loss: 0.25493887066841125\n",
            "Epoch 50, Step 253, Loss: 0.22403346002101898\n",
            "Epoch 50, Step 254, Loss: 0.2718580365180969\n",
            "Epoch 50, Step 255, Loss: 0.41849005222320557\n",
            "Epoch 50, Step 256, Loss: 0.2694169282913208\n",
            "Epoch 50, Step 257, Loss: 0.2663843035697937\n",
            "Epoch 50, Step 258, Loss: 0.30493128299713135\n",
            "Epoch 50, Step 259, Loss: 0.2620147168636322\n",
            "Epoch 50, Step 260, Loss: 0.28199905157089233\n",
            "Epoch 50, Step 261, Loss: 0.18372613191604614\n",
            "Epoch 50, Step 262, Loss: 0.14483776688575745\n",
            "Epoch 50, Step 263, Loss: 0.14836332201957703\n",
            "Epoch 50, Step 264, Loss: 0.18909253180027008\n",
            "Epoch 50, Step 265, Loss: 0.20583575963974\n",
            "Epoch 50, Step 266, Loss: 0.20457005500793457\n",
            "Epoch 50, Step 267, Loss: 0.30875566601753235\n",
            "Epoch 50, Step 268, Loss: 0.25527316331863403\n",
            "Epoch 50, Step 269, Loss: 0.25844985246658325\n",
            "Epoch 50, Step 270, Loss: 0.27864688634872437\n",
            "Epoch 50, Step 271, Loss: 0.22066059708595276\n",
            "Epoch 50, Step 272, Loss: 0.2540093660354614\n",
            "Epoch 50, Step 273, Loss: 0.2045934498310089\n",
            "Epoch 50, Step 274, Loss: 0.2267511636018753\n",
            "Epoch 50, Step 275, Loss: 0.2705058455467224\n",
            "Epoch 50, Step 276, Loss: 0.2310047447681427\n",
            "Epoch 50, Step 277, Loss: 0.16838917136192322\n",
            "Epoch 50, Step 278, Loss: 0.2098032534122467\n",
            "Epoch 50, Step 279, Loss: 0.2123488038778305\n",
            "Epoch 50, Step 280, Loss: 0.3457837402820587\n",
            "Epoch 50, Step 281, Loss: 0.13844740390777588\n",
            "Epoch 50, Step 282, Loss: 0.22907182574272156\n",
            "Epoch 50, Step 283, Loss: 0.33056339621543884\n",
            "Epoch 50, Step 284, Loss: 0.3007863163948059\n",
            "Epoch 50, Step 285, Loss: 0.18310123682022095\n",
            "Epoch 50, Step 286, Loss: 0.285664439201355\n",
            "Epoch 50, Step 287, Loss: 0.35899239778518677\n",
            "Epoch 50, Step 288, Loss: 0.22448381781578064\n",
            "Epoch 50, Step 289, Loss: 0.3228945732116699\n",
            "Epoch 50, Step 290, Loss: 0.1353275328874588\n",
            "Epoch 50, Step 291, Loss: 0.2133105844259262\n",
            "Epoch 50, Step 292, Loss: 0.25991714000701904\n",
            "Epoch 50, Step 293, Loss: 0.33198580145835876\n",
            "Epoch 50, Step 294, Loss: 0.3643951416015625\n",
            "Epoch 50, Step 295, Loss: 0.2651175558567047\n",
            "Epoch 50, Step 296, Loss: 0.1662459522485733\n",
            "Epoch 50, Step 297, Loss: 0.31925714015960693\n",
            "Epoch 50, Step 298, Loss: 0.211202010512352\n",
            "Epoch 50, Step 299, Loss: 0.23128090798854828\n",
            "Epoch 50, Step 300, Loss: 0.2307678759098053\n",
            "Epoch 50, Step 301, Loss: 0.18369685113430023\n",
            "Epoch 50, Step 302, Loss: 0.2874695658683777\n",
            "Epoch 50, Step 303, Loss: 0.30451473593711853\n",
            "Epoch 50, Step 304, Loss: 0.15178251266479492\n",
            "Epoch 50, Step 305, Loss: 0.3507396876811981\n",
            "Epoch 50, Step 306, Loss: 0.3135303854942322\n",
            "Epoch 50, Step 307, Loss: 0.11425989866256714\n",
            "Epoch 50, Step 308, Loss: 0.3053267300128937\n",
            "Epoch 50, Step 309, Loss: 0.2545514702796936\n",
            "Epoch 50, Step 310, Loss: 0.15210852026939392\n",
            "Epoch 50, Step 311, Loss: 0.32150816917419434\n",
            "Epoch 50, Step 312, Loss: 0.16480055451393127\n",
            "Epoch 50 end, avg train loss: 0.24253147590560273\n",
            "Epoch 50 end, avg val loss: 0.36338065640081335, accuracy: 89.12%\n",
            "GPU memory allocated: 0.24 GB\n",
            "GPU memory reserved: 0.31 GB\n",
            "Training complete.\n"
          ]
        }
      ],
      "source": [
        "adaIpsModel = ResNetWithDropout().to(device)\n",
        "adaIpsOptimizer = AdaIPS_S(adaIpsModel.parameters())\n",
        "train(adaIpsModel, adaIpsOptimizer, epochs=epochs)\n",
        "adaIpsModel = adaIpsModel.cpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "eHiNJ80x24Oz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d738475-f011-45ac-848b-e1270bcc9fae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 35, Step 44, Loss: 0.05589728429913521\n",
            "Epoch 35, Step 45, Loss: 0.03187151253223419\n",
            "Epoch 35, Step 46, Loss: 0.03066922165453434\n",
            "Epoch 35, Step 47, Loss: 0.024223940446972847\n",
            "Epoch 35, Step 48, Loss: 0.03960906341671944\n",
            "Epoch 35, Step 49, Loss: 0.12261944264173508\n",
            "Epoch 35, Step 50, Loss: 0.07972738146781921\n",
            "Epoch 35, Step 51, Loss: 0.029377758502960205\n",
            "Epoch 35, Step 52, Loss: 0.07814454287290573\n",
            "Epoch 35, Step 53, Loss: 0.042489927262067795\n",
            "Epoch 35, Step 54, Loss: 0.08107897639274597\n",
            "Epoch 35, Step 55, Loss: 0.05527295917272568\n",
            "Epoch 35, Step 56, Loss: 0.04826977849006653\n",
            "Epoch 35, Step 57, Loss: 0.12599864602088928\n",
            "Epoch 35, Step 58, Loss: 0.08408117294311523\n",
            "Epoch 35, Step 59, Loss: 0.026470277458429337\n",
            "Epoch 35, Step 60, Loss: 0.03770766407251358\n",
            "Epoch 35, Step 61, Loss: 0.06097793951630592\n",
            "Epoch 35, Step 62, Loss: 0.06763362884521484\n",
            "Epoch 35, Step 63, Loss: 0.07582220435142517\n",
            "Epoch 35, Step 64, Loss: 0.13383570313453674\n",
            "Epoch 35, Step 65, Loss: 0.08325622975826263\n",
            "Epoch 35, Step 66, Loss: 0.05272418633103371\n",
            "Epoch 35, Step 67, Loss: 0.04963002726435661\n",
            "Epoch 35, Step 68, Loss: 0.09329381585121155\n",
            "Epoch 35, Step 69, Loss: 0.1200009286403656\n",
            "Epoch 35, Step 70, Loss: 0.043554432690143585\n",
            "Epoch 35, Step 71, Loss: 0.031308580189943314\n",
            "Epoch 35, Step 72, Loss: 0.03338385745882988\n",
            "Epoch 35, Step 73, Loss: 0.08451168239116669\n",
            "Epoch 35, Step 74, Loss: 0.0465659461915493\n",
            "Epoch 35, Step 75, Loss: 0.03373565897345543\n",
            "Epoch 35, Step 76, Loss: 0.05888238549232483\n",
            "Epoch 35, Step 77, Loss: 0.10298648476600647\n",
            "Epoch 35, Step 78, Loss: 0.06945912539958954\n",
            "Epoch 35, Step 79, Loss: 0.02717115916311741\n",
            "Epoch 35, Step 80, Loss: 0.07125578820705414\n",
            "Epoch 35, Step 81, Loss: 0.08901958167552948\n",
            "Epoch 35, Step 82, Loss: 0.0705133005976677\n",
            "Epoch 35, Step 83, Loss: 0.05035846680402756\n",
            "Epoch 35, Step 84, Loss: 0.07811181247234344\n",
            "Epoch 35, Step 85, Loss: 0.022580094635486603\n",
            "Epoch 35, Step 86, Loss: 0.0568733774125576\n",
            "Epoch 35, Step 87, Loss: 0.023876793682575226\n",
            "Epoch 35, Step 88, Loss: 0.05800773203372955\n",
            "Epoch 35, Step 89, Loss: 0.048941198736429214\n",
            "Epoch 35, Step 90, Loss: 0.15087395906448364\n",
            "Epoch 35, Step 91, Loss: 0.18703106045722961\n",
            "Epoch 35, Step 92, Loss: 0.048112884163856506\n",
            "Epoch 35, Step 93, Loss: 0.061737995594739914\n",
            "Epoch 35, Step 94, Loss: 0.02860591746866703\n",
            "Epoch 35, Step 95, Loss: 0.060727979987859726\n",
            "Epoch 35, Step 96, Loss: 0.02462868206202984\n",
            "Epoch 35, Step 97, Loss: 0.3022429347038269\n",
            "Epoch 35, Step 98, Loss: 0.09174010157585144\n",
            "Epoch 35, Step 99, Loss: 0.07816637307405472\n",
            "Epoch 35, Step 100, Loss: 0.057081349194049835\n",
            "Epoch 35, Step 101, Loss: 0.09562940150499344\n",
            "Epoch 35, Step 102, Loss: 0.07870512455701828\n",
            "Epoch 35, Step 103, Loss: 0.02635258622467518\n",
            "Epoch 35, Step 104, Loss: 0.09301149845123291\n",
            "Epoch 35, Step 105, Loss: 0.06673049181699753\n",
            "Epoch 35, Step 106, Loss: 0.08980372548103333\n",
            "Epoch 35, Step 107, Loss: 0.07072650641202927\n",
            "Epoch 35, Step 108, Loss: 0.04244273900985718\n",
            "Epoch 35, Step 109, Loss: 0.12375359237194061\n",
            "Epoch 35, Step 110, Loss: 0.15055979788303375\n",
            "Epoch 35, Step 111, Loss: 0.11435869336128235\n",
            "Epoch 35, Step 112, Loss: 0.113862045109272\n",
            "Epoch 35, Step 113, Loss: 0.06530545651912689\n",
            "Epoch 35, Step 114, Loss: 0.06393340975046158\n",
            "Epoch 35, Step 115, Loss: 0.10193540155887604\n",
            "Epoch 35, Step 116, Loss: 0.09194426983594894\n",
            "Epoch 35, Step 117, Loss: 0.09722549468278885\n",
            "Epoch 35, Step 118, Loss: 0.0848894938826561\n",
            "Epoch 35, Step 119, Loss: 0.11188409477472305\n",
            "Epoch 35, Step 120, Loss: 0.08515633642673492\n",
            "Epoch 35, Step 121, Loss: 0.053324490785598755\n",
            "Epoch 35, Step 122, Loss: 0.1006651520729065\n",
            "Epoch 35, Step 123, Loss: 0.04508360102772713\n",
            "Epoch 35, Step 124, Loss: 0.04417193681001663\n",
            "Epoch 35, Step 125, Loss: 0.0428294911980629\n",
            "Epoch 35, Step 126, Loss: 0.02863216958940029\n",
            "Epoch 35, Step 127, Loss: 0.07840779423713684\n",
            "Epoch 35, Step 128, Loss: 0.11298792064189911\n",
            "Epoch 35, Step 129, Loss: 0.1520349681377411\n",
            "Epoch 35, Step 130, Loss: 0.021619699895381927\n",
            "Epoch 35, Step 131, Loss: 0.083201102912426\n",
            "Epoch 35, Step 132, Loss: 0.14012043178081512\n",
            "Epoch 35, Step 133, Loss: 0.08946413546800613\n",
            "Epoch 35, Step 134, Loss: 0.09231967478990555\n",
            "Epoch 35, Step 135, Loss: 0.09081099182367325\n",
            "Epoch 35, Step 136, Loss: 0.17058603465557098\n",
            "Epoch 35, Step 137, Loss: 0.07889248430728912\n",
            "Epoch 35, Step 138, Loss: 0.04884921759366989\n",
            "Epoch 35, Step 139, Loss: 0.09009804576635361\n",
            "Epoch 35, Step 140, Loss: 0.02069012075662613\n",
            "Epoch 35, Step 141, Loss: 0.0850900262594223\n",
            "Epoch 35, Step 142, Loss: 0.032750096172094345\n",
            "Epoch 35, Step 143, Loss: 0.14188939332962036\n",
            "Epoch 35, Step 144, Loss: 0.04905539005994797\n",
            "Epoch 35, Step 145, Loss: 0.05566850304603577\n",
            "Epoch 35, Step 146, Loss: 0.05287390202283859\n",
            "Epoch 35, Step 147, Loss: 0.029883073642849922\n",
            "Epoch 35, Step 148, Loss: 0.038407549262046814\n",
            "Epoch 35, Step 149, Loss: 0.0526050440967083\n",
            "Epoch 35, Step 150, Loss: 0.0943065881729126\n",
            "Epoch 35, Step 151, Loss: 0.07501586526632309\n",
            "Epoch 35, Step 152, Loss: 0.04455529525876045\n",
            "Epoch 35, Step 153, Loss: 0.03212916851043701\n",
            "Epoch 35, Step 154, Loss: 0.08507494628429413\n",
            "Epoch 35, Step 155, Loss: 0.08629554510116577\n",
            "Epoch 35, Step 156, Loss: 0.017064111307263374\n",
            "Epoch 35, Step 157, Loss: 0.045886360108852386\n",
            "Epoch 35, Step 158, Loss: 0.027828795835375786\n",
            "Epoch 35, Step 159, Loss: 0.04579472169280052\n",
            "Epoch 35, Step 160, Loss: 0.03952382132411003\n",
            "Epoch 35, Step 161, Loss: 0.06393934041261673\n",
            "Epoch 35, Step 162, Loss: 0.08150971680879593\n",
            "Epoch 35, Step 163, Loss: 0.10180126875638962\n",
            "Epoch 35, Step 164, Loss: 0.09813929349184036\n",
            "Epoch 35, Step 165, Loss: 0.022230014204978943\n",
            "Epoch 35, Step 166, Loss: 0.06651624292135239\n",
            "Epoch 35, Step 167, Loss: 0.03799768537282944\n",
            "Epoch 35, Step 168, Loss: 0.050409335643053055\n",
            "Epoch 35, Step 169, Loss: 0.06621462106704712\n",
            "Epoch 35, Step 170, Loss: 0.051334090530872345\n",
            "Epoch 35, Step 171, Loss: 0.07591380923986435\n",
            "Epoch 35, Step 172, Loss: 0.019761743023991585\n",
            "Epoch 35, Step 173, Loss: 0.147682785987854\n",
            "Epoch 35, Step 174, Loss: 0.1694725602865219\n",
            "Epoch 35, Step 175, Loss: 0.02077433094382286\n",
            "Epoch 35, Step 176, Loss: 0.032024841755628586\n",
            "Epoch 35, Step 177, Loss: 0.11584757268428802\n",
            "Epoch 35, Step 178, Loss: 0.08008120954036713\n",
            "Epoch 35, Step 179, Loss: 0.07615490257740021\n",
            "Epoch 35, Step 180, Loss: 0.06956619024276733\n",
            "Epoch 35, Step 181, Loss: 0.07182018458843231\n",
            "Epoch 35, Step 182, Loss: 0.10238534957170486\n",
            "Epoch 35, Step 183, Loss: 0.11655966937541962\n",
            "Epoch 35, Step 184, Loss: 0.08701862394809723\n",
            "Epoch 35, Step 185, Loss: 0.08086435496807098\n",
            "Epoch 35, Step 186, Loss: 0.16968904435634613\n",
            "Epoch 35, Step 187, Loss: 0.058467041701078415\n",
            "Epoch 35, Step 188, Loss: 0.06684468686580658\n",
            "Epoch 35, Step 189, Loss: 0.07261023670434952\n",
            "Epoch 35, Step 190, Loss: 0.10115934908390045\n",
            "Epoch 35, Step 191, Loss: 0.07241494208574295\n",
            "Epoch 35, Step 192, Loss: 0.028572993353009224\n",
            "Epoch 35, Step 193, Loss: 0.057968635112047195\n",
            "Epoch 35, Step 194, Loss: 0.05439618602395058\n",
            "Epoch 35, Step 195, Loss: 0.2473796308040619\n",
            "Epoch 35, Step 196, Loss: 0.08167204260826111\n",
            "Epoch 35, Step 197, Loss: 0.02780207060277462\n",
            "Epoch 35, Step 198, Loss: 0.10875043272972107\n",
            "Epoch 35, Step 199, Loss: 0.06935437768697739\n",
            "Epoch 35, Step 200, Loss: 0.23198829591274261\n",
            "Epoch 35, Step 201, Loss: 0.12881088256835938\n",
            "Epoch 35, Step 202, Loss: 0.10285352170467377\n",
            "Epoch 35, Step 203, Loss: 0.09039641171693802\n",
            "Epoch 35, Step 204, Loss: 0.06016339734196663\n",
            "Epoch 35, Step 205, Loss: 0.07467322051525116\n",
            "Epoch 35, Step 206, Loss: 0.04058343917131424\n",
            "Epoch 35, Step 207, Loss: 0.07203501462936401\n",
            "Epoch 35, Step 208, Loss: 0.07562267035245895\n",
            "Epoch 35, Step 209, Loss: 0.09043684601783752\n",
            "Epoch 35, Step 210, Loss: 0.05362480878829956\n",
            "Epoch 35, Step 211, Loss: 0.0717029869556427\n",
            "Epoch 35, Step 212, Loss: 0.08501176536083221\n",
            "Epoch 35, Step 213, Loss: 0.08301199227571487\n",
            "Epoch 35, Step 214, Loss: 0.05656063184142113\n",
            "Epoch 35, Step 215, Loss: 0.05638398975133896\n",
            "Epoch 35, Step 216, Loss: 0.03293057531118393\n",
            "Epoch 35, Step 217, Loss: 0.05716512352228165\n",
            "Epoch 35, Step 218, Loss: 0.05136466398835182\n",
            "Epoch 35, Step 219, Loss: 0.10147257894277573\n",
            "Epoch 35, Step 220, Loss: 0.14732205867767334\n",
            "Epoch 35, Step 221, Loss: 0.04309871420264244\n",
            "Epoch 35, Step 222, Loss: 0.11106861382722855\n",
            "Epoch 35, Step 223, Loss: 0.04277479648590088\n",
            "Epoch 35, Step 224, Loss: 0.05137178674340248\n",
            "Epoch 35, Step 225, Loss: 0.05171411111950874\n",
            "Epoch 35, Step 226, Loss: 0.09652000665664673\n",
            "Epoch 35, Step 227, Loss: 0.04342181608080864\n",
            "Epoch 35, Step 228, Loss: 0.14546532928943634\n",
            "Epoch 35, Step 229, Loss: 0.0701930895447731\n",
            "Epoch 35, Step 230, Loss: 0.12753094732761383\n",
            "Epoch 35, Step 231, Loss: 0.1460115909576416\n",
            "Epoch 35, Step 232, Loss: 0.023602548986673355\n",
            "Epoch 35, Step 233, Loss: 0.11664120852947235\n",
            "Epoch 35, Step 234, Loss: 0.026932338252663612\n",
            "Epoch 35, Step 235, Loss: 0.10026564449071884\n",
            "Epoch 35, Step 236, Loss: 0.06657884269952774\n",
            "Epoch 35, Step 237, Loss: 0.08050757646560669\n",
            "Epoch 35, Step 238, Loss: 0.06831591576337814\n",
            "Epoch 35, Step 239, Loss: 0.07534191757440567\n",
            "Epoch 35, Step 240, Loss: 0.13200201094150543\n",
            "Epoch 35, Step 241, Loss: 0.0649014413356781\n",
            "Epoch 35, Step 242, Loss: 0.14132781326770782\n",
            "Epoch 35, Step 243, Loss: 0.06577936559915543\n",
            "Epoch 35, Step 244, Loss: 0.11959992349147797\n",
            "Epoch 35, Step 245, Loss: 0.15981848537921906\n",
            "Epoch 35, Step 246, Loss: 0.16266746819019318\n",
            "Epoch 35, Step 247, Loss: 0.04846801608800888\n",
            "Epoch 35, Step 248, Loss: 0.04991132766008377\n",
            "Epoch 35, Step 249, Loss: 0.04531773552298546\n",
            "Epoch 35, Step 250, Loss: 0.12976430356502533\n",
            "Epoch 35, Step 251, Loss: 0.04361076280474663\n",
            "Epoch 35, Step 252, Loss: 0.05184197053313255\n",
            "Epoch 35, Step 253, Loss: 0.07475206255912781\n",
            "Epoch 35, Step 254, Loss: 0.09769048541784286\n",
            "Epoch 35, Step 255, Loss: 0.17859609425067902\n",
            "Epoch 35, Step 256, Loss: 0.1337161809206009\n",
            "Epoch 35, Step 257, Loss: 0.06172672659158707\n",
            "Epoch 35, Step 258, Loss: 0.08753513544797897\n",
            "Epoch 35, Step 259, Loss: 0.10902191698551178\n",
            "Epoch 35, Step 260, Loss: 0.05892983451485634\n",
            "Epoch 35, Step 261, Loss: 0.04111666604876518\n",
            "Epoch 35, Step 262, Loss: 0.04970225319266319\n",
            "Epoch 35, Step 263, Loss: 0.06391823291778564\n",
            "Epoch 35, Step 264, Loss: 0.05674626678228378\n",
            "Epoch 35, Step 265, Loss: 0.058652184903621674\n",
            "Epoch 35, Step 266, Loss: 0.09563055634498596\n",
            "Epoch 35, Step 267, Loss: 0.04737461358308792\n",
            "Epoch 35, Step 268, Loss: 0.08371908217668533\n",
            "Epoch 35, Step 269, Loss: 0.14341463148593903\n",
            "Epoch 35, Step 270, Loss: 0.0849788635969162\n",
            "Epoch 35, Step 271, Loss: 0.13074104487895966\n",
            "Epoch 35, Step 272, Loss: 0.1164025291800499\n",
            "Epoch 35, Step 273, Loss: 0.09492865204811096\n",
            "Epoch 35, Step 274, Loss: 0.09098142385482788\n",
            "Epoch 35, Step 275, Loss: 0.03945106640458107\n",
            "Epoch 35, Step 276, Loss: 0.054952457547187805\n",
            "Epoch 35, Step 277, Loss: 0.10130314528942108\n",
            "Epoch 35, Step 278, Loss: 0.06480349600315094\n",
            "Epoch 35, Step 279, Loss: 0.04018719121813774\n",
            "Epoch 35, Step 280, Loss: 0.11075339466333389\n",
            "Epoch 35, Step 281, Loss: 0.07273587584495544\n",
            "Epoch 35, Step 282, Loss: 0.07969123870134354\n",
            "Epoch 35, Step 283, Loss: 0.21464549005031586\n",
            "Epoch 35, Step 284, Loss: 0.03417043760418892\n",
            "Epoch 35, Step 285, Loss: 0.0885009914636612\n",
            "Epoch 35, Step 286, Loss: 0.048097796738147736\n",
            "Epoch 35, Step 287, Loss: 0.090237557888031\n",
            "Epoch 35, Step 288, Loss: 0.11467821151018143\n",
            "Epoch 35, Step 289, Loss: 0.10533110797405243\n",
            "Epoch 35, Step 290, Loss: 0.08363726735115051\n",
            "Epoch 35, Step 291, Loss: 0.1708344966173172\n",
            "Epoch 35, Step 292, Loss: 0.07224424183368683\n",
            "Epoch 35, Step 293, Loss: 0.11939357966184616\n",
            "Epoch 35, Step 294, Loss: 0.03023444302380085\n",
            "Epoch 35, Step 295, Loss: 0.07730554044246674\n",
            "Epoch 35, Step 296, Loss: 0.13664166629314423\n",
            "Epoch 35, Step 297, Loss: 0.12013456970453262\n",
            "Epoch 35, Step 298, Loss: 0.04177625849843025\n",
            "Epoch 35, Step 299, Loss: 0.06995794922113419\n",
            "Epoch 35, Step 300, Loss: 0.09277231246232986\n",
            "Epoch 35, Step 301, Loss: 0.04779127985239029\n",
            "Epoch 35, Step 302, Loss: 0.1136297807097435\n",
            "Epoch 35, Step 303, Loss: 0.07672242075204849\n",
            "Epoch 35, Step 304, Loss: 0.09919325262308121\n",
            "Epoch 35, Step 305, Loss: 0.13962125778198242\n",
            "Epoch 35, Step 306, Loss: 0.10958333313465118\n",
            "Epoch 35, Step 307, Loss: 0.2538221776485443\n",
            "Epoch 35, Step 308, Loss: 0.11573150753974915\n",
            "Epoch 35, Step 309, Loss: 0.06115560606122017\n",
            "Epoch 35, Step 310, Loss: 0.07624609768390656\n",
            "Epoch 35, Step 311, Loss: 0.05688929185271263\n",
            "Epoch 35, Step 312, Loss: 0.09730025380849838\n",
            "Epoch 35 end, avg train loss: 0.07791678916912871\n",
            "Epoch 35 end, avg val loss: 0.3932723804742475, accuracy: 90.25%\n",
            "Epoch 36, Step 0, Loss: 0.04891691729426384\n",
            "Epoch 36, Step 1, Loss: 0.058326661586761475\n",
            "Epoch 36, Step 2, Loss: 0.15305963158607483\n",
            "Epoch 36, Step 3, Loss: 0.020160891115665436\n",
            "Epoch 36, Step 4, Loss: 0.057768434286117554\n",
            "Epoch 36, Step 5, Loss: 0.09258962422609329\n",
            "Epoch 36, Step 6, Loss: 0.04721742868423462\n",
            "Epoch 36, Step 7, Loss: 0.03869788721203804\n",
            "Epoch 36, Step 8, Loss: 0.03774511441588402\n",
            "Epoch 36, Step 9, Loss: 0.11246373504400253\n",
            "Epoch 36, Step 10, Loss: 0.09975941479206085\n",
            "Epoch 36, Step 11, Loss: 0.09293880313634872\n",
            "Epoch 36, Step 12, Loss: 0.14016178250312805\n",
            "Epoch 36, Step 13, Loss: 0.07638191431760788\n",
            "Epoch 36, Step 14, Loss: 0.02791384793817997\n",
            "Epoch 36, Step 15, Loss: 0.08996918797492981\n",
            "Epoch 36, Step 16, Loss: 0.08634470403194427\n",
            "Epoch 36, Step 17, Loss: 0.033063992857933044\n",
            "Epoch 36, Step 18, Loss: 0.07904770970344543\n",
            "Epoch 36, Step 19, Loss: 0.05773695558309555\n",
            "Epoch 36, Step 20, Loss: 0.13329200446605682\n",
            "Epoch 36, Step 21, Loss: 0.12518765032291412\n",
            "Epoch 36, Step 22, Loss: 0.06712451577186584\n",
            "Epoch 36, Step 23, Loss: 0.04198926314711571\n",
            "Epoch 36, Step 24, Loss: 0.04434429854154587\n",
            "Epoch 36, Step 25, Loss: 0.056407324969768524\n",
            "Epoch 36, Step 26, Loss: 0.07428265362977982\n",
            "Epoch 36, Step 27, Loss: 0.11295576393604279\n",
            "Epoch 36, Step 28, Loss: 0.07440286129713058\n",
            "Epoch 36, Step 29, Loss: 0.06373146176338196\n",
            "Epoch 36, Step 30, Loss: 0.09572893381118774\n",
            "Epoch 36, Step 31, Loss: 0.06049485504627228\n",
            "Epoch 36, Step 32, Loss: 0.14619921147823334\n",
            "Epoch 36, Step 33, Loss: 0.05076016113162041\n",
            "Epoch 36, Step 34, Loss: 0.042589589953422546\n",
            "Epoch 36, Step 35, Loss: 0.07385491579771042\n",
            "Epoch 36, Step 36, Loss: 0.027932001277804375\n",
            "Epoch 36, Step 37, Loss: 0.1175595372915268\n",
            "Epoch 36, Step 38, Loss: 0.14736829698085785\n",
            "Epoch 36, Step 39, Loss: 0.05208616331219673\n",
            "Epoch 36, Step 40, Loss: 0.04233241826295853\n",
            "Epoch 36, Step 41, Loss: 0.05333520099520683\n",
            "Epoch 36, Step 42, Loss: 0.07050269842147827\n",
            "Epoch 36, Step 43, Loss: 0.0725523978471756\n",
            "Epoch 36, Step 44, Loss: 0.1449155956506729\n",
            "Epoch 36, Step 45, Loss: 0.032087430357933044\n",
            "Epoch 36, Step 46, Loss: 0.05886000767350197\n",
            "Epoch 36, Step 47, Loss: 0.06299751251935959\n",
            "Epoch 36, Step 48, Loss: 0.0652524083852768\n",
            "Epoch 36, Step 49, Loss: 0.10704095661640167\n",
            "Epoch 36, Step 50, Loss: 0.03711087256669998\n",
            "Epoch 36, Step 51, Loss: 0.056568942964076996\n",
            "Epoch 36, Step 52, Loss: 0.046318598091602325\n",
            "Epoch 36, Step 53, Loss: 0.06858155131340027\n",
            "Epoch 36, Step 54, Loss: 0.06987796723842621\n",
            "Epoch 36, Step 55, Loss: 0.07858134806156158\n",
            "Epoch 36, Step 56, Loss: 0.0874340757727623\n",
            "Epoch 36, Step 57, Loss: 0.08880916237831116\n",
            "Epoch 36, Step 58, Loss: 0.021471194922924042\n",
            "Epoch 36, Step 59, Loss: 0.106063112616539\n",
            "Epoch 36, Step 60, Loss: 0.07448944449424744\n",
            "Epoch 36, Step 61, Loss: 0.13825130462646484\n",
            "Epoch 36, Step 62, Loss: 0.03080875799059868\n",
            "Epoch 36, Step 63, Loss: 0.04521479085087776\n",
            "Epoch 36, Step 64, Loss: 0.051648229360580444\n",
            "Epoch 36, Step 65, Loss: 0.06313446164131165\n",
            "Epoch 36, Step 66, Loss: 0.03607722744345665\n",
            "Epoch 36, Step 67, Loss: 0.11259718239307404\n",
            "Epoch 36, Step 68, Loss: 0.038664497435092926\n",
            "Epoch 36, Step 69, Loss: 0.12494304776191711\n",
            "Epoch 36, Step 70, Loss: 0.03891457989811897\n",
            "Epoch 36, Step 71, Loss: 0.09960422664880753\n",
            "Epoch 36, Step 72, Loss: 0.06504984945058823\n",
            "Epoch 36, Step 73, Loss: 0.025835717096924782\n",
            "Epoch 36, Step 74, Loss: 0.0798342302441597\n",
            "Epoch 36, Step 75, Loss: 0.07886011898517609\n",
            "Epoch 36, Step 76, Loss: 0.05284002795815468\n",
            "Epoch 36, Step 77, Loss: 0.06095192953944206\n",
            "Epoch 36, Step 78, Loss: 0.025999024510383606\n",
            "Epoch 36, Step 79, Loss: 0.025562500581145287\n",
            "Epoch 36, Step 80, Loss: 0.07694914937019348\n",
            "Epoch 36, Step 81, Loss: 0.06494119763374329\n",
            "Epoch 36, Step 82, Loss: 0.07427531480789185\n",
            "Epoch 36, Step 83, Loss: 0.041000157594680786\n",
            "Epoch 36, Step 84, Loss: 0.12187187373638153\n",
            "Epoch 36, Step 85, Loss: 0.0972585454583168\n",
            "Epoch 36, Step 86, Loss: 0.05715292692184448\n",
            "Epoch 36, Step 87, Loss: 0.08798303455114365\n",
            "Epoch 36, Step 88, Loss: 0.06520481407642365\n",
            "Epoch 36, Step 89, Loss: 0.03708491101861\n",
            "Epoch 36, Step 90, Loss: 0.04501413553953171\n",
            "Epoch 36, Step 91, Loss: 0.08503298461437225\n",
            "Epoch 36, Step 92, Loss: 0.0786849856376648\n",
            "Epoch 36, Step 93, Loss: 0.08730950206518173\n",
            "Epoch 36, Step 94, Loss: 0.0473620742559433\n",
            "Epoch 36, Step 95, Loss: 0.13376648724079132\n",
            "Epoch 36, Step 96, Loss: 0.03435559570789337\n",
            "Epoch 36, Step 97, Loss: 0.06302729994058609\n",
            "Epoch 36, Step 98, Loss: 0.053072843700647354\n",
            "Epoch 36, Step 99, Loss: 0.07041071355342865\n",
            "Epoch 36, Step 100, Loss: 0.053026940673589706\n",
            "Epoch 36, Step 101, Loss: 0.04050736874341965\n",
            "Epoch 36, Step 102, Loss: 0.027514906600117683\n",
            "Epoch 36, Step 103, Loss: 0.06804107874631882\n",
            "Epoch 36, Step 104, Loss: 0.07871685177087784\n",
            "Epoch 36, Step 105, Loss: 0.03593776747584343\n",
            "Epoch 36, Step 106, Loss: 0.08580554276704788\n",
            "Epoch 36, Step 107, Loss: 0.04151812940835953\n",
            "Epoch 36, Step 108, Loss: 0.05007665231823921\n",
            "Epoch 36, Step 109, Loss: 0.06368060410022736\n",
            "Epoch 36, Step 110, Loss: 0.09770587831735611\n",
            "Epoch 36, Step 111, Loss: 0.04737772420048714\n",
            "Epoch 36, Step 112, Loss: 0.05196160450577736\n",
            "Epoch 36, Step 113, Loss: 0.07748819887638092\n",
            "Epoch 36, Step 114, Loss: 0.17141656577587128\n",
            "Epoch 36, Step 115, Loss: 0.08294422924518585\n",
            "Epoch 36, Step 116, Loss: 0.015452338382601738\n",
            "Epoch 36, Step 117, Loss: 0.019193755462765694\n",
            "Epoch 36, Step 118, Loss: 0.11275894939899445\n",
            "Epoch 36, Step 119, Loss: 0.07433375716209412\n",
            "Epoch 36, Step 120, Loss: 0.1598891168832779\n",
            "Epoch 36, Step 121, Loss: 0.02055351808667183\n",
            "Epoch 36, Step 122, Loss: 0.0977378711104393\n",
            "Epoch 36, Step 123, Loss: 0.061654865741729736\n",
            "Epoch 36, Step 124, Loss: 0.14255309104919434\n",
            "Epoch 36, Step 125, Loss: 0.015976788476109505\n",
            "Epoch 36, Step 126, Loss: 0.06730928272008896\n",
            "Epoch 36, Step 127, Loss: 0.049417510628700256\n",
            "Epoch 36, Step 128, Loss: 0.02599555253982544\n",
            "Epoch 36, Step 129, Loss: 0.12549184262752533\n",
            "Epoch 36, Step 130, Loss: 0.06949930638074875\n",
            "Epoch 36, Step 131, Loss: 0.03475545346736908\n",
            "Epoch 36, Step 132, Loss: 0.06335864216089249\n",
            "Epoch 36, Step 133, Loss: 0.03808441013097763\n",
            "Epoch 36, Step 134, Loss: 0.11198025196790695\n",
            "Epoch 36, Step 135, Loss: 0.10080744326114655\n",
            "Epoch 36, Step 136, Loss: 0.04224349930882454\n",
            "Epoch 36, Step 137, Loss: 0.08238231390714645\n",
            "Epoch 36, Step 138, Loss: 0.029044995084404945\n",
            "Epoch 36, Step 139, Loss: 0.14280720055103302\n",
            "Epoch 36, Step 140, Loss: 0.052074771374464035\n",
            "Epoch 36, Step 141, Loss: 0.06213894486427307\n",
            "Epoch 36, Step 142, Loss: 0.022326303645968437\n",
            "Epoch 36, Step 143, Loss: 0.026843536645174026\n",
            "Epoch 36, Step 144, Loss: 0.11962283402681351\n",
            "Epoch 36, Step 145, Loss: 0.05427415668964386\n",
            "Epoch 36, Step 146, Loss: 0.0783788189291954\n",
            "Epoch 36, Step 147, Loss: 0.13916082680225372\n",
            "Epoch 36, Step 148, Loss: 0.07016811519861221\n",
            "Epoch 36, Step 149, Loss: 0.1101110577583313\n",
            "Epoch 36, Step 150, Loss: 0.11131289601325989\n",
            "Epoch 36, Step 151, Loss: 0.03945890814065933\n",
            "Epoch 36, Step 152, Loss: 0.06593212485313416\n",
            "Epoch 36, Step 153, Loss: 0.10732652992010117\n",
            "Epoch 36, Step 154, Loss: 0.048117149621248245\n",
            "Epoch 36, Step 155, Loss: 0.05652652680873871\n",
            "Epoch 36, Step 156, Loss: 0.10244718939065933\n",
            "Epoch 36, Step 157, Loss: 0.07422947883605957\n",
            "Epoch 36, Step 158, Loss: 0.10242299735546112\n",
            "Epoch 36, Step 159, Loss: 0.025004874914884567\n",
            "Epoch 36, Step 160, Loss: 0.08501789718866348\n",
            "Epoch 36, Step 161, Loss: 0.09902587532997131\n",
            "Epoch 36, Step 162, Loss: 0.0567026287317276\n",
            "Epoch 36, Step 163, Loss: 0.12643182277679443\n",
            "Epoch 36, Step 164, Loss: 0.06936511397361755\n",
            "Epoch 36, Step 165, Loss: 0.027067769318819046\n",
            "Epoch 36, Step 166, Loss: 0.08817676454782486\n",
            "Epoch 36, Step 167, Loss: 0.07292307168245316\n",
            "Epoch 36, Step 168, Loss: 0.05957522988319397\n",
            "Epoch 36, Step 169, Loss: 0.022195059806108475\n",
            "Epoch 36, Step 170, Loss: 0.0539289154112339\n",
            "Epoch 36, Step 171, Loss: 0.01873287558555603\n",
            "Epoch 36, Step 172, Loss: 0.044368211179971695\n",
            "Epoch 36, Step 173, Loss: 0.06296999007463455\n",
            "Epoch 36, Step 174, Loss: 0.1400708556175232\n",
            "Epoch 36, Step 175, Loss: 0.10493862628936768\n",
            "Epoch 36, Step 176, Loss: 0.05231747403740883\n",
            "Epoch 36, Step 177, Loss: 0.06449783593416214\n",
            "Epoch 36, Step 178, Loss: 0.1119353249669075\n",
            "Epoch 36, Step 179, Loss: 0.056535568088293076\n",
            "Epoch 36, Step 180, Loss: 0.1153864860534668\n",
            "Epoch 36, Step 181, Loss: 0.04398230463266373\n",
            "Epoch 36, Step 182, Loss: 0.08100644499063492\n",
            "Epoch 36, Step 183, Loss: 0.0626218393445015\n",
            "Epoch 36, Step 184, Loss: 0.13312235474586487\n",
            "Epoch 36, Step 185, Loss: 0.07323991507291794\n",
            "Epoch 36, Step 186, Loss: 0.09449237585067749\n",
            "Epoch 36, Step 187, Loss: 0.15192744135856628\n",
            "Epoch 36, Step 188, Loss: 0.03717559948563576\n",
            "Epoch 36, Step 189, Loss: 0.11517047137022018\n",
            "Epoch 36, Step 190, Loss: 0.05385482311248779\n",
            "Epoch 36, Step 191, Loss: 0.10067451000213623\n",
            "Epoch 36, Step 192, Loss: 0.056460339576005936\n",
            "Epoch 36, Step 193, Loss: 0.1063869521021843\n",
            "Epoch 36, Step 194, Loss: 0.07148057967424393\n",
            "Epoch 36, Step 195, Loss: 0.0496697872877121\n",
            "Epoch 36, Step 196, Loss: 0.12534628808498383\n",
            "Epoch 36, Step 197, Loss: 0.05083014816045761\n",
            "Epoch 36, Step 198, Loss: 0.08560281246900558\n",
            "Epoch 36, Step 199, Loss: 0.06750146299600601\n",
            "Epoch 36, Step 200, Loss: 0.04025755822658539\n",
            "Epoch 36, Step 201, Loss: 0.07128129154443741\n",
            "Epoch 36, Step 202, Loss: 0.10990316420793533\n",
            "Epoch 36, Step 203, Loss: 0.09035991132259369\n",
            "Epoch 36, Step 204, Loss: 0.08558839559555054\n",
            "Epoch 36, Step 205, Loss: 0.0572340227663517\n",
            "Epoch 36, Step 206, Loss: 0.06761802732944489\n",
            "Epoch 36, Step 207, Loss: 0.0987788736820221\n",
            "Epoch 36, Step 208, Loss: 0.025045078247785568\n",
            "Epoch 36, Step 209, Loss: 0.08553022891283035\n",
            "Epoch 36, Step 210, Loss: 0.06741006672382355\n",
            "Epoch 36, Step 211, Loss: 0.05625152960419655\n",
            "Epoch 36, Step 212, Loss: 0.106734998524189\n",
            "Epoch 36, Step 213, Loss: 0.017860036343336105\n",
            "Epoch 36, Step 214, Loss: 0.11242231726646423\n",
            "Epoch 36, Step 215, Loss: 0.06463462114334106\n",
            "Epoch 36, Step 216, Loss: 0.13271932303905487\n",
            "Epoch 36, Step 217, Loss: 0.09062086045742035\n",
            "Epoch 36, Step 218, Loss: 0.02487734518945217\n",
            "Epoch 36, Step 219, Loss: 0.08124836534261703\n",
            "Epoch 36, Step 220, Loss: 0.1103782132267952\n",
            "Epoch 36, Step 221, Loss: 0.019992582499980927\n",
            "Epoch 36, Step 222, Loss: 0.09646879881620407\n",
            "Epoch 36, Step 223, Loss: 0.046787992119789124\n",
            "Epoch 36, Step 224, Loss: 0.022795768454670906\n",
            "Epoch 36, Step 225, Loss: 0.07683252543210983\n",
            "Epoch 36, Step 226, Loss: 0.07341520488262177\n",
            "Epoch 36, Step 227, Loss: 0.12037128955125809\n",
            "Epoch 36, Step 228, Loss: 0.16755473613739014\n",
            "Epoch 36, Step 229, Loss: 0.20899666845798492\n",
            "Epoch 36, Step 230, Loss: 0.04044124856591225\n",
            "Epoch 36, Step 231, Loss: 0.1180872842669487\n",
            "Epoch 36, Step 232, Loss: 0.04136543720960617\n",
            "Epoch 36, Step 233, Loss: 0.09874922782182693\n",
            "Epoch 36, Step 234, Loss: 0.07603505998849869\n",
            "Epoch 36, Step 235, Loss: 0.08127495646476746\n",
            "Epoch 36, Step 236, Loss: 0.06810130178928375\n",
            "Epoch 36, Step 237, Loss: 0.13256509602069855\n",
            "Epoch 36, Step 238, Loss: 0.0571712926030159\n",
            "Epoch 36, Step 239, Loss: 0.07323532551527023\n",
            "Epoch 36, Step 240, Loss: 0.0680304691195488\n",
            "Epoch 36, Step 241, Loss: 0.08634764701128006\n",
            "Epoch 36, Step 242, Loss: 0.11966976523399353\n",
            "Epoch 36, Step 243, Loss: 0.05896790698170662\n",
            "Epoch 36, Step 244, Loss: 0.04898887127637863\n",
            "Epoch 36, Step 245, Loss: 0.0579964853823185\n",
            "Epoch 36, Step 246, Loss: 0.07585123926401138\n",
            "Epoch 36, Step 247, Loss: 0.10334829241037369\n",
            "Epoch 36, Step 248, Loss: 0.06274069845676422\n",
            "Epoch 36, Step 249, Loss: 0.08390486240386963\n",
            "Epoch 36, Step 250, Loss: 0.07880373299121857\n",
            "Epoch 36, Step 251, Loss: 0.13683533668518066\n",
            "Epoch 36, Step 252, Loss: 0.07467781752347946\n",
            "Epoch 36, Step 253, Loss: 0.0761856734752655\n",
            "Epoch 36, Step 254, Loss: 0.09363999217748642\n",
            "Epoch 36, Step 255, Loss: 0.07407431304454803\n",
            "Epoch 36, Step 256, Loss: 0.07946060597896576\n",
            "Epoch 36, Step 257, Loss: 0.1452399045228958\n",
            "Epoch 36, Step 258, Loss: 0.1970011293888092\n",
            "Epoch 36, Step 259, Loss: 0.10593913495540619\n",
            "Epoch 36, Step 260, Loss: 0.07766416668891907\n",
            "Epoch 36, Step 261, Loss: 0.0299910269677639\n",
            "Epoch 36, Step 262, Loss: 0.09172208607196808\n",
            "Epoch 36, Step 263, Loss: 0.09468866884708405\n",
            "Epoch 36, Step 264, Loss: 0.08575259149074554\n",
            "Epoch 36, Step 265, Loss: 0.08461589366197586\n",
            "Epoch 36, Step 266, Loss: 0.17931538820266724\n",
            "Epoch 36, Step 267, Loss: 0.03180016204714775\n",
            "Epoch 36, Step 268, Loss: 0.11103017628192902\n",
            "Epoch 36, Step 269, Loss: 0.0634583905339241\n",
            "Epoch 36, Step 270, Loss: 0.13927723467350006\n",
            "Epoch 36, Step 271, Loss: 0.09674399346113205\n",
            "Epoch 36, Step 272, Loss: 0.07943098247051239\n",
            "Epoch 36, Step 273, Loss: 0.1442624181509018\n",
            "Epoch 36, Step 274, Loss: 0.0754392072558403\n",
            "Epoch 36, Step 275, Loss: 0.12524659931659698\n",
            "Epoch 36, Step 276, Loss: 0.1025664210319519\n",
            "Epoch 36, Step 277, Loss: 0.09120393544435501\n",
            "Epoch 36, Step 278, Loss: 0.22533616423606873\n",
            "Epoch 36, Step 279, Loss: 0.055791448801755905\n",
            "Epoch 36, Step 280, Loss: 0.0453471802175045\n",
            "Epoch 36, Step 281, Loss: 0.1864093542098999\n",
            "Epoch 36, Step 282, Loss: 0.05220809951424599\n",
            "Epoch 36, Step 283, Loss: 0.06594733148813248\n",
            "Epoch 36, Step 284, Loss: 0.10304341465234756\n",
            "Epoch 36, Step 285, Loss: 0.061848852783441544\n",
            "Epoch 36, Step 286, Loss: 0.11015739291906357\n",
            "Epoch 36, Step 287, Loss: 0.07621239870786667\n",
            "Epoch 36, Step 288, Loss: 0.039120983332395554\n",
            "Epoch 36, Step 289, Loss: 0.09089241921901703\n",
            "Epoch 36, Step 290, Loss: 0.06876928359270096\n",
            "Epoch 36, Step 291, Loss: 0.07076973468065262\n",
            "Epoch 36, Step 292, Loss: 0.11023559421300888\n",
            "Epoch 36, Step 293, Loss: 0.07040785998106003\n",
            "Epoch 36, Step 294, Loss: 0.08339043706655502\n",
            "Epoch 36, Step 295, Loss: 0.06072187051177025\n",
            "Epoch 36, Step 296, Loss: 0.12840567529201508\n",
            "Epoch 36, Step 297, Loss: 0.14412789046764374\n",
            "Epoch 36, Step 298, Loss: 0.11176424473524094\n",
            "Epoch 36, Step 299, Loss: 0.1010415181517601\n",
            "Epoch 36, Step 300, Loss: 0.08890042454004288\n",
            "Epoch 36, Step 301, Loss: 0.09311053901910782\n",
            "Epoch 36, Step 302, Loss: 0.06293874233961105\n",
            "Epoch 36, Step 303, Loss: 0.05872935429215431\n",
            "Epoch 36, Step 304, Loss: 0.04587720334529877\n",
            "Epoch 36, Step 305, Loss: 0.04995553940534592\n",
            "Epoch 36, Step 306, Loss: 0.05287780985236168\n",
            "Epoch 36, Step 307, Loss: 0.11215702444314957\n",
            "Epoch 36, Step 308, Loss: 0.09332964569330215\n",
            "Epoch 36, Step 309, Loss: 0.02972010336816311\n",
            "Epoch 36, Step 310, Loss: 0.04142734780907631\n",
            "Epoch 36, Step 311, Loss: 0.11247500777244568\n",
            "Epoch 36, Step 312, Loss: 0.06760987639427185\n",
            "Epoch 36 end, avg train loss: 0.0772455142269405\n",
            "Epoch 36 end, avg val loss: 0.37160501421629627, accuracy: 90.96%\n",
            "Epoch 37, Step 0, Loss: 0.0398583821952343\n",
            "Epoch 37, Step 1, Loss: 0.01973837800323963\n",
            "Epoch 37, Step 2, Loss: 0.03643079847097397\n",
            "Epoch 37, Step 3, Loss: 0.13452023267745972\n",
            "Epoch 37, Step 4, Loss: 0.05125945433974266\n",
            "Epoch 37, Step 5, Loss: 0.08628661185503006\n",
            "Epoch 37, Step 6, Loss: 0.09425938874483109\n",
            "Epoch 37, Step 7, Loss: 0.0502065010368824\n",
            "Epoch 37, Step 8, Loss: 0.09992261230945587\n",
            "Epoch 37, Step 9, Loss: 0.031700268387794495\n",
            "Epoch 37, Step 10, Loss: 0.06727971136569977\n",
            "Epoch 37, Step 11, Loss: 0.0699896514415741\n",
            "Epoch 37, Step 12, Loss: 0.03295212984085083\n",
            "Epoch 37, Step 13, Loss: 0.08261798322200775\n",
            "Epoch 37, Step 14, Loss: 0.04923772066831589\n",
            "Epoch 37, Step 15, Loss: 0.0806918516755104\n",
            "Epoch 37, Step 16, Loss: 0.08343017846345901\n",
            "Epoch 37, Step 17, Loss: 0.09870697557926178\n",
            "Epoch 37, Step 18, Loss: 0.06421265006065369\n",
            "Epoch 37, Step 19, Loss: 0.1291266828775406\n",
            "Epoch 37, Step 20, Loss: 0.06170731037855148\n",
            "Epoch 37, Step 21, Loss: 0.08111933618783951\n",
            "Epoch 37, Step 22, Loss: 0.07251449674367905\n",
            "Epoch 37, Step 23, Loss: 0.05660129338502884\n",
            "Epoch 37, Step 24, Loss: 0.06209564581513405\n",
            "Epoch 37, Step 25, Loss: 0.06852485984563828\n",
            "Epoch 37, Step 26, Loss: 0.029680876061320305\n",
            "Epoch 37, Step 27, Loss: 0.031385716050863266\n",
            "Epoch 37, Step 28, Loss: 0.059278927743434906\n",
            "Epoch 37, Step 29, Loss: 0.08319295197725296\n",
            "Epoch 37, Step 30, Loss: 0.1614772081375122\n",
            "Epoch 37, Step 31, Loss: 0.05475335940718651\n",
            "Epoch 37, Step 32, Loss: 0.05595133453607559\n",
            "Epoch 37, Step 33, Loss: 0.0537421777844429\n",
            "Epoch 37, Step 34, Loss: 0.03278421610593796\n",
            "Epoch 37, Step 35, Loss: 0.08409837633371353\n",
            "Epoch 37, Step 36, Loss: 0.046393271535634995\n",
            "Epoch 37, Step 37, Loss: 0.04191137105226517\n",
            "Epoch 37, Step 38, Loss: 0.12883305549621582\n",
            "Epoch 37, Step 39, Loss: 0.11084391921758652\n",
            "Epoch 37, Step 40, Loss: 0.07803615927696228\n",
            "Epoch 37, Step 41, Loss: 0.04660861939191818\n",
            "Epoch 37, Step 42, Loss: 0.06046824902296066\n",
            "Epoch 37, Step 43, Loss: 0.044933587312698364\n",
            "Epoch 37, Step 44, Loss: 0.025640657171607018\n",
            "Epoch 37, Step 45, Loss: 0.029306206852197647\n",
            "Epoch 37, Step 46, Loss: 0.05838099494576454\n",
            "Epoch 37, Step 47, Loss: 0.05312370881438255\n",
            "Epoch 37, Step 48, Loss: 0.03899442404508591\n",
            "Epoch 37, Step 49, Loss: 0.06222845986485481\n",
            "Epoch 37, Step 50, Loss: 0.03943568095564842\n",
            "Epoch 37, Step 51, Loss: 0.10367684066295624\n",
            "Epoch 37, Step 52, Loss: 0.06081466004252434\n",
            "Epoch 37, Step 53, Loss: 0.03729040175676346\n",
            "Epoch 37, Step 54, Loss: 0.04447459429502487\n",
            "Epoch 37, Step 55, Loss: 0.08268037438392639\n",
            "Epoch 37, Step 56, Loss: 0.044703058898448944\n",
            "Epoch 37, Step 57, Loss: 0.04057030752301216\n",
            "Epoch 37, Step 58, Loss: 0.09088718891143799\n",
            "Epoch 37, Step 59, Loss: 0.045914992690086365\n",
            "Epoch 37, Step 60, Loss: 0.009612753987312317\n",
            "Epoch 37, Step 61, Loss: 0.07565951347351074\n",
            "Epoch 37, Step 62, Loss: 0.06846953928470612\n",
            "Epoch 37, Step 63, Loss: 0.06494856625795364\n",
            "Epoch 37, Step 64, Loss: 0.07336437702178955\n",
            "Epoch 37, Step 65, Loss: 0.0690496563911438\n",
            "Epoch 37, Step 66, Loss: 0.05811344459652901\n",
            "Epoch 37, Step 67, Loss: 0.04720640182495117\n",
            "Epoch 37, Step 68, Loss: 0.08635618537664413\n",
            "Epoch 37, Step 69, Loss: 0.0655672624707222\n",
            "Epoch 37, Step 70, Loss: 0.06362137198448181\n",
            "Epoch 37, Step 71, Loss: 0.06599017977714539\n",
            "Epoch 37, Step 72, Loss: 0.049478914588689804\n",
            "Epoch 37, Step 73, Loss: 0.02179974690079689\n",
            "Epoch 37, Step 74, Loss: 0.1815568208694458\n",
            "Epoch 37, Step 75, Loss: 0.048268623650074005\n",
            "Epoch 37, Step 76, Loss: 0.045855406671762466\n",
            "Epoch 37, Step 77, Loss: 0.05585521459579468\n",
            "Epoch 37, Step 78, Loss: 0.049379508942365646\n",
            "Epoch 37, Step 79, Loss: 0.0545295774936676\n",
            "Epoch 37, Step 80, Loss: 0.09355368465185165\n",
            "Epoch 37, Step 81, Loss: 0.12243976444005966\n",
            "Epoch 37, Step 82, Loss: 0.09563428908586502\n",
            "Epoch 37, Step 83, Loss: 0.040191370993852615\n",
            "Epoch 37, Step 84, Loss: 0.04391937330365181\n",
            "Epoch 37, Step 85, Loss: 0.05078873783349991\n",
            "Epoch 37, Step 86, Loss: 0.05173170566558838\n",
            "Epoch 37, Step 87, Loss: 0.017224185168743134\n",
            "Epoch 37, Step 88, Loss: 0.06420879811048508\n",
            "Epoch 37, Step 89, Loss: 0.03051537275314331\n",
            "Epoch 37, Step 90, Loss: 0.04915701597929001\n",
            "Epoch 37, Step 91, Loss: 0.03933863341808319\n",
            "Epoch 37, Step 92, Loss: 0.12570995092391968\n",
            "Epoch 37, Step 93, Loss: 0.07634682208299637\n",
            "Epoch 37, Step 94, Loss: 0.13024616241455078\n",
            "Epoch 37, Step 95, Loss: 0.036899980157613754\n",
            "Epoch 37, Step 96, Loss: 0.08333656191825867\n",
            "Epoch 37, Step 97, Loss: 0.06707441061735153\n",
            "Epoch 37, Step 98, Loss: 0.053484994918107986\n",
            "Epoch 37, Step 99, Loss: 0.1821833699941635\n",
            "Epoch 37, Step 100, Loss: 0.09952819347381592\n",
            "Epoch 37, Step 101, Loss: 0.06994219869375229\n",
            "Epoch 37, Step 102, Loss: 0.07713571935892105\n",
            "Epoch 37, Step 103, Loss: 0.04110913351178169\n",
            "Epoch 37, Step 104, Loss: 0.05209968239068985\n",
            "Epoch 37, Step 105, Loss: 0.11510637402534485\n",
            "Epoch 37, Step 106, Loss: 0.026938773691654205\n",
            "Epoch 37, Step 107, Loss: 0.11759433150291443\n",
            "Epoch 37, Step 108, Loss: 0.10884444415569305\n",
            "Epoch 37, Step 109, Loss: 0.05561006814241409\n",
            "Epoch 37, Step 110, Loss: 0.06594574451446533\n",
            "Epoch 37, Step 111, Loss: 0.140050008893013\n",
            "Epoch 37, Step 112, Loss: 0.04021293669939041\n",
            "Epoch 37, Step 113, Loss: 0.1006411761045456\n",
            "Epoch 37, Step 114, Loss: 0.10058943927288055\n",
            "Epoch 37, Step 115, Loss: 0.05876519903540611\n",
            "Epoch 37, Step 116, Loss: 0.06692013889551163\n",
            "Epoch 37, Step 117, Loss: 0.10494925081729889\n",
            "Epoch 37, Step 118, Loss: 0.06294506043195724\n",
            "Epoch 37, Step 119, Loss: 0.10961892455816269\n",
            "Epoch 37, Step 120, Loss: 0.10523132234811783\n",
            "Epoch 37, Step 121, Loss: 0.060786373913288116\n",
            "Epoch 37, Step 122, Loss: 0.09737613052129745\n",
            "Epoch 37, Step 123, Loss: 0.10888345539569855\n",
            "Epoch 37, Step 124, Loss: 0.04151657596230507\n",
            "Epoch 37, Step 125, Loss: 0.05818086862564087\n",
            "Epoch 37, Step 126, Loss: 0.06722136586904526\n",
            "Epoch 37, Step 127, Loss: 0.06847973167896271\n",
            "Epoch 37, Step 128, Loss: 0.1305759847164154\n",
            "Epoch 37, Step 129, Loss: 0.07421949505805969\n",
            "Epoch 37, Step 130, Loss: 0.09878210723400116\n",
            "Epoch 37, Step 131, Loss: 0.08265441656112671\n",
            "Epoch 37, Step 132, Loss: 0.03692308068275452\n",
            "Epoch 37, Step 133, Loss: 0.10324987024068832\n",
            "Epoch 37, Step 134, Loss: 0.11458662897348404\n",
            "Epoch 37, Step 135, Loss: 0.14126494526863098\n",
            "Epoch 37, Step 136, Loss: 0.03376583382487297\n",
            "Epoch 37, Step 137, Loss: 0.13013778626918793\n",
            "Epoch 37, Step 138, Loss: 0.06818404793739319\n",
            "Epoch 37, Step 139, Loss: 0.07520779222249985\n",
            "Epoch 37, Step 140, Loss: 0.07484553754329681\n",
            "Epoch 37, Step 141, Loss: 0.12176713347434998\n",
            "Epoch 37, Step 142, Loss: 0.07408183813095093\n",
            "Epoch 37, Step 143, Loss: 0.06754066050052643\n",
            "Epoch 37, Step 144, Loss: 0.09664075076580048\n",
            "Epoch 37, Step 145, Loss: 0.06470371782779694\n",
            "Epoch 37, Step 146, Loss: 0.07107182592153549\n",
            "Epoch 37, Step 147, Loss: 0.11815585196018219\n",
            "Epoch 37, Step 148, Loss: 0.11819084733724594\n",
            "Epoch 37, Step 149, Loss: 0.0833059549331665\n",
            "Epoch 37, Step 150, Loss: 0.04692477360367775\n",
            "Epoch 37, Step 151, Loss: 0.1712215691804886\n",
            "Epoch 37, Step 152, Loss: 0.10147935897111893\n",
            "Epoch 37, Step 153, Loss: 0.099715456366539\n",
            "Epoch 37, Step 154, Loss: 0.05096263810992241\n",
            "Epoch 37, Step 155, Loss: 0.03785618767142296\n",
            "Epoch 37, Step 156, Loss: 0.08330204337835312\n",
            "Epoch 37, Step 157, Loss: 0.10522942245006561\n",
            "Epoch 37, Step 158, Loss: 0.11942370235919952\n",
            "Epoch 37, Step 159, Loss: 0.03443091735243797\n",
            "Epoch 37, Step 160, Loss: 0.05672570690512657\n",
            "Epoch 37, Step 161, Loss: 0.05641629546880722\n",
            "Epoch 37, Step 162, Loss: 0.11359056830406189\n",
            "Epoch 37, Step 163, Loss: 0.032185088843107224\n",
            "Epoch 37, Step 164, Loss: 0.06544151157140732\n",
            "Epoch 37, Step 165, Loss: 0.06534629315137863\n",
            "Epoch 37, Step 166, Loss: 0.031017066910862923\n",
            "Epoch 37, Step 167, Loss: 0.11907689273357391\n",
            "Epoch 37, Step 168, Loss: 0.07630570232868195\n",
            "Epoch 37, Step 169, Loss: 0.16626974940299988\n",
            "Epoch 37, Step 170, Loss: 0.07815909385681152\n",
            "Epoch 37, Step 171, Loss: 0.060364361852407455\n",
            "Epoch 37, Step 172, Loss: 0.0735926404595375\n",
            "Epoch 37, Step 173, Loss: 0.11088921129703522\n",
            "Epoch 37, Step 174, Loss: 0.13567852973937988\n",
            "Epoch 37, Step 175, Loss: 0.040609199553728104\n",
            "Epoch 37, Step 176, Loss: 0.05789812654256821\n",
            "Epoch 37, Step 177, Loss: 0.051472608000040054\n",
            "Epoch 37, Step 178, Loss: 0.25350677967071533\n",
            "Epoch 37, Step 179, Loss: 0.07749934494495392\n",
            "Epoch 37, Step 180, Loss: 0.0901397168636322\n",
            "Epoch 37, Step 181, Loss: 0.10158728063106537\n",
            "Epoch 37, Step 182, Loss: 0.07821956276893616\n",
            "Epoch 37, Step 183, Loss: 0.07155468314886093\n",
            "Epoch 37, Step 184, Loss: 0.12887176871299744\n",
            "Epoch 37, Step 185, Loss: 0.0385085754096508\n",
            "Epoch 37, Step 186, Loss: 0.09558694064617157\n",
            "Epoch 37, Step 187, Loss: 0.02776990458369255\n",
            "Epoch 37, Step 188, Loss: 0.036427225917577744\n",
            "Epoch 37, Step 189, Loss: 0.13897672295570374\n",
            "Epoch 37, Step 190, Loss: 0.038745053112506866\n",
            "Epoch 37, Step 191, Loss: 0.11916597187519073\n",
            "Epoch 37, Step 192, Loss: 0.10152915865182877\n",
            "Epoch 37, Step 193, Loss: 0.14157861471176147\n",
            "Epoch 37, Step 194, Loss: 0.10453317314386368\n",
            "Epoch 37, Step 195, Loss: 0.06605250388383865\n",
            "Epoch 37, Step 196, Loss: 0.06755300611257553\n",
            "Epoch 37, Step 197, Loss: 0.07040773332118988\n",
            "Epoch 37, Step 198, Loss: 0.07222867012023926\n",
            "Epoch 37, Step 199, Loss: 0.08349442481994629\n",
            "Epoch 37, Step 200, Loss: 0.057715076953172684\n",
            "Epoch 37, Step 201, Loss: 0.060496941208839417\n",
            "Epoch 37, Step 202, Loss: 0.08955949544906616\n",
            "Epoch 37, Step 203, Loss: 0.0654798224568367\n",
            "Epoch 37, Step 204, Loss: 0.0720352753996849\n",
            "Epoch 37, Step 205, Loss: 0.08577615767717361\n",
            "Epoch 37, Step 206, Loss: 0.028808098286390305\n",
            "Epoch 37, Step 207, Loss: 0.09423093497753143\n",
            "Epoch 37, Step 208, Loss: 0.026511983945965767\n",
            "Epoch 37, Step 209, Loss: 0.038668323308229446\n",
            "Epoch 37, Step 210, Loss: 0.1591709405183792\n",
            "Epoch 37, Step 211, Loss: 0.0726047083735466\n",
            "Epoch 37, Step 212, Loss: 0.148077130317688\n",
            "Epoch 37, Step 213, Loss: 0.04711230471730232\n",
            "Epoch 37, Step 214, Loss: 0.057967305183410645\n",
            "Epoch 37, Step 215, Loss: 0.08469661325216293\n",
            "Epoch 37, Step 216, Loss: 0.03180662542581558\n",
            "Epoch 37, Step 217, Loss: 0.03808439150452614\n",
            "Epoch 37, Step 218, Loss: 0.06512000411748886\n",
            "Epoch 37, Step 219, Loss: 0.11350955069065094\n",
            "Epoch 37, Step 220, Loss: 0.10278225690126419\n",
            "Epoch 37, Step 221, Loss: 0.0313093326985836\n",
            "Epoch 37, Step 222, Loss: 0.02685096673667431\n",
            "Epoch 37, Step 223, Loss: 0.07360335439443588\n",
            "Epoch 37, Step 224, Loss: 0.09870362281799316\n",
            "Epoch 37, Step 225, Loss: 0.049720730632543564\n",
            "Epoch 37, Step 226, Loss: 0.05528784543275833\n",
            "Epoch 37, Step 227, Loss: 0.09852802753448486\n",
            "Epoch 37, Step 228, Loss: 0.0849800854921341\n",
            "Epoch 37, Step 229, Loss: 0.0414506271481514\n",
            "Epoch 37, Step 230, Loss: 0.03313463553786278\n",
            "Epoch 37, Step 231, Loss: 0.10509795695543289\n",
            "Epoch 37, Step 232, Loss: 0.06718485802412033\n",
            "Epoch 37, Step 233, Loss: 0.027188364416360855\n",
            "Epoch 37, Step 234, Loss: 0.07340427488088608\n",
            "Epoch 37, Step 235, Loss: 0.07862783223390579\n",
            "Epoch 37, Step 236, Loss: 0.06959547102451324\n",
            "Epoch 37, Step 237, Loss: 0.10208188742399216\n",
            "Epoch 37, Step 238, Loss: 0.08975214511156082\n",
            "Epoch 37, Step 239, Loss: 0.06220714747905731\n",
            "Epoch 37, Step 240, Loss: 0.06575378775596619\n",
            "Epoch 37, Step 241, Loss: 0.1476275771856308\n",
            "Epoch 37, Step 242, Loss: 0.04954633489251137\n",
            "Epoch 37, Step 243, Loss: 0.0617215558886528\n",
            "Epoch 37, Step 244, Loss: 0.04600491374731064\n",
            "Epoch 37, Step 245, Loss: 0.09462318569421768\n",
            "Epoch 37, Step 246, Loss: 0.03987029939889908\n",
            "Epoch 37, Step 247, Loss: 0.12282583862543106\n",
            "Epoch 37, Step 248, Loss: 0.05968344211578369\n",
            "Epoch 37, Step 249, Loss: 0.04486807808279991\n",
            "Epoch 37, Step 250, Loss: 0.06362057477235794\n",
            "Epoch 37, Step 251, Loss: 0.07783790677785873\n",
            "Epoch 37, Step 252, Loss: 0.08571887016296387\n",
            "Epoch 37, Step 253, Loss: 0.09747272729873657\n",
            "Epoch 37, Step 254, Loss: 0.13598109781742096\n",
            "Epoch 37, Step 255, Loss: 0.06673264503479004\n",
            "Epoch 37, Step 256, Loss: 0.06985437870025635\n",
            "Epoch 37, Step 257, Loss: 0.0523981899023056\n",
            "Epoch 37, Step 258, Loss: 0.04902588576078415\n",
            "Epoch 37, Step 259, Loss: 0.052867092192173004\n",
            "Epoch 37, Step 260, Loss: 0.02530660480260849\n",
            "Epoch 37, Step 261, Loss: 0.047148242592811584\n",
            "Epoch 37, Step 262, Loss: 0.016550961881875992\n",
            "Epoch 37, Step 263, Loss: 0.019642727449536324\n",
            "Epoch 37, Step 264, Loss: 0.08436694741249084\n",
            "Epoch 37, Step 265, Loss: 0.10003050416707993\n",
            "Epoch 37, Step 266, Loss: 0.058189909905195236\n",
            "Epoch 37, Step 267, Loss: 0.07080243527889252\n",
            "Epoch 37, Step 268, Loss: 0.08493199199438095\n",
            "Epoch 37, Step 269, Loss: 0.1272585391998291\n",
            "Epoch 37, Step 270, Loss: 0.11177802830934525\n",
            "Epoch 37, Step 271, Loss: 0.11987908184528351\n",
            "Epoch 37, Step 272, Loss: 0.046793948858976364\n",
            "Epoch 37, Step 273, Loss: 0.12155188620090485\n",
            "Epoch 37, Step 274, Loss: 0.041614629328250885\n",
            "Epoch 37, Step 275, Loss: 0.12315132468938828\n",
            "Epoch 37, Step 276, Loss: 0.028442759066820145\n",
            "Epoch 37, Step 277, Loss: 0.0314059741795063\n",
            "Epoch 37, Step 278, Loss: 0.0858374685049057\n",
            "Epoch 37, Step 279, Loss: 0.02978736348450184\n",
            "Epoch 37, Step 280, Loss: 0.05598195269703865\n",
            "Epoch 37, Step 281, Loss: 0.044168829917907715\n",
            "Epoch 37, Step 282, Loss: 0.08650843054056168\n",
            "Epoch 37, Step 283, Loss: 0.05307439714670181\n",
            "Epoch 37, Step 284, Loss: 0.06102892383933067\n",
            "Epoch 37, Step 285, Loss: 0.13471956551074982\n",
            "Epoch 37, Step 286, Loss: 0.06289365887641907\n",
            "Epoch 37, Step 287, Loss: 0.1526755839586258\n",
            "Epoch 37, Step 288, Loss: 0.05332406237721443\n",
            "Epoch 37, Step 289, Loss: 0.08532242476940155\n",
            "Epoch 37, Step 290, Loss: 0.06881745904684067\n",
            "Epoch 37, Step 291, Loss: 0.04819675534963608\n",
            "Epoch 37, Step 292, Loss: 0.021197417750954628\n",
            "Epoch 37, Step 293, Loss: 0.06975073367357254\n",
            "Epoch 37, Step 294, Loss: 0.05284067615866661\n",
            "Epoch 37, Step 295, Loss: 0.051164980977773666\n",
            "Epoch 37, Step 296, Loss: 0.0840873271226883\n",
            "Epoch 37, Step 297, Loss: 0.15784387290477753\n",
            "Epoch 37, Step 298, Loss: 0.09572391211986542\n",
            "Epoch 37, Step 299, Loss: 0.11412286013364792\n",
            "Epoch 37, Step 300, Loss: 0.03043755702674389\n",
            "Epoch 37, Step 301, Loss: 0.07772229611873627\n",
            "Epoch 37, Step 302, Loss: 0.08896578848361969\n",
            "Epoch 37, Step 303, Loss: 0.05658857151865959\n",
            "Epoch 37, Step 304, Loss: 0.0939359962940216\n",
            "Epoch 37, Step 305, Loss: 0.08360104262828827\n",
            "Epoch 37, Step 306, Loss: 0.1262078434228897\n",
            "Epoch 37, Step 307, Loss: 0.040861740708351135\n",
            "Epoch 37, Step 308, Loss: 0.07348456978797913\n",
            "Epoch 37, Step 309, Loss: 0.06094314157962799\n",
            "Epoch 37, Step 310, Loss: 0.09758473187685013\n",
            "Epoch 37, Step 311, Loss: 0.08929727971553802\n",
            "Epoch 37, Step 312, Loss: 0.0336984284222126\n",
            "Epoch 37 end, avg train loss: 0.0741148791588343\n",
            "Epoch 37 end, avg val loss: 0.3598023056983948, accuracy: 91.41%\n",
            "Epoch 38, Step 0, Loss: 0.035276032984256744\n",
            "Epoch 38, Step 1, Loss: 0.09400865435600281\n",
            "Epoch 38, Step 2, Loss: 0.06012555956840515\n",
            "Epoch 38, Step 3, Loss: 0.03113151714205742\n",
            "Epoch 38, Step 4, Loss: 0.020178167149424553\n",
            "Epoch 38, Step 5, Loss: 0.04382922127842903\n",
            "Epoch 38, Step 6, Loss: 0.03174829110503197\n",
            "Epoch 38, Step 7, Loss: 0.056038595736026764\n",
            "Epoch 38, Step 8, Loss: 0.03320390358567238\n",
            "Epoch 38, Step 9, Loss: 0.05115646496415138\n",
            "Epoch 38, Step 10, Loss: 0.023841194808483124\n",
            "Epoch 38, Step 11, Loss: 0.1321822553873062\n",
            "Epoch 38, Step 12, Loss: 0.03438904508948326\n",
            "Epoch 38, Step 13, Loss: 0.08896202594041824\n",
            "Epoch 38, Step 14, Loss: 0.10947182029485703\n",
            "Epoch 38, Step 15, Loss: 0.02122369222342968\n",
            "Epoch 38, Step 16, Loss: 0.03913842514157295\n",
            "Epoch 38, Step 17, Loss: 0.10603954643011093\n",
            "Epoch 38, Step 18, Loss: 0.0423930361866951\n",
            "Epoch 38, Step 19, Loss: 0.10140009224414825\n",
            "Epoch 38, Step 20, Loss: 0.05763012170791626\n",
            "Epoch 38, Step 21, Loss: 0.05838644132018089\n",
            "Epoch 38, Step 22, Loss: 0.13974587619304657\n",
            "Epoch 38, Step 23, Loss: 0.03240565210580826\n",
            "Epoch 38, Step 24, Loss: 0.09241180121898651\n",
            "Epoch 38, Step 25, Loss: 0.0653097927570343\n",
            "Epoch 38, Step 26, Loss: 0.07407771795988083\n",
            "Epoch 38, Step 27, Loss: 0.058607205748558044\n",
            "Epoch 38, Step 28, Loss: 0.04966910928487778\n",
            "Epoch 38, Step 29, Loss: 0.06687524169683456\n",
            "Epoch 38, Step 30, Loss: 0.03518494963645935\n",
            "Epoch 38, Step 31, Loss: 0.10176265984773636\n",
            "Epoch 38, Step 32, Loss: 0.13007499277591705\n",
            "Epoch 38, Step 33, Loss: 0.06757330149412155\n",
            "Epoch 38, Step 34, Loss: 0.024293063208460808\n",
            "Epoch 38, Step 35, Loss: 0.07012833654880524\n",
            "Epoch 38, Step 36, Loss: 0.07202550768852234\n",
            "Epoch 38, Step 37, Loss: 0.11515048146247864\n",
            "Epoch 38, Step 38, Loss: 0.04519969969987869\n",
            "Epoch 38, Step 39, Loss: 0.017818370833992958\n",
            "Epoch 38, Step 40, Loss: 0.058068230748176575\n",
            "Epoch 38, Step 41, Loss: 0.04345690459012985\n",
            "Epoch 38, Step 42, Loss: 0.114594466984272\n",
            "Epoch 38, Step 43, Loss: 0.045073002576828\n",
            "Epoch 38, Step 44, Loss: 0.07582736015319824\n",
            "Epoch 38, Step 45, Loss: 0.05871003121137619\n",
            "Epoch 38, Step 46, Loss: 0.039214957505464554\n",
            "Epoch 38, Step 47, Loss: 0.08285969495773315\n",
            "Epoch 38, Step 48, Loss: 0.022231582552194595\n",
            "Epoch 38, Step 49, Loss: 0.05383962392807007\n",
            "Epoch 38, Step 50, Loss: 0.12943874299526215\n",
            "Epoch 38, Step 51, Loss: 0.05515671893954277\n",
            "Epoch 38, Step 52, Loss: 0.027963489294052124\n",
            "Epoch 38, Step 53, Loss: 0.06169934943318367\n",
            "Epoch 38, Step 54, Loss: 0.034753769636154175\n",
            "Epoch 38, Step 55, Loss: 0.04408843815326691\n",
            "Epoch 38, Step 56, Loss: 0.07532697916030884\n",
            "Epoch 38, Step 57, Loss: 0.08136507123708725\n",
            "Epoch 38, Step 58, Loss: 0.02288873679935932\n",
            "Epoch 38, Step 59, Loss: 0.05013871565461159\n",
            "Epoch 38, Step 60, Loss: 0.0549648143351078\n",
            "Epoch 38, Step 61, Loss: 0.04957131668925285\n",
            "Epoch 38, Step 62, Loss: 0.05422056466341019\n",
            "Epoch 38, Step 63, Loss: 0.11222140491008759\n",
            "Epoch 38, Step 64, Loss: 0.09469544142484665\n",
            "Epoch 38, Step 65, Loss: 0.058309901505708694\n",
            "Epoch 38, Step 66, Loss: 0.03116161748766899\n",
            "Epoch 38, Step 67, Loss: 0.03769577294588089\n",
            "Epoch 38, Step 68, Loss: 0.04376295581459999\n",
            "Epoch 38, Step 69, Loss: 0.061384379863739014\n",
            "Epoch 38, Step 70, Loss: 0.11709102988243103\n",
            "Epoch 38, Step 71, Loss: 0.08006040751934052\n",
            "Epoch 38, Step 72, Loss: 0.04209466651082039\n",
            "Epoch 38, Step 73, Loss: 0.09492310136556625\n",
            "Epoch 38, Step 74, Loss: 0.044864434748888016\n",
            "Epoch 38, Step 75, Loss: 0.02341996505856514\n",
            "Epoch 38, Step 76, Loss: 0.025415031239390373\n",
            "Epoch 38, Step 77, Loss: 0.014919028617441654\n",
            "Epoch 38, Step 78, Loss: 0.07579158991575241\n",
            "Epoch 38, Step 79, Loss: 0.027757864445447922\n",
            "Epoch 38, Step 80, Loss: 0.1287485957145691\n",
            "Epoch 38, Step 81, Loss: 0.13945680856704712\n",
            "Epoch 38, Step 82, Loss: 0.06684065610170364\n",
            "Epoch 38, Step 83, Loss: 0.07626816630363464\n",
            "Epoch 38, Step 84, Loss: 0.091621033847332\n",
            "Epoch 38, Step 85, Loss: 0.10436639189720154\n",
            "Epoch 38, Step 86, Loss: 0.06831094622612\n",
            "Epoch 38, Step 87, Loss: 0.05747029557824135\n",
            "Epoch 38, Step 88, Loss: 0.037859752774238586\n",
            "Epoch 38, Step 89, Loss: 0.09474166482686996\n",
            "Epoch 38, Step 90, Loss: 0.0648283064365387\n",
            "Epoch 38, Step 91, Loss: 0.16748027503490448\n",
            "Epoch 38, Step 92, Loss: 0.020362498238682747\n",
            "Epoch 38, Step 93, Loss: 0.11025980859994888\n",
            "Epoch 38, Step 94, Loss: 0.06694085896015167\n",
            "Epoch 38, Step 95, Loss: 0.04108619689941406\n",
            "Epoch 38, Step 96, Loss: 0.08630899339914322\n",
            "Epoch 38, Step 97, Loss: 0.07656411081552505\n",
            "Epoch 38, Step 98, Loss: 0.07513798773288727\n",
            "Epoch 38, Step 99, Loss: 0.041011203080415726\n",
            "Epoch 38, Step 100, Loss: 0.04716706648468971\n",
            "Epoch 38, Step 101, Loss: 0.030720138922333717\n",
            "Epoch 38, Step 102, Loss: 0.08572664856910706\n",
            "Epoch 38, Step 103, Loss: 0.0900956317782402\n",
            "Epoch 38, Step 104, Loss: 0.044820670038461685\n",
            "Epoch 38, Step 105, Loss: 0.06832796335220337\n",
            "Epoch 38, Step 106, Loss: 0.07871277630329132\n",
            "Epoch 38, Step 107, Loss: 0.08032863587141037\n",
            "Epoch 38, Step 108, Loss: 0.04006751626729965\n",
            "Epoch 38, Step 109, Loss: 0.041794437915086746\n",
            "Epoch 38, Step 110, Loss: 0.03225462883710861\n",
            "Epoch 38, Step 111, Loss: 0.027060963213443756\n",
            "Epoch 38, Step 112, Loss: 0.08204732835292816\n",
            "Epoch 38, Step 113, Loss: 0.1626410335302353\n",
            "Epoch 38, Step 114, Loss: 0.11625909060239792\n",
            "Epoch 38, Step 115, Loss: 0.09710419178009033\n",
            "Epoch 38, Step 116, Loss: 0.1103014424443245\n",
            "Epoch 38, Step 117, Loss: 0.10687938332557678\n",
            "Epoch 38, Step 118, Loss: 0.08039814233779907\n",
            "Epoch 38, Step 119, Loss: 0.07068373262882233\n",
            "Epoch 38, Step 120, Loss: 0.05065669119358063\n",
            "Epoch 38, Step 121, Loss: 0.11908097565174103\n",
            "Epoch 38, Step 122, Loss: 0.11727023869752884\n",
            "Epoch 38, Step 123, Loss: 0.03454127162694931\n",
            "Epoch 38, Step 124, Loss: 0.13381755352020264\n",
            "Epoch 38, Step 125, Loss: 0.07387229800224304\n",
            "Epoch 38, Step 126, Loss: 0.12122731655836105\n",
            "Epoch 38, Step 127, Loss: 0.07541044056415558\n",
            "Epoch 38, Step 128, Loss: 0.10953930765390396\n",
            "Epoch 38, Step 129, Loss: 0.1736457794904709\n",
            "Epoch 38, Step 130, Loss: 0.09313923120498657\n",
            "Epoch 38, Step 131, Loss: 0.035681284964084625\n",
            "Epoch 38, Step 132, Loss: 0.1137765645980835\n",
            "Epoch 38, Step 133, Loss: 0.07815686613321304\n",
            "Epoch 38, Step 134, Loss: 0.11617711186408997\n",
            "Epoch 38, Step 135, Loss: 0.019196007400751114\n",
            "Epoch 38, Step 136, Loss: 0.04951141029596329\n",
            "Epoch 38, Step 137, Loss: 0.11312638223171234\n",
            "Epoch 38, Step 138, Loss: 0.13376080989837646\n",
            "Epoch 38, Step 139, Loss: 0.08810608834028244\n",
            "Epoch 38, Step 140, Loss: 0.07731529325246811\n",
            "Epoch 38, Step 141, Loss: 0.04152373597025871\n",
            "Epoch 38, Step 142, Loss: 0.0751631036400795\n",
            "Epoch 38, Step 143, Loss: 0.10751185566186905\n",
            "Epoch 38, Step 144, Loss: 0.054658226668834686\n",
            "Epoch 38, Step 145, Loss: 0.06965342164039612\n",
            "Epoch 38, Step 146, Loss: 0.09501238167285919\n",
            "Epoch 38, Step 147, Loss: 0.11430476605892181\n",
            "Epoch 38, Step 148, Loss: 0.08812431246042252\n",
            "Epoch 38, Step 149, Loss: 0.10029756277799606\n",
            "Epoch 38, Step 150, Loss: 0.03525995835661888\n",
            "Epoch 38, Step 151, Loss: 0.09569545090198517\n",
            "Epoch 38, Step 152, Loss: 0.09344794601202011\n",
            "Epoch 38, Step 153, Loss: 0.06372485309839249\n",
            "Epoch 38, Step 154, Loss: 0.0609562061727047\n",
            "Epoch 38, Step 155, Loss: 0.05613415315747261\n",
            "Epoch 38, Step 156, Loss: 0.04771437868475914\n",
            "Epoch 38, Step 157, Loss: 0.05676421523094177\n",
            "Epoch 38, Step 158, Loss: 0.17214004695415497\n",
            "Epoch 38, Step 159, Loss: 0.06452976167201996\n",
            "Epoch 38, Step 160, Loss: 0.07442721724510193\n",
            "Epoch 38, Step 161, Loss: 0.052160054445266724\n",
            "Epoch 38, Step 162, Loss: 0.046783413738012314\n",
            "Epoch 38, Step 163, Loss: 0.09801449626684189\n",
            "Epoch 38, Step 164, Loss: 0.06474261730909348\n",
            "Epoch 38, Step 165, Loss: 0.1222594603896141\n",
            "Epoch 38, Step 166, Loss: 0.08345036208629608\n",
            "Epoch 38, Step 167, Loss: 0.049114905297756195\n",
            "Epoch 38, Step 168, Loss: 0.11138459295034409\n",
            "Epoch 38, Step 169, Loss: 0.16214610636234283\n",
            "Epoch 38, Step 170, Loss: 0.020056117326021194\n",
            "Epoch 38, Step 171, Loss: 0.0340329185128212\n",
            "Epoch 38, Step 172, Loss: 0.1321852207183838\n",
            "Epoch 38, Step 173, Loss: 0.0697665810585022\n",
            "Epoch 38, Step 174, Loss: 0.08506123721599579\n",
            "Epoch 38, Step 175, Loss: 0.061070092022418976\n",
            "Epoch 38, Step 176, Loss: 0.07240008562803268\n",
            "Epoch 38, Step 177, Loss: 0.08873742073774338\n",
            "Epoch 38, Step 178, Loss: 0.08011877536773682\n",
            "Epoch 38, Step 179, Loss: 0.06859046965837479\n",
            "Epoch 38, Step 180, Loss: 0.09219754487276077\n",
            "Epoch 38, Step 181, Loss: 0.05652375891804695\n",
            "Epoch 38, Step 182, Loss: 0.14136238396167755\n",
            "Epoch 38, Step 183, Loss: 0.10498617589473724\n",
            "Epoch 38, Step 184, Loss: 0.05018266290426254\n",
            "Epoch 38, Step 185, Loss: 0.07893278449773788\n",
            "Epoch 38, Step 186, Loss: 0.10633181035518646\n",
            "Epoch 38, Step 187, Loss: 0.08233451098203659\n",
            "Epoch 38, Step 188, Loss: 0.05002830550074577\n",
            "Epoch 38, Step 189, Loss: 0.04914664104580879\n",
            "Epoch 38, Step 190, Loss: 0.07182197272777557\n",
            "Epoch 38, Step 191, Loss: 0.09912963211536407\n",
            "Epoch 38, Step 192, Loss: 0.10188961774110794\n",
            "Epoch 38, Step 193, Loss: 0.036392681300640106\n",
            "Epoch 38, Step 194, Loss: 0.047097399830818176\n",
            "Epoch 38, Step 195, Loss: 0.07084817439317703\n",
            "Epoch 38, Step 196, Loss: 0.0907420888543129\n",
            "Epoch 38, Step 197, Loss: 0.08090777695178986\n",
            "Epoch 38, Step 198, Loss: 0.11517340689897537\n",
            "Epoch 38, Step 199, Loss: 0.11748450994491577\n",
            "Epoch 38, Step 200, Loss: 0.04349985718727112\n",
            "Epoch 38, Step 201, Loss: 0.07129202783107758\n",
            "Epoch 38, Step 202, Loss: 0.09664373844861984\n",
            "Epoch 38, Step 203, Loss: 0.1278204470872879\n",
            "Epoch 38, Step 204, Loss: 0.07969382405281067\n",
            "Epoch 38, Step 205, Loss: 0.10575111955404282\n",
            "Epoch 38, Step 206, Loss: 0.09060818701982498\n",
            "Epoch 38, Step 207, Loss: 0.0397082157433033\n",
            "Epoch 38, Step 208, Loss: 0.07486361265182495\n",
            "Epoch 38, Step 209, Loss: 0.08168081939220428\n",
            "Epoch 38, Step 210, Loss: 0.07804938405752182\n",
            "Epoch 38, Step 211, Loss: 0.07675063610076904\n",
            "Epoch 38, Step 212, Loss: 0.02595369517803192\n",
            "Epoch 38, Step 213, Loss: 0.11360977590084076\n",
            "Epoch 38, Step 214, Loss: 0.12623418867588043\n",
            "Epoch 38, Step 215, Loss: 0.13400253653526306\n",
            "Epoch 38, Step 216, Loss: 0.042452502995729446\n",
            "Epoch 38, Step 217, Loss: 0.13562841713428497\n",
            "Epoch 38, Step 218, Loss: 0.040255580097436905\n",
            "Epoch 38, Step 219, Loss: 0.07116300612688065\n",
            "Epoch 38, Step 220, Loss: 0.06849194318056107\n",
            "Epoch 38, Step 221, Loss: 0.09723761677742004\n",
            "Epoch 38, Step 222, Loss: 0.07651039212942123\n",
            "Epoch 38, Step 223, Loss: 0.05122030898928642\n",
            "Epoch 38, Step 224, Loss: 0.07561830431222916\n",
            "Epoch 38, Step 225, Loss: 0.046010591089725494\n",
            "Epoch 38, Step 226, Loss: 0.03653223067522049\n",
            "Epoch 38, Step 227, Loss: 0.06119609251618385\n",
            "Epoch 38, Step 228, Loss: 0.1467946469783783\n",
            "Epoch 38, Step 229, Loss: 0.13052718341350555\n",
            "Epoch 38, Step 230, Loss: 0.0755777508020401\n",
            "Epoch 38, Step 231, Loss: 0.10228092223405838\n",
            "Epoch 38, Step 232, Loss: 0.061257343739271164\n",
            "Epoch 38, Step 233, Loss: 0.05582471936941147\n",
            "Epoch 38, Step 234, Loss: 0.043951716274023056\n",
            "Epoch 38, Step 235, Loss: 0.05576428398489952\n",
            "Epoch 38, Step 236, Loss: 0.073321633040905\n",
            "Epoch 38, Step 237, Loss: 0.06299381703138351\n",
            "Epoch 38, Step 238, Loss: 0.09762454032897949\n",
            "Epoch 38, Step 239, Loss: 0.08151419460773468\n",
            "Epoch 38, Step 240, Loss: 0.13048264384269714\n",
            "Epoch 38, Step 241, Loss: 0.06853172183036804\n",
            "Epoch 38, Step 242, Loss: 0.05625157430768013\n",
            "Epoch 38, Step 243, Loss: 0.10671089589595795\n",
            "Epoch 38, Step 244, Loss: 0.038787733763456345\n",
            "Epoch 38, Step 245, Loss: 0.05691366642713547\n",
            "Epoch 38, Step 246, Loss: 0.06383109092712402\n",
            "Epoch 38, Step 247, Loss: 0.034829575568437576\n",
            "Epoch 38, Step 248, Loss: 0.09018818289041519\n",
            "Epoch 38, Step 249, Loss: 0.05897657200694084\n",
            "Epoch 38, Step 250, Loss: 0.10186116397380829\n",
            "Epoch 38, Step 251, Loss: 0.12111619114875793\n",
            "Epoch 38, Step 252, Loss: 0.06116950511932373\n",
            "Epoch 38, Step 253, Loss: 0.09326009452342987\n",
            "Epoch 38, Step 254, Loss: 0.08541541546583176\n",
            "Epoch 38, Step 255, Loss: 0.10477807372808456\n",
            "Epoch 38, Step 256, Loss: 0.0242797639220953\n",
            "Epoch 38, Step 257, Loss: 0.20356345176696777\n",
            "Epoch 38, Step 258, Loss: 0.07628978788852692\n",
            "Epoch 38, Step 259, Loss: 0.06825712323188782\n",
            "Epoch 38, Step 260, Loss: 0.060561757534742355\n",
            "Epoch 38, Step 261, Loss: 0.09786131232976913\n",
            "Epoch 38, Step 262, Loss: 0.06406710296869278\n",
            "Epoch 38, Step 263, Loss: 0.1185259073972702\n",
            "Epoch 38, Step 264, Loss: 0.024960597977042198\n",
            "Epoch 38, Step 265, Loss: 0.06344703584909439\n",
            "Epoch 38, Step 266, Loss: 0.05367033928632736\n",
            "Epoch 38, Step 267, Loss: 0.062424615025520325\n",
            "Epoch 38, Step 268, Loss: 0.04627266526222229\n",
            "Epoch 38, Step 269, Loss: 0.1136641800403595\n",
            "Epoch 38, Step 270, Loss: 0.07651997357606888\n",
            "Epoch 38, Step 271, Loss: 0.13345879316329956\n",
            "Epoch 38, Step 272, Loss: 0.07357795536518097\n",
            "Epoch 38, Step 273, Loss: 0.08216574043035507\n",
            "Epoch 38, Step 274, Loss: 0.03256594389677048\n",
            "Epoch 38, Step 275, Loss: 0.14767999947071075\n",
            "Epoch 38, Step 276, Loss: 0.06459958851337433\n",
            "Epoch 38, Step 277, Loss: 0.061846595257520676\n",
            "Epoch 38, Step 278, Loss: 0.07914313673973083\n",
            "Epoch 38, Step 279, Loss: 0.07470960170030594\n",
            "Epoch 38, Step 280, Loss: 0.24573910236358643\n",
            "Epoch 38, Step 281, Loss: 0.08118205517530441\n",
            "Epoch 38, Step 282, Loss: 0.03162989392876625\n",
            "Epoch 38, Step 283, Loss: 0.06129567697644234\n",
            "Epoch 38, Step 284, Loss: 0.0658344179391861\n",
            "Epoch 38, Step 285, Loss: 0.1431683897972107\n",
            "Epoch 38, Step 286, Loss: 0.0764731764793396\n",
            "Epoch 38, Step 287, Loss: 0.10033072531223297\n",
            "Epoch 38, Step 288, Loss: 0.04778316617012024\n",
            "Epoch 38, Step 289, Loss: 0.11937569081783295\n",
            "Epoch 38, Step 290, Loss: 0.040727123618125916\n",
            "Epoch 38, Step 291, Loss: 0.06208520755171776\n",
            "Epoch 38, Step 292, Loss: 0.028176460415124893\n",
            "Epoch 38, Step 293, Loss: 0.13496822118759155\n",
            "Epoch 38, Step 294, Loss: 0.10363850742578506\n",
            "Epoch 38, Step 295, Loss: 0.1090313121676445\n",
            "Epoch 38, Step 296, Loss: 0.08014101535081863\n",
            "Epoch 38, Step 297, Loss: 0.18046711385250092\n",
            "Epoch 38, Step 298, Loss: 0.08463730663061142\n",
            "Epoch 38, Step 299, Loss: 0.05201733857393265\n",
            "Epoch 38, Step 300, Loss: 0.11431320011615753\n",
            "Epoch 38, Step 301, Loss: 0.11200987547636032\n",
            "Epoch 38, Step 302, Loss: 0.061038315296173096\n",
            "Epoch 38, Step 303, Loss: 0.041456252336502075\n",
            "Epoch 38, Step 304, Loss: 0.0469810888171196\n",
            "Epoch 38, Step 305, Loss: 0.05210520327091217\n",
            "Epoch 38, Step 306, Loss: 0.1577475666999817\n",
            "Epoch 38, Step 307, Loss: 0.05917920917272568\n",
            "Epoch 38, Step 308, Loss: 0.07183437049388885\n",
            "Epoch 38, Step 309, Loss: 0.08431509137153625\n",
            "Epoch 38, Step 310, Loss: 0.026664434000849724\n",
            "Epoch 38, Step 311, Loss: 0.08268888294696808\n",
            "Epoch 38, Step 312, Loss: 0.14759016036987305\n",
            "Epoch 38 end, avg train loss: 0.0761646666555121\n",
            "Epoch 38 end, avg val loss: 0.3801828096561794, accuracy: 90.63%\n",
            "Epoch 39, Step 0, Loss: 0.05750545114278793\n",
            "Epoch 39, Step 1, Loss: 0.07751749455928802\n",
            "Epoch 39, Step 2, Loss: 0.061070289462804794\n",
            "Epoch 39, Step 3, Loss: 0.03403584659099579\n",
            "Epoch 39, Step 4, Loss: 0.03916167840361595\n",
            "Epoch 39, Step 5, Loss: 0.06008032709360123\n",
            "Epoch 39, Step 6, Loss: 0.08077942579984665\n",
            "Epoch 39, Step 7, Loss: 0.06767261028289795\n",
            "Epoch 39, Step 8, Loss: 0.036376215517520905\n",
            "Epoch 39, Step 9, Loss: 0.023797694593667984\n",
            "Epoch 39, Step 10, Loss: 0.054149921983480453\n",
            "Epoch 39, Step 11, Loss: 0.04661548137664795\n",
            "Epoch 39, Step 12, Loss: 0.07194151729345322\n",
            "Epoch 39, Step 13, Loss: 0.045902103185653687\n",
            "Epoch 39, Step 14, Loss: 0.053166404366493225\n",
            "Epoch 39, Step 15, Loss: 0.08795013278722763\n",
            "Epoch 39, Step 16, Loss: 0.044683169573545456\n",
            "Epoch 39, Step 17, Loss: 0.057745352387428284\n",
            "Epoch 39, Step 18, Loss: 0.04617655649781227\n",
            "Epoch 39, Step 19, Loss: 0.07164980471134186\n",
            "Epoch 39, Step 20, Loss: 0.04359691962599754\n",
            "Epoch 39, Step 21, Loss: 0.013318715617060661\n",
            "Epoch 39, Step 22, Loss: 0.04206528887152672\n",
            "Epoch 39, Step 23, Loss: 0.057407330721616745\n",
            "Epoch 39, Step 24, Loss: 0.05263374373316765\n",
            "Epoch 39, Step 25, Loss: 0.039218638092279434\n",
            "Epoch 39, Step 26, Loss: 0.10279516875743866\n",
            "Epoch 39, Step 27, Loss: 0.07370626926422119\n",
            "Epoch 39, Step 28, Loss: 0.04928417131304741\n",
            "Epoch 39, Step 29, Loss: 0.06756295263767242\n",
            "Epoch 39, Step 30, Loss: 0.028083305805921555\n",
            "Epoch 39, Step 31, Loss: 0.049408718943595886\n",
            "Epoch 39, Step 32, Loss: 0.06233837828040123\n",
            "Epoch 39, Step 33, Loss: 0.02761806547641754\n",
            "Epoch 39, Step 34, Loss: 0.04534396529197693\n",
            "Epoch 39, Step 35, Loss: 0.056952230632305145\n",
            "Epoch 39, Step 36, Loss: 0.07396718114614487\n",
            "Epoch 39, Step 37, Loss: 0.011685292236506939\n",
            "Epoch 39, Step 38, Loss: 0.10443102568387985\n",
            "Epoch 39, Step 39, Loss: 0.06565617024898529\n",
            "Epoch 39, Step 40, Loss: 0.01922076940536499\n",
            "Epoch 39, Step 41, Loss: 0.04592473432421684\n",
            "Epoch 39, Step 42, Loss: 0.07277791202068329\n",
            "Epoch 39, Step 43, Loss: 0.020856663584709167\n",
            "Epoch 39, Step 44, Loss: 0.020115744322538376\n",
            "Epoch 39, Step 45, Loss: 0.038618702441453934\n",
            "Epoch 39, Step 46, Loss: 0.051962949335575104\n",
            "Epoch 39, Step 47, Loss: 0.02787798084318638\n",
            "Epoch 39, Step 48, Loss: 0.03681335225701332\n",
            "Epoch 39, Step 49, Loss: 0.05179686099290848\n",
            "Epoch 39, Step 50, Loss: 0.030503535643219948\n",
            "Epoch 39, Step 51, Loss: 0.08620604127645493\n",
            "Epoch 39, Step 52, Loss: 0.03505919873714447\n",
            "Epoch 39, Step 53, Loss: 0.12968887388706207\n",
            "Epoch 39, Step 54, Loss: 0.034739136695861816\n",
            "Epoch 39, Step 55, Loss: 0.04660599306225777\n",
            "Epoch 39, Step 56, Loss: 0.06214166805148125\n",
            "Epoch 39, Step 57, Loss: 0.03834651783108711\n",
            "Epoch 39, Step 58, Loss: 0.03410114347934723\n",
            "Epoch 39, Step 59, Loss: 0.03851967304944992\n",
            "Epoch 39, Step 60, Loss: 0.036292631179094315\n",
            "Epoch 39, Step 61, Loss: 0.04365057498216629\n",
            "Epoch 39, Step 62, Loss: 0.05599036067724228\n",
            "Epoch 39, Step 63, Loss: 0.06018808111548424\n",
            "Epoch 39, Step 64, Loss: 0.0956750139594078\n",
            "Epoch 39, Step 65, Loss: 0.04372822865843773\n",
            "Epoch 39, Step 66, Loss: 0.03300632908940315\n",
            "Epoch 39, Step 67, Loss: 0.053689636290073395\n",
            "Epoch 39, Step 68, Loss: 0.06627150624990463\n",
            "Epoch 39, Step 69, Loss: 0.10909292846918106\n",
            "Epoch 39, Step 70, Loss: 0.0612049475312233\n",
            "Epoch 39, Step 71, Loss: 0.05140971019864082\n",
            "Epoch 39, Step 72, Loss: 0.05801362171769142\n",
            "Epoch 39, Step 73, Loss: 0.05994440242648125\n",
            "Epoch 39, Step 74, Loss: 0.04971717298030853\n",
            "Epoch 39, Step 75, Loss: 0.11409108340740204\n",
            "Epoch 39, Step 76, Loss: 0.03538170084357262\n",
            "Epoch 39, Step 77, Loss: 0.05326831713318825\n",
            "Epoch 39, Step 78, Loss: 0.04808573052287102\n",
            "Epoch 39, Step 79, Loss: 0.08530157804489136\n",
            "Epoch 39, Step 80, Loss: 0.05767316743731499\n",
            "Epoch 39, Step 81, Loss: 0.07662054151296616\n",
            "Epoch 39, Step 82, Loss: 0.060112956911325455\n",
            "Epoch 39, Step 83, Loss: 0.0889841690659523\n",
            "Epoch 39, Step 84, Loss: 0.0499873049557209\n",
            "Epoch 39, Step 85, Loss: 0.03213551267981529\n",
            "Epoch 39, Step 86, Loss: 0.12018533051013947\n",
            "Epoch 39, Step 87, Loss: 0.08221723139286041\n",
            "Epoch 39, Step 88, Loss: 0.10601227730512619\n",
            "Epoch 39, Step 89, Loss: 0.04996646195650101\n",
            "Epoch 39, Step 90, Loss: 0.048395879566669464\n",
            "Epoch 39, Step 91, Loss: 0.017118871212005615\n",
            "Epoch 39, Step 92, Loss: 0.1149475947022438\n",
            "Epoch 39, Step 93, Loss: 0.046214278787374496\n",
            "Epoch 39, Step 94, Loss: 0.10365529358386993\n",
            "Epoch 39, Step 95, Loss: 0.031179796904325485\n",
            "Epoch 39, Step 96, Loss: 0.02654925175011158\n",
            "Epoch 39, Step 97, Loss: 0.06504380702972412\n",
            "Epoch 39, Step 98, Loss: 0.04691224917769432\n",
            "Epoch 39, Step 99, Loss: 0.1142311543226242\n",
            "Epoch 39, Step 100, Loss: 0.10577289760112762\n",
            "Epoch 39, Step 101, Loss: 0.05533566698431969\n",
            "Epoch 39, Step 102, Loss: 0.06262218952178955\n",
            "Epoch 39, Step 103, Loss: 0.03968926891684532\n",
            "Epoch 39, Step 104, Loss: 0.022001996636390686\n",
            "Epoch 39, Step 105, Loss: 0.024795018136501312\n",
            "Epoch 39, Step 106, Loss: 0.06844363361597061\n",
            "Epoch 39, Step 107, Loss: 0.03908207640051842\n",
            "Epoch 39, Step 108, Loss: 0.04916209354996681\n",
            "Epoch 39, Step 109, Loss: 0.1024734228849411\n",
            "Epoch 39, Step 110, Loss: 0.11899572610855103\n",
            "Epoch 39, Step 111, Loss: 0.08582179248332977\n",
            "Epoch 39, Step 112, Loss: 0.12618933618068695\n",
            "Epoch 39, Step 113, Loss: 0.03232162445783615\n",
            "Epoch 39, Step 114, Loss: 0.013761993497610092\n",
            "Epoch 39, Step 115, Loss: 0.12045834213495255\n",
            "Epoch 39, Step 116, Loss: 0.08605077862739563\n",
            "Epoch 39, Step 117, Loss: 0.12739354372024536\n",
            "Epoch 39, Step 118, Loss: 0.0485544390976429\n",
            "Epoch 39, Step 119, Loss: 0.14936241507530212\n",
            "Epoch 39, Step 120, Loss: 0.09235737472772598\n",
            "Epoch 39, Step 121, Loss: 0.05018270015716553\n",
            "Epoch 39, Step 122, Loss: 0.049586258828639984\n",
            "Epoch 39, Step 123, Loss: 0.04810493066906929\n",
            "Epoch 39, Step 124, Loss: 0.04069077968597412\n",
            "Epoch 39, Step 125, Loss: 0.057053349912166595\n",
            "Epoch 39, Step 126, Loss: 0.06707391887903214\n",
            "Epoch 39, Step 127, Loss: 0.05678331106901169\n",
            "Epoch 39, Step 128, Loss: 0.07373186200857162\n",
            "Epoch 39, Step 129, Loss: 0.05409759655594826\n",
            "Epoch 39, Step 130, Loss: 0.1228301078081131\n",
            "Epoch 39, Step 131, Loss: 0.1174950897693634\n",
            "Epoch 39, Step 132, Loss: 0.05054234340786934\n",
            "Epoch 39, Step 133, Loss: 0.09625126421451569\n",
            "Epoch 39, Step 134, Loss: 0.023989355191588402\n",
            "Epoch 39, Step 135, Loss: 0.06591609120368958\n",
            "Epoch 39, Step 136, Loss: 0.08923736214637756\n",
            "Epoch 39, Step 137, Loss: 0.103929303586483\n",
            "Epoch 39, Step 138, Loss: 0.11379089206457138\n",
            "Epoch 39, Step 139, Loss: 0.07869035750627518\n",
            "Epoch 39, Step 140, Loss: 0.03682929277420044\n",
            "Epoch 39, Step 141, Loss: 0.0782257542014122\n",
            "Epoch 39, Step 142, Loss: 0.08869237452745438\n",
            "Epoch 39, Step 143, Loss: 0.12643782794475555\n",
            "Epoch 39, Step 144, Loss: 0.05058557912707329\n",
            "Epoch 39, Step 145, Loss: 0.06984531134366989\n",
            "Epoch 39, Step 146, Loss: 0.0682215765118599\n",
            "Epoch 39, Step 147, Loss: 0.04205310344696045\n",
            "Epoch 39, Step 148, Loss: 0.04434262216091156\n",
            "Epoch 39, Step 149, Loss: 0.0589909553527832\n",
            "Epoch 39, Step 150, Loss: 0.06534677743911743\n",
            "Epoch 39, Step 151, Loss: 0.029469462111592293\n",
            "Epoch 39, Step 152, Loss: 0.06822041422128677\n",
            "Epoch 39, Step 153, Loss: 0.0920177474617958\n",
            "Epoch 39, Step 154, Loss: 0.06129655987024307\n",
            "Epoch 39, Step 155, Loss: 0.03972932696342468\n",
            "Epoch 39, Step 156, Loss: 0.03252604231238365\n",
            "Epoch 39, Step 157, Loss: 0.0949205681681633\n",
            "Epoch 39, Step 158, Loss: 0.08851457387208939\n",
            "Epoch 39, Step 159, Loss: 0.06224486231803894\n",
            "Epoch 39, Step 160, Loss: 0.08350622653961182\n",
            "Epoch 39, Step 161, Loss: 0.09359728544950485\n",
            "Epoch 39, Step 162, Loss: 0.06536635756492615\n",
            "Epoch 39, Step 163, Loss: 0.07644988596439362\n",
            "Epoch 39, Step 164, Loss: 0.03757452964782715\n",
            "Epoch 39, Step 165, Loss: 0.0635281652212143\n",
            "Epoch 39, Step 166, Loss: 0.04361868277192116\n",
            "Epoch 39, Step 167, Loss: 0.03187372535467148\n",
            "Epoch 39, Step 168, Loss: 0.11597833782434464\n",
            "Epoch 39, Step 169, Loss: 0.018315907567739487\n",
            "Epoch 39, Step 170, Loss: 0.10447442531585693\n",
            "Epoch 39, Step 171, Loss: 0.026272060349583626\n",
            "Epoch 39, Step 172, Loss: 0.06910426914691925\n",
            "Epoch 39, Step 173, Loss: 0.03489534556865692\n",
            "Epoch 39, Step 174, Loss: 0.10003460198640823\n",
            "Epoch 39, Step 175, Loss: 0.034859880805015564\n",
            "Epoch 39, Step 176, Loss: 0.01911347731947899\n",
            "Epoch 39, Step 177, Loss: 0.062353361397981644\n",
            "Epoch 39, Step 178, Loss: 0.06879264861345291\n",
            "Epoch 39, Step 179, Loss: 0.044908881187438965\n",
            "Epoch 39, Step 180, Loss: 0.0718761533498764\n",
            "Epoch 39, Step 181, Loss: 0.07304240763187408\n",
            "Epoch 39, Step 182, Loss: 0.04788186773657799\n",
            "Epoch 39, Step 183, Loss: 0.0657850056886673\n",
            "Epoch 39, Step 184, Loss: 0.038567446172237396\n",
            "Epoch 39, Step 185, Loss: 0.1141451820731163\n",
            "Epoch 39, Step 186, Loss: 0.07909892499446869\n",
            "Epoch 39, Step 187, Loss: 0.11457119137048721\n",
            "Epoch 39, Step 188, Loss: 0.08341128379106522\n",
            "Epoch 39, Step 189, Loss: 0.04886477813124657\n",
            "Epoch 39, Step 190, Loss: 0.02267487160861492\n",
            "Epoch 39, Step 191, Loss: 0.049295421689748764\n",
            "Epoch 39, Step 192, Loss: 0.10915812849998474\n",
            "Epoch 39, Step 193, Loss: 0.017572326585650444\n",
            "Epoch 39, Step 194, Loss: 0.06766585260629654\n",
            "Epoch 39, Step 195, Loss: 0.14747948944568634\n",
            "Epoch 39, Step 196, Loss: 0.09614028036594391\n",
            "Epoch 39, Step 197, Loss: 0.028826171532273293\n",
            "Epoch 39, Step 198, Loss: 0.10530100017786026\n",
            "Epoch 39, Step 199, Loss: 0.04001704230904579\n",
            "Epoch 39, Step 200, Loss: 0.14634433388710022\n",
            "Epoch 39, Step 201, Loss: 0.0591157041490078\n",
            "Epoch 39, Step 202, Loss: 0.031799014657735825\n",
            "Epoch 39, Step 203, Loss: 0.06973912566900253\n",
            "Epoch 39, Step 204, Loss: 0.05857672542333603\n",
            "Epoch 39, Step 205, Loss: 0.05257367715239525\n",
            "Epoch 39, Step 206, Loss: 0.08986208587884903\n",
            "Epoch 39, Step 207, Loss: 0.038651611655950546\n",
            "Epoch 39, Step 208, Loss: 0.053863734006881714\n",
            "Epoch 39, Step 209, Loss: 0.0987778902053833\n",
            "Epoch 39, Step 210, Loss: 0.044987499713897705\n",
            "Epoch 39, Step 211, Loss: 0.09423648566007614\n",
            "Epoch 39, Step 212, Loss: 0.07104090601205826\n",
            "Epoch 39, Step 213, Loss: 0.1389472335577011\n",
            "Epoch 39, Step 214, Loss: 0.046552758663892746\n",
            "Epoch 39, Step 215, Loss: 0.04398597776889801\n",
            "Epoch 39, Step 216, Loss: 0.10843733698129654\n",
            "Epoch 39, Step 217, Loss: 0.0933404341340065\n",
            "Epoch 39, Step 218, Loss: 0.030085017904639244\n",
            "Epoch 39, Step 219, Loss: 0.07693644613027573\n",
            "Epoch 39, Step 220, Loss: 0.07033062726259232\n",
            "Epoch 39, Step 221, Loss: 0.08106077462434769\n",
            "Epoch 39, Step 222, Loss: 0.04474673420190811\n",
            "Epoch 39, Step 223, Loss: 0.07496198266744614\n",
            "Epoch 39, Step 224, Loss: 0.08646465837955475\n",
            "Epoch 39, Step 225, Loss: 0.0836344063282013\n",
            "Epoch 39, Step 226, Loss: 0.05056626349687576\n",
            "Epoch 39, Step 227, Loss: 0.15755434334278107\n",
            "Epoch 39, Step 228, Loss: 0.09674762189388275\n",
            "Epoch 39, Step 229, Loss: 0.06524278968572617\n",
            "Epoch 39, Step 230, Loss: 0.09012627601623535\n",
            "Epoch 39, Step 231, Loss: 0.1383698731660843\n",
            "Epoch 39, Step 232, Loss: 0.14850012958049774\n",
            "Epoch 39, Step 233, Loss: 0.042988020926713943\n",
            "Epoch 39, Step 234, Loss: 0.09128996729850769\n",
            "Epoch 39, Step 235, Loss: 0.10037682205438614\n",
            "Epoch 39, Step 236, Loss: 0.014521711505949497\n",
            "Epoch 39, Step 237, Loss: 0.05071912705898285\n",
            "Epoch 39, Step 238, Loss: 0.09241486340761185\n",
            "Epoch 39, Step 239, Loss: 0.0840691551566124\n",
            "Epoch 39, Step 240, Loss: 0.14196047186851501\n",
            "Epoch 39, Step 241, Loss: 0.08673829585313797\n",
            "Epoch 39, Step 242, Loss: 0.1276894509792328\n",
            "Epoch 39, Step 243, Loss: 0.07238370180130005\n",
            "Epoch 39, Step 244, Loss: 0.061959512531757355\n",
            "Epoch 39, Step 245, Loss: 0.11262696236371994\n",
            "Epoch 39, Step 246, Loss: 0.12150111794471741\n",
            "Epoch 39, Step 247, Loss: 0.021962035447359085\n",
            "Epoch 39, Step 248, Loss: 0.08107145130634308\n",
            "Epoch 39, Step 249, Loss: 0.05645069479942322\n",
            "Epoch 39, Step 250, Loss: 0.11080065369606018\n",
            "Epoch 39, Step 251, Loss: 0.04300938546657562\n",
            "Epoch 39, Step 252, Loss: 0.08868896961212158\n",
            "Epoch 39, Step 253, Loss: 0.03293602913618088\n",
            "Epoch 39, Step 254, Loss: 0.047551415860652924\n",
            "Epoch 39, Step 255, Loss: 0.06891800463199615\n",
            "Epoch 39, Step 256, Loss: 0.09762255102396011\n",
            "Epoch 39, Step 257, Loss: 0.09284001588821411\n",
            "Epoch 39, Step 258, Loss: 0.06270747631788254\n",
            "Epoch 39, Step 259, Loss: 0.03373159095644951\n",
            "Epoch 39, Step 260, Loss: 0.10380762070417404\n",
            "Epoch 39, Step 261, Loss: 0.037213824689388275\n",
            "Epoch 39, Step 262, Loss: 0.09760735929012299\n",
            "Epoch 39, Step 263, Loss: 0.03144967183470726\n",
            "Epoch 39, Step 264, Loss: 0.06785138696432114\n",
            "Epoch 39, Step 265, Loss: 0.08222036063671112\n",
            "Epoch 39, Step 266, Loss: 0.06483092904090881\n",
            "Epoch 39, Step 267, Loss: 0.0892505794763565\n",
            "Epoch 39, Step 268, Loss: 0.08641423285007477\n",
            "Epoch 39, Step 269, Loss: 0.08545848727226257\n",
            "Epoch 39, Step 270, Loss: 0.05535798519849777\n",
            "Epoch 39, Step 271, Loss: 0.0829131007194519\n",
            "Epoch 39, Step 272, Loss: 0.033881619572639465\n",
            "Epoch 39, Step 273, Loss: 0.02912413887679577\n",
            "Epoch 39, Step 274, Loss: 0.04354429990053177\n",
            "Epoch 39, Step 275, Loss: 0.10572642832994461\n",
            "Epoch 39, Step 276, Loss: 0.06540629267692566\n",
            "Epoch 39, Step 277, Loss: 0.07367261499166489\n",
            "Epoch 39, Step 278, Loss: 0.05016206577420235\n",
            "Epoch 39, Step 279, Loss: 0.09879515320062637\n",
            "Epoch 39, Step 280, Loss: 0.013512044213712215\n",
            "Epoch 39, Step 281, Loss: 0.04450741037726402\n",
            "Epoch 39, Step 282, Loss: 0.07135914266109467\n",
            "Epoch 39, Step 283, Loss: 0.065416119992733\n",
            "Epoch 39, Step 284, Loss: 0.04730360954999924\n",
            "Epoch 39, Step 285, Loss: 0.06374183297157288\n",
            "Epoch 39, Step 286, Loss: 0.02259496971964836\n",
            "Epoch 39, Step 287, Loss: 0.04372088983654976\n",
            "Epoch 39, Step 288, Loss: 0.03927057608962059\n",
            "Epoch 39, Step 289, Loss: 0.08186347037553787\n",
            "Epoch 39, Step 290, Loss: 0.04992680996656418\n",
            "Epoch 39, Step 291, Loss: 0.09073151648044586\n",
            "Epoch 39, Step 292, Loss: 0.02501150779426098\n",
            "Epoch 39, Step 293, Loss: 0.06510386615991592\n",
            "Epoch 39, Step 294, Loss: 0.05205463990569115\n",
            "Epoch 39, Step 295, Loss: 0.04526720941066742\n",
            "Epoch 39, Step 296, Loss: 0.07706420868635178\n",
            "Epoch 39, Step 297, Loss: 0.11079136282205582\n",
            "Epoch 39, Step 298, Loss: 0.049439478665590286\n",
            "Epoch 39, Step 299, Loss: 0.06574831902980804\n",
            "Epoch 39, Step 300, Loss: 0.03209425508975983\n",
            "Epoch 39, Step 301, Loss: 0.03350695222616196\n",
            "Epoch 39, Step 302, Loss: 0.03544028848409653\n",
            "Epoch 39, Step 303, Loss: 0.06406133621931076\n",
            "Epoch 39, Step 304, Loss: 0.033381618559360504\n",
            "Epoch 39, Step 305, Loss: 0.09025001525878906\n",
            "Epoch 39, Step 306, Loss: 0.0259208045899868\n",
            "Epoch 39, Step 307, Loss: 0.07492955774068832\n",
            "Epoch 39, Step 308, Loss: 0.0391228049993515\n",
            "Epoch 39, Step 309, Loss: 0.11055655032396317\n",
            "Epoch 39, Step 310, Loss: 0.16945040225982666\n",
            "Epoch 39, Step 311, Loss: 0.0403759740293026\n",
            "Epoch 39, Step 312, Loss: 0.17506583034992218\n",
            "Epoch 39 end, avg train loss: 0.06585675631813444\n",
            "Epoch 39 end, avg val loss: 0.3852222477899322, accuracy: 90.94%\n",
            "Epoch 40, Step 0, Loss: 0.13148954510688782\n",
            "Epoch 40, Step 1, Loss: 0.10910699516534805\n",
            "Epoch 40, Step 2, Loss: 0.03097514435648918\n",
            "Epoch 40, Step 3, Loss: 0.04538518935441971\n",
            "Epoch 40, Step 4, Loss: 0.10672064125537872\n",
            "Epoch 40, Step 5, Loss: 0.09257402271032333\n",
            "Epoch 40, Step 6, Loss: 0.0762505903840065\n",
            "Epoch 40, Step 7, Loss: 0.033827297389507294\n",
            "Epoch 40, Step 8, Loss: 0.023902175948023796\n",
            "Epoch 40, Step 9, Loss: 0.13404302299022675\n",
            "Epoch 40, Step 10, Loss: 0.030673181638121605\n",
            "Epoch 40, Step 11, Loss: 0.060408324003219604\n",
            "Epoch 40, Step 12, Loss: 0.054045774042606354\n",
            "Epoch 40, Step 13, Loss: 0.01883065700531006\n",
            "Epoch 40, Step 14, Loss: 0.051517926156520844\n",
            "Epoch 40, Step 15, Loss: 0.056687548756599426\n",
            "Epoch 40, Step 16, Loss: 0.0452505424618721\n",
            "Epoch 40, Step 17, Loss: 0.07065782696008682\n",
            "Epoch 40, Step 18, Loss: 0.11678370833396912\n",
            "Epoch 40, Step 19, Loss: 0.06614083051681519\n",
            "Epoch 40, Step 20, Loss: 0.06245630234479904\n",
            "Epoch 40, Step 21, Loss: 0.016271796077489853\n",
            "Epoch 40, Step 22, Loss: 0.05760910362005234\n",
            "Epoch 40, Step 23, Loss: 0.05273627117276192\n",
            "Epoch 40, Step 24, Loss: 0.07649177312850952\n",
            "Epoch 40, Step 25, Loss: 0.055175866931676865\n",
            "Epoch 40, Step 26, Loss: 0.045453473925590515\n",
            "Epoch 40, Step 27, Loss: 0.020238608121871948\n",
            "Epoch 40, Step 28, Loss: 0.02228553593158722\n",
            "Epoch 40, Step 29, Loss: 0.0772939920425415\n",
            "Epoch 40, Step 30, Loss: 0.06759017705917358\n",
            "Epoch 40, Step 31, Loss: 0.09526877105236053\n",
            "Epoch 40, Step 32, Loss: 0.025622831657528877\n",
            "Epoch 40, Step 33, Loss: 0.05519796535372734\n",
            "Epoch 40, Step 34, Loss: 0.055144548416137695\n",
            "Epoch 40, Step 35, Loss: 0.09246746450662613\n",
            "Epoch 40, Step 36, Loss: 0.032382719218730927\n",
            "Epoch 40, Step 37, Loss: 0.057112161070108414\n",
            "Epoch 40, Step 38, Loss: 0.06824344396591187\n",
            "Epoch 40, Step 39, Loss: 0.09668164700269699\n",
            "Epoch 40, Step 40, Loss: 0.10233847051858902\n",
            "Epoch 40, Step 41, Loss: 0.06631115078926086\n",
            "Epoch 40, Step 42, Loss: 0.04752415046095848\n",
            "Epoch 40, Step 43, Loss: 0.07902693748474121\n",
            "Epoch 40, Step 44, Loss: 0.03694150596857071\n",
            "Epoch 40, Step 45, Loss: 0.029236754402518272\n",
            "Epoch 40, Step 46, Loss: 0.033246319741010666\n",
            "Epoch 40, Step 47, Loss: 0.04607785493135452\n",
            "Epoch 40, Step 48, Loss: 0.037560462951660156\n",
            "Epoch 40, Step 49, Loss: 0.07290859520435333\n",
            "Epoch 40, Step 50, Loss: 0.05980750545859337\n",
            "Epoch 40, Step 51, Loss: 0.09140226244926453\n",
            "Epoch 40, Step 52, Loss: 0.01612662337720394\n",
            "Epoch 40, Step 53, Loss: 0.09609097242355347\n",
            "Epoch 40, Step 54, Loss: 0.14450252056121826\n",
            "Epoch 40, Step 55, Loss: 0.0292460136115551\n",
            "Epoch 40, Step 56, Loss: 0.056539472192525864\n",
            "Epoch 40, Step 57, Loss: 0.026452140882611275\n",
            "Epoch 40, Step 58, Loss: 0.06098805367946625\n",
            "Epoch 40, Step 59, Loss: 0.1496056616306305\n",
            "Epoch 40, Step 60, Loss: 0.08703098446130753\n",
            "Epoch 40, Step 61, Loss: 0.04070684686303139\n",
            "Epoch 40, Step 62, Loss: 0.05858157202601433\n",
            "Epoch 40, Step 63, Loss: 0.05860793590545654\n",
            "Epoch 40, Step 64, Loss: 0.04304250702261925\n",
            "Epoch 40, Step 65, Loss: 0.02780453860759735\n",
            "Epoch 40, Step 66, Loss: 0.15012440085411072\n",
            "Epoch 40, Step 67, Loss: 0.0814744308590889\n",
            "Epoch 40, Step 68, Loss: 0.07584681361913681\n",
            "Epoch 40, Step 69, Loss: 0.048352669924497604\n",
            "Epoch 40, Step 70, Loss: 0.020116491243243217\n",
            "Epoch 40, Step 71, Loss: 0.04938347265124321\n",
            "Epoch 40, Step 72, Loss: 0.045336272567510605\n",
            "Epoch 40, Step 73, Loss: 0.09828906506299973\n",
            "Epoch 40, Step 74, Loss: 0.04503191262483597\n",
            "Epoch 40, Step 75, Loss: 0.024544769898056984\n",
            "Epoch 40, Step 76, Loss: 0.04035142809152603\n",
            "Epoch 40, Step 77, Loss: 0.18355010449886322\n",
            "Epoch 40, Step 78, Loss: 0.06758258491754532\n",
            "Epoch 40, Step 79, Loss: 0.05581087991595268\n",
            "Epoch 40, Step 80, Loss: 0.04389320686459541\n",
            "Epoch 40, Step 81, Loss: 0.024921929463744164\n",
            "Epoch 40, Step 82, Loss: 0.01235539373010397\n",
            "Epoch 40, Step 83, Loss: 0.04842739179730415\n",
            "Epoch 40, Step 84, Loss: 0.05579390376806259\n",
            "Epoch 40, Step 85, Loss: 0.07332228124141693\n",
            "Epoch 40, Step 86, Loss: 0.058694686740636826\n",
            "Epoch 40, Step 87, Loss: 0.014324458315968513\n",
            "Epoch 40, Step 88, Loss: 0.060053568333387375\n",
            "Epoch 40, Step 89, Loss: 0.05921764299273491\n",
            "Epoch 40, Step 90, Loss: 0.022292444482445717\n",
            "Epoch 40, Step 91, Loss: 0.06571871042251587\n",
            "Epoch 40, Step 92, Loss: 0.02825789526104927\n",
            "Epoch 40, Step 93, Loss: 0.06495744735002518\n",
            "Epoch 40, Step 94, Loss: 0.052019622176885605\n",
            "Epoch 40, Step 95, Loss: 0.05943383276462555\n",
            "Epoch 40, Step 96, Loss: 0.11446010321378708\n",
            "Epoch 40, Step 97, Loss: 0.11405494064092636\n",
            "Epoch 40, Step 98, Loss: 0.040947649627923965\n",
            "Epoch 40, Step 99, Loss: 0.032857347279787064\n",
            "Epoch 40, Step 100, Loss: 0.10699987411499023\n",
            "Epoch 40, Step 101, Loss: 0.01943492330610752\n",
            "Epoch 40, Step 102, Loss: 0.09845730662345886\n",
            "Epoch 40, Step 103, Loss: 0.053540900349617004\n",
            "Epoch 40, Step 104, Loss: 0.04689003527164459\n",
            "Epoch 40, Step 105, Loss: 0.07665367424488068\n",
            "Epoch 40, Step 106, Loss: 0.0338825061917305\n",
            "Epoch 40, Step 107, Loss: 0.019175343215465546\n",
            "Epoch 40, Step 108, Loss: 0.05054488778114319\n",
            "Epoch 40, Step 109, Loss: 0.09170282632112503\n",
            "Epoch 40, Step 110, Loss: 0.035728421062231064\n",
            "Epoch 40, Step 111, Loss: 0.05156716704368591\n",
            "Epoch 40, Step 112, Loss: 0.10285791009664536\n",
            "Epoch 40, Step 113, Loss: 0.02147531509399414\n",
            "Epoch 40, Step 114, Loss: 0.08040966093540192\n",
            "Epoch 40, Step 115, Loss: 0.08754919469356537\n",
            "Epoch 40, Step 116, Loss: 0.019020020961761475\n",
            "Epoch 40, Step 117, Loss: 0.10768527537584305\n",
            "Epoch 40, Step 118, Loss: 0.11456683278083801\n",
            "Epoch 40, Step 119, Loss: 0.04028734192252159\n",
            "Epoch 40, Step 120, Loss: 0.05240385979413986\n",
            "Epoch 40, Step 121, Loss: 0.06504997611045837\n",
            "Epoch 40, Step 122, Loss: 0.06594039499759674\n",
            "Epoch 40, Step 123, Loss: 0.06536366790533066\n",
            "Epoch 40, Step 124, Loss: 0.06735321134328842\n",
            "Epoch 40, Step 125, Loss: 0.0714045986533165\n",
            "Epoch 40, Step 126, Loss: 0.0665280669927597\n",
            "Epoch 40, Step 127, Loss: 0.061964429914951324\n",
            "Epoch 40, Step 128, Loss: 0.10418674349784851\n",
            "Epoch 40, Step 129, Loss: 0.10323470830917358\n",
            "Epoch 40, Step 130, Loss: 0.02181200124323368\n",
            "Epoch 40, Step 131, Loss: 0.05490441992878914\n",
            "Epoch 40, Step 132, Loss: 0.12614011764526367\n",
            "Epoch 40, Step 133, Loss: 0.04267601668834686\n",
            "Epoch 40, Step 134, Loss: 0.054380711168050766\n",
            "Epoch 40, Step 135, Loss: 0.09960398823022842\n",
            "Epoch 40, Step 136, Loss: 0.1458224058151245\n",
            "Epoch 40, Step 137, Loss: 0.08016032725572586\n",
            "Epoch 40, Step 138, Loss: 0.04786979407072067\n",
            "Epoch 40, Step 139, Loss: 0.05570777505636215\n",
            "Epoch 40, Step 140, Loss: 0.03083440288901329\n",
            "Epoch 40, Step 141, Loss: 0.060130491852760315\n",
            "Epoch 40, Step 142, Loss: 0.04684442654252052\n",
            "Epoch 40, Step 143, Loss: 0.026021184399724007\n",
            "Epoch 40, Step 144, Loss: 0.10727295279502869\n",
            "Epoch 40, Step 145, Loss: 0.07427657395601273\n",
            "Epoch 40, Step 146, Loss: 0.01865037903189659\n",
            "Epoch 40, Step 147, Loss: 0.06333240121603012\n",
            "Epoch 40, Step 148, Loss: 0.04615893214941025\n",
            "Epoch 40, Step 149, Loss: 0.022010503336787224\n",
            "Epoch 40, Step 150, Loss: 0.027880597859621048\n",
            "Epoch 40, Step 151, Loss: 0.04105958342552185\n",
            "Epoch 40, Step 152, Loss: 0.06414596736431122\n",
            "Epoch 40, Step 153, Loss: 0.07506959140300751\n",
            "Epoch 40, Step 154, Loss: 0.04596519470214844\n",
            "Epoch 40, Step 155, Loss: 0.03886086493730545\n",
            "Epoch 40, Step 156, Loss: 0.11583230644464493\n",
            "Epoch 40, Step 157, Loss: 0.18959057331085205\n",
            "Epoch 40, Step 158, Loss: 0.07524004578590393\n",
            "Epoch 40, Step 159, Loss: 0.04005616158246994\n",
            "Epoch 40, Step 160, Loss: 0.09460978209972382\n",
            "Epoch 40, Step 161, Loss: 0.07097990065813065\n",
            "Epoch 40, Step 162, Loss: 0.03105982579290867\n",
            "Epoch 40, Step 163, Loss: 0.05710092559456825\n",
            "Epoch 40, Step 164, Loss: 0.09055172652006149\n",
            "Epoch 40, Step 165, Loss: 0.049272939562797546\n",
            "Epoch 40, Step 166, Loss: 0.04631919413805008\n",
            "Epoch 40, Step 167, Loss: 0.13759393990039825\n",
            "Epoch 40, Step 168, Loss: 0.046220120042562485\n",
            "Epoch 40, Step 169, Loss: 0.08704793453216553\n",
            "Epoch 40, Step 170, Loss: 0.09196369349956512\n",
            "Epoch 40, Step 171, Loss: 0.09288575500249863\n",
            "Epoch 40, Step 172, Loss: 0.05150372534990311\n",
            "Epoch 40, Step 173, Loss: 0.05812740698456764\n",
            "Epoch 40, Step 174, Loss: 0.08231966942548752\n",
            "Epoch 40, Step 175, Loss: 0.02688949927687645\n",
            "Epoch 40, Step 176, Loss: 0.10404538363218307\n",
            "Epoch 40, Step 177, Loss: 0.08548817038536072\n",
            "Epoch 40, Step 178, Loss: 0.07805539667606354\n",
            "Epoch 40, Step 179, Loss: 0.11548778414726257\n",
            "Epoch 40, Step 180, Loss: 0.030402572825551033\n",
            "Epoch 40, Step 181, Loss: 0.05860098451375961\n",
            "Epoch 40, Step 182, Loss: 0.04159523546695709\n",
            "Epoch 40, Step 183, Loss: 0.10398992151021957\n",
            "Epoch 40, Step 184, Loss: 0.13044069707393646\n",
            "Epoch 40, Step 185, Loss: 0.07716070115566254\n",
            "Epoch 40, Step 186, Loss: 0.07971645891666412\n",
            "Epoch 40, Step 187, Loss: 0.026812544092535973\n",
            "Epoch 40, Step 188, Loss: 0.1102372407913208\n",
            "Epoch 40, Step 189, Loss: 0.10435356944799423\n",
            "Epoch 40, Step 190, Loss: 0.11640967428684235\n",
            "Epoch 40, Step 191, Loss: 0.02763805352151394\n",
            "Epoch 40, Step 192, Loss: 0.10808814316987991\n",
            "Epoch 40, Step 193, Loss: 0.0661679208278656\n",
            "Epoch 40, Step 194, Loss: 0.07705795019865036\n",
            "Epoch 40, Step 195, Loss: 0.015148053877055645\n",
            "Epoch 40, Step 196, Loss: 0.06740830093622208\n",
            "Epoch 40, Step 197, Loss: 0.08106935769319534\n",
            "Epoch 40, Step 198, Loss: 0.1439969539642334\n",
            "Epoch 40, Step 199, Loss: 0.07789446413516998\n",
            "Epoch 40, Step 200, Loss: 0.09083373844623566\n",
            "Epoch 40, Step 201, Loss: 0.042270075529813766\n",
            "Epoch 40, Step 202, Loss: 0.09486233443021774\n",
            "Epoch 40, Step 203, Loss: 0.017239496111869812\n",
            "Epoch 40, Step 204, Loss: 0.09287870675325394\n",
            "Epoch 40, Step 205, Loss: 0.06139518693089485\n",
            "Epoch 40, Step 206, Loss: 0.08301964402198792\n",
            "Epoch 40, Step 207, Loss: 0.07506969571113586\n",
            "Epoch 40, Step 208, Loss: 0.09590587019920349\n",
            "Epoch 40, Step 209, Loss: 0.09426242113113403\n",
            "Epoch 40, Step 210, Loss: 0.07416320592164993\n",
            "Epoch 40, Step 211, Loss: 0.06592223048210144\n",
            "Epoch 40, Step 212, Loss: 0.09938327968120575\n",
            "Epoch 40, Step 213, Loss: 0.10281085222959518\n",
            "Epoch 40, Step 214, Loss: 0.1607668548822403\n",
            "Epoch 40, Step 215, Loss: 0.08167152851819992\n",
            "Epoch 40, Step 216, Loss: 0.08058173209428787\n",
            "Epoch 40, Step 217, Loss: 0.0967784896492958\n",
            "Epoch 40, Step 218, Loss: 0.11287815123796463\n",
            "Epoch 40, Step 219, Loss: 0.2109512835741043\n",
            "Epoch 40, Step 220, Loss: 0.03703847900032997\n",
            "Epoch 40, Step 221, Loss: 0.08126720786094666\n",
            "Epoch 40, Step 222, Loss: 0.08965181559324265\n",
            "Epoch 40, Step 223, Loss: 0.1413891613483429\n",
            "Epoch 40, Step 224, Loss: 0.1103486493229866\n",
            "Epoch 40, Step 225, Loss: 0.02118360623717308\n",
            "Epoch 40, Step 226, Loss: 0.12273789197206497\n",
            "Epoch 40, Step 227, Loss: 0.14197856187820435\n",
            "Epoch 40, Step 228, Loss: 0.03927392512559891\n",
            "Epoch 40, Step 229, Loss: 0.058670736849308014\n",
            "Epoch 40, Step 230, Loss: 0.07781152427196503\n",
            "Epoch 40, Step 231, Loss: 0.08870957046747208\n",
            "Epoch 40, Step 232, Loss: 0.03719111904501915\n",
            "Epoch 40, Step 233, Loss: 0.04271504655480385\n",
            "Epoch 40, Step 234, Loss: 0.10948194563388824\n",
            "Epoch 40, Step 235, Loss: 0.07025318592786789\n",
            "Epoch 40, Step 236, Loss: 0.042883459478616714\n",
            "Epoch 40, Step 237, Loss: 0.07338141649961472\n",
            "Epoch 40, Step 238, Loss: 0.06498473137617111\n",
            "Epoch 40, Step 239, Loss: 0.04762420058250427\n",
            "Epoch 40, Step 240, Loss: 0.0387943871319294\n",
            "Epoch 40, Step 241, Loss: 0.03821035102009773\n",
            "Epoch 40, Step 242, Loss: 0.11555347591638565\n",
            "Epoch 40, Step 243, Loss: 0.09416741132736206\n",
            "Epoch 40, Step 244, Loss: 0.044470060616731644\n",
            "Epoch 40, Step 245, Loss: 0.08122831583023071\n",
            "Epoch 40, Step 246, Loss: 0.0509878471493721\n",
            "Epoch 40, Step 247, Loss: 0.03330497443675995\n",
            "Epoch 40, Step 248, Loss: 0.07095286250114441\n",
            "Epoch 40, Step 249, Loss: 0.008185225538909435\n",
            "Epoch 40, Step 250, Loss: 0.09979915618896484\n",
            "Epoch 40, Step 251, Loss: 0.08034823089838028\n",
            "Epoch 40, Step 252, Loss: 0.11791586130857468\n",
            "Epoch 40, Step 253, Loss: 0.07208725064992905\n",
            "Epoch 40, Step 254, Loss: 0.0976228192448616\n",
            "Epoch 40, Step 255, Loss: 0.08863844722509384\n",
            "Epoch 40, Step 256, Loss: 0.09608718007802963\n",
            "Epoch 40, Step 257, Loss: 0.0789441168308258\n",
            "Epoch 40, Step 258, Loss: 0.05361942574381828\n",
            "Epoch 40, Step 259, Loss: 0.02880624122917652\n",
            "Epoch 40, Step 260, Loss: 0.04137346148490906\n",
            "Epoch 40, Step 261, Loss: 0.05722840502858162\n",
            "Epoch 40, Step 262, Loss: 0.06157834827899933\n",
            "Epoch 40, Step 263, Loss: 0.04745006561279297\n",
            "Epoch 40, Step 264, Loss: 0.07397760450839996\n",
            "Epoch 40, Step 265, Loss: 0.0973137691617012\n",
            "Epoch 40, Step 266, Loss: 0.038192491978406906\n",
            "Epoch 40, Step 267, Loss: 0.11623635143041611\n",
            "Epoch 40, Step 268, Loss: 0.03208313509821892\n",
            "Epoch 40, Step 269, Loss: 0.0771312490105629\n",
            "Epoch 40, Step 270, Loss: 0.08494545519351959\n",
            "Epoch 40, Step 271, Loss: 0.10832200199365616\n",
            "Epoch 40, Step 272, Loss: 0.055984072387218475\n",
            "Epoch 40, Step 273, Loss: 0.060996174812316895\n",
            "Epoch 40, Step 274, Loss: 0.034819845110177994\n",
            "Epoch 40, Step 275, Loss: 0.05513368174433708\n",
            "Epoch 40, Step 276, Loss: 0.0878215953707695\n",
            "Epoch 40, Step 277, Loss: 0.04989439249038696\n",
            "Epoch 40, Step 278, Loss: 0.030479488894343376\n",
            "Epoch 40, Step 279, Loss: 0.097662054002285\n",
            "Epoch 40, Step 280, Loss: 0.03703129291534424\n",
            "Epoch 40, Step 281, Loss: 0.13444632291793823\n",
            "Epoch 40, Step 282, Loss: 0.08066800981760025\n",
            "Epoch 40, Step 283, Loss: 0.03808605670928955\n",
            "Epoch 40, Step 284, Loss: 0.08248259872198105\n",
            "Epoch 40, Step 285, Loss: 0.04115436598658562\n",
            "Epoch 40, Step 286, Loss: 0.0931583046913147\n",
            "Epoch 40, Step 287, Loss: 0.07372338324785233\n",
            "Epoch 40, Step 288, Loss: 0.03516967594623566\n",
            "Epoch 40, Step 289, Loss: 0.028517508879303932\n",
            "Epoch 40, Step 290, Loss: 0.05971626564860344\n",
            "Epoch 40, Step 291, Loss: 0.045243341475725174\n",
            "Epoch 40, Step 292, Loss: 0.01508676540106535\n",
            "Epoch 40, Step 293, Loss: 0.04266816005110741\n",
            "Epoch 40, Step 294, Loss: 0.05411115288734436\n",
            "Epoch 40, Step 295, Loss: 0.05018913000822067\n",
            "Epoch 40, Step 296, Loss: 0.14295858144760132\n",
            "Epoch 40, Step 297, Loss: 0.0727984607219696\n",
            "Epoch 40, Step 298, Loss: 0.09200609475374222\n",
            "Epoch 40, Step 299, Loss: 0.07697124034166336\n",
            "Epoch 40, Step 300, Loss: 0.11792243272066116\n",
            "Epoch 40, Step 301, Loss: 0.05701756104826927\n",
            "Epoch 40, Step 302, Loss: 0.05963098630309105\n",
            "Epoch 40, Step 303, Loss: 0.057583510875701904\n",
            "Epoch 40, Step 304, Loss: 0.029839355498552322\n",
            "Epoch 40, Step 305, Loss: 0.06577194482088089\n",
            "Epoch 40, Step 306, Loss: 0.06741981953382492\n",
            "Epoch 40, Step 307, Loss: 0.055260684341192245\n",
            "Epoch 40, Step 308, Loss: 0.06812167912721634\n",
            "Epoch 40, Step 309, Loss: 0.037868011742830276\n",
            "Epoch 40, Step 310, Loss: 0.031637780368328094\n",
            "Epoch 40, Step 311, Loss: 0.10169834643602371\n",
            "Epoch 40, Step 312, Loss: 0.05702532082796097\n",
            "Epoch 40 end, avg train loss: 0.0677697659609988\n",
            "Epoch 40 end, avg val loss: 0.3740639854458314, accuracy: 91.36%\n",
            "Epoch 41, Step 0, Loss: 0.0207136869430542\n",
            "Epoch 41, Step 1, Loss: 0.09823782742023468\n",
            "Epoch 41, Step 2, Loss: 0.07319877296686172\n",
            "Epoch 41, Step 3, Loss: 0.05549474433064461\n",
            "Epoch 41, Step 4, Loss: 0.027408845722675323\n",
            "Epoch 41, Step 5, Loss: 0.053789664059877396\n",
            "Epoch 41, Step 6, Loss: 0.0782269835472107\n",
            "Epoch 41, Step 7, Loss: 0.05190156772732735\n",
            "Epoch 41, Step 8, Loss: 0.035242460668087006\n",
            "Epoch 41, Step 9, Loss: 0.06486797332763672\n",
            "Epoch 41, Step 10, Loss: 0.021686721593141556\n",
            "Epoch 41, Step 11, Loss: 0.025548111647367477\n",
            "Epoch 41, Step 12, Loss: 0.0401286818087101\n",
            "Epoch 41, Step 13, Loss: 0.02630562148988247\n",
            "Epoch 41, Step 14, Loss: 0.03490551933646202\n",
            "Epoch 41, Step 15, Loss: 0.04109002649784088\n",
            "Epoch 41, Step 16, Loss: 0.04068075865507126\n",
            "Epoch 41, Step 17, Loss: 0.04178033396601677\n",
            "Epoch 41, Step 18, Loss: 0.1090535819530487\n",
            "Epoch 41, Step 19, Loss: 0.08076267689466476\n",
            "Epoch 41, Step 20, Loss: 0.036861732602119446\n",
            "Epoch 41, Step 21, Loss: 0.09670205414295197\n",
            "Epoch 41, Step 22, Loss: 0.0700681060552597\n",
            "Epoch 41, Step 23, Loss: 0.0328129343688488\n",
            "Epoch 41, Step 24, Loss: 0.04166929051280022\n",
            "Epoch 41, Step 25, Loss: 0.04226354882121086\n",
            "Epoch 41, Step 26, Loss: 0.13219000399112701\n",
            "Epoch 41, Step 27, Loss: 0.03395311161875725\n",
            "Epoch 41, Step 28, Loss: 0.018672123551368713\n",
            "Epoch 41, Step 29, Loss: 0.03396444395184517\n",
            "Epoch 41, Step 30, Loss: 0.07245582342147827\n",
            "Epoch 41, Step 31, Loss: 0.08551903814077377\n",
            "Epoch 41, Step 32, Loss: 0.1724509596824646\n",
            "Epoch 41, Step 33, Loss: 0.11377869546413422\n",
            "Epoch 41, Step 34, Loss: 0.04114067927002907\n",
            "Epoch 41, Step 35, Loss: 0.07520952075719833\n",
            "Epoch 41, Step 36, Loss: 0.09592070430517197\n",
            "Epoch 41, Step 37, Loss: 0.05938632786273956\n",
            "Epoch 41, Step 38, Loss: 0.1196613609790802\n",
            "Epoch 41, Step 39, Loss: 0.09332612156867981\n",
            "Epoch 41, Step 40, Loss: 0.03519182279706001\n",
            "Epoch 41, Step 41, Loss: 0.07312237471342087\n",
            "Epoch 41, Step 42, Loss: 0.025640886276960373\n",
            "Epoch 41, Step 43, Loss: 0.013669600710272789\n",
            "Epoch 41, Step 44, Loss: 0.07582902163267136\n",
            "Epoch 41, Step 45, Loss: 0.10101111978292465\n",
            "Epoch 41, Step 46, Loss: 0.12134295701980591\n",
            "Epoch 41, Step 47, Loss: 0.02533314935863018\n",
            "Epoch 41, Step 48, Loss: 0.04556472599506378\n",
            "Epoch 41, Step 49, Loss: 0.08533882349729538\n",
            "Epoch 41, Step 50, Loss: 0.06832139939069748\n",
            "Epoch 41, Step 51, Loss: 0.06268364191055298\n",
            "Epoch 41, Step 52, Loss: 0.13033118844032288\n",
            "Epoch 41, Step 53, Loss: 0.14144963026046753\n",
            "Epoch 41, Step 54, Loss: 0.06717856973409653\n",
            "Epoch 41, Step 55, Loss: 0.05631714314222336\n",
            "Epoch 41, Step 56, Loss: 0.07873965054750443\n",
            "Epoch 41, Step 57, Loss: 0.07260400801897049\n",
            "Epoch 41, Step 58, Loss: 0.08487994968891144\n",
            "Epoch 41, Step 59, Loss: 0.04480597749352455\n",
            "Epoch 41, Step 60, Loss: 0.06373582780361176\n",
            "Epoch 41, Step 61, Loss: 0.022905750200152397\n",
            "Epoch 41, Step 62, Loss: 0.04340159893035889\n",
            "Epoch 41, Step 63, Loss: 0.059190601110458374\n",
            "Epoch 41, Step 64, Loss: 0.06941674649715424\n",
            "Epoch 41, Step 65, Loss: 0.11663525551557541\n",
            "Epoch 41, Step 66, Loss: 0.10531943291425705\n",
            "Epoch 41, Step 67, Loss: 0.04685576260089874\n",
            "Epoch 41, Step 68, Loss: 0.07951578497886658\n",
            "Epoch 41, Step 69, Loss: 0.07827465236186981\n",
            "Epoch 41, Step 70, Loss: 0.047528866678476334\n",
            "Epoch 41, Step 71, Loss: 0.026472672820091248\n",
            "Epoch 41, Step 72, Loss: 0.03428204730153084\n",
            "Epoch 41, Step 73, Loss: 0.06461992114782333\n",
            "Epoch 41, Step 74, Loss: 0.016455767676234245\n",
            "Epoch 41, Step 75, Loss: 0.13816006481647491\n",
            "Epoch 41, Step 76, Loss: 0.07306785881519318\n",
            "Epoch 41, Step 77, Loss: 0.030118292197585106\n",
            "Epoch 41, Step 78, Loss: 0.05461417883634567\n",
            "Epoch 41, Step 79, Loss: 0.056558459997177124\n",
            "Epoch 41, Step 80, Loss: 0.15202096104621887\n",
            "Epoch 41, Step 81, Loss: 0.03450696915388107\n",
            "Epoch 41, Step 82, Loss: 0.054796237498521805\n",
            "Epoch 41, Step 83, Loss: 0.0620403066277504\n",
            "Epoch 41, Step 84, Loss: 0.08392968028783798\n",
            "Epoch 41, Step 85, Loss: 0.02916194684803486\n",
            "Epoch 41, Step 86, Loss: 0.034033823758363724\n",
            "Epoch 41, Step 87, Loss: 0.11893821507692337\n",
            "Epoch 41, Step 88, Loss: 0.17055918276309967\n",
            "Epoch 41, Step 89, Loss: 0.03568189591169357\n",
            "Epoch 41, Step 90, Loss: 0.09568037837743759\n",
            "Epoch 41, Step 91, Loss: 0.03810380399227142\n",
            "Epoch 41, Step 92, Loss: 0.09992676973342896\n",
            "Epoch 41, Step 93, Loss: 0.025215929374098778\n",
            "Epoch 41, Step 94, Loss: 0.025311917066574097\n",
            "Epoch 41, Step 95, Loss: 0.040674008429050446\n",
            "Epoch 41, Step 96, Loss: 0.06503311544656754\n",
            "Epoch 41, Step 97, Loss: 0.046264972537755966\n",
            "Epoch 41, Step 98, Loss: 0.09570640325546265\n",
            "Epoch 41, Step 99, Loss: 0.0812126100063324\n",
            "Epoch 41, Step 100, Loss: 0.11888096481561661\n",
            "Epoch 41, Step 101, Loss: 0.07271885871887207\n",
            "Epoch 41, Step 102, Loss: 0.04706568270921707\n",
            "Epoch 41, Step 103, Loss: 0.022220365703105927\n",
            "Epoch 41, Step 104, Loss: 0.04320702701807022\n",
            "Epoch 41, Step 105, Loss: 0.09924569725990295\n",
            "Epoch 41, Step 106, Loss: 0.027185482904314995\n",
            "Epoch 41, Step 107, Loss: 0.0532337948679924\n",
            "Epoch 41, Step 108, Loss: 0.04083758220076561\n",
            "Epoch 41, Step 109, Loss: 0.05891537666320801\n",
            "Epoch 41, Step 110, Loss: 0.03087383322417736\n",
            "Epoch 41, Step 111, Loss: 0.03145868703722954\n",
            "Epoch 41, Step 112, Loss: 0.029663868248462677\n",
            "Epoch 41, Step 113, Loss: 0.0340275876224041\n",
            "Epoch 41, Step 114, Loss: 0.03159653767943382\n",
            "Epoch 41, Step 115, Loss: 0.056642334908246994\n",
            "Epoch 41, Step 116, Loss: 0.07108332961797714\n",
            "Epoch 41, Step 117, Loss: 0.05260370671749115\n",
            "Epoch 41, Step 118, Loss: 0.07009218633174896\n",
            "Epoch 41, Step 119, Loss: 0.10459645837545395\n",
            "Epoch 41, Step 120, Loss: 0.0629463791847229\n",
            "Epoch 41, Step 121, Loss: 0.18369781970977783\n",
            "Epoch 41, Step 122, Loss: 0.011597897857427597\n",
            "Epoch 41, Step 123, Loss: 0.04129922762513161\n",
            "Epoch 41, Step 124, Loss: 0.09110108762979507\n",
            "Epoch 41, Step 125, Loss: 0.029087305068969727\n",
            "Epoch 41, Step 126, Loss: 0.0316077284514904\n",
            "Epoch 41, Step 127, Loss: 0.14515145123004913\n",
            "Epoch 41, Step 128, Loss: 0.039199572056531906\n",
            "Epoch 41, Step 129, Loss: 0.12504328787326813\n",
            "Epoch 41, Step 130, Loss: 0.05749604105949402\n",
            "Epoch 41, Step 131, Loss: 0.05166437476873398\n",
            "Epoch 41, Step 132, Loss: 0.13632847368717194\n",
            "Epoch 41, Step 133, Loss: 0.05606721341609955\n",
            "Epoch 41, Step 134, Loss: 0.07199335843324661\n",
            "Epoch 41, Step 135, Loss: 0.04934502765536308\n",
            "Epoch 41, Step 136, Loss: 0.06484424322843552\n",
            "Epoch 41, Step 137, Loss: 0.01566462591290474\n",
            "Epoch 41, Step 138, Loss: 0.04277542978525162\n",
            "Epoch 41, Step 139, Loss: 0.0825476199388504\n",
            "Epoch 41, Step 140, Loss: 0.02933099865913391\n",
            "Epoch 41, Step 141, Loss: 0.08179200440645218\n",
            "Epoch 41, Step 142, Loss: 0.06149711087346077\n",
            "Epoch 41, Step 143, Loss: 0.04257446527481079\n",
            "Epoch 41, Step 144, Loss: 0.03622058033943176\n",
            "Epoch 41, Step 145, Loss: 0.026646852493286133\n",
            "Epoch 41, Step 146, Loss: 0.07317999005317688\n",
            "Epoch 41, Step 147, Loss: 0.09665419161319733\n",
            "Epoch 41, Step 148, Loss: 0.10267674177885056\n",
            "Epoch 41, Step 149, Loss: 0.033613547682762146\n",
            "Epoch 41, Step 150, Loss: 0.07432903349399567\n",
            "Epoch 41, Step 151, Loss: 0.025788340717554092\n",
            "Epoch 41, Step 152, Loss: 0.08191686868667603\n",
            "Epoch 41, Step 153, Loss: 0.03549026697874069\n",
            "Epoch 41, Step 154, Loss: 0.13499146699905396\n",
            "Epoch 41, Step 155, Loss: 0.04690179601311684\n",
            "Epoch 41, Step 156, Loss: 0.09274819493293762\n",
            "Epoch 41, Step 157, Loss: 0.07191858440637589\n",
            "Epoch 41, Step 158, Loss: 0.043385159224271774\n",
            "Epoch 41, Step 159, Loss: 0.056086041033267975\n",
            "Epoch 41, Step 160, Loss: 0.014551782049238682\n",
            "Epoch 41, Step 161, Loss: 0.07420623302459717\n",
            "Epoch 41, Step 162, Loss: 0.047949112951755524\n",
            "Epoch 41, Step 163, Loss: 0.011883115395903587\n",
            "Epoch 41, Step 164, Loss: 0.03779127448797226\n",
            "Epoch 41, Step 165, Loss: 0.05104459449648857\n",
            "Epoch 41, Step 166, Loss: 0.0686294212937355\n",
            "Epoch 41, Step 167, Loss: 0.0470629446208477\n",
            "Epoch 41, Step 168, Loss: 0.03900955617427826\n",
            "Epoch 41, Step 169, Loss: 0.05833839997649193\n",
            "Epoch 41, Step 170, Loss: 0.05049758031964302\n",
            "Epoch 41, Step 171, Loss: 0.07416241616010666\n",
            "Epoch 41, Step 172, Loss: 0.08023481070995331\n",
            "Epoch 41, Step 173, Loss: 0.04700157791376114\n",
            "Epoch 41, Step 174, Loss: 0.07359301298856735\n",
            "Epoch 41, Step 175, Loss: 0.03848990797996521\n",
            "Epoch 41, Step 176, Loss: 0.08607963472604752\n",
            "Epoch 41, Step 177, Loss: 0.023393360897898674\n",
            "Epoch 41, Step 178, Loss: 0.042339786887168884\n",
            "Epoch 41, Step 179, Loss: 0.011050952598452568\n",
            "Epoch 41, Step 180, Loss: 0.0355314202606678\n",
            "Epoch 41, Step 181, Loss: 0.0864534005522728\n",
            "Epoch 41, Step 182, Loss: 0.03726983070373535\n",
            "Epoch 41, Step 183, Loss: 0.097731813788414\n",
            "Epoch 41, Step 184, Loss: 0.058450791984796524\n",
            "Epoch 41, Step 185, Loss: 0.07935081422328949\n",
            "Epoch 41, Step 186, Loss: 0.10828493535518646\n",
            "Epoch 41, Step 187, Loss: 0.0671720877289772\n",
            "Epoch 41, Step 188, Loss: 0.029060760512948036\n",
            "Epoch 41, Step 189, Loss: 0.07634639739990234\n",
            "Epoch 41, Step 190, Loss: 0.049199849367141724\n",
            "Epoch 41, Step 191, Loss: 0.12518984079360962\n",
            "Epoch 41, Step 192, Loss: 0.05781953036785126\n",
            "Epoch 41, Step 193, Loss: 0.015137852169573307\n",
            "Epoch 41, Step 194, Loss: 0.05616120621562004\n",
            "Epoch 41, Step 195, Loss: 0.09390386193990707\n",
            "Epoch 41, Step 196, Loss: 0.03733726963400841\n",
            "Epoch 41, Step 197, Loss: 0.03918880224227905\n",
            "Epoch 41, Step 198, Loss: 0.06000543013215065\n",
            "Epoch 41, Step 199, Loss: 0.06358098238706589\n",
            "Epoch 41, Step 200, Loss: 0.0803530216217041\n",
            "Epoch 41, Step 201, Loss: 0.0678255707025528\n",
            "Epoch 41, Step 202, Loss: 0.06363730877637863\n",
            "Epoch 41, Step 203, Loss: 0.059088800102472305\n",
            "Epoch 41, Step 204, Loss: 0.07062821090221405\n",
            "Epoch 41, Step 205, Loss: 0.06311297416687012\n",
            "Epoch 41, Step 206, Loss: 0.09286707639694214\n",
            "Epoch 41, Step 207, Loss: 0.03364810347557068\n",
            "Epoch 41, Step 208, Loss: 0.040080077946186066\n",
            "Epoch 41, Step 209, Loss: 0.0827096477150917\n",
            "Epoch 41, Step 210, Loss: 0.12904709577560425\n",
            "Epoch 41, Step 211, Loss: 0.05825252830982208\n",
            "Epoch 41, Step 212, Loss: 0.04459664598107338\n",
            "Epoch 41, Step 213, Loss: 0.04607265442609787\n",
            "Epoch 41, Step 214, Loss: 0.08491729944944382\n",
            "Epoch 41, Step 215, Loss: 0.03287402540445328\n",
            "Epoch 41, Step 216, Loss: 0.028907932341098785\n",
            "Epoch 41, Step 217, Loss: 0.10507955402135849\n",
            "Epoch 41, Step 218, Loss: 0.0442797988653183\n",
            "Epoch 41, Step 219, Loss: 0.036884259432554245\n",
            "Epoch 41, Step 220, Loss: 0.06110658869147301\n",
            "Epoch 41, Step 221, Loss: 0.0638415515422821\n",
            "Epoch 41, Step 222, Loss: 0.0447787381708622\n",
            "Epoch 41, Step 223, Loss: 0.10450431704521179\n",
            "Epoch 41, Step 224, Loss: 0.08413871377706528\n",
            "Epoch 41, Step 225, Loss: 0.025545990094542503\n",
            "Epoch 41, Step 226, Loss: 0.05518835410475731\n",
            "Epoch 41, Step 227, Loss: 0.07588847726583481\n",
            "Epoch 41, Step 228, Loss: 0.02731284685432911\n",
            "Epoch 41, Step 229, Loss: 0.12325512617826462\n",
            "Epoch 41, Step 230, Loss: 0.05787813290953636\n",
            "Epoch 41, Step 231, Loss: 0.10799906402826309\n",
            "Epoch 41, Step 232, Loss: 0.03315490856766701\n",
            "Epoch 41, Step 233, Loss: 0.0511537604033947\n",
            "Epoch 41, Step 234, Loss: 0.04547261446714401\n",
            "Epoch 41, Step 235, Loss: 0.07669757306575775\n",
            "Epoch 41, Step 236, Loss: 0.07363639771938324\n",
            "Epoch 41, Step 237, Loss: 0.06849059462547302\n",
            "Epoch 41, Step 238, Loss: 0.10032682865858078\n",
            "Epoch 41, Step 239, Loss: 0.06703619658946991\n",
            "Epoch 41, Step 240, Loss: 0.09819944947957993\n",
            "Epoch 41, Step 241, Loss: 0.15974999964237213\n",
            "Epoch 41, Step 242, Loss: 0.10382486134767532\n",
            "Epoch 41, Step 243, Loss: 0.02774406038224697\n",
            "Epoch 41, Step 244, Loss: 0.033516936004161835\n",
            "Epoch 41, Step 245, Loss: 0.018603945150971413\n",
            "Epoch 41, Step 246, Loss: 0.03741900250315666\n",
            "Epoch 41, Step 247, Loss: 0.05689487233757973\n",
            "Epoch 41, Step 248, Loss: 0.09932086616754532\n",
            "Epoch 41, Step 249, Loss: 0.054524995386600494\n",
            "Epoch 41, Step 250, Loss: 0.16822269558906555\n",
            "Epoch 41, Step 251, Loss: 0.08455204218626022\n",
            "Epoch 41, Step 252, Loss: 0.04742567986249924\n",
            "Epoch 41, Step 253, Loss: 0.03882267698645592\n",
            "Epoch 41, Step 254, Loss: 0.06478112936019897\n",
            "Epoch 41, Step 255, Loss: 0.09044402837753296\n",
            "Epoch 41, Step 256, Loss: 0.11953581124544144\n",
            "Epoch 41, Step 257, Loss: 0.008193266578018665\n",
            "Epoch 41, Step 258, Loss: 0.0217985138297081\n",
            "Epoch 41, Step 259, Loss: 0.012221160344779491\n",
            "Epoch 41, Step 260, Loss: 0.07556595653295517\n",
            "Epoch 41, Step 261, Loss: 0.01952757127583027\n",
            "Epoch 41, Step 262, Loss: 0.03867477923631668\n",
            "Epoch 41, Step 263, Loss: 0.0358584001660347\n",
            "Epoch 41, Step 264, Loss: 0.03647153824567795\n",
            "Epoch 41, Step 265, Loss: 0.0645100399851799\n",
            "Epoch 41, Step 266, Loss: 0.03033386915922165\n",
            "Epoch 41, Step 267, Loss: 0.0980612263083458\n",
            "Epoch 41, Step 268, Loss: 0.04672645777463913\n",
            "Epoch 41, Step 269, Loss: 0.06527367979288101\n",
            "Epoch 41, Step 270, Loss: 0.03886740654706955\n",
            "Epoch 41, Step 271, Loss: 0.06135168671607971\n",
            "Epoch 41, Step 272, Loss: 0.0909826010465622\n",
            "Epoch 41, Step 273, Loss: 0.04483060538768768\n",
            "Epoch 41, Step 274, Loss: 0.055476114153862\n",
            "Epoch 41, Step 275, Loss: 0.12467962503433228\n",
            "Epoch 41, Step 276, Loss: 0.060126520693302155\n",
            "Epoch 41, Step 277, Loss: 0.04102983698248863\n",
            "Epoch 41, Step 278, Loss: 0.04795965552330017\n",
            "Epoch 41, Step 279, Loss: 0.05768710374832153\n",
            "Epoch 41, Step 280, Loss: 0.06380316615104675\n",
            "Epoch 41, Step 281, Loss: 0.12928669154644012\n",
            "Epoch 41, Step 282, Loss: 0.06205230951309204\n",
            "Epoch 41, Step 283, Loss: 0.02624090202152729\n",
            "Epoch 41, Step 284, Loss: 0.06781738996505737\n",
            "Epoch 41, Step 285, Loss: 0.046099331229925156\n",
            "Epoch 41, Step 286, Loss: 0.13056880235671997\n",
            "Epoch 41, Step 287, Loss: 0.1279071420431137\n",
            "Epoch 41, Step 288, Loss: 0.0347164124250412\n",
            "Epoch 41, Step 289, Loss: 0.06935372948646545\n",
            "Epoch 41, Step 290, Loss: 0.05164602771401405\n",
            "Epoch 41, Step 291, Loss: 0.17031648755073547\n",
            "Epoch 41, Step 292, Loss: 0.05919569358229637\n",
            "Epoch 41, Step 293, Loss: 0.05666838958859444\n",
            "Epoch 41, Step 294, Loss: 0.07736228406429291\n",
            "Epoch 41, Step 295, Loss: 0.06120508164167404\n",
            "Epoch 41, Step 296, Loss: 0.12289249151945114\n",
            "Epoch 41, Step 297, Loss: 0.11104457080364227\n",
            "Epoch 41, Step 298, Loss: 0.12521082162857056\n",
            "Epoch 41, Step 299, Loss: 0.026375260204076767\n",
            "Epoch 41, Step 300, Loss: 0.02927674911916256\n",
            "Epoch 41, Step 301, Loss: 0.0638427883386612\n",
            "Epoch 41, Step 302, Loss: 0.05319288745522499\n",
            "Epoch 41, Step 303, Loss: 0.049780264496803284\n",
            "Epoch 41, Step 304, Loss: 0.10410363972187042\n",
            "Epoch 41, Step 305, Loss: 0.07521266490221024\n",
            "Epoch 41, Step 306, Loss: 0.16564427316188812\n",
            "Epoch 41, Step 307, Loss: 0.06450843065977097\n",
            "Epoch 41, Step 308, Loss: 0.15404795110225677\n",
            "Epoch 41, Step 309, Loss: 0.0395108200609684\n",
            "Epoch 41, Step 310, Loss: 0.10956394672393799\n",
            "Epoch 41, Step 311, Loss: 0.06831179559230804\n",
            "Epoch 41, Step 312, Loss: 0.12588536739349365\n",
            "Epoch 41 end, avg train loss: 0.06489730402589225\n",
            "Epoch 41 end, avg val loss: 0.4494339984051789, accuracy: 90.13%\n",
            "Checkpoint saved: Adam_41.pth\n",
            "Epoch 42, Step 0, Loss: 0.02379884012043476\n",
            "Epoch 42, Step 1, Loss: 0.05810524523258209\n",
            "Epoch 42, Step 2, Loss: 0.07331909239292145\n",
            "Epoch 42, Step 3, Loss: 0.053113825619220734\n",
            "Epoch 42, Step 4, Loss: 0.05294472351670265\n",
            "Epoch 42, Step 5, Loss: 0.03181159123778343\n",
            "Epoch 42, Step 6, Loss: 0.03683209419250488\n",
            "Epoch 42, Step 7, Loss: 0.06953797489404678\n",
            "Epoch 42, Step 8, Loss: 0.024343838915228844\n",
            "Epoch 42, Step 9, Loss: 0.04344598576426506\n",
            "Epoch 42, Step 10, Loss: 0.068107008934021\n",
            "Epoch 42, Step 11, Loss: 0.1037793755531311\n",
            "Epoch 42, Step 12, Loss: 0.03422289341688156\n",
            "Epoch 42, Step 13, Loss: 0.02431737259030342\n",
            "Epoch 42, Step 14, Loss: 0.09513327479362488\n",
            "Epoch 42, Step 15, Loss: 0.04857058450579643\n",
            "Epoch 42, Step 16, Loss: 0.06652548164129257\n",
            "Epoch 42, Step 17, Loss: 0.028349675238132477\n",
            "Epoch 42, Step 18, Loss: 0.037693291902542114\n",
            "Epoch 42, Step 19, Loss: 0.06189059466123581\n",
            "Epoch 42, Step 20, Loss: 0.04047866538167\n",
            "Epoch 42, Step 21, Loss: 0.07644067704677582\n",
            "Epoch 42, Step 22, Loss: 0.059282828122377396\n",
            "Epoch 42, Step 23, Loss: 0.04573599249124527\n",
            "Epoch 42, Step 24, Loss: 0.051472101360559464\n",
            "Epoch 42, Step 25, Loss: 0.08517896384000778\n",
            "Epoch 42, Step 26, Loss: 0.12218189984560013\n",
            "Epoch 42, Step 27, Loss: 0.019265970215201378\n",
            "Epoch 42, Step 28, Loss: 0.04133089631795883\n",
            "Epoch 42, Step 29, Loss: 0.07573796808719635\n",
            "Epoch 42, Step 30, Loss: 0.09053612500429153\n",
            "Epoch 42, Step 31, Loss: 0.07476785033941269\n",
            "Epoch 42, Step 32, Loss: 0.018215330317616463\n",
            "Epoch 42, Step 33, Loss: 0.05528945103287697\n",
            "Epoch 42, Step 34, Loss: 0.053491439670324326\n",
            "Epoch 42, Step 35, Loss: 0.04379221424460411\n",
            "Epoch 42, Step 36, Loss: 0.07344743609428406\n",
            "Epoch 42, Step 37, Loss: 0.08318272233009338\n",
            "Epoch 42, Step 38, Loss: 0.03640783950686455\n",
            "Epoch 42, Step 39, Loss: 0.0670301541686058\n",
            "Epoch 42, Step 40, Loss: 0.05522248521447182\n",
            "Epoch 42, Step 41, Loss: 0.0063841380178928375\n",
            "Epoch 42, Step 42, Loss: 0.11828375607728958\n",
            "Epoch 42, Step 43, Loss: 0.12443703413009644\n",
            "Epoch 42, Step 44, Loss: 0.07168815284967422\n",
            "Epoch 42, Step 45, Loss: 0.10060563683509827\n",
            "Epoch 42, Step 46, Loss: 0.07817498594522476\n",
            "Epoch 42, Step 47, Loss: 0.07040733098983765\n",
            "Epoch 42, Step 48, Loss: 0.027728281915187836\n",
            "Epoch 42, Step 49, Loss: 0.06748805940151215\n",
            "Epoch 42, Step 50, Loss: 0.012776480056345463\n",
            "Epoch 42, Step 51, Loss: 0.07175817340612411\n",
            "Epoch 42, Step 52, Loss: 0.03197871148586273\n",
            "Epoch 42, Step 53, Loss: 0.024737702682614326\n",
            "Epoch 42, Step 54, Loss: 0.09033742547035217\n",
            "Epoch 42, Step 55, Loss: 0.06282415241003036\n",
            "Epoch 42, Step 56, Loss: 0.06977292895317078\n",
            "Epoch 42, Step 57, Loss: 0.08272434771060944\n",
            "Epoch 42, Step 58, Loss: 0.13272765278816223\n",
            "Epoch 42, Step 59, Loss: 0.033169351518154144\n",
            "Epoch 42, Step 60, Loss: 0.09911882132291794\n",
            "Epoch 42, Step 61, Loss: 0.018858464434742928\n",
            "Epoch 42, Step 62, Loss: 0.06415016949176788\n",
            "Epoch 42, Step 63, Loss: 0.14451994001865387\n",
            "Epoch 42, Step 64, Loss: 0.12276256829500198\n",
            "Epoch 42, Step 65, Loss: 0.0319410115480423\n",
            "Epoch 42, Step 66, Loss: 0.04193533957004547\n",
            "Epoch 42, Step 67, Loss: 0.038143083453178406\n",
            "Epoch 42, Step 68, Loss: 0.04000626131892204\n",
            "Epoch 42, Step 69, Loss: 0.09022113680839539\n",
            "Epoch 42, Step 70, Loss: 0.06033625081181526\n",
            "Epoch 42, Step 71, Loss: 0.05132443457841873\n",
            "Epoch 42, Step 72, Loss: 0.048298429697752\n",
            "Epoch 42, Step 73, Loss: 0.049867648631334305\n",
            "Epoch 42, Step 74, Loss: 0.03256536275148392\n",
            "Epoch 42, Step 75, Loss: 0.09943649917840958\n",
            "Epoch 42, Step 76, Loss: 0.025089353322982788\n",
            "Epoch 42, Step 77, Loss: 0.08882876485586166\n",
            "Epoch 42, Step 78, Loss: 0.0845959410071373\n",
            "Epoch 42, Step 79, Loss: 0.08879835158586502\n",
            "Epoch 42, Step 80, Loss: 0.08256375044584274\n",
            "Epoch 42, Step 81, Loss: 0.03331533074378967\n",
            "Epoch 42, Step 82, Loss: 0.05790548399090767\n",
            "Epoch 42, Step 83, Loss: 0.025718145072460175\n",
            "Epoch 42, Step 84, Loss: 0.0497003011405468\n",
            "Epoch 42, Step 85, Loss: 0.030243216082453728\n",
            "Epoch 42, Step 86, Loss: 0.08869239687919617\n",
            "Epoch 42, Step 87, Loss: 0.179532989859581\n",
            "Epoch 42, Step 88, Loss: 0.07096477597951889\n",
            "Epoch 42, Step 89, Loss: 0.043849870562553406\n",
            "Epoch 42, Step 90, Loss: 0.10212872922420502\n",
            "Epoch 42, Step 91, Loss: 0.026888113468885422\n",
            "Epoch 42, Step 92, Loss: 0.08187192678451538\n",
            "Epoch 42, Step 93, Loss: 0.04212532192468643\n",
            "Epoch 42, Step 94, Loss: 0.04634920880198479\n",
            "Epoch 42, Step 95, Loss: 0.11242076754570007\n",
            "Epoch 42, Step 96, Loss: 0.029598021879792213\n",
            "Epoch 42, Step 97, Loss: 0.1215093657374382\n",
            "Epoch 42, Step 98, Loss: 0.09116367995738983\n",
            "Epoch 42, Step 99, Loss: 0.05121143162250519\n",
            "Epoch 42, Step 100, Loss: 0.1591171771287918\n",
            "Epoch 42, Step 101, Loss: 0.06569687277078629\n",
            "Epoch 42, Step 102, Loss: 0.03653082251548767\n",
            "Epoch 42, Step 103, Loss: 0.04173057898879051\n",
            "Epoch 42, Step 104, Loss: 0.1201569139957428\n",
            "Epoch 42, Step 105, Loss: 0.058894529938697815\n",
            "Epoch 42, Step 106, Loss: 0.06804206967353821\n",
            "Epoch 42, Step 107, Loss: 0.06272609531879425\n",
            "Epoch 42, Step 108, Loss: 0.10113850980997086\n",
            "Epoch 42, Step 109, Loss: 0.05657700449228287\n",
            "Epoch 42, Step 110, Loss: 0.044579774141311646\n",
            "Epoch 42, Step 111, Loss: 0.046882398426532745\n",
            "Epoch 42, Step 112, Loss: 0.0687992125749588\n",
            "Epoch 42, Step 113, Loss: 0.12250170111656189\n",
            "Epoch 42, Step 114, Loss: 0.04631926119327545\n",
            "Epoch 42, Step 115, Loss: 0.024983439594507217\n",
            "Epoch 42, Step 116, Loss: 0.1447918713092804\n",
            "Epoch 42, Step 117, Loss: 0.04691512882709503\n",
            "Epoch 42, Step 118, Loss: 0.02188611589372158\n",
            "Epoch 42, Step 119, Loss: 0.12296660244464874\n",
            "Epoch 42, Step 120, Loss: 0.14403896033763885\n",
            "Epoch 42, Step 121, Loss: 0.11345519125461578\n",
            "Epoch 42, Step 122, Loss: 0.04676362872123718\n",
            "Epoch 42, Step 123, Loss: 0.053665608167648315\n",
            "Epoch 42, Step 124, Loss: 0.04409420117735863\n",
            "Epoch 42, Step 125, Loss: 0.03382334113121033\n",
            "Epoch 42, Step 126, Loss: 0.15065674483776093\n",
            "Epoch 42, Step 127, Loss: 0.09296534955501556\n",
            "Epoch 42, Step 128, Loss: 0.04123706370592117\n",
            "Epoch 42, Step 129, Loss: 0.10810011625289917\n",
            "Epoch 42, Step 130, Loss: 0.1413482129573822\n",
            "Epoch 42, Step 131, Loss: 0.11349211633205414\n",
            "Epoch 42, Step 132, Loss: 0.06898541748523712\n",
            "Epoch 42, Step 133, Loss: 0.11263938993215561\n",
            "Epoch 42, Step 134, Loss: 0.04280607029795647\n",
            "Epoch 42, Step 135, Loss: 0.044367268681526184\n",
            "Epoch 42, Step 136, Loss: 0.047195788472890854\n",
            "Epoch 42, Step 137, Loss: 0.05730878561735153\n",
            "Epoch 42, Step 138, Loss: 0.04635671153664589\n",
            "Epoch 42, Step 139, Loss: 0.11532546579837799\n",
            "Epoch 42, Step 140, Loss: 0.04301396384835243\n",
            "Epoch 42, Step 141, Loss: 0.07830765843391418\n",
            "Epoch 42, Step 142, Loss: 0.036481909453868866\n",
            "Epoch 42, Step 143, Loss: 0.049904681742191315\n",
            "Epoch 42, Step 144, Loss: 0.036087360233068466\n",
            "Epoch 42, Step 145, Loss: 0.08859028667211533\n",
            "Epoch 42, Step 146, Loss: 0.12385166436433792\n",
            "Epoch 42, Step 147, Loss: 0.041348546743392944\n",
            "Epoch 42, Step 148, Loss: 0.07908380031585693\n",
            "Epoch 42, Step 149, Loss: 0.06844282150268555\n",
            "Epoch 42, Step 150, Loss: 0.056610334664583206\n",
            "Epoch 42, Step 151, Loss: 0.0800756961107254\n",
            "Epoch 42, Step 152, Loss: 0.046525988727808\n",
            "Epoch 42, Step 153, Loss: 0.09503025561571121\n",
            "Epoch 42, Step 154, Loss: 0.05152709037065506\n",
            "Epoch 42, Step 155, Loss: 0.08039993792772293\n",
            "Epoch 42, Step 156, Loss: 0.04650108888745308\n",
            "Epoch 42, Step 157, Loss: 0.0883261188864708\n",
            "Epoch 42, Step 158, Loss: 0.05646189674735069\n",
            "Epoch 42, Step 159, Loss: 0.11816436797380447\n",
            "Epoch 42, Step 160, Loss: 0.07974476367235184\n",
            "Epoch 42, Step 161, Loss: 0.04346839711070061\n",
            "Epoch 42, Step 162, Loss: 0.04235267639160156\n",
            "Epoch 42, Step 163, Loss: 0.012585684657096863\n",
            "Epoch 42, Step 164, Loss: 0.06807426363229752\n",
            "Epoch 42, Step 165, Loss: 0.08882217854261398\n",
            "Epoch 42, Step 166, Loss: 0.07723270356655121\n",
            "Epoch 42, Step 167, Loss: 0.028262512758374214\n",
            "Epoch 42, Step 168, Loss: 0.10071348398923874\n",
            "Epoch 42, Step 169, Loss: 0.04684155061841011\n",
            "Epoch 42, Step 170, Loss: 0.11908940970897675\n",
            "Epoch 42, Step 171, Loss: 0.03599552437663078\n",
            "Epoch 42, Step 172, Loss: 0.028615562245249748\n",
            "Epoch 42, Step 173, Loss: 0.10541683435440063\n",
            "Epoch 42, Step 174, Loss: 0.10032542794942856\n",
            "Epoch 42, Step 175, Loss: 0.07185783237218857\n",
            "Epoch 42, Step 176, Loss: 0.10441535711288452\n",
            "Epoch 42, Step 177, Loss: 0.02963314950466156\n",
            "Epoch 42, Step 178, Loss: 0.06310073286294937\n",
            "Epoch 42, Step 179, Loss: 0.0716724619269371\n",
            "Epoch 42, Step 180, Loss: 0.10194442421197891\n",
            "Epoch 42, Step 181, Loss: 0.06512480974197388\n",
            "Epoch 42, Step 182, Loss: 0.08563781529664993\n",
            "Epoch 42, Step 183, Loss: 0.06646138429641724\n",
            "Epoch 42, Step 184, Loss: 0.09436247497797012\n",
            "Epoch 42, Step 185, Loss: 0.10341000556945801\n",
            "Epoch 42, Step 186, Loss: 0.025195633992552757\n",
            "Epoch 42, Step 187, Loss: 0.08032998442649841\n",
            "Epoch 42, Step 188, Loss: 0.15025660395622253\n",
            "Epoch 42, Step 189, Loss: 0.051915258169174194\n",
            "Epoch 42, Step 190, Loss: 0.06771240383386612\n",
            "Epoch 42, Step 191, Loss: 0.05758816376328468\n",
            "Epoch 42, Step 192, Loss: 0.058924704790115356\n",
            "Epoch 42, Step 193, Loss: 0.0425410121679306\n",
            "Epoch 42, Step 194, Loss: 0.06995135545730591\n",
            "Epoch 42, Step 195, Loss: 0.04725683480501175\n",
            "Epoch 42, Step 196, Loss: 0.11128255724906921\n",
            "Epoch 42, Step 197, Loss: 0.09512137621641159\n",
            "Epoch 42, Step 198, Loss: 0.08633624017238617\n",
            "Epoch 42, Step 199, Loss: 0.022601664066314697\n",
            "Epoch 42, Step 200, Loss: 0.03916327655315399\n",
            "Epoch 42, Step 201, Loss: 0.04631233587861061\n",
            "Epoch 42, Step 202, Loss: 0.0732225701212883\n",
            "Epoch 42, Step 203, Loss: 0.06578747928142548\n",
            "Epoch 42, Step 204, Loss: 0.06906052678823471\n",
            "Epoch 42, Step 205, Loss: 0.03443986922502518\n",
            "Epoch 42, Step 206, Loss: 0.020662803202867508\n",
            "Epoch 42, Step 207, Loss: 0.12629634141921997\n",
            "Epoch 42, Step 208, Loss: 0.08160793781280518\n",
            "Epoch 42, Step 209, Loss: 0.06362412869930267\n",
            "Epoch 42, Step 210, Loss: 0.12929120659828186\n",
            "Epoch 42, Step 211, Loss: 0.08943011611700058\n",
            "Epoch 42, Step 212, Loss: 0.040106210857629776\n",
            "Epoch 42, Step 213, Loss: 0.048687588423490524\n",
            "Epoch 42, Step 214, Loss: 0.041661281138658524\n",
            "Epoch 42, Step 215, Loss: 0.07886461168527603\n",
            "Epoch 42, Step 216, Loss: 0.07080260664224625\n",
            "Epoch 42, Step 217, Loss: 0.061452917754650116\n",
            "Epoch 42, Step 218, Loss: 0.11313263326883316\n",
            "Epoch 42, Step 219, Loss: 0.031228424981236458\n",
            "Epoch 42, Step 220, Loss: 0.050262175500392914\n",
            "Epoch 42, Step 221, Loss: 0.05736607313156128\n",
            "Epoch 42, Step 222, Loss: 0.07273880392313004\n",
            "Epoch 42, Step 223, Loss: 0.08475976437330246\n",
            "Epoch 42, Step 224, Loss: 0.03887128829956055\n",
            "Epoch 42, Step 225, Loss: 0.070665143430233\n",
            "Epoch 42, Step 226, Loss: 0.09123150259256363\n",
            "Epoch 42, Step 227, Loss: 0.1539842188358307\n",
            "Epoch 42, Step 228, Loss: 0.04602921009063721\n",
            "Epoch 42, Step 229, Loss: 0.04852050915360451\n",
            "Epoch 42, Step 230, Loss: 0.09200195968151093\n",
            "Epoch 42, Step 231, Loss: 0.08152324706315994\n",
            "Epoch 42, Step 232, Loss: 0.06379633396863937\n",
            "Epoch 42, Step 233, Loss: 0.07598446309566498\n",
            "Epoch 42, Step 234, Loss: 0.09079016745090485\n",
            "Epoch 42, Step 235, Loss: 0.1644507646560669\n",
            "Epoch 42, Step 236, Loss: 0.08621305227279663\n",
            "Epoch 42, Step 237, Loss: 0.08563365042209625\n",
            "Epoch 42, Step 238, Loss: 0.08802023530006409\n",
            "Epoch 42, Step 239, Loss: 0.07544641196727753\n",
            "Epoch 42, Step 240, Loss: 0.07123372703790665\n",
            "Epoch 42, Step 241, Loss: 0.13854968547821045\n",
            "Epoch 42, Step 242, Loss: 0.09960121661424637\n",
            "Epoch 42, Step 243, Loss: 0.07664951682090759\n",
            "Epoch 42, Step 244, Loss: 0.040504924952983856\n",
            "Epoch 42, Step 245, Loss: 0.040133580565452576\n",
            "Epoch 42, Step 246, Loss: 0.08229327946901321\n",
            "Epoch 42, Step 247, Loss: 0.13422223925590515\n",
            "Epoch 42, Step 248, Loss: 0.06821253150701523\n",
            "Epoch 42, Step 249, Loss: 0.10278266668319702\n",
            "Epoch 42, Step 250, Loss: 0.05516257509589195\n",
            "Epoch 42, Step 251, Loss: 0.030203528702259064\n",
            "Epoch 42, Step 252, Loss: 0.05309182405471802\n",
            "Epoch 42, Step 253, Loss: 0.08082309365272522\n",
            "Epoch 42, Step 254, Loss: 0.04531903192400932\n",
            "Epoch 42, Step 255, Loss: 0.04845099896192551\n",
            "Epoch 42, Step 256, Loss: 0.149179607629776\n",
            "Epoch 42, Step 257, Loss: 0.07122258841991425\n",
            "Epoch 42, Step 258, Loss: 0.09160294383764267\n",
            "Epoch 42, Step 259, Loss: 0.07334379106760025\n",
            "Epoch 42, Step 260, Loss: 0.034435443580150604\n",
            "Epoch 42, Step 261, Loss: 0.1486688256263733\n",
            "Epoch 42, Step 262, Loss: 0.08177601546049118\n",
            "Epoch 42, Step 263, Loss: 0.08669006079435349\n",
            "Epoch 42, Step 264, Loss: 0.03953862935304642\n",
            "Epoch 42, Step 265, Loss: 0.09435274451971054\n",
            "Epoch 42, Step 266, Loss: 0.037455055862665176\n",
            "Epoch 42, Step 267, Loss: 0.050236303359270096\n",
            "Epoch 42, Step 268, Loss: 0.07331490516662598\n",
            "Epoch 42, Step 269, Loss: 0.09835990518331528\n",
            "Epoch 42, Step 270, Loss: 0.03410793095827103\n",
            "Epoch 42, Step 271, Loss: 0.0511075034737587\n",
            "Epoch 42, Step 272, Loss: 0.01797523908317089\n",
            "Epoch 42, Step 273, Loss: 0.01861930452287197\n",
            "Epoch 42, Step 274, Loss: 0.1043221652507782\n",
            "Epoch 42, Step 275, Loss: 0.03845898061990738\n",
            "Epoch 42, Step 276, Loss: 0.04787898436188698\n",
            "Epoch 42, Step 277, Loss: 0.09789250791072845\n",
            "Epoch 42, Step 278, Loss: 0.07481785863637924\n",
            "Epoch 42, Step 279, Loss: 0.07272735983133316\n",
            "Epoch 42, Step 280, Loss: 0.05638953670859337\n",
            "Epoch 42, Step 281, Loss: 0.033225174993276596\n",
            "Epoch 42, Step 282, Loss: 0.0821271762251854\n",
            "Epoch 42, Step 283, Loss: 0.03435346111655235\n",
            "Epoch 42, Step 284, Loss: 0.07302352041006088\n",
            "Epoch 42, Step 285, Loss: 0.09673561900854111\n",
            "Epoch 42, Step 286, Loss: 0.04877232015132904\n",
            "Epoch 42, Step 287, Loss: 0.03884788975119591\n",
            "Epoch 42, Step 288, Loss: 0.04490043595433235\n",
            "Epoch 42, Step 289, Loss: 0.10016748309135437\n",
            "Epoch 42, Step 290, Loss: 0.02187199890613556\n",
            "Epoch 42, Step 291, Loss: 0.1216217428445816\n",
            "Epoch 42, Step 292, Loss: 0.07407871633768082\n",
            "Epoch 42, Step 293, Loss: 0.09078702330589294\n",
            "Epoch 42, Step 294, Loss: 0.049096450209617615\n",
            "Epoch 42, Step 295, Loss: 0.03426038846373558\n",
            "Epoch 42, Step 296, Loss: 0.03512931242585182\n",
            "Epoch 42, Step 297, Loss: 0.06704381108283997\n",
            "Epoch 42, Step 298, Loss: 0.08575667440891266\n",
            "Epoch 42, Step 299, Loss: 0.056883130222558975\n",
            "Epoch 42, Step 300, Loss: 0.08566848188638687\n",
            "Epoch 42, Step 301, Loss: 0.09142006933689117\n",
            "Epoch 42, Step 302, Loss: 0.04809778183698654\n",
            "Epoch 42, Step 303, Loss: 0.04573030769824982\n",
            "Epoch 42, Step 304, Loss: 0.16588932275772095\n",
            "Epoch 42, Step 305, Loss: 0.14088286459445953\n",
            "Epoch 42, Step 306, Loss: 0.038843803107738495\n",
            "Epoch 42, Step 307, Loss: 0.08515742421150208\n",
            "Epoch 42, Step 308, Loss: 0.03793180361390114\n",
            "Epoch 42, Step 309, Loss: 0.10667325556278229\n",
            "Epoch 42, Step 310, Loss: 0.08107060194015503\n",
            "Epoch 42, Step 311, Loss: 0.09764450788497925\n",
            "Epoch 42, Step 312, Loss: 0.11220249533653259\n",
            "Epoch 42 end, avg train loss: 0.06932391832990292\n",
            "Epoch 42 end, avg val loss: 0.3773007709768754, accuracy: 91.01%\n",
            "Epoch 43, Step 0, Loss: 0.02870779111981392\n",
            "Epoch 43, Step 1, Loss: 0.16225557029247284\n",
            "Epoch 43, Step 2, Loss: 0.0428951233625412\n",
            "Epoch 43, Step 3, Loss: 0.05822841823101044\n",
            "Epoch 43, Step 4, Loss: 0.05871954560279846\n",
            "Epoch 43, Step 5, Loss: 0.08486288040876389\n",
            "Epoch 43, Step 6, Loss: 0.06521093845367432\n",
            "Epoch 43, Step 7, Loss: 0.09475135803222656\n",
            "Epoch 43, Step 8, Loss: 0.032866548746824265\n",
            "Epoch 43, Step 9, Loss: 0.049774494022130966\n",
            "Epoch 43, Step 10, Loss: 0.0701233372092247\n",
            "Epoch 43, Step 11, Loss: 0.0256363395601511\n",
            "Epoch 43, Step 12, Loss: 0.03582220524549484\n",
            "Epoch 43, Step 13, Loss: 0.04803431034088135\n",
            "Epoch 43, Step 14, Loss: 0.07710039615631104\n",
            "Epoch 43, Step 15, Loss: 0.055264879018068314\n",
            "Epoch 43, Step 16, Loss: 0.07812714576721191\n",
            "Epoch 43, Step 17, Loss: 0.046048879623413086\n",
            "Epoch 43, Step 18, Loss: 0.05961984768509865\n",
            "Epoch 43, Step 19, Loss: 0.06082472205162048\n",
            "Epoch 43, Step 20, Loss: 0.09737404435873032\n",
            "Epoch 43, Step 21, Loss: 0.07562422007322311\n",
            "Epoch 43, Step 22, Loss: 0.07782157510519028\n",
            "Epoch 43, Step 23, Loss: 0.1400534063577652\n",
            "Epoch 43, Step 24, Loss: 0.17896386981010437\n",
            "Epoch 43, Step 25, Loss: 0.04832065850496292\n",
            "Epoch 43, Step 26, Loss: 0.06889206916093826\n",
            "Epoch 43, Step 27, Loss: 0.06021660193800926\n",
            "Epoch 43, Step 28, Loss: 0.04124993830919266\n",
            "Epoch 43, Step 29, Loss: 0.059835873544216156\n",
            "Epoch 43, Step 30, Loss: 0.03513956815004349\n",
            "Epoch 43, Step 31, Loss: 0.025036761537194252\n",
            "Epoch 43, Step 32, Loss: 0.013592619448900223\n",
            "Epoch 43, Step 33, Loss: 0.04793896526098251\n",
            "Epoch 43, Step 34, Loss: 0.02438671886920929\n",
            "Epoch 43, Step 35, Loss: 0.11663764715194702\n",
            "Epoch 43, Step 36, Loss: 0.04798649623990059\n",
            "Epoch 43, Step 37, Loss: 0.07116961479187012\n",
            "Epoch 43, Step 38, Loss: 0.02120523899793625\n",
            "Epoch 43, Step 39, Loss: 0.08071166276931763\n",
            "Epoch 43, Step 40, Loss: 0.027323411777615547\n",
            "Epoch 43, Step 41, Loss: 0.02363044209778309\n",
            "Epoch 43, Step 42, Loss: 0.07018880546092987\n",
            "Epoch 43, Step 43, Loss: 0.039244145154953\n",
            "Epoch 43, Step 44, Loss: 0.03607073426246643\n",
            "Epoch 43, Step 45, Loss: 0.03569865971803665\n",
            "Epoch 43, Step 46, Loss: 0.03734526410698891\n",
            "Epoch 43, Step 47, Loss: 0.09041032195091248\n",
            "Epoch 43, Step 48, Loss: 0.03335652872920036\n",
            "Epoch 43, Step 49, Loss: 0.04053227975964546\n",
            "Epoch 43, Step 50, Loss: 0.019441567361354828\n",
            "Epoch 43, Step 51, Loss: 0.046630606055259705\n",
            "Epoch 43, Step 52, Loss: 0.04607875272631645\n",
            "Epoch 43, Step 53, Loss: 0.0966520681977272\n",
            "Epoch 43, Step 54, Loss: 0.057538848370313644\n",
            "Epoch 43, Step 55, Loss: 0.049620334059000015\n",
            "Epoch 43, Step 56, Loss: 0.04324902221560478\n",
            "Epoch 43, Step 57, Loss: 0.03226860985159874\n",
            "Epoch 43, Step 58, Loss: 0.05888637155294418\n",
            "Epoch 43, Step 59, Loss: 0.050192561000585556\n",
            "Epoch 43, Step 60, Loss: 0.037943724542856216\n",
            "Epoch 43, Step 61, Loss: 0.1426401287317276\n",
            "Epoch 43, Step 62, Loss: 0.12208753079175949\n",
            "Epoch 43, Step 63, Loss: 0.0715177059173584\n",
            "Epoch 43, Step 64, Loss: 0.035495661199092865\n",
            "Epoch 43, Step 65, Loss: 0.06614135205745697\n",
            "Epoch 43, Step 66, Loss: 0.02565694786608219\n",
            "Epoch 43, Step 67, Loss: 0.0664321556687355\n",
            "Epoch 43, Step 68, Loss: 0.10509374737739563\n",
            "Epoch 43, Step 69, Loss: 0.02903681993484497\n",
            "Epoch 43, Step 70, Loss: 0.018513981252908707\n",
            "Epoch 43, Step 71, Loss: 0.06274691969156265\n",
            "Epoch 43, Step 72, Loss: 0.05192522704601288\n",
            "Epoch 43, Step 73, Loss: 0.035573121160268784\n",
            "Epoch 43, Step 74, Loss: 0.09465710818767548\n",
            "Epoch 43, Step 75, Loss: 0.03887748718261719\n",
            "Epoch 43, Step 76, Loss: 0.07979563623666763\n",
            "Epoch 43, Step 77, Loss: 0.05341702699661255\n",
            "Epoch 43, Step 78, Loss: 0.09579937160015106\n",
            "Epoch 43, Step 79, Loss: 0.020506378263235092\n",
            "Epoch 43, Step 80, Loss: 0.03265571966767311\n",
            "Epoch 43, Step 81, Loss: 0.03155514970421791\n",
            "Epoch 43, Step 82, Loss: 0.04356418550014496\n",
            "Epoch 43, Step 83, Loss: 0.048259202390909195\n",
            "Epoch 43, Step 84, Loss: 0.06312302500009537\n",
            "Epoch 43, Step 85, Loss: 0.01903248205780983\n",
            "Epoch 43, Step 86, Loss: 0.016391392797231674\n",
            "Epoch 43, Step 87, Loss: 0.024866685271263123\n",
            "Epoch 43, Step 88, Loss: 0.021089794114232063\n",
            "Epoch 43, Step 89, Loss: 0.08556059747934341\n",
            "Epoch 43, Step 90, Loss: 0.04287565127015114\n",
            "Epoch 43, Step 91, Loss: 0.04982966184616089\n",
            "Epoch 43, Step 92, Loss: 0.1854914128780365\n",
            "Epoch 43, Step 93, Loss: 0.05055077001452446\n",
            "Epoch 43, Step 94, Loss: 0.07575591653585434\n",
            "Epoch 43, Step 95, Loss: 0.057573772966861725\n",
            "Epoch 43, Step 96, Loss: 0.035101886838674545\n",
            "Epoch 43, Step 97, Loss: 0.06546934694051743\n",
            "Epoch 43, Step 98, Loss: 0.03559998795390129\n",
            "Epoch 43, Step 99, Loss: 0.07236224412918091\n",
            "Epoch 43, Step 100, Loss: 0.04632321745157242\n",
            "Epoch 43, Step 101, Loss: 0.07325877249240875\n",
            "Epoch 43, Step 102, Loss: 0.04363677650690079\n",
            "Epoch 43, Step 103, Loss: 0.05914489924907684\n",
            "Epoch 43, Step 104, Loss: 0.06839550286531448\n",
            "Epoch 43, Step 105, Loss: 0.012888485565781593\n",
            "Epoch 43, Step 106, Loss: 0.08441642671823502\n",
            "Epoch 43, Step 107, Loss: 0.07643070816993713\n",
            "Epoch 43, Step 108, Loss: 0.05187588185071945\n",
            "Epoch 43, Step 109, Loss: 0.033109139651060104\n",
            "Epoch 43, Step 110, Loss: 0.024999354034662247\n",
            "Epoch 43, Step 111, Loss: 0.058614231646060944\n",
            "Epoch 43, Step 112, Loss: 0.02022096887230873\n",
            "Epoch 43, Step 113, Loss: 0.036726515740156174\n",
            "Epoch 43, Step 114, Loss: 0.047950610518455505\n",
            "Epoch 43, Step 115, Loss: 0.06123567000031471\n",
            "Epoch 43, Step 116, Loss: 0.035620782524347305\n",
            "Epoch 43, Step 117, Loss: 0.0892077386379242\n",
            "Epoch 43, Step 118, Loss: 0.04197239130735397\n",
            "Epoch 43, Step 119, Loss: 0.013918566517531872\n",
            "Epoch 43, Step 120, Loss: 0.012190367095172405\n",
            "Epoch 43, Step 121, Loss: 0.11966921389102936\n",
            "Epoch 43, Step 122, Loss: 0.1050628274679184\n",
            "Epoch 43, Step 123, Loss: 0.02427850291132927\n",
            "Epoch 43, Step 124, Loss: 0.015076818875968456\n",
            "Epoch 43, Step 125, Loss: 0.08459623157978058\n",
            "Epoch 43, Step 126, Loss: 0.04130394384264946\n",
            "Epoch 43, Step 127, Loss: 0.05748878791928291\n",
            "Epoch 43, Step 128, Loss: 0.08577698469161987\n",
            "Epoch 43, Step 129, Loss: 0.030212070792913437\n",
            "Epoch 43, Step 130, Loss: 0.03713715821504593\n",
            "Epoch 43, Step 131, Loss: 0.061583299189805984\n",
            "Epoch 43, Step 132, Loss: 0.08311133086681366\n",
            "Epoch 43, Step 133, Loss: 0.017348308116197586\n",
            "Epoch 43, Step 134, Loss: 0.07809371501207352\n",
            "Epoch 43, Step 135, Loss: 0.05751356855034828\n",
            "Epoch 43, Step 136, Loss: 0.03911275044083595\n",
            "Epoch 43, Step 137, Loss: 0.05975976958870888\n",
            "Epoch 43, Step 138, Loss: 0.04633300006389618\n",
            "Epoch 43, Step 139, Loss: 0.028419017791748047\n",
            "Epoch 43, Step 140, Loss: 0.12189801782369614\n",
            "Epoch 43, Step 141, Loss: 0.07346504181623459\n",
            "Epoch 43, Step 142, Loss: 0.02609848417341709\n",
            "Epoch 43, Step 143, Loss: 0.038179244846105576\n",
            "Epoch 43, Step 144, Loss: 0.05244825780391693\n",
            "Epoch 43, Step 145, Loss: 0.03992120176553726\n",
            "Epoch 43, Step 146, Loss: 0.05874023213982582\n",
            "Epoch 43, Step 147, Loss: 0.028986670076847076\n",
            "Epoch 43, Step 148, Loss: 0.042990460991859436\n",
            "Epoch 43, Step 149, Loss: 0.022080494090914726\n",
            "Epoch 43, Step 150, Loss: 0.034710872918367386\n",
            "Epoch 43, Step 151, Loss: 0.013626912608742714\n",
            "Epoch 43, Step 152, Loss: 0.04647399112582207\n",
            "Epoch 43, Step 153, Loss: 0.03629971668124199\n",
            "Epoch 43, Step 154, Loss: 0.03031439706683159\n",
            "Epoch 43, Step 155, Loss: 0.032177895307540894\n",
            "Epoch 43, Step 156, Loss: 0.0454740934073925\n",
            "Epoch 43, Step 157, Loss: 0.019131120294332504\n",
            "Epoch 43, Step 158, Loss: 0.03294500708580017\n",
            "Epoch 43, Step 159, Loss: 0.03398400917649269\n",
            "Epoch 43, Step 160, Loss: 0.04039518162608147\n",
            "Epoch 43, Step 161, Loss: 0.030198363587260246\n",
            "Epoch 43, Step 162, Loss: 0.0275887344032526\n",
            "Epoch 43, Step 163, Loss: 0.04549058899283409\n",
            "Epoch 43, Step 164, Loss: 0.10447327792644501\n",
            "Epoch 43, Step 165, Loss: 0.014818771742284298\n",
            "Epoch 43, Step 166, Loss: 0.03250232711434364\n",
            "Epoch 43, Step 167, Loss: 0.027061881497502327\n",
            "Epoch 43, Step 168, Loss: 0.03921633958816528\n",
            "Epoch 43, Step 169, Loss: 0.01958160474896431\n",
            "Epoch 43, Step 170, Loss: 0.04695330187678337\n",
            "Epoch 43, Step 171, Loss: 0.04484410211443901\n",
            "Epoch 43, Step 172, Loss: 0.03884730115532875\n",
            "Epoch 43, Step 173, Loss: 0.05211860314011574\n",
            "Epoch 43, Step 174, Loss: 0.04207843169569969\n",
            "Epoch 43, Step 175, Loss: 0.14229834079742432\n",
            "Epoch 43, Step 176, Loss: 0.04979106783866882\n",
            "Epoch 43, Step 177, Loss: 0.06271779537200928\n",
            "Epoch 43, Step 178, Loss: 0.07707299292087555\n",
            "Epoch 43, Step 179, Loss: 0.03916565701365471\n",
            "Epoch 43, Step 180, Loss: 0.05469847470521927\n",
            "Epoch 43, Step 181, Loss: 0.042569611221551895\n",
            "Epoch 43, Step 182, Loss: 0.02004081942141056\n",
            "Epoch 43, Step 183, Loss: 0.08178166300058365\n",
            "Epoch 43, Step 184, Loss: 0.09519553184509277\n",
            "Epoch 43, Step 185, Loss: 0.03984534740447998\n",
            "Epoch 43, Step 186, Loss: 0.05679619312286377\n",
            "Epoch 43, Step 187, Loss: 0.06538501381874084\n",
            "Epoch 43, Step 188, Loss: 0.027532678097486496\n",
            "Epoch 43, Step 189, Loss: 0.07709545642137527\n",
            "Epoch 43, Step 190, Loss: 0.05504929646849632\n",
            "Epoch 43, Step 191, Loss: 0.06610241532325745\n",
            "Epoch 43, Step 192, Loss: 0.04257955402135849\n",
            "Epoch 43, Step 193, Loss: 0.04718632251024246\n",
            "Epoch 43, Step 194, Loss: 0.02117983251810074\n",
            "Epoch 43, Step 195, Loss: 0.04676942899823189\n",
            "Epoch 43, Step 196, Loss: 0.06833939999341965\n",
            "Epoch 43, Step 197, Loss: 0.042241211980581284\n",
            "Epoch 43, Step 198, Loss: 0.034574270248413086\n",
            "Epoch 43, Step 199, Loss: 0.10522443056106567\n",
            "Epoch 43, Step 200, Loss: 0.02500823140144348\n",
            "Epoch 43, Step 201, Loss: 0.06078747659921646\n",
            "Epoch 43, Step 202, Loss: 0.08953797072172165\n",
            "Epoch 43, Step 203, Loss: 0.13243256509304047\n",
            "Epoch 43, Step 204, Loss: 0.026229076087474823\n",
            "Epoch 43, Step 205, Loss: 0.03393944352865219\n",
            "Epoch 43, Step 206, Loss: 0.06535758823156357\n",
            "Epoch 43, Step 207, Loss: 0.07430270314216614\n",
            "Epoch 43, Step 208, Loss: 0.04825517535209656\n",
            "Epoch 43, Step 209, Loss: 0.019129175692796707\n",
            "Epoch 43, Step 210, Loss: 0.047473106533288956\n",
            "Epoch 43, Step 211, Loss: 0.0451040044426918\n",
            "Epoch 43, Step 212, Loss: 0.05097263306379318\n",
            "Epoch 43, Step 213, Loss: 0.18145053088665009\n",
            "Epoch 43, Step 214, Loss: 0.10887285321950912\n",
            "Epoch 43, Step 215, Loss: 0.027831343933939934\n",
            "Epoch 43, Step 216, Loss: 0.04790157824754715\n",
            "Epoch 43, Step 217, Loss: 0.07062467932701111\n",
            "Epoch 43, Step 218, Loss: 0.02190525084733963\n",
            "Epoch 43, Step 219, Loss: 0.05158425122499466\n",
            "Epoch 43, Step 220, Loss: 0.04036013036966324\n",
            "Epoch 43, Step 221, Loss: 0.027738085016608238\n",
            "Epoch 43, Step 222, Loss: 0.026574179530143738\n",
            "Epoch 43, Step 223, Loss: 0.07630190253257751\n",
            "Epoch 43, Step 224, Loss: 0.05727100372314453\n",
            "Epoch 43, Step 225, Loss: 0.012891589663922787\n",
            "Epoch 43, Step 226, Loss: 0.030952028930187225\n",
            "Epoch 43, Step 227, Loss: 0.050328221172094345\n",
            "Epoch 43, Step 228, Loss: 0.033599063754081726\n",
            "Epoch 43, Step 229, Loss: 0.035559799522161484\n",
            "Epoch 43, Step 230, Loss: 0.08653351664543152\n",
            "Epoch 43, Step 231, Loss: 0.038596976548433304\n",
            "Epoch 43, Step 232, Loss: 0.029040686786174774\n",
            "Epoch 43, Step 233, Loss: 0.07277196645736694\n",
            "Epoch 43, Step 234, Loss: 0.09681759774684906\n",
            "Epoch 43, Step 235, Loss: 0.051035478711128235\n",
            "Epoch 43, Step 236, Loss: 0.0667688399553299\n",
            "Epoch 43, Step 237, Loss: 0.03492044284939766\n",
            "Epoch 43, Step 238, Loss: 0.04776564985513687\n",
            "Epoch 43, Step 239, Loss: 0.06655274331569672\n",
            "Epoch 43, Step 240, Loss: 0.042761169373989105\n",
            "Epoch 43, Step 241, Loss: 0.014560840092599392\n",
            "Epoch 43, Step 242, Loss: 0.03166996315121651\n",
            "Epoch 43, Step 243, Loss: 0.021533209830522537\n",
            "Epoch 43, Step 244, Loss: 0.06219214200973511\n",
            "Epoch 43, Step 245, Loss: 0.16980642080307007\n",
            "Epoch 43, Step 246, Loss: 0.09978742897510529\n",
            "Epoch 43, Step 247, Loss: 0.021012568846344948\n",
            "Epoch 43, Step 248, Loss: 0.06585725396871567\n",
            "Epoch 43, Step 249, Loss: 0.05757185071706772\n",
            "Epoch 43, Step 250, Loss: 0.04348864033818245\n",
            "Epoch 43, Step 251, Loss: 0.054815031588077545\n",
            "Epoch 43, Step 252, Loss: 0.04454220458865166\n",
            "Epoch 43, Step 253, Loss: 0.1355685144662857\n",
            "Epoch 43, Step 254, Loss: 0.10268428921699524\n",
            "Epoch 43, Step 255, Loss: 0.036592185497283936\n",
            "Epoch 43, Step 256, Loss: 0.06886778771877289\n",
            "Epoch 43, Step 257, Loss: 0.13392801582813263\n",
            "Epoch 43, Step 258, Loss: 0.04970519244670868\n",
            "Epoch 43, Step 259, Loss: 0.03301689028739929\n",
            "Epoch 43, Step 260, Loss: 0.0297789815813303\n",
            "Epoch 43, Step 261, Loss: 0.10212674736976624\n",
            "Epoch 43, Step 262, Loss: 0.05265757068991661\n",
            "Epoch 43, Step 263, Loss: 0.04598892852663994\n",
            "Epoch 43, Step 264, Loss: 0.04014063626527786\n",
            "Epoch 43, Step 265, Loss: 0.05604948103427887\n",
            "Epoch 43, Step 266, Loss: 0.05571114271879196\n",
            "Epoch 43, Step 267, Loss: 0.061653293669223785\n",
            "Epoch 43, Step 268, Loss: 0.07844031602144241\n",
            "Epoch 43, Step 269, Loss: 0.03381926193833351\n",
            "Epoch 43, Step 270, Loss: 0.1193632185459137\n",
            "Epoch 43, Step 271, Loss: 0.02272685430943966\n",
            "Epoch 43, Step 272, Loss: 0.025314489379525185\n",
            "Epoch 43, Step 273, Loss: 0.07657676190137863\n",
            "Epoch 43, Step 274, Loss: 0.05848401412367821\n",
            "Epoch 43, Step 275, Loss: 0.0377657487988472\n",
            "Epoch 43, Step 276, Loss: 0.03546050190925598\n",
            "Epoch 43, Step 277, Loss: 0.11406417936086655\n",
            "Epoch 43, Step 278, Loss: 0.09587568789720535\n",
            "Epoch 43, Step 279, Loss: 0.047909047454595566\n",
            "Epoch 43, Step 280, Loss: 0.11705991625785828\n",
            "Epoch 43, Step 281, Loss: 0.055189162492752075\n",
            "Epoch 43, Step 282, Loss: 0.08161932229995728\n",
            "Epoch 43, Step 283, Loss: 0.11845178157091141\n",
            "Epoch 43, Step 284, Loss: 0.03354133293032646\n",
            "Epoch 43, Step 285, Loss: 0.061065610498189926\n",
            "Epoch 43, Step 286, Loss: 0.06701066344976425\n",
            "Epoch 43, Step 287, Loss: 0.028189005330204964\n",
            "Epoch 43, Step 288, Loss: 0.06409525126218796\n",
            "Epoch 43, Step 289, Loss: 0.030107293277978897\n",
            "Epoch 43, Step 290, Loss: 0.02038409560918808\n",
            "Epoch 43, Step 291, Loss: 0.044387493282556534\n",
            "Epoch 43, Step 292, Loss: 0.06772731989622116\n",
            "Epoch 43, Step 293, Loss: 0.09061254560947418\n",
            "Epoch 43, Step 294, Loss: 0.20817561447620392\n",
            "Epoch 43, Step 295, Loss: 0.0558038204908371\n",
            "Epoch 43, Step 296, Loss: 0.04452267289161682\n",
            "Epoch 43, Step 297, Loss: 0.019618164747953415\n",
            "Epoch 43, Step 298, Loss: 0.029015783220529556\n",
            "Epoch 43, Step 299, Loss: 0.08895425498485565\n",
            "Epoch 43, Step 300, Loss: 0.07627882063388824\n",
            "Epoch 43, Step 301, Loss: 0.07755734771490097\n",
            "Epoch 43, Step 302, Loss: 0.04343895614147186\n",
            "Epoch 43, Step 303, Loss: 0.08694667369127274\n",
            "Epoch 43, Step 304, Loss: 0.057843565940856934\n",
            "Epoch 43, Step 305, Loss: 0.07549697160720825\n",
            "Epoch 43, Step 306, Loss: 0.07058487832546234\n",
            "Epoch 43, Step 307, Loss: 0.07583577930927277\n",
            "Epoch 43, Step 308, Loss: 0.02003692463040352\n",
            "Epoch 43, Step 309, Loss: 0.027838002890348434\n",
            "Epoch 43, Step 310, Loss: 0.04393351450562477\n",
            "Epoch 43, Step 311, Loss: 0.04492056369781494\n",
            "Epoch 43, Step 312, Loss: 0.06280401349067688\n",
            "Epoch 43 end, avg train loss: 0.05608088082779711\n",
            "Epoch 43 end, avg val loss: 0.38372683298738697, accuracy: 91.44%\n",
            "Epoch 44, Step 0, Loss: 0.04853922873735428\n",
            "Epoch 44, Step 1, Loss: 0.0386718213558197\n",
            "Epoch 44, Step 2, Loss: 0.032309599220752716\n",
            "Epoch 44, Step 3, Loss: 0.03981201723217964\n",
            "Epoch 44, Step 4, Loss: 0.004932570271193981\n",
            "Epoch 44, Step 5, Loss: 0.046956345438957214\n",
            "Epoch 44, Step 6, Loss: 0.07759024202823639\n",
            "Epoch 44, Step 7, Loss: 0.034819867461919785\n",
            "Epoch 44, Step 8, Loss: 0.01083312463015318\n",
            "Epoch 44, Step 9, Loss: 0.03396276757121086\n",
            "Epoch 44, Step 10, Loss: 0.0415058396756649\n",
            "Epoch 44, Step 11, Loss: 0.06539323925971985\n",
            "Epoch 44, Step 12, Loss: 0.03850844129920006\n",
            "Epoch 44, Step 13, Loss: 0.035188283771276474\n",
            "Epoch 44, Step 14, Loss: 0.012701510451734066\n",
            "Epoch 44, Step 15, Loss: 0.04949205741286278\n",
            "Epoch 44, Step 16, Loss: 0.06979011744260788\n",
            "Epoch 44, Step 17, Loss: 0.04217120632529259\n",
            "Epoch 44, Step 18, Loss: 0.0700264573097229\n",
            "Epoch 44, Step 19, Loss: 0.06333687156438828\n",
            "Epoch 44, Step 20, Loss: 0.07141020894050598\n",
            "Epoch 44, Step 21, Loss: 0.04989581182599068\n",
            "Epoch 44, Step 22, Loss: 0.02817549742758274\n",
            "Epoch 44, Step 23, Loss: 0.020972074940800667\n",
            "Epoch 44, Step 24, Loss: 0.04421987012028694\n",
            "Epoch 44, Step 25, Loss: 0.06322472542524338\n",
            "Epoch 44, Step 26, Loss: 0.02355838008224964\n",
            "Epoch 44, Step 27, Loss: 0.034451670944690704\n",
            "Epoch 44, Step 28, Loss: 0.015995485708117485\n",
            "Epoch 44, Step 29, Loss: 0.048809804022312164\n",
            "Epoch 44, Step 30, Loss: 0.020419618114829063\n",
            "Epoch 44, Step 31, Loss: 0.027407152578234673\n",
            "Epoch 44, Step 32, Loss: 0.021463973447680473\n",
            "Epoch 44, Step 33, Loss: 0.01749248243868351\n",
            "Epoch 44, Step 34, Loss: 0.04246003180742264\n",
            "Epoch 44, Step 35, Loss: 0.06777704507112503\n",
            "Epoch 44, Step 36, Loss: 0.01440166961401701\n",
            "Epoch 44, Step 37, Loss: 0.03564874082803726\n",
            "Epoch 44, Step 38, Loss: 0.0420139916241169\n",
            "Epoch 44, Step 39, Loss: 0.009146900847554207\n",
            "Epoch 44, Step 40, Loss: 0.01814359799027443\n",
            "Epoch 44, Step 41, Loss: 0.047267474234104156\n",
            "Epoch 44, Step 42, Loss: 0.028518177568912506\n",
            "Epoch 44, Step 43, Loss: 0.0240870863199234\n",
            "Epoch 44, Step 44, Loss: 0.02117227204144001\n",
            "Epoch 44, Step 45, Loss: 0.02777332067489624\n",
            "Epoch 44, Step 46, Loss: 0.0760761946439743\n",
            "Epoch 44, Step 47, Loss: 0.08693476766347885\n",
            "Epoch 44, Step 48, Loss: 0.04563238471746445\n",
            "Epoch 44, Step 49, Loss: 0.08348044008016586\n",
            "Epoch 44, Step 50, Loss: 0.013965224847197533\n",
            "Epoch 44, Step 51, Loss: 0.04571691155433655\n",
            "Epoch 44, Step 52, Loss: 0.03655108064413071\n",
            "Epoch 44, Step 53, Loss: 0.06902366131544113\n",
            "Epoch 44, Step 54, Loss: 0.0073858993127942085\n",
            "Epoch 44, Step 55, Loss: 0.0338674820959568\n",
            "Epoch 44, Step 56, Loss: 0.02085808292031288\n",
            "Epoch 44, Step 57, Loss: 0.06416013091802597\n",
            "Epoch 44, Step 58, Loss: 0.057529427111148834\n",
            "Epoch 44, Step 59, Loss: 0.03259976580739021\n",
            "Epoch 44, Step 60, Loss: 0.013490401208400726\n",
            "Epoch 44, Step 61, Loss: 0.008593913167715073\n",
            "Epoch 44, Step 62, Loss: 0.011086424812674522\n",
            "Epoch 44, Step 63, Loss: 0.020539013668894768\n",
            "Epoch 44, Step 64, Loss: 0.022864675149321556\n",
            "Epoch 44, Step 65, Loss: 0.011713890358805656\n",
            "Epoch 44, Step 66, Loss: 0.04156733304262161\n",
            "Epoch 44, Step 67, Loss: 0.015011642128229141\n",
            "Epoch 44, Step 68, Loss: 0.08742348849773407\n",
            "Epoch 44, Step 69, Loss: 0.0929352194070816\n",
            "Epoch 44, Step 70, Loss: 0.07234066724777222\n",
            "Epoch 44, Step 71, Loss: 0.05883575230836868\n",
            "Epoch 44, Step 72, Loss: 0.03097156248986721\n",
            "Epoch 44, Step 73, Loss: 0.06030173599720001\n",
            "Epoch 44, Step 74, Loss: 0.022965360432863235\n",
            "Epoch 44, Step 75, Loss: 0.12301397323608398\n",
            "Epoch 44, Step 76, Loss: 0.025746142491698265\n",
            "Epoch 44, Step 77, Loss: 0.057048432528972626\n",
            "Epoch 44, Step 78, Loss: 0.024011854082345963\n",
            "Epoch 44, Step 79, Loss: 0.015471315942704678\n",
            "Epoch 44, Step 80, Loss: 0.05150701850652695\n",
            "Epoch 44, Step 81, Loss: 0.04551282152533531\n",
            "Epoch 44, Step 82, Loss: 0.09932423382997513\n",
            "Epoch 44, Step 83, Loss: 0.07833944261074066\n",
            "Epoch 44, Step 84, Loss: 0.05867964029312134\n",
            "Epoch 44, Step 85, Loss: 0.073837511241436\n",
            "Epoch 44, Step 86, Loss: 0.04018383100628853\n",
            "Epoch 44, Step 87, Loss: 0.09225042164325714\n",
            "Epoch 44, Step 88, Loss: 0.03207283094525337\n",
            "Epoch 44, Step 89, Loss: 0.09178740531206131\n",
            "Epoch 44, Step 90, Loss: 0.030110027641057968\n",
            "Epoch 44, Step 91, Loss: 0.03184797614812851\n",
            "Epoch 44, Step 92, Loss: 0.02875555120408535\n",
            "Epoch 44, Step 93, Loss: 0.04438726231455803\n",
            "Epoch 44, Step 94, Loss: 0.07320166379213333\n",
            "Epoch 44, Step 95, Loss: 0.0948396772146225\n",
            "Epoch 44, Step 96, Loss: 0.16074682772159576\n",
            "Epoch 44, Step 97, Loss: 0.03312008082866669\n",
            "Epoch 44, Step 98, Loss: 0.036334630101919174\n",
            "Epoch 44, Step 99, Loss: 0.0744529664516449\n",
            "Epoch 44, Step 100, Loss: 0.05543700233101845\n",
            "Epoch 44, Step 101, Loss: 0.03593352064490318\n",
            "Epoch 44, Step 102, Loss: 0.04563141614198685\n",
            "Epoch 44, Step 103, Loss: 0.10159517824649811\n",
            "Epoch 44, Step 104, Loss: 0.05064038932323456\n",
            "Epoch 44, Step 105, Loss: 0.037893135100603104\n",
            "Epoch 44, Step 106, Loss: 0.05892081931233406\n",
            "Epoch 44, Step 107, Loss: 0.02842864580452442\n",
            "Epoch 44, Step 108, Loss: 0.11345268040895462\n",
            "Epoch 44, Step 109, Loss: 0.0288697462528944\n",
            "Epoch 44, Step 110, Loss: 0.02684701234102249\n",
            "Epoch 44, Step 111, Loss: 0.03235650435090065\n",
            "Epoch 44, Step 112, Loss: 0.03858907148241997\n",
            "Epoch 44, Step 113, Loss: 0.038176365196704865\n",
            "Epoch 44, Step 114, Loss: 0.060592155903577805\n",
            "Epoch 44, Step 115, Loss: 0.027045808732509613\n",
            "Epoch 44, Step 116, Loss: 0.0783000960946083\n",
            "Epoch 44, Step 117, Loss: 0.02580006793141365\n",
            "Epoch 44, Step 118, Loss: 0.05582086741924286\n",
            "Epoch 44, Step 119, Loss: 0.03379378095269203\n",
            "Epoch 44, Step 120, Loss: 0.016766298562288284\n",
            "Epoch 44, Step 121, Loss: 0.015213394537568092\n",
            "Epoch 44, Step 122, Loss: 0.1091843843460083\n",
            "Epoch 44, Step 123, Loss: 0.024171659722924232\n",
            "Epoch 44, Step 124, Loss: 0.025490112602710724\n",
            "Epoch 44, Step 125, Loss: 0.11682344228029251\n",
            "Epoch 44, Step 126, Loss: 0.09508592635393143\n",
            "Epoch 44, Step 127, Loss: 0.024464694783091545\n",
            "Epoch 44, Step 128, Loss: 0.019695060327649117\n",
            "Epoch 44, Step 129, Loss: 0.04207837954163551\n",
            "Epoch 44, Step 130, Loss: 0.1193043664097786\n",
            "Epoch 44, Step 131, Loss: 0.08165819197893143\n",
            "Epoch 44, Step 132, Loss: 0.013917472213506699\n",
            "Epoch 44, Step 133, Loss: 0.052580319344997406\n",
            "Epoch 44, Step 134, Loss: 0.048765260726213455\n",
            "Epoch 44, Step 135, Loss: 0.09155365079641342\n",
            "Epoch 44, Step 136, Loss: 0.05352955684065819\n",
            "Epoch 44, Step 137, Loss: 0.060872867703437805\n",
            "Epoch 44, Step 138, Loss: 0.09266974776983261\n",
            "Epoch 44, Step 139, Loss: 0.021212473511695862\n",
            "Epoch 44, Step 140, Loss: 0.013309862464666367\n",
            "Epoch 44, Step 141, Loss: 0.10355520993471146\n",
            "Epoch 44, Step 142, Loss: 0.03938239440321922\n",
            "Epoch 44, Step 143, Loss: 0.026964109390974045\n",
            "Epoch 44, Step 144, Loss: 0.11825152486562729\n",
            "Epoch 44, Step 145, Loss: 0.05383883789181709\n",
            "Epoch 44, Step 146, Loss: 0.044863197952508926\n",
            "Epoch 44, Step 147, Loss: 0.02428301051259041\n",
            "Epoch 44, Step 148, Loss: 0.03169304504990578\n",
            "Epoch 44, Step 149, Loss: 0.02548583410680294\n",
            "Epoch 44, Step 150, Loss: 0.0557841919362545\n",
            "Epoch 44, Step 151, Loss: 0.04028195142745972\n",
            "Epoch 44, Step 152, Loss: 0.021311070770025253\n",
            "Epoch 44, Step 153, Loss: 0.03569542616605759\n",
            "Epoch 44, Step 154, Loss: 0.07173902541399002\n",
            "Epoch 44, Step 155, Loss: 0.09053097665309906\n",
            "Epoch 44, Step 156, Loss: 0.03368565812706947\n",
            "Epoch 44, Step 157, Loss: 0.04719129204750061\n",
            "Epoch 44, Step 158, Loss: 0.07368334382772446\n",
            "Epoch 44, Step 159, Loss: 0.008310438133776188\n",
            "Epoch 44, Step 160, Loss: 0.06718689948320389\n",
            "Epoch 44, Step 161, Loss: 0.004887547343969345\n",
            "Epoch 44, Step 162, Loss: 0.09896029531955719\n",
            "Epoch 44, Step 163, Loss: 0.05973073095083237\n",
            "Epoch 44, Step 164, Loss: 0.05183538421988487\n",
            "Epoch 44, Step 165, Loss: 0.06909839063882828\n",
            "Epoch 44, Step 166, Loss: 0.02521476522088051\n",
            "Epoch 44, Step 167, Loss: 0.044934727251529694\n",
            "Epoch 44, Step 168, Loss: 0.04023261368274689\n",
            "Epoch 44, Step 169, Loss: 0.10063091665506363\n",
            "Epoch 44, Step 170, Loss: 0.0268954299390316\n",
            "Epoch 44, Step 171, Loss: 0.1260540783405304\n",
            "Epoch 44, Step 172, Loss: 0.12466371804475784\n",
            "Epoch 44, Step 173, Loss: 0.06002047657966614\n",
            "Epoch 44, Step 174, Loss: 0.05933153256773949\n",
            "Epoch 44, Step 175, Loss: 0.012340279296040535\n",
            "Epoch 44, Step 176, Loss: 0.10468018800020218\n",
            "Epoch 44, Step 177, Loss: 0.09447237104177475\n",
            "Epoch 44, Step 178, Loss: 0.14243102073669434\n",
            "Epoch 44, Step 179, Loss: 0.009716442786157131\n",
            "Epoch 44, Step 180, Loss: 0.027516985312104225\n",
            "Epoch 44, Step 181, Loss: 0.042882099747657776\n",
            "Epoch 44, Step 182, Loss: 0.09085272252559662\n",
            "Epoch 44, Step 183, Loss: 0.020706839859485626\n",
            "Epoch 44, Step 184, Loss: 0.13164500892162323\n",
            "Epoch 44, Step 185, Loss: 0.09789260476827621\n",
            "Epoch 44, Step 186, Loss: 0.0720655769109726\n",
            "Epoch 44, Step 187, Loss: 0.031709473580121994\n",
            "Epoch 44, Step 188, Loss: 0.06750465929508209\n",
            "Epoch 44, Step 189, Loss: 0.04743006080389023\n",
            "Epoch 44, Step 190, Loss: 0.06684430688619614\n",
            "Epoch 44, Step 191, Loss: 0.06443225592374802\n",
            "Epoch 44, Step 192, Loss: 0.03901279345154762\n",
            "Epoch 44, Step 193, Loss: 0.05057645961642265\n",
            "Epoch 44, Step 194, Loss: 0.021579179912805557\n",
            "Epoch 44, Step 195, Loss: 0.10632699728012085\n",
            "Epoch 44, Step 196, Loss: 0.03079960122704506\n",
            "Epoch 44, Step 197, Loss: 0.0436667799949646\n",
            "Epoch 44, Step 198, Loss: 0.023516204208135605\n",
            "Epoch 44, Step 199, Loss: 0.07381664216518402\n",
            "Epoch 44, Step 200, Loss: 0.029574459418654442\n",
            "Epoch 44, Step 201, Loss: 0.03486545383930206\n",
            "Epoch 44, Step 202, Loss: 0.048466749489307404\n",
            "Epoch 44, Step 203, Loss: 0.022453967481851578\n",
            "Epoch 44, Step 204, Loss: 0.12411278486251831\n",
            "Epoch 44, Step 205, Loss: 0.02954994887113571\n",
            "Epoch 44, Step 206, Loss: 0.045978058129549026\n",
            "Epoch 44, Step 207, Loss: 0.018085097894072533\n",
            "Epoch 44, Step 208, Loss: 0.031079106032848358\n",
            "Epoch 44, Step 209, Loss: 0.0570138655602932\n",
            "Epoch 44, Step 210, Loss: 0.11440041661262512\n",
            "Epoch 44, Step 211, Loss: 0.06484575569629669\n",
            "Epoch 44, Step 212, Loss: 0.06141570582985878\n",
            "Epoch 44, Step 213, Loss: 0.039377786219120026\n",
            "Epoch 44, Step 214, Loss: 0.06202510744333267\n",
            "Epoch 44, Step 215, Loss: 0.03477480635046959\n",
            "Epoch 44, Step 216, Loss: 0.058332208544015884\n",
            "Epoch 44, Step 217, Loss: 0.02223055437207222\n",
            "Epoch 44, Step 218, Loss: 0.07297713309526443\n",
            "Epoch 44, Step 219, Loss: 0.06203664094209671\n",
            "Epoch 44, Step 220, Loss: 0.08581453561782837\n",
            "Epoch 44, Step 221, Loss: 0.050506480038166046\n",
            "Epoch 44, Step 222, Loss: 0.08659234642982483\n",
            "Epoch 44, Step 223, Loss: 0.0346231535077095\n",
            "Epoch 44, Step 224, Loss: 0.07411153614521027\n",
            "Epoch 44, Step 225, Loss: 0.09049757570028305\n",
            "Epoch 44, Step 226, Loss: 0.04663573578000069\n",
            "Epoch 44, Step 227, Loss: 0.06106879934668541\n",
            "Epoch 44, Step 228, Loss: 0.08770666271448135\n",
            "Epoch 44, Step 229, Loss: 0.07658635079860687\n",
            "Epoch 44, Step 230, Loss: 0.045500997453927994\n",
            "Epoch 44, Step 231, Loss: 0.1305960863828659\n",
            "Epoch 44, Step 232, Loss: 0.04163205996155739\n",
            "Epoch 44, Step 233, Loss: 0.051160652190446854\n",
            "Epoch 44, Step 234, Loss: 0.053205132484436035\n",
            "Epoch 44, Step 235, Loss: 0.07305829226970673\n",
            "Epoch 44, Step 236, Loss: 0.012568825855851173\n",
            "Epoch 44, Step 237, Loss: 0.020686035975813866\n",
            "Epoch 44, Step 238, Loss: 0.11045651882886887\n",
            "Epoch 44, Step 239, Loss: 0.03767814859747887\n",
            "Epoch 44, Step 240, Loss: 0.03016001544892788\n",
            "Epoch 44, Step 241, Loss: 0.014268186874687672\n",
            "Epoch 44, Step 242, Loss: 0.05899297818541527\n",
            "Epoch 44, Step 243, Loss: 0.09401246905326843\n",
            "Epoch 44, Step 244, Loss: 0.070188008248806\n",
            "Epoch 44, Step 245, Loss: 0.04442182183265686\n",
            "Epoch 44, Step 246, Loss: 0.05424933880567551\n",
            "Epoch 44, Step 247, Loss: 0.0491706021130085\n",
            "Epoch 44, Step 248, Loss: 0.047841474413871765\n",
            "Epoch 44, Step 249, Loss: 0.04494483768939972\n",
            "Epoch 44, Step 250, Loss: 0.009907684288918972\n",
            "Epoch 44, Step 251, Loss: 0.05181429162621498\n",
            "Epoch 44, Step 252, Loss: 0.07244528830051422\n",
            "Epoch 44, Step 253, Loss: 0.049366775900125504\n",
            "Epoch 44, Step 254, Loss: 0.08502254635095596\n",
            "Epoch 44, Step 255, Loss: 0.08950018137693405\n",
            "Epoch 44, Step 256, Loss: 0.0729103833436966\n",
            "Epoch 44, Step 257, Loss: 0.06148375943303108\n",
            "Epoch 44, Step 258, Loss: 0.021557247266173363\n",
            "Epoch 44, Step 259, Loss: 0.034557320177555084\n",
            "Epoch 44, Step 260, Loss: 0.022238630801439285\n",
            "Epoch 44, Step 261, Loss: 0.03441871330142021\n",
            "Epoch 44, Step 262, Loss: 0.03811683505773544\n",
            "Epoch 44, Step 263, Loss: 0.052656251937150955\n",
            "Epoch 44, Step 264, Loss: 0.13281060755252838\n",
            "Epoch 44, Step 265, Loss: 0.04338354989886284\n",
            "Epoch 44, Step 266, Loss: 0.04757285118103027\n",
            "Epoch 44, Step 267, Loss: 0.054542284458875656\n",
            "Epoch 44, Step 268, Loss: 0.10023240000009537\n",
            "Epoch 44, Step 269, Loss: 0.06995360553264618\n",
            "Epoch 44, Step 270, Loss: 0.008611507713794708\n",
            "Epoch 44, Step 271, Loss: 0.005296185612678528\n",
            "Epoch 44, Step 272, Loss: 0.0585128515958786\n",
            "Epoch 44, Step 273, Loss: 0.05008500814437866\n",
            "Epoch 44, Step 274, Loss: 0.09371354430913925\n",
            "Epoch 44, Step 275, Loss: 0.06244348734617233\n",
            "Epoch 44, Step 276, Loss: 0.11911001801490784\n",
            "Epoch 44, Step 277, Loss: 0.05568091571331024\n",
            "Epoch 44, Step 278, Loss: 0.020256493240594864\n",
            "Epoch 44, Step 279, Loss: 0.07793872058391571\n",
            "Epoch 44, Step 280, Loss: 0.0892857015132904\n",
            "Epoch 44, Step 281, Loss: 0.13455425202846527\n",
            "Epoch 44, Step 282, Loss: 0.039288975298404694\n",
            "Epoch 44, Step 283, Loss: 0.08353127539157867\n",
            "Epoch 44, Step 284, Loss: 0.1324724704027176\n",
            "Epoch 44, Step 285, Loss: 0.043201833963394165\n",
            "Epoch 44, Step 286, Loss: 0.02655741758644581\n",
            "Epoch 44, Step 287, Loss: 0.07012176513671875\n",
            "Epoch 44, Step 288, Loss: 0.05190558731555939\n",
            "Epoch 44, Step 289, Loss: 0.0690188780426979\n",
            "Epoch 44, Step 290, Loss: 0.017568323761224747\n",
            "Epoch 44, Step 291, Loss: 0.10462649911642075\n",
            "Epoch 44, Step 292, Loss: 0.08214130252599716\n",
            "Epoch 44, Step 293, Loss: 0.08695901185274124\n",
            "Epoch 44, Step 294, Loss: 0.0356743261218071\n",
            "Epoch 44, Step 295, Loss: 0.034690722823143005\n",
            "Epoch 44, Step 296, Loss: 0.11693228781223297\n",
            "Epoch 44, Step 297, Loss: 0.08581119775772095\n",
            "Epoch 44, Step 298, Loss: 0.07248671352863312\n",
            "Epoch 44, Step 299, Loss: 0.07963983714580536\n",
            "Epoch 44, Step 300, Loss: 0.06605812162160873\n",
            "Epoch 44, Step 301, Loss: 0.020353183150291443\n",
            "Epoch 44, Step 302, Loss: 0.047090109437704086\n",
            "Epoch 44, Step 303, Loss: 0.06720481067895889\n",
            "Epoch 44, Step 304, Loss: 0.062360428273677826\n",
            "Epoch 44, Step 305, Loss: 0.13542440533638\n",
            "Epoch 44, Step 306, Loss: 0.044576246291399\n",
            "Epoch 44, Step 307, Loss: 0.06227826699614525\n",
            "Epoch 44, Step 308, Loss: 0.04412194713950157\n",
            "Epoch 44, Step 309, Loss: 0.1682947427034378\n",
            "Epoch 44, Step 310, Loss: 0.05553426221013069\n",
            "Epoch 44, Step 311, Loss: 0.06201133131980896\n",
            "Epoch 44, Step 312, Loss: 0.0418308824300766\n",
            "Epoch 44 end, avg train loss: 0.0538620768477932\n",
            "Epoch 44 end, avg val loss: 0.3899425393607043, accuracy: 91.62%\n",
            "Epoch 45, Step 0, Loss: 0.023413652554154396\n",
            "Epoch 45, Step 1, Loss: 0.017070870846509933\n",
            "Epoch 45, Step 2, Loss: 0.05940072983503342\n",
            "Epoch 45, Step 3, Loss: 0.020461970940232277\n",
            "Epoch 45, Step 4, Loss: 0.06766635924577713\n",
            "Epoch 45, Step 5, Loss: 0.052604202181100845\n",
            "Epoch 45, Step 6, Loss: 0.05828135460615158\n",
            "Epoch 45, Step 7, Loss: 0.042026422917842865\n",
            "Epoch 45, Step 8, Loss: 0.03507987782359123\n",
            "Epoch 45, Step 9, Loss: 0.1077992394566536\n",
            "Epoch 45, Step 10, Loss: 0.07711204886436462\n",
            "Epoch 45, Step 11, Loss: 0.08661497384309769\n",
            "Epoch 45, Step 12, Loss: 0.013206991367042065\n",
            "Epoch 45, Step 13, Loss: 0.01901005394756794\n",
            "Epoch 45, Step 14, Loss: 0.035047538578510284\n",
            "Epoch 45, Step 15, Loss: 0.050349052995443344\n",
            "Epoch 45, Step 16, Loss: 0.05396111682057381\n",
            "Epoch 45, Step 17, Loss: 0.05307317525148392\n",
            "Epoch 45, Step 18, Loss: 0.1191113218665123\n",
            "Epoch 45, Step 19, Loss: 0.03871035575866699\n",
            "Epoch 45, Step 20, Loss: 0.022114135324954987\n",
            "Epoch 45, Step 21, Loss: 0.012762344442307949\n",
            "Epoch 45, Step 22, Loss: 0.04228745400905609\n",
            "Epoch 45, Step 23, Loss: 0.08563830703496933\n",
            "Epoch 45, Step 24, Loss: 0.06072314456105232\n",
            "Epoch 45, Step 25, Loss: 0.024675903841853142\n",
            "Epoch 45, Step 26, Loss: 0.0766102597117424\n",
            "Epoch 45, Step 27, Loss: 0.018920304253697395\n",
            "Epoch 45, Step 28, Loss: 0.03265073895454407\n",
            "Epoch 45, Step 29, Loss: 0.046858493238687515\n",
            "Epoch 45, Step 30, Loss: 0.06745800375938416\n",
            "Epoch 45, Step 31, Loss: 0.039635639637708664\n",
            "Epoch 45, Step 32, Loss: 0.013218236155807972\n",
            "Epoch 45, Step 33, Loss: 0.03892660513520241\n",
            "Epoch 45, Step 34, Loss: 0.12096996605396271\n",
            "Epoch 45, Step 35, Loss: 0.029403096064925194\n",
            "Epoch 45, Step 36, Loss: 0.09255558252334595\n",
            "Epoch 45, Step 37, Loss: 0.017141155898571014\n",
            "Epoch 45, Step 38, Loss: 0.10324779152870178\n",
            "Epoch 45, Step 39, Loss: 0.007167251780629158\n",
            "Epoch 45, Step 40, Loss: 0.014395796693861485\n",
            "Epoch 45, Step 41, Loss: 0.02627740614116192\n",
            "Epoch 45, Step 42, Loss: 0.10361161082983017\n",
            "Epoch 45, Step 43, Loss: 0.02715934067964554\n",
            "Epoch 45, Step 44, Loss: 0.03548485040664673\n",
            "Epoch 45, Step 45, Loss: 0.04631135240197182\n",
            "Epoch 45, Step 46, Loss: 0.02346074767410755\n",
            "Epoch 45, Step 47, Loss: 0.008377501741051674\n",
            "Epoch 45, Step 48, Loss: 0.0611569806933403\n",
            "Epoch 45, Step 49, Loss: 0.058371927589178085\n",
            "Epoch 45, Step 50, Loss: 0.09166666120290756\n",
            "Epoch 45, Step 51, Loss: 0.08551277965307236\n",
            "Epoch 45, Step 52, Loss: 0.05799522623419762\n",
            "Epoch 45, Step 53, Loss: 0.02650165557861328\n",
            "Epoch 45, Step 54, Loss: 0.10919104516506195\n",
            "Epoch 45, Step 55, Loss: 0.07984373718500137\n",
            "Epoch 45, Step 56, Loss: 0.05225827544927597\n",
            "Epoch 45, Step 57, Loss: 0.03620125725865364\n",
            "Epoch 45, Step 58, Loss: 0.04544105753302574\n",
            "Epoch 45, Step 59, Loss: 0.08873524516820908\n",
            "Epoch 45, Step 60, Loss: 0.07304546982049942\n",
            "Epoch 45, Step 61, Loss: 0.05965730547904968\n",
            "Epoch 45, Step 62, Loss: 0.07666371017694473\n",
            "Epoch 45, Step 63, Loss: 0.09277843683958054\n",
            "Epoch 45, Step 64, Loss: 0.05116189271211624\n",
            "Epoch 45, Step 65, Loss: 0.13987557590007782\n",
            "Epoch 45, Step 66, Loss: 0.03814947232604027\n",
            "Epoch 45, Step 67, Loss: 0.045088786631822586\n",
            "Epoch 45, Step 68, Loss: 0.0635746642947197\n",
            "Epoch 45, Step 69, Loss: 0.009143849834799767\n",
            "Epoch 45, Step 70, Loss: 0.05050482600927353\n",
            "Epoch 45, Step 71, Loss: 0.04937645047903061\n",
            "Epoch 45, Step 72, Loss: 0.06344759464263916\n",
            "Epoch 45, Step 73, Loss: 0.032631248235702515\n",
            "Epoch 45, Step 74, Loss: 0.07168831676244736\n",
            "Epoch 45, Step 75, Loss: 0.024852033704519272\n",
            "Epoch 45, Step 76, Loss: 0.09694907069206238\n",
            "Epoch 45, Step 77, Loss: 0.15908390283584595\n",
            "Epoch 45, Step 78, Loss: 0.027525335550308228\n",
            "Epoch 45, Step 79, Loss: 0.01542067714035511\n",
            "Epoch 45, Step 80, Loss: 0.04458703473210335\n",
            "Epoch 45, Step 81, Loss: 0.024397987872362137\n",
            "Epoch 45, Step 82, Loss: 0.05155910551548004\n",
            "Epoch 45, Step 83, Loss: 0.06892184168100357\n",
            "Epoch 45, Step 84, Loss: 0.11586248874664307\n",
            "Epoch 45, Step 85, Loss: 0.04933647811412811\n",
            "Epoch 45, Step 86, Loss: 0.13309895992279053\n",
            "Epoch 45, Step 87, Loss: 0.05338672921061516\n",
            "Epoch 45, Step 88, Loss: 0.033086251467466354\n",
            "Epoch 45, Step 89, Loss: 0.021462297067046165\n",
            "Epoch 45, Step 90, Loss: 0.0904557928442955\n",
            "Epoch 45, Step 91, Loss: 0.07386317104101181\n",
            "Epoch 45, Step 92, Loss: 0.05524072051048279\n",
            "Epoch 45, Step 93, Loss: 0.10709598660469055\n",
            "Epoch 45, Step 94, Loss: 0.08598817884922028\n",
            "Epoch 45, Step 95, Loss: 0.15575550496578217\n",
            "Epoch 45, Step 96, Loss: 0.07040844857692719\n",
            "Epoch 45, Step 97, Loss: 0.05389523133635521\n",
            "Epoch 45, Step 98, Loss: 0.03510890528559685\n",
            "Epoch 45, Step 99, Loss: 0.044667668640613556\n",
            "Epoch 45, Step 100, Loss: 0.0909985601902008\n",
            "Epoch 45, Step 101, Loss: 0.04309992119669914\n",
            "Epoch 45, Step 102, Loss: 0.03409415856003761\n",
            "Epoch 45, Step 103, Loss: 0.06775832921266556\n",
            "Epoch 45, Step 104, Loss: 0.08664810657501221\n",
            "Epoch 45, Step 105, Loss: 0.06887426972389221\n",
            "Epoch 45, Step 106, Loss: 0.09355413913726807\n",
            "Epoch 45, Step 107, Loss: 0.0701172724366188\n",
            "Epoch 45, Step 108, Loss: 0.03895309567451477\n",
            "Epoch 45, Step 109, Loss: 0.050682950764894485\n",
            "Epoch 45, Step 110, Loss: 0.10498972982168198\n",
            "Epoch 45, Step 111, Loss: 0.045084793120622635\n",
            "Epoch 45, Step 112, Loss: 0.11391719430685043\n",
            "Epoch 45, Step 113, Loss: 0.03588946908712387\n",
            "Epoch 45, Step 114, Loss: 0.03703083097934723\n",
            "Epoch 45, Step 115, Loss: 0.030701274052262306\n",
            "Epoch 45, Step 116, Loss: 0.02892937697470188\n",
            "Epoch 45, Step 117, Loss: 0.02191496267914772\n",
            "Epoch 45, Step 118, Loss: 0.0776764452457428\n",
            "Epoch 45, Step 119, Loss: 0.0854087546467781\n",
            "Epoch 45, Step 120, Loss: 0.029460333287715912\n",
            "Epoch 45, Step 121, Loss: 0.03788519650697708\n",
            "Epoch 45, Step 122, Loss: 0.08087555319070816\n",
            "Epoch 45, Step 123, Loss: 0.07368311285972595\n",
            "Epoch 45, Step 124, Loss: 0.04390722140669823\n",
            "Epoch 45, Step 125, Loss: 0.01582144945859909\n",
            "Epoch 45, Step 126, Loss: 0.12095063924789429\n",
            "Epoch 45, Step 127, Loss: 0.09712636470794678\n",
            "Epoch 45, Step 128, Loss: 0.046502046287059784\n",
            "Epoch 45, Step 129, Loss: 0.11122612655162811\n",
            "Epoch 45, Step 130, Loss: 0.03414374217391014\n",
            "Epoch 45, Step 131, Loss: 0.05327785015106201\n",
            "Epoch 45, Step 132, Loss: 0.09060779958963394\n",
            "Epoch 45, Step 133, Loss: 0.018081465736031532\n",
            "Epoch 45, Step 134, Loss: 0.05503219738602638\n",
            "Epoch 45, Step 135, Loss: 0.10429549217224121\n",
            "Epoch 45, Step 136, Loss: 0.1070089042186737\n",
            "Epoch 45, Step 137, Loss: 0.03047347441315651\n",
            "Epoch 45, Step 138, Loss: 0.041858743876218796\n",
            "Epoch 45, Step 139, Loss: 0.025189895182847977\n",
            "Epoch 45, Step 140, Loss: 0.08283919095993042\n",
            "Epoch 45, Step 141, Loss: 0.02025594562292099\n",
            "Epoch 45, Step 142, Loss: 0.04404810070991516\n",
            "Epoch 45, Step 143, Loss: 0.05414016544818878\n",
            "Epoch 45, Step 144, Loss: 0.055223554372787476\n",
            "Epoch 45, Step 145, Loss: 0.032791778445243835\n",
            "Epoch 45, Step 146, Loss: 0.04719465225934982\n",
            "Epoch 45, Step 147, Loss: 0.03100411221385002\n",
            "Epoch 45, Step 148, Loss: 0.039453670382499695\n",
            "Epoch 45, Step 149, Loss: 0.02969961427152157\n",
            "Epoch 45, Step 150, Loss: 0.030069822445511818\n",
            "Epoch 45, Step 151, Loss: 0.023770952597260475\n",
            "Epoch 45, Step 152, Loss: 0.11493057757616043\n",
            "Epoch 45, Step 153, Loss: 0.09131573885679245\n",
            "Epoch 45, Step 154, Loss: 0.08158085495233536\n",
            "Epoch 45, Step 155, Loss: 0.030122511088848114\n",
            "Epoch 45, Step 156, Loss: 0.08311008661985397\n",
            "Epoch 45, Step 157, Loss: 0.04027441889047623\n",
            "Epoch 45, Step 158, Loss: 0.03538820892572403\n",
            "Epoch 45, Step 159, Loss: 0.03333910182118416\n",
            "Epoch 45, Step 160, Loss: 0.058034978806972504\n",
            "Epoch 45, Step 161, Loss: 0.07004494220018387\n",
            "Epoch 45, Step 162, Loss: 0.05122584477066994\n",
            "Epoch 45, Step 163, Loss: 0.08382612466812134\n",
            "Epoch 45, Step 164, Loss: 0.05002349987626076\n",
            "Epoch 45, Step 165, Loss: 0.06877055764198303\n",
            "Epoch 45, Step 166, Loss: 0.030272524803876877\n",
            "Epoch 45, Step 167, Loss: 0.09709221869707108\n",
            "Epoch 45, Step 168, Loss: 0.07053203880786896\n",
            "Epoch 45, Step 169, Loss: 0.07032541930675507\n",
            "Epoch 45, Step 170, Loss: 0.1235571876168251\n",
            "Epoch 45, Step 171, Loss: 0.06000681221485138\n",
            "Epoch 45, Step 172, Loss: 0.020795894786715508\n",
            "Epoch 45, Step 173, Loss: 0.08708415180444717\n",
            "Epoch 45, Step 174, Loss: 0.029066026210784912\n",
            "Epoch 45, Step 175, Loss: 0.03467709943652153\n",
            "Epoch 45, Step 176, Loss: 0.0663335770368576\n",
            "Epoch 45, Step 177, Loss: 0.038582783192396164\n",
            "Epoch 45, Step 178, Loss: 0.040828295052051544\n",
            "Epoch 45, Step 179, Loss: 0.039608944207429886\n",
            "Epoch 45, Step 180, Loss: 0.021498695015907288\n",
            "Epoch 45, Step 181, Loss: 0.052944429218769073\n",
            "Epoch 45, Step 182, Loss: 0.06726720184087753\n",
            "Epoch 45, Step 183, Loss: 0.05382828414440155\n",
            "Epoch 45, Step 184, Loss: 0.027964327484369278\n",
            "Epoch 45, Step 185, Loss: 0.09502250701189041\n",
            "Epoch 45, Step 186, Loss: 0.059135712683200836\n",
            "Epoch 45, Step 187, Loss: 0.07554370164871216\n",
            "Epoch 45, Step 188, Loss: 0.05286133289337158\n",
            "Epoch 45, Step 189, Loss: 0.019784139469265938\n",
            "Epoch 45, Step 190, Loss: 0.03712457790970802\n",
            "Epoch 45, Step 191, Loss: 0.03786102682352066\n",
            "Epoch 45, Step 192, Loss: 0.09582711011171341\n",
            "Epoch 45, Step 193, Loss: 0.09778103977441788\n",
            "Epoch 45, Step 194, Loss: 0.030973108485341072\n",
            "Epoch 45, Step 195, Loss: 0.05602835863828659\n",
            "Epoch 45, Step 196, Loss: 0.021047106012701988\n",
            "Epoch 45, Step 197, Loss: 0.057348813861608505\n",
            "Epoch 45, Step 198, Loss: 0.01959393545985222\n",
            "Epoch 45, Step 199, Loss: 0.062102898955345154\n",
            "Epoch 45, Step 200, Loss: 0.07290690392255783\n",
            "Epoch 45, Step 201, Loss: 0.00900573842227459\n",
            "Epoch 45, Step 202, Loss: 0.022152911871671677\n",
            "Epoch 45, Step 203, Loss: 0.03736228495836258\n",
            "Epoch 45, Step 204, Loss: 0.024334628134965897\n",
            "Epoch 45, Step 205, Loss: 0.11030171811580658\n",
            "Epoch 45, Step 206, Loss: 0.02521953359246254\n",
            "Epoch 45, Step 207, Loss: 0.05078861862421036\n",
            "Epoch 45, Step 208, Loss: 0.025083020329475403\n",
            "Epoch 45, Step 209, Loss: 0.029000328853726387\n",
            "Epoch 45, Step 210, Loss: 0.047311943024396896\n",
            "Epoch 45, Step 211, Loss: 0.01692335307598114\n",
            "Epoch 45, Step 212, Loss: 0.048145685344934464\n",
            "Epoch 45, Step 213, Loss: 0.0331277959048748\n",
            "Epoch 45, Step 214, Loss: 0.05134749412536621\n",
            "Epoch 45, Step 215, Loss: 0.06231033056974411\n",
            "Epoch 45, Step 216, Loss: 0.10692521184682846\n",
            "Epoch 45, Step 217, Loss: 0.04655378311872482\n",
            "Epoch 45, Step 218, Loss: 0.10058268904685974\n",
            "Epoch 45, Step 219, Loss: 0.07154229283332825\n",
            "Epoch 45, Step 220, Loss: 0.07470180839300156\n",
            "Epoch 45, Step 221, Loss: 0.06510213762521744\n",
            "Epoch 45, Step 222, Loss: 0.05498791113495827\n",
            "Epoch 45, Step 223, Loss: 0.039919186383485794\n",
            "Epoch 45, Step 224, Loss: 0.016103744506835938\n",
            "Epoch 45, Step 225, Loss: 0.059605274349451065\n",
            "Epoch 45, Step 226, Loss: 0.04208235442638397\n",
            "Epoch 45, Step 227, Loss: 0.03746838495135307\n",
            "Epoch 45, Step 228, Loss: 0.0653446614742279\n",
            "Epoch 45, Step 229, Loss: 0.03466493636369705\n",
            "Epoch 45, Step 230, Loss: 0.1131291314959526\n",
            "Epoch 45, Step 231, Loss: 0.023516498506069183\n",
            "Epoch 45, Step 232, Loss: 0.06879475712776184\n",
            "Epoch 45, Step 233, Loss: 0.04305846989154816\n",
            "Epoch 45, Step 234, Loss: 0.0762844830751419\n",
            "Epoch 45, Step 235, Loss: 0.03100006654858589\n",
            "Epoch 45, Step 236, Loss: 0.11942622065544128\n",
            "Epoch 45, Step 237, Loss: 0.05496140569448471\n",
            "Epoch 45, Step 238, Loss: 0.033640988171100616\n",
            "Epoch 45, Step 239, Loss: 0.04435194656252861\n",
            "Epoch 45, Step 240, Loss: 0.008174358867108822\n",
            "Epoch 45, Step 241, Loss: 0.01468556560575962\n",
            "Epoch 45, Step 242, Loss: 0.0557979978621006\n",
            "Epoch 45, Step 243, Loss: 0.06034952029585838\n",
            "Epoch 45, Step 244, Loss: 0.07561138272285461\n",
            "Epoch 45, Step 245, Loss: 0.09324102103710175\n",
            "Epoch 45, Step 246, Loss: 0.02428867667913437\n",
            "Epoch 45, Step 247, Loss: 0.07521054893732071\n",
            "Epoch 45, Step 248, Loss: 0.08657161891460419\n",
            "Epoch 45, Step 249, Loss: 0.04820265993475914\n",
            "Epoch 45, Step 250, Loss: 0.09140536934137344\n",
            "Epoch 45, Step 251, Loss: 0.08596472442150116\n",
            "Epoch 45, Step 252, Loss: 0.03688051924109459\n",
            "Epoch 45, Step 253, Loss: 0.08059754967689514\n",
            "Epoch 45, Step 254, Loss: 0.09399927407503128\n",
            "Epoch 45, Step 255, Loss: 0.05019238218665123\n",
            "Epoch 45, Step 256, Loss: 0.04976861923933029\n",
            "Epoch 45, Step 257, Loss: 0.064995177090168\n",
            "Epoch 45, Step 258, Loss: 0.03474856913089752\n",
            "Epoch 45, Step 259, Loss: 0.04273157939314842\n",
            "Epoch 45, Step 260, Loss: 0.07877106219530106\n",
            "Epoch 45, Step 261, Loss: 0.05287395417690277\n",
            "Epoch 45, Step 262, Loss: 0.0788021981716156\n",
            "Epoch 45, Step 263, Loss: 0.0669613629579544\n",
            "Epoch 45, Step 264, Loss: 0.057559240609407425\n",
            "Epoch 45, Step 265, Loss: 0.06801443547010422\n",
            "Epoch 45, Step 266, Loss: 0.08709795773029327\n",
            "Epoch 45, Step 267, Loss: 0.04930952936410904\n",
            "Epoch 45, Step 268, Loss: 0.03383035957813263\n",
            "Epoch 45, Step 269, Loss: 0.055161915719509125\n",
            "Epoch 45, Step 270, Loss: 0.06779378652572632\n",
            "Epoch 45, Step 271, Loss: 0.039211537688970566\n",
            "Epoch 45, Step 272, Loss: 0.07713961601257324\n",
            "Epoch 45, Step 273, Loss: 0.1342356652021408\n",
            "Epoch 45, Step 274, Loss: 0.05626221373677254\n",
            "Epoch 45, Step 275, Loss: 0.03658188506960869\n",
            "Epoch 45, Step 276, Loss: 0.08557940274477005\n",
            "Epoch 45, Step 277, Loss: 0.0522056482732296\n",
            "Epoch 45, Step 278, Loss: 0.07831640541553497\n",
            "Epoch 45, Step 279, Loss: 0.06070997193455696\n",
            "Epoch 45, Step 280, Loss: 0.0757438912987709\n",
            "Epoch 45, Step 281, Loss: 0.03760886937379837\n",
            "Epoch 45, Step 282, Loss: 0.12949857115745544\n",
            "Epoch 45, Step 283, Loss: 0.12249474972486496\n",
            "Epoch 45, Step 284, Loss: 0.05592060089111328\n",
            "Epoch 45, Step 285, Loss: 0.06019927188754082\n",
            "Epoch 45, Step 286, Loss: 0.11752578616142273\n",
            "Epoch 45, Step 287, Loss: 0.027918949723243713\n",
            "Epoch 45, Step 288, Loss: 0.08951526135206223\n",
            "Epoch 45, Step 289, Loss: 0.11290676146745682\n",
            "Epoch 45, Step 290, Loss: 0.04831858351826668\n",
            "Epoch 45, Step 291, Loss: 0.08470278978347778\n",
            "Epoch 45, Step 292, Loss: 0.03141710162162781\n",
            "Epoch 45, Step 293, Loss: 0.058894962072372437\n",
            "Epoch 45, Step 294, Loss: 0.06302348524332047\n",
            "Epoch 45, Step 295, Loss: 0.026135535910725594\n",
            "Epoch 45, Step 296, Loss: 0.10367123782634735\n",
            "Epoch 45, Step 297, Loss: 0.060253918170928955\n",
            "Epoch 45, Step 298, Loss: 0.033286530524492264\n",
            "Epoch 45, Step 299, Loss: 0.037405695766210556\n",
            "Epoch 45, Step 300, Loss: 0.06800002604722977\n",
            "Epoch 45, Step 301, Loss: 0.16087038815021515\n",
            "Epoch 45, Step 302, Loss: 0.05479279160499573\n",
            "Epoch 45, Step 303, Loss: 0.06598999351263046\n",
            "Epoch 45, Step 304, Loss: 0.054903239011764526\n",
            "Epoch 45, Step 305, Loss: 0.060505807399749756\n",
            "Epoch 45, Step 306, Loss: 0.09880560636520386\n",
            "Epoch 45, Step 307, Loss: 0.04841510206460953\n",
            "Epoch 45, Step 308, Loss: 0.0903608500957489\n",
            "Epoch 45, Step 309, Loss: 0.17026519775390625\n",
            "Epoch 45, Step 310, Loss: 0.17821669578552246\n",
            "Epoch 45, Step 311, Loss: 0.04444603994488716\n",
            "Epoch 45, Step 312, Loss: 0.0791088417172432\n",
            "Epoch 45 end, avg train loss: 0.05902957872520335\n",
            "Epoch 45 end, avg val loss: 0.4352226356350923, accuracy: 90.63%\n",
            "Epoch 46, Step 0, Loss: 0.022231724113225937\n",
            "Epoch 46, Step 1, Loss: 0.07749692350625992\n",
            "Epoch 46, Step 2, Loss: 0.11353078484535217\n",
            "Epoch 46, Step 3, Loss: 0.02423373982310295\n",
            "Epoch 46, Step 4, Loss: 0.03514494001865387\n",
            "Epoch 46, Step 5, Loss: 0.009432732127606869\n",
            "Epoch 46, Step 6, Loss: 0.04167967662215233\n",
            "Epoch 46, Step 7, Loss: 0.09321411699056625\n",
            "Epoch 46, Step 8, Loss: 0.02859104983508587\n",
            "Epoch 46, Step 9, Loss: 0.0537932887673378\n",
            "Epoch 46, Step 10, Loss: 0.12820276618003845\n",
            "Epoch 46, Step 11, Loss: 0.09176519513130188\n",
            "Epoch 46, Step 12, Loss: 0.044311244040727615\n",
            "Epoch 46, Step 13, Loss: 0.021014075726270676\n",
            "Epoch 46, Step 14, Loss: 0.051972150802612305\n",
            "Epoch 46, Step 15, Loss: 0.0855087861418724\n",
            "Epoch 46, Step 16, Loss: 0.07998552173376083\n",
            "Epoch 46, Step 17, Loss: 0.028891567140817642\n",
            "Epoch 46, Step 18, Loss: 0.08056885749101639\n",
            "Epoch 46, Step 19, Loss: 0.07427167892456055\n",
            "Epoch 46, Step 20, Loss: 0.048079852014780045\n",
            "Epoch 46, Step 21, Loss: 0.11096277832984924\n",
            "Epoch 46, Step 22, Loss: 0.0638992041349411\n",
            "Epoch 46, Step 23, Loss: 0.02883358858525753\n",
            "Epoch 46, Step 24, Loss: 0.06225939095020294\n",
            "Epoch 46, Step 25, Loss: 0.046700239181518555\n",
            "Epoch 46, Step 26, Loss: 0.04974233731627464\n",
            "Epoch 46, Step 27, Loss: 0.04752765968441963\n",
            "Epoch 46, Step 28, Loss: 0.09981022030115128\n",
            "Epoch 46, Step 29, Loss: 0.05543982610106468\n",
            "Epoch 46, Step 30, Loss: 0.11324911564588547\n",
            "Epoch 46, Step 31, Loss: 0.02301793172955513\n",
            "Epoch 46, Step 32, Loss: 0.08301998674869537\n",
            "Epoch 46, Step 33, Loss: 0.07248105108737946\n",
            "Epoch 46, Step 34, Loss: 0.0984140932559967\n",
            "Epoch 46, Step 35, Loss: 0.02868892252445221\n",
            "Epoch 46, Step 36, Loss: 0.02042628824710846\n",
            "Epoch 46, Step 37, Loss: 0.06312830746173859\n",
            "Epoch 46, Step 38, Loss: 0.01965431310236454\n",
            "Epoch 46, Step 39, Loss: 0.035860996693372726\n",
            "Epoch 46, Step 40, Loss: 0.0676007866859436\n",
            "Epoch 46, Step 41, Loss: 0.05593802407383919\n",
            "Epoch 46, Step 42, Loss: 0.108943872153759\n",
            "Epoch 46, Step 43, Loss: 0.024750420823693275\n",
            "Epoch 46, Step 44, Loss: 0.1078629344701767\n",
            "Epoch 46, Step 45, Loss: 0.09362335503101349\n",
            "Epoch 46, Step 46, Loss: 0.06636863201856613\n",
            "Epoch 46, Step 47, Loss: 0.048987988382577896\n",
            "Epoch 46, Step 48, Loss: 0.02141190879046917\n",
            "Epoch 46, Step 49, Loss: 0.012676069512963295\n",
            "Epoch 46, Step 50, Loss: 0.056269340217113495\n",
            "Epoch 46, Step 51, Loss: 0.0688418298959732\n",
            "Epoch 46, Step 52, Loss: 0.046971578150987625\n",
            "Epoch 46, Step 53, Loss: 0.04139048606157303\n",
            "Epoch 46, Step 54, Loss: 0.020504673942923546\n",
            "Epoch 46, Step 55, Loss: 0.10626748949289322\n",
            "Epoch 46, Step 56, Loss: 0.1356038600206375\n",
            "Epoch 46, Step 57, Loss: 0.07389593869447708\n",
            "Epoch 46, Step 58, Loss: 0.06839592754840851\n",
            "Epoch 46, Step 59, Loss: 0.08121705800294876\n",
            "Epoch 46, Step 60, Loss: 0.06476138532161713\n",
            "Epoch 46, Step 61, Loss: 0.06251596659421921\n",
            "Epoch 46, Step 62, Loss: 0.04695781320333481\n",
            "Epoch 46, Step 63, Loss: 0.017076196148991585\n",
            "Epoch 46, Step 64, Loss: 0.046746354550123215\n",
            "Epoch 46, Step 65, Loss: 0.08135451376438141\n",
            "Epoch 46, Step 66, Loss: 0.06187685206532478\n",
            "Epoch 46, Step 67, Loss: 0.031120548024773598\n",
            "Epoch 46, Step 68, Loss: 0.09022028744220734\n",
            "Epoch 46, Step 69, Loss: 0.034510958939790726\n",
            "Epoch 46, Step 70, Loss: 0.06333563476800919\n",
            "Epoch 46, Step 71, Loss: 0.02845734916627407\n",
            "Epoch 46, Step 72, Loss: 0.13425496220588684\n",
            "Epoch 46, Step 73, Loss: 0.04235376417636871\n",
            "Epoch 46, Step 74, Loss: 0.08522707968950272\n",
            "Epoch 46, Step 75, Loss: 0.00830819457769394\n",
            "Epoch 46, Step 76, Loss: 0.06189660727977753\n",
            "Epoch 46, Step 77, Loss: 0.10916321724653244\n",
            "Epoch 46, Step 78, Loss: 0.016282234340906143\n",
            "Epoch 46, Step 79, Loss: 0.06595596671104431\n",
            "Epoch 46, Step 80, Loss: 0.019501619040966034\n",
            "Epoch 46, Step 81, Loss: 0.1601552814245224\n",
            "Epoch 46, Step 82, Loss: 0.028724737465381622\n",
            "Epoch 46, Step 83, Loss: 0.07819566875696182\n",
            "Epoch 46, Step 84, Loss: 0.017965970560908318\n",
            "Epoch 46, Step 85, Loss: 0.028583437204360962\n",
            "Epoch 46, Step 86, Loss: 0.06326597183942795\n",
            "Epoch 46, Step 87, Loss: 0.04255224019289017\n",
            "Epoch 46, Step 88, Loss: 0.10955163836479187\n",
            "Epoch 46, Step 89, Loss: 0.08530424535274506\n",
            "Epoch 46, Step 90, Loss: 0.04742888733744621\n",
            "Epoch 46, Step 91, Loss: 0.08363667130470276\n",
            "Epoch 46, Step 92, Loss: 0.0648767426609993\n",
            "Epoch 46, Step 93, Loss: 0.05864677578210831\n",
            "Epoch 46, Step 94, Loss: 0.06181139871478081\n",
            "Epoch 46, Step 95, Loss: 0.00836612842977047\n",
            "Epoch 46, Step 96, Loss: 0.03701106831431389\n",
            "Epoch 46, Step 97, Loss: 0.03317518159747124\n",
            "Epoch 46, Step 98, Loss: 0.017107857391238213\n",
            "Epoch 46, Step 99, Loss: 0.011566022410988808\n",
            "Epoch 46, Step 100, Loss: 0.07045910507440567\n",
            "Epoch 46, Step 101, Loss: 0.05528228357434273\n",
            "Epoch 46, Step 102, Loss: 0.024806471541523933\n",
            "Epoch 46, Step 103, Loss: 0.03437865525484085\n",
            "Epoch 46, Step 104, Loss: 0.05832088738679886\n",
            "Epoch 46, Step 105, Loss: 0.0484309159219265\n",
            "Epoch 46, Step 106, Loss: 0.08732892572879791\n",
            "Epoch 46, Step 107, Loss: 0.04461298882961273\n",
            "Epoch 46, Step 108, Loss: 0.019177721813321114\n",
            "Epoch 46, Step 109, Loss: 0.0423353910446167\n",
            "Epoch 46, Step 110, Loss: 0.030232569202780724\n",
            "Epoch 46, Step 111, Loss: 0.035545963793992996\n",
            "Epoch 46, Step 112, Loss: 0.053810689598321915\n",
            "Epoch 46, Step 113, Loss: 0.04394941031932831\n",
            "Epoch 46, Step 114, Loss: 0.02823703922331333\n",
            "Epoch 46, Step 115, Loss: 0.04787297546863556\n",
            "Epoch 46, Step 116, Loss: 0.0604376383125782\n",
            "Epoch 46, Step 117, Loss: 0.0946497991681099\n",
            "Epoch 46, Step 118, Loss: 0.016882071271538734\n",
            "Epoch 46, Step 119, Loss: 0.022297799587249756\n",
            "Epoch 46, Step 120, Loss: 0.02239248901605606\n",
            "Epoch 46, Step 121, Loss: 0.019154522567987442\n",
            "Epoch 46, Step 122, Loss: 0.08609512448310852\n",
            "Epoch 46, Step 123, Loss: 0.01649310626089573\n",
            "Epoch 46, Step 124, Loss: 0.04060731083154678\n",
            "Epoch 46, Step 125, Loss: 0.0754946619272232\n",
            "Epoch 46, Step 126, Loss: 0.035411544144153595\n",
            "Epoch 46, Step 127, Loss: 0.014463134109973907\n",
            "Epoch 46, Step 128, Loss: 0.02935776486992836\n",
            "Epoch 46, Step 129, Loss: 0.0435754731297493\n",
            "Epoch 46, Step 130, Loss: 0.09420978277921677\n",
            "Epoch 46, Step 131, Loss: 0.03712566941976547\n",
            "Epoch 46, Step 132, Loss: 0.06779780238866806\n",
            "Epoch 46, Step 133, Loss: 0.01650114357471466\n",
            "Epoch 46, Step 134, Loss: 0.02627662569284439\n",
            "Epoch 46, Step 135, Loss: 0.04309236630797386\n",
            "Epoch 46, Step 136, Loss: 0.03276728838682175\n",
            "Epoch 46, Step 137, Loss: 0.05020381882786751\n",
            "Epoch 46, Step 138, Loss: 0.022343574091792107\n",
            "Epoch 46, Step 139, Loss: 0.03079959750175476\n",
            "Epoch 46, Step 140, Loss: 0.08020441234111786\n",
            "Epoch 46, Step 141, Loss: 0.05362739413976669\n",
            "Epoch 46, Step 142, Loss: 0.032407570630311966\n",
            "Epoch 46, Step 143, Loss: 0.055631332099437714\n",
            "Epoch 46, Step 144, Loss: 0.06452399492263794\n",
            "Epoch 46, Step 145, Loss: 0.07416076213121414\n",
            "Epoch 46, Step 146, Loss: 0.10844723135232925\n",
            "Epoch 46, Step 147, Loss: 0.03069998137652874\n",
            "Epoch 46, Step 148, Loss: 0.06822332739830017\n",
            "Epoch 46, Step 149, Loss: 0.037110377103090286\n",
            "Epoch 46, Step 150, Loss: 0.03852628916501999\n",
            "Epoch 46, Step 151, Loss: 0.05242905393242836\n",
            "Epoch 46, Step 152, Loss: 0.03788606449961662\n",
            "Epoch 46, Step 153, Loss: 0.04944199323654175\n",
            "Epoch 46, Step 154, Loss: 0.07430484145879745\n",
            "Epoch 46, Step 155, Loss: 0.061192259192466736\n",
            "Epoch 46, Step 156, Loss: 0.07371119409799576\n",
            "Epoch 46, Step 157, Loss: 0.0477154403924942\n",
            "Epoch 46, Step 158, Loss: 0.05215338617563248\n",
            "Epoch 46, Step 159, Loss: 0.027564924210309982\n",
            "Epoch 46, Step 160, Loss: 0.023235926404595375\n",
            "Epoch 46, Step 161, Loss: 0.03614727780222893\n",
            "Epoch 46, Step 162, Loss: 0.04403768479824066\n",
            "Epoch 46, Step 163, Loss: 0.08620671927928925\n",
            "Epoch 46, Step 164, Loss: 0.05982768163084984\n",
            "Epoch 46, Step 165, Loss: 0.09644036740064621\n",
            "Epoch 46, Step 166, Loss: 0.018243510276079178\n",
            "Epoch 46, Step 167, Loss: 0.007093006279319525\n",
            "Epoch 46, Step 168, Loss: 0.05299324542284012\n",
            "Epoch 46, Step 169, Loss: 0.09666348993778229\n",
            "Epoch 46, Step 170, Loss: 0.1477861851453781\n",
            "Epoch 46, Step 171, Loss: 0.041301801800727844\n",
            "Epoch 46, Step 172, Loss: 0.0956798568367958\n",
            "Epoch 46, Step 173, Loss: 0.04462306201457977\n",
            "Epoch 46, Step 174, Loss: 0.08305343240499496\n",
            "Epoch 46, Step 175, Loss: 0.06565148383378983\n",
            "Epoch 46, Step 176, Loss: 0.16586674749851227\n",
            "Epoch 46, Step 177, Loss: 0.1462963968515396\n",
            "Epoch 46, Step 178, Loss: 0.02243119850754738\n",
            "Epoch 46, Step 179, Loss: 0.04045296832919121\n",
            "Epoch 46, Step 180, Loss: 0.12471920251846313\n",
            "Epoch 46, Step 181, Loss: 0.017661409452557564\n",
            "Epoch 46, Step 182, Loss: 0.06595741212368011\n",
            "Epoch 46, Step 183, Loss: 0.0298264492303133\n",
            "Epoch 46, Step 184, Loss: 0.03470635414123535\n",
            "Epoch 46, Step 185, Loss: 0.023465095087885857\n",
            "Epoch 46, Step 186, Loss: 0.030893949791789055\n",
            "Epoch 46, Step 187, Loss: 0.05657733976840973\n",
            "Epoch 46, Step 188, Loss: 0.017932798713445663\n",
            "Epoch 46, Step 189, Loss: 0.046279143542051315\n",
            "Epoch 46, Step 190, Loss: 0.0510757714509964\n",
            "Epoch 46, Step 191, Loss: 0.19103246927261353\n",
            "Epoch 46, Step 192, Loss: 0.09827446937561035\n",
            "Epoch 46, Step 193, Loss: 0.0852108895778656\n",
            "Epoch 46, Step 194, Loss: 0.030306288972496986\n",
            "Epoch 46, Step 195, Loss: 0.03242124617099762\n",
            "Epoch 46, Step 196, Loss: 0.05190975219011307\n",
            "Epoch 46, Step 197, Loss: 0.01750386692583561\n",
            "Epoch 46, Step 198, Loss: 0.058864425867795944\n",
            "Epoch 46, Step 199, Loss: 0.08137296885251999\n",
            "Epoch 46, Step 200, Loss: 0.05765731260180473\n",
            "Epoch 46, Step 201, Loss: 0.08171098679304123\n",
            "Epoch 46, Step 202, Loss: 0.01582963392138481\n",
            "Epoch 46, Step 203, Loss: 0.04181092604994774\n",
            "Epoch 46, Step 204, Loss: 0.052574846893548965\n",
            "Epoch 46, Step 205, Loss: 0.08303491771221161\n",
            "Epoch 46, Step 206, Loss: 0.04286335036158562\n",
            "Epoch 46, Step 207, Loss: 0.05913815647363663\n",
            "Epoch 46, Step 208, Loss: 0.08652880042791367\n",
            "Epoch 46, Step 209, Loss: 0.02468828298151493\n",
            "Epoch 46, Step 210, Loss: 0.06529129296541214\n",
            "Epoch 46, Step 211, Loss: 0.1600579470396042\n",
            "Epoch 46, Step 212, Loss: 0.09897025674581528\n",
            "Epoch 46, Step 213, Loss: 0.013719995506107807\n",
            "Epoch 46, Step 214, Loss: 0.04992851987481117\n",
            "Epoch 46, Step 215, Loss: 0.02708330750465393\n",
            "Epoch 46, Step 216, Loss: 0.0975562185049057\n",
            "Epoch 46, Step 217, Loss: 0.14657609164714813\n",
            "Epoch 46, Step 218, Loss: 0.03536687791347504\n",
            "Epoch 46, Step 219, Loss: 0.04239141196012497\n",
            "Epoch 46, Step 220, Loss: 0.06297440826892853\n",
            "Epoch 46, Step 221, Loss: 0.061042942106723785\n",
            "Epoch 46, Step 222, Loss: 0.030446603894233704\n",
            "Epoch 46, Step 223, Loss: 0.08242806047201157\n",
            "Epoch 46, Step 224, Loss: 0.07844788581132889\n",
            "Epoch 46, Step 225, Loss: 0.05588327720761299\n",
            "Epoch 46, Step 226, Loss: 0.047617893666028976\n",
            "Epoch 46, Step 227, Loss: 0.11316259205341339\n",
            "Epoch 46, Step 228, Loss: 0.01959536224603653\n",
            "Epoch 46, Step 229, Loss: 0.03247541934251785\n",
            "Epoch 46, Step 230, Loss: 0.04908960312604904\n",
            "Epoch 46, Step 231, Loss: 0.06935472786426544\n",
            "Epoch 46, Step 232, Loss: 0.03443531319499016\n",
            "Epoch 46, Step 233, Loss: 0.044348813593387604\n",
            "Epoch 46, Step 234, Loss: 0.02900998480618\n",
            "Epoch 46, Step 235, Loss: 0.03404103219509125\n",
            "Epoch 46, Step 236, Loss: 0.02094252221286297\n",
            "Epoch 46, Step 237, Loss: 0.02509932406246662\n",
            "Epoch 46, Step 238, Loss: 0.0412798710167408\n",
            "Epoch 46, Step 239, Loss: 0.07020105421543121\n",
            "Epoch 46, Step 240, Loss: 0.06719714403152466\n",
            "Epoch 46, Step 241, Loss: 0.05917378515005112\n",
            "Epoch 46, Step 242, Loss: 0.07076038420200348\n",
            "Epoch 46, Step 243, Loss: 0.05836177617311478\n",
            "Epoch 46, Step 244, Loss: 0.0315142460167408\n",
            "Epoch 46, Step 245, Loss: 0.033687103539705276\n",
            "Epoch 46, Step 246, Loss: 0.042458854615688324\n",
            "Epoch 46, Step 247, Loss: 0.10857194662094116\n",
            "Epoch 46, Step 248, Loss: 0.05484795942902565\n",
            "Epoch 46, Step 249, Loss: 0.04184161126613617\n",
            "Epoch 46, Step 250, Loss: 0.043981507420539856\n",
            "Epoch 46, Step 251, Loss: 0.041749924421310425\n",
            "Epoch 46, Step 252, Loss: 0.062296461313962936\n",
            "Epoch 46, Step 253, Loss: 0.07468748837709427\n",
            "Epoch 46, Step 254, Loss: 0.04378410428762436\n",
            "Epoch 46, Step 255, Loss: 0.10490046441555023\n",
            "Epoch 46, Step 256, Loss: 0.059904612600803375\n",
            "Epoch 46, Step 257, Loss: 0.044224731624126434\n",
            "Epoch 46, Step 258, Loss: 0.07094310224056244\n",
            "Epoch 46, Step 259, Loss: 0.06229189783334732\n",
            "Epoch 46, Step 260, Loss: 0.07249008119106293\n",
            "Epoch 46, Step 261, Loss: 0.09705115109682083\n",
            "Epoch 46, Step 262, Loss: 0.028858516365289688\n",
            "Epoch 46, Step 263, Loss: 0.01815623976290226\n",
            "Epoch 46, Step 264, Loss: 0.062294572591781616\n",
            "Epoch 46, Step 265, Loss: 0.03585685417056084\n",
            "Epoch 46, Step 266, Loss: 0.05639408528804779\n",
            "Epoch 46, Step 267, Loss: 0.05294810235500336\n",
            "Epoch 46, Step 268, Loss: 0.041728291660547256\n",
            "Epoch 46, Step 269, Loss: 0.062016457319259644\n",
            "Epoch 46, Step 270, Loss: 0.07990793883800507\n",
            "Epoch 46, Step 271, Loss: 0.05396139994263649\n",
            "Epoch 46, Step 272, Loss: 0.13561642169952393\n",
            "Epoch 46, Step 273, Loss: 0.09772118926048279\n",
            "Epoch 46, Step 274, Loss: 0.07386503368616104\n",
            "Epoch 46, Step 275, Loss: 0.13933958113193512\n",
            "Epoch 46, Step 276, Loss: 0.07045915722846985\n",
            "Epoch 46, Step 277, Loss: 0.05373591184616089\n",
            "Epoch 46, Step 278, Loss: 0.025828886777162552\n",
            "Epoch 46, Step 279, Loss: 0.042487580329179764\n",
            "Epoch 46, Step 280, Loss: 0.11364728212356567\n",
            "Epoch 46, Step 281, Loss: 0.052517447620630264\n",
            "Epoch 46, Step 282, Loss: 0.03662963956594467\n",
            "Epoch 46, Step 283, Loss: 0.023711374029517174\n",
            "Epoch 46, Step 284, Loss: 0.11608017981052399\n",
            "Epoch 46, Step 285, Loss: 0.05254354327917099\n",
            "Epoch 46, Step 286, Loss: 0.038564909249544144\n",
            "Epoch 46, Step 287, Loss: 0.042695995420217514\n",
            "Epoch 46, Step 288, Loss: 0.11783560365438461\n",
            "Epoch 46, Step 289, Loss: 0.05654129013419151\n",
            "Epoch 46, Step 290, Loss: 0.08640919625759125\n",
            "Epoch 46, Step 291, Loss: 0.06559855490922928\n",
            "Epoch 46, Step 292, Loss: 0.07021927088499069\n",
            "Epoch 46, Step 293, Loss: 0.018189117312431335\n",
            "Epoch 46, Step 294, Loss: 0.058593325316905975\n",
            "Epoch 46, Step 295, Loss: 0.08434410393238068\n",
            "Epoch 46, Step 296, Loss: 0.04454607889056206\n",
            "Epoch 46, Step 297, Loss: 0.086008720099926\n",
            "Epoch 46, Step 298, Loss: 0.09110092371702194\n",
            "Epoch 46, Step 299, Loss: 0.04261171072721481\n",
            "Epoch 46, Step 300, Loss: 0.07873773574829102\n",
            "Epoch 46, Step 301, Loss: 0.06594249606132507\n",
            "Epoch 46, Step 302, Loss: 0.05390873923897743\n",
            "Epoch 46, Step 303, Loss: 0.05338258668780327\n",
            "Epoch 46, Step 304, Loss: 0.09042273461818695\n",
            "Epoch 46, Step 305, Loss: 0.11852037906646729\n",
            "Epoch 46, Step 306, Loss: 0.029670516029000282\n",
            "Epoch 46, Step 307, Loss: 0.09066164493560791\n",
            "Epoch 46, Step 308, Loss: 0.1090518981218338\n",
            "Epoch 46, Step 309, Loss: 0.09560362994670868\n",
            "Epoch 46, Step 310, Loss: 0.05148733779788017\n",
            "Epoch 46, Step 311, Loss: 0.05027603730559349\n",
            "Epoch 46, Step 312, Loss: 0.047837432473897934\n",
            "Epoch 46 end, avg train loss: 0.05825560263093239\n",
            "Epoch 46 end, avg val loss: 0.4448613347131995, accuracy: 90.32%\n",
            "Epoch 47, Step 0, Loss: 0.024019140750169754\n",
            "Epoch 47, Step 1, Loss: 0.02673678658902645\n",
            "Epoch 47, Step 2, Loss: 0.08340508490800858\n",
            "Epoch 47, Step 3, Loss: 0.05897996202111244\n",
            "Epoch 47, Step 4, Loss: 0.15477780997753143\n",
            "Epoch 47, Step 5, Loss: 0.05632676184177399\n",
            "Epoch 47, Step 6, Loss: 0.029989372938871384\n",
            "Epoch 47, Step 7, Loss: 0.054536014795303345\n",
            "Epoch 47, Step 8, Loss: 0.06439803540706635\n",
            "Epoch 47, Step 9, Loss: 0.02758900634944439\n",
            "Epoch 47, Step 10, Loss: 0.055130306631326675\n",
            "Epoch 47, Step 11, Loss: 0.032911743968725204\n",
            "Epoch 47, Step 12, Loss: 0.07212669402360916\n",
            "Epoch 47, Step 13, Loss: 0.08909013122320175\n",
            "Epoch 47, Step 14, Loss: 0.02569052204489708\n",
            "Epoch 47, Step 15, Loss: 0.015631569549441338\n",
            "Epoch 47, Step 16, Loss: 0.018574759364128113\n",
            "Epoch 47, Step 17, Loss: 0.012999450787901878\n",
            "Epoch 47, Step 18, Loss: 0.08471408486366272\n",
            "Epoch 47, Step 19, Loss: 0.033194854855537415\n",
            "Epoch 47, Step 20, Loss: 0.04448157921433449\n",
            "Epoch 47, Step 21, Loss: 0.033591367304325104\n",
            "Epoch 47, Step 22, Loss: 0.06413645297288895\n",
            "Epoch 47, Step 23, Loss: 0.09494795650243759\n",
            "Epoch 47, Step 24, Loss: 0.020846093073487282\n",
            "Epoch 47, Step 25, Loss: 0.04781773313879967\n",
            "Epoch 47, Step 26, Loss: 0.0845390260219574\n",
            "Epoch 47, Step 27, Loss: 0.08487536013126373\n",
            "Epoch 47, Step 28, Loss: 0.017741700634360313\n",
            "Epoch 47, Step 29, Loss: 0.028588909655809402\n",
            "Epoch 47, Step 30, Loss: 0.06672528386116028\n",
            "Epoch 47, Step 31, Loss: 0.05406972020864487\n",
            "Epoch 47, Step 32, Loss: 0.028983427211642265\n",
            "Epoch 47, Step 33, Loss: 0.042826056480407715\n",
            "Epoch 47, Step 34, Loss: 0.07305730879306793\n",
            "Epoch 47, Step 35, Loss: 0.04826800525188446\n",
            "Epoch 47, Step 36, Loss: 0.07148581743240356\n",
            "Epoch 47, Step 37, Loss: 0.009772002696990967\n",
            "Epoch 47, Step 38, Loss: 0.08492843806743622\n",
            "Epoch 47, Step 39, Loss: 0.05106428638100624\n",
            "Epoch 47, Step 40, Loss: 0.03617255017161369\n",
            "Epoch 47, Step 41, Loss: 0.07604338973760605\n",
            "Epoch 47, Step 42, Loss: 0.07889702171087265\n",
            "Epoch 47, Step 43, Loss: 0.048202868551015854\n",
            "Epoch 47, Step 44, Loss: 0.0212845578789711\n",
            "Epoch 47, Step 45, Loss: 0.037239015102386475\n",
            "Epoch 47, Step 46, Loss: 0.057345323264598846\n",
            "Epoch 47, Step 47, Loss: 0.020743634551763535\n",
            "Epoch 47, Step 48, Loss: 0.04906349629163742\n",
            "Epoch 47, Step 49, Loss: 0.07516844570636749\n",
            "Epoch 47, Step 50, Loss: 0.028425902128219604\n",
            "Epoch 47, Step 51, Loss: 0.06275852769613266\n",
            "Epoch 47, Step 52, Loss: 0.036470696330070496\n",
            "Epoch 47, Step 53, Loss: 0.04647165909409523\n",
            "Epoch 47, Step 54, Loss: 0.008657407946884632\n",
            "Epoch 47, Step 55, Loss: 0.017583167180418968\n",
            "Epoch 47, Step 56, Loss: 0.06190900877118111\n",
            "Epoch 47, Step 57, Loss: 0.044185783714056015\n",
            "Epoch 47, Step 58, Loss: 0.03494831547141075\n",
            "Epoch 47, Step 59, Loss: 0.057338275015354156\n",
            "Epoch 47, Step 60, Loss: 0.024869076907634735\n",
            "Epoch 47, Step 61, Loss: 0.04817942529916763\n",
            "Epoch 47, Step 62, Loss: 0.03012223355472088\n",
            "Epoch 47, Step 63, Loss: 0.02537480741739273\n",
            "Epoch 47, Step 64, Loss: 0.02693920023739338\n",
            "Epoch 47, Step 65, Loss: 0.03660815581679344\n",
            "Epoch 47, Step 66, Loss: 0.07790015637874603\n",
            "Epoch 47, Step 67, Loss: 0.04875745624303818\n",
            "Epoch 47, Step 68, Loss: 0.005432863719761372\n",
            "Epoch 47, Step 69, Loss: 0.03663391247391701\n",
            "Epoch 47, Step 70, Loss: 0.043170828372240067\n",
            "Epoch 47, Step 71, Loss: 0.09854087978601456\n",
            "Epoch 47, Step 72, Loss: 0.06229183077812195\n",
            "Epoch 47, Step 73, Loss: 0.029053468257188797\n",
            "Epoch 47, Step 74, Loss: 0.03728386387228966\n",
            "Epoch 47, Step 75, Loss: 0.016301758587360382\n",
            "Epoch 47, Step 76, Loss: 0.08085048943758011\n",
            "Epoch 47, Step 77, Loss: 0.029853785410523415\n",
            "Epoch 47, Step 78, Loss: 0.01781339943408966\n",
            "Epoch 47, Step 79, Loss: 0.020968491211533546\n",
            "Epoch 47, Step 80, Loss: 0.02005961909890175\n",
            "Epoch 47, Step 81, Loss: 0.03322627767920494\n",
            "Epoch 47, Step 82, Loss: 0.07200904935598373\n",
            "Epoch 47, Step 83, Loss: 0.056865908205509186\n",
            "Epoch 47, Step 84, Loss: 0.0913180410861969\n",
            "Epoch 47, Step 85, Loss: 0.04939623177051544\n",
            "Epoch 47, Step 86, Loss: 0.059849876910448074\n",
            "Epoch 47, Step 87, Loss: 0.007158611435443163\n",
            "Epoch 47, Step 88, Loss: 0.09050681442022324\n",
            "Epoch 47, Step 89, Loss: 0.049480848014354706\n",
            "Epoch 47, Step 90, Loss: 0.04464467242360115\n",
            "Epoch 47, Step 91, Loss: 0.07041022181510925\n",
            "Epoch 47, Step 92, Loss: 0.11313489824533463\n",
            "Epoch 47, Step 93, Loss: 0.00996477622538805\n",
            "Epoch 47, Step 94, Loss: 0.023600975051522255\n",
            "Epoch 47, Step 95, Loss: 0.08716689795255661\n",
            "Epoch 47, Step 96, Loss: 0.11409054696559906\n",
            "Epoch 47, Step 97, Loss: 0.04962008073925972\n",
            "Epoch 47, Step 98, Loss: 0.05237855017185211\n",
            "Epoch 47, Step 99, Loss: 0.03713983669877052\n",
            "Epoch 47, Step 100, Loss: 0.05611554905772209\n",
            "Epoch 47, Step 101, Loss: 0.10586713254451752\n",
            "Epoch 47, Step 102, Loss: 0.07875117659568787\n",
            "Epoch 47, Step 103, Loss: 0.023144317790865898\n",
            "Epoch 47, Step 104, Loss: 0.033081479370594025\n",
            "Epoch 47, Step 105, Loss: 0.0826910138130188\n",
            "Epoch 47, Step 106, Loss: 0.019453413784503937\n",
            "Epoch 47, Step 107, Loss: 0.03805601969361305\n",
            "Epoch 47, Step 108, Loss: 0.03221255913376808\n",
            "Epoch 47, Step 109, Loss: 0.046216968446969986\n",
            "Epoch 47, Step 110, Loss: 0.02896410971879959\n",
            "Epoch 47, Step 111, Loss: 0.03891419619321823\n",
            "Epoch 47, Step 112, Loss: 0.07591138780117035\n",
            "Epoch 47, Step 113, Loss: 0.04193282499909401\n",
            "Epoch 47, Step 114, Loss: 0.030861031264066696\n",
            "Epoch 47, Step 115, Loss: 0.08058988302946091\n",
            "Epoch 47, Step 116, Loss: 0.020443644374608994\n",
            "Epoch 47, Step 117, Loss: 0.0387885682284832\n",
            "Epoch 47, Step 118, Loss: 0.05504939705133438\n",
            "Epoch 47, Step 119, Loss: 0.04658862203359604\n",
            "Epoch 47, Step 120, Loss: 0.027165468782186508\n",
            "Epoch 47, Step 121, Loss: 0.011220359243452549\n",
            "Epoch 47, Step 122, Loss: 0.06190392002463341\n",
            "Epoch 47, Step 123, Loss: 0.059840697795152664\n",
            "Epoch 47, Step 124, Loss: 0.06199890002608299\n",
            "Epoch 47, Step 125, Loss: 0.03015580028295517\n",
            "Epoch 47, Step 126, Loss: 0.024361087009310722\n",
            "Epoch 47, Step 127, Loss: 0.030027488246560097\n",
            "Epoch 47, Step 128, Loss: 0.07968253642320633\n",
            "Epoch 47, Step 129, Loss: 0.017379343509674072\n",
            "Epoch 47, Step 130, Loss: 0.16890282928943634\n",
            "Epoch 47, Step 131, Loss: 0.04567106068134308\n",
            "Epoch 47, Step 132, Loss: 0.09234274178743362\n",
            "Epoch 47, Step 133, Loss: 0.03660320118069649\n",
            "Epoch 47, Step 134, Loss: 0.03777587041258812\n",
            "Epoch 47, Step 135, Loss: 0.011478455737233162\n",
            "Epoch 47, Step 136, Loss: 0.06585637480020523\n",
            "Epoch 47, Step 137, Loss: 0.02809402160346508\n",
            "Epoch 47, Step 138, Loss: 0.018521368503570557\n",
            "Epoch 47, Step 139, Loss: 0.04556052386760712\n",
            "Epoch 47, Step 140, Loss: 0.0847615972161293\n",
            "Epoch 47, Step 141, Loss: 0.05823064222931862\n",
            "Epoch 47, Step 142, Loss: 0.06007758900523186\n",
            "Epoch 47, Step 143, Loss: 0.02686801739037037\n",
            "Epoch 47, Step 144, Loss: 0.06603449583053589\n",
            "Epoch 47, Step 145, Loss: 0.008798428811132908\n",
            "Epoch 47, Step 146, Loss: 0.09724143892526627\n",
            "Epoch 47, Step 147, Loss: 0.023869292810559273\n",
            "Epoch 47, Step 148, Loss: 0.05563851818442345\n",
            "Epoch 47, Step 149, Loss: 0.09431108087301254\n",
            "Epoch 47, Step 150, Loss: 0.05590696260333061\n",
            "Epoch 47, Step 151, Loss: 0.06143687665462494\n",
            "Epoch 47, Step 152, Loss: 0.05064651742577553\n",
            "Epoch 47, Step 153, Loss: 0.03659480810165405\n",
            "Epoch 47, Step 154, Loss: 0.06206538528203964\n",
            "Epoch 47, Step 155, Loss: 0.035994891077280045\n",
            "Epoch 47, Step 156, Loss: 0.05622906610369682\n",
            "Epoch 47, Step 157, Loss: 0.019182898104190826\n",
            "Epoch 47, Step 158, Loss: 0.020389005541801453\n",
            "Epoch 47, Step 159, Loss: 0.05220407247543335\n",
            "Epoch 47, Step 160, Loss: 0.0715215653181076\n",
            "Epoch 47, Step 161, Loss: 0.03470298647880554\n",
            "Epoch 47, Step 162, Loss: 0.035718582570552826\n",
            "Epoch 47, Step 163, Loss: 0.05116754770278931\n",
            "Epoch 47, Step 164, Loss: 0.0374874472618103\n",
            "Epoch 47, Step 165, Loss: 0.09649460762739182\n",
            "Epoch 47, Step 166, Loss: 0.021133771166205406\n",
            "Epoch 47, Step 167, Loss: 0.020078884437680244\n",
            "Epoch 47, Step 168, Loss: 0.029512455686926842\n",
            "Epoch 47, Step 169, Loss: 0.07028965651988983\n",
            "Epoch 47, Step 170, Loss: 0.07195956259965897\n",
            "Epoch 47, Step 171, Loss: 0.04607539623975754\n",
            "Epoch 47, Step 172, Loss: 0.07256651669740677\n",
            "Epoch 47, Step 173, Loss: 0.07185117900371552\n",
            "Epoch 47, Step 174, Loss: 0.0439445786178112\n",
            "Epoch 47, Step 175, Loss: 0.05096523091197014\n",
            "Epoch 47, Step 176, Loss: 0.005193999502807856\n",
            "Epoch 47, Step 177, Loss: 0.07280177623033524\n",
            "Epoch 47, Step 178, Loss: 0.028657522052526474\n",
            "Epoch 47, Step 179, Loss: 0.021339673548936844\n",
            "Epoch 47, Step 180, Loss: 0.042733851820230484\n",
            "Epoch 47, Step 181, Loss: 0.03019186109304428\n",
            "Epoch 47, Step 182, Loss: 0.04068231210112572\n",
            "Epoch 47, Step 183, Loss: 0.030043093487620354\n",
            "Epoch 47, Step 184, Loss: 0.04458377882838249\n",
            "Epoch 47, Step 185, Loss: 0.03404957428574562\n",
            "Epoch 47, Step 186, Loss: 0.04090225324034691\n",
            "Epoch 47, Step 187, Loss: 0.07383459061384201\n",
            "Epoch 47, Step 188, Loss: 0.030672041699290276\n",
            "Epoch 47, Step 189, Loss: 0.05206833407282829\n",
            "Epoch 47, Step 190, Loss: 0.0473177395761013\n",
            "Epoch 47, Step 191, Loss: 0.058337561786174774\n",
            "Epoch 47, Step 192, Loss: 0.038645531982183456\n",
            "Epoch 47, Step 193, Loss: 0.022189555689692497\n",
            "Epoch 47, Step 194, Loss: 0.07053093612194061\n",
            "Epoch 47, Step 195, Loss: 0.13613219559192657\n",
            "Epoch 47, Step 196, Loss: 0.029185470193624496\n",
            "Epoch 47, Step 197, Loss: 0.05041695758700371\n",
            "Epoch 47, Step 198, Loss: 0.02378905937075615\n",
            "Epoch 47, Step 199, Loss: 0.025002675130963326\n",
            "Epoch 47, Step 200, Loss: 0.03365224599838257\n",
            "Epoch 47, Step 201, Loss: 0.0808563381433487\n",
            "Epoch 47, Step 202, Loss: 0.05489795282483101\n",
            "Epoch 47, Step 203, Loss: 0.03299098461866379\n",
            "Epoch 47, Step 204, Loss: 0.08001221716403961\n",
            "Epoch 47, Step 205, Loss: 0.03920475021004677\n",
            "Epoch 47, Step 206, Loss: 0.011563090607523918\n",
            "Epoch 47, Step 207, Loss: 0.06403403729200363\n",
            "Epoch 47, Step 208, Loss: 0.03409656509757042\n",
            "Epoch 47, Step 209, Loss: 0.048711467534303665\n",
            "Epoch 47, Step 210, Loss: 0.1360001415014267\n",
            "Epoch 47, Step 211, Loss: 0.040758632123470306\n",
            "Epoch 47, Step 212, Loss: 0.04459470137953758\n",
            "Epoch 47, Step 213, Loss: 0.07649289816617966\n",
            "Epoch 47, Step 214, Loss: 0.037999227643013\n",
            "Epoch 47, Step 215, Loss: 0.0455554723739624\n",
            "Epoch 47, Step 216, Loss: 0.07551023364067078\n",
            "Epoch 47, Step 217, Loss: 0.042046159505844116\n",
            "Epoch 47, Step 218, Loss: 0.02542886696755886\n",
            "Epoch 47, Step 219, Loss: 0.057466328144073486\n",
            "Epoch 47, Step 220, Loss: 0.04532468691468239\n",
            "Epoch 47, Step 221, Loss: 0.03542532026767731\n",
            "Epoch 47, Step 222, Loss: 0.0818842351436615\n",
            "Epoch 47, Step 223, Loss: 0.07747016102075577\n",
            "Epoch 47, Step 224, Loss: 0.01990664005279541\n",
            "Epoch 47, Step 225, Loss: 0.014451973140239716\n",
            "Epoch 47, Step 226, Loss: 0.11316134035587311\n",
            "Epoch 47, Step 227, Loss: 0.030663512647151947\n",
            "Epoch 47, Step 228, Loss: 0.062253426760435104\n",
            "Epoch 47, Step 229, Loss: 0.053244370967149734\n",
            "Epoch 47, Step 230, Loss: 0.05627989023923874\n",
            "Epoch 47, Step 231, Loss: 0.027053797617554665\n",
            "Epoch 47, Step 232, Loss: 0.0833902657032013\n",
            "Epoch 47, Step 233, Loss: 0.030373450368642807\n",
            "Epoch 47, Step 234, Loss: 0.08314820379018784\n",
            "Epoch 47, Step 235, Loss: 0.014641602523624897\n",
            "Epoch 47, Step 236, Loss: 0.02880222722887993\n",
            "Epoch 47, Step 237, Loss: 0.06870365887880325\n",
            "Epoch 47, Step 238, Loss: 0.021668676286935806\n",
            "Epoch 47, Step 239, Loss: 0.04785711690783501\n",
            "Epoch 47, Step 240, Loss: 0.07296910881996155\n",
            "Epoch 47, Step 241, Loss: 0.02256726287305355\n",
            "Epoch 47, Step 242, Loss: 0.039798006415367126\n",
            "Epoch 47, Step 243, Loss: 0.052589863538742065\n",
            "Epoch 47, Step 244, Loss: 0.036991141736507416\n",
            "Epoch 47, Step 245, Loss: 0.017363904044032097\n",
            "Epoch 47, Step 246, Loss: 0.06626000255346298\n",
            "Epoch 47, Step 247, Loss: 0.034718528389930725\n",
            "Epoch 47, Step 248, Loss: 0.07321842759847641\n",
            "Epoch 47, Step 249, Loss: 0.03516066446900368\n",
            "Epoch 47, Step 250, Loss: 0.059033945202827454\n",
            "Epoch 47, Step 251, Loss: 0.07339657843112946\n",
            "Epoch 47, Step 252, Loss: 0.007375818677246571\n",
            "Epoch 47, Step 253, Loss: 0.015863150358200073\n",
            "Epoch 47, Step 254, Loss: 0.0707300454378128\n",
            "Epoch 47, Step 255, Loss: 0.027462730184197426\n",
            "Epoch 47, Step 256, Loss: 0.022950321435928345\n",
            "Epoch 47, Step 257, Loss: 0.06784752011299133\n",
            "Epoch 47, Step 258, Loss: 0.027565164491534233\n",
            "Epoch 47, Step 259, Loss: 0.0629708543419838\n",
            "Epoch 47, Step 260, Loss: 0.09841001778841019\n",
            "Epoch 47, Step 261, Loss: 0.03985512629151344\n",
            "Epoch 47, Step 262, Loss: 0.01989612728357315\n",
            "Epoch 47, Step 263, Loss: 0.08589625358581543\n",
            "Epoch 47, Step 264, Loss: 0.0629834532737732\n",
            "Epoch 47, Step 265, Loss: 0.0436396449804306\n",
            "Epoch 47, Step 266, Loss: 0.024588629603385925\n",
            "Epoch 47, Step 267, Loss: 0.0659206435084343\n",
            "Epoch 47, Step 268, Loss: 0.10996600985527039\n",
            "Epoch 47, Step 269, Loss: 0.014082778245210648\n",
            "Epoch 47, Step 270, Loss: 0.042479027062654495\n",
            "Epoch 47, Step 271, Loss: 0.0317198745906353\n",
            "Epoch 47, Step 272, Loss: 0.061096303164958954\n",
            "Epoch 47, Step 273, Loss: 0.054746877402067184\n",
            "Epoch 47, Step 274, Loss: 0.05470354110002518\n",
            "Epoch 47, Step 275, Loss: 0.03771529719233513\n",
            "Epoch 47, Step 276, Loss: 0.06684111803770065\n",
            "Epoch 47, Step 277, Loss: 0.040530044585466385\n",
            "Epoch 47, Step 278, Loss: 0.074198879301548\n",
            "Epoch 47, Step 279, Loss: 0.08677374571561813\n",
            "Epoch 47, Step 280, Loss: 0.03939087316393852\n",
            "Epoch 47, Step 281, Loss: 0.004000141751021147\n",
            "Epoch 47, Step 282, Loss: 0.05051914602518082\n",
            "Epoch 47, Step 283, Loss: 0.0328647755086422\n",
            "Epoch 47, Step 284, Loss: 0.0339326374232769\n",
            "Epoch 47, Step 285, Loss: 0.05348709225654602\n",
            "Epoch 47, Step 286, Loss: 0.061076607555150986\n",
            "Epoch 47, Step 287, Loss: 0.03808679059147835\n",
            "Epoch 47, Step 288, Loss: 0.09577570855617523\n",
            "Epoch 47, Step 289, Loss: 0.07489103078842163\n",
            "Epoch 47, Step 290, Loss: 0.06615224480628967\n",
            "Epoch 47, Step 291, Loss: 0.05463676154613495\n",
            "Epoch 47, Step 292, Loss: 0.05051003023982048\n",
            "Epoch 47, Step 293, Loss: 0.09466584026813507\n",
            "Epoch 47, Step 294, Loss: 0.14114421606063843\n",
            "Epoch 47, Step 295, Loss: 0.0929141491651535\n",
            "Epoch 47, Step 296, Loss: 0.0696578100323677\n",
            "Epoch 47, Step 297, Loss: 0.04749870300292969\n",
            "Epoch 47, Step 298, Loss: 0.1053307056427002\n",
            "Epoch 47, Step 299, Loss: 0.061734288930892944\n",
            "Epoch 47, Step 300, Loss: 0.10392940044403076\n",
            "Epoch 47, Step 301, Loss: 0.02646084502339363\n",
            "Epoch 47, Step 302, Loss: 0.009839525446295738\n",
            "Epoch 47, Step 303, Loss: 0.05742047354578972\n",
            "Epoch 47, Step 304, Loss: 0.07759245485067368\n",
            "Epoch 47, Step 305, Loss: 0.0937248021364212\n",
            "Epoch 47, Step 306, Loss: 0.0811326801776886\n",
            "Epoch 47, Step 307, Loss: 0.07565542310476303\n",
            "Epoch 47, Step 308, Loss: 0.07257339358329773\n",
            "Epoch 47, Step 309, Loss: 0.09836578369140625\n",
            "Epoch 47, Step 310, Loss: 0.10185349732637405\n",
            "Epoch 47, Step 311, Loss: 0.03909286856651306\n",
            "Epoch 47, Step 312, Loss: 0.13932335376739502\n",
            "Epoch 47 end, avg train loss: 0.051235025812583136\n",
            "Epoch 47 end, avg val loss: 0.42914386508585534, accuracy: 90.66%\n",
            "Epoch 48, Step 0, Loss: 0.01577772945165634\n",
            "Epoch 48, Step 1, Loss: 0.10248449444770813\n",
            "Epoch 48, Step 2, Loss: 0.08918994665145874\n",
            "Epoch 48, Step 3, Loss: 0.037317708134651184\n",
            "Epoch 48, Step 4, Loss: 0.04020675644278526\n",
            "Epoch 48, Step 5, Loss: 0.050409696996212006\n",
            "Epoch 48, Step 6, Loss: 0.04646674916148186\n",
            "Epoch 48, Step 7, Loss: 0.11205805093050003\n",
            "Epoch 48, Step 8, Loss: 0.08320076763629913\n",
            "Epoch 48, Step 9, Loss: 0.06404055655002594\n",
            "Epoch 48, Step 10, Loss: 0.11221346259117126\n",
            "Epoch 48, Step 11, Loss: 0.22962360084056854\n",
            "Epoch 48, Step 12, Loss: 0.06336145102977753\n",
            "Epoch 48, Step 13, Loss: 0.05110050365328789\n",
            "Epoch 48, Step 14, Loss: 0.08027657121419907\n",
            "Epoch 48, Step 15, Loss: 0.038494303822517395\n",
            "Epoch 48, Step 16, Loss: 0.0965849980711937\n",
            "Epoch 48, Step 17, Loss: 0.12005256116390228\n",
            "Epoch 48, Step 18, Loss: 0.07897332310676575\n",
            "Epoch 48, Step 19, Loss: 0.05412595719099045\n",
            "Epoch 48, Step 20, Loss: 0.08249117434024811\n",
            "Epoch 48, Step 21, Loss: 0.17920857667922974\n",
            "Epoch 48, Step 22, Loss: 0.021789945662021637\n",
            "Epoch 48, Step 23, Loss: 0.06428537517786026\n",
            "Epoch 48, Step 24, Loss: 0.04969165846705437\n",
            "Epoch 48, Step 25, Loss: 0.09307628870010376\n",
            "Epoch 48, Step 26, Loss: 0.08777930587530136\n",
            "Epoch 48, Step 27, Loss: 0.06321314722299576\n",
            "Epoch 48, Step 28, Loss: 0.05936472862958908\n",
            "Epoch 48, Step 29, Loss: 0.07335545122623444\n",
            "Epoch 48, Step 30, Loss: 0.0615105964243412\n",
            "Epoch 48, Step 31, Loss: 0.03392816334962845\n",
            "Epoch 48, Step 32, Loss: 0.1059006080031395\n",
            "Epoch 48, Step 33, Loss: 0.07121166586875916\n",
            "Epoch 48, Step 34, Loss: 0.09850134700536728\n",
            "Epoch 48, Step 35, Loss: 0.15237490832805634\n",
            "Epoch 48, Step 36, Loss: 0.03216089680790901\n",
            "Epoch 48, Step 37, Loss: 0.034727420657873154\n",
            "Epoch 48, Step 38, Loss: 0.02651236392557621\n",
            "Epoch 48, Step 39, Loss: 0.03431710973381996\n",
            "Epoch 48, Step 40, Loss: 0.04794925078749657\n",
            "Epoch 48, Step 41, Loss: 0.08067689090967178\n",
            "Epoch 48, Step 42, Loss: 0.03491005301475525\n",
            "Epoch 48, Step 43, Loss: 0.11293414980173111\n",
            "Epoch 48, Step 44, Loss: 0.09013649076223373\n",
            "Epoch 48, Step 45, Loss: 0.06631322205066681\n",
            "Epoch 48, Step 46, Loss: 0.05535002797842026\n",
            "Epoch 48, Step 47, Loss: 0.07539843767881393\n",
            "Epoch 48, Step 48, Loss: 0.04482266679406166\n",
            "Epoch 48, Step 49, Loss: 0.01092385221272707\n",
            "Epoch 48, Step 50, Loss: 0.04265729337930679\n",
            "Epoch 48, Step 51, Loss: 0.019022691994905472\n",
            "Epoch 48, Step 52, Loss: 0.03903096169233322\n",
            "Epoch 48, Step 53, Loss: 0.0406891368329525\n",
            "Epoch 48, Step 54, Loss: 0.09222572296857834\n",
            "Epoch 48, Step 55, Loss: 0.032337356358766556\n",
            "Epoch 48, Step 56, Loss: 0.027287600561976433\n",
            "Epoch 48, Step 57, Loss: 0.01800227165222168\n",
            "Epoch 48, Step 58, Loss: 0.06293982267379761\n",
            "Epoch 48, Step 59, Loss: 0.07215754687786102\n",
            "Epoch 48, Step 60, Loss: 0.02576301246881485\n",
            "Epoch 48, Step 61, Loss: 0.09805101156234741\n",
            "Epoch 48, Step 62, Loss: 0.044034793972969055\n",
            "Epoch 48, Step 63, Loss: 0.0427699089050293\n",
            "Epoch 48, Step 64, Loss: 0.05668017268180847\n",
            "Epoch 48, Step 65, Loss: 0.0922076404094696\n",
            "Epoch 48, Step 66, Loss: 0.038658257573843\n",
            "Epoch 48, Step 67, Loss: 0.018465079367160797\n",
            "Epoch 48, Step 68, Loss: 0.11577398329973221\n",
            "Epoch 48, Step 69, Loss: 0.020388273522257805\n",
            "Epoch 48, Step 70, Loss: 0.02537892572581768\n",
            "Epoch 48, Step 71, Loss: 0.0623348131775856\n",
            "Epoch 48, Step 72, Loss: 0.030284635722637177\n",
            "Epoch 48, Step 73, Loss: 0.028932854533195496\n",
            "Epoch 48, Step 74, Loss: 0.02103770524263382\n",
            "Epoch 48, Step 75, Loss: 0.028021758422255516\n",
            "Epoch 48, Step 76, Loss: 0.017237568274140358\n",
            "Epoch 48, Step 77, Loss: 0.048074208199977875\n",
            "Epoch 48, Step 78, Loss: 0.03582557663321495\n",
            "Epoch 48, Step 79, Loss: 0.06815744936466217\n",
            "Epoch 48, Step 80, Loss: 0.023243112489581108\n",
            "Epoch 48, Step 81, Loss: 0.046926967799663544\n",
            "Epoch 48, Step 82, Loss: 0.08857036381959915\n",
            "Epoch 48, Step 83, Loss: 0.044268812984228134\n",
            "Epoch 48, Step 84, Loss: 0.07646944373846054\n",
            "Epoch 48, Step 85, Loss: 0.06944067776203156\n",
            "Epoch 48, Step 86, Loss: 0.023736458271741867\n",
            "Epoch 48, Step 87, Loss: 0.04457297921180725\n",
            "Epoch 48, Step 88, Loss: 0.03839745745062828\n",
            "Epoch 48, Step 89, Loss: 0.05049757659435272\n",
            "Epoch 48, Step 90, Loss: 0.04709276184439659\n",
            "Epoch 48, Step 91, Loss: 0.16342730820178986\n",
            "Epoch 48, Step 92, Loss: 0.09503274410963058\n",
            "Epoch 48, Step 93, Loss: 0.011162029579281807\n",
            "Epoch 48, Step 94, Loss: 0.051319148391485214\n",
            "Epoch 48, Step 95, Loss: 0.03327684849500656\n",
            "Epoch 48, Step 96, Loss: 0.10790454596281052\n",
            "Epoch 48, Step 97, Loss: 0.051728520542383194\n",
            "Epoch 48, Step 98, Loss: 0.10114039480686188\n",
            "Epoch 48, Step 99, Loss: 0.06583499163389206\n",
            "Epoch 48, Step 100, Loss: 0.055897247046232224\n",
            "Epoch 48, Step 101, Loss: 0.05712413042783737\n",
            "Epoch 48, Step 102, Loss: 0.08826559036970139\n",
            "Epoch 48, Step 103, Loss: 0.00899206381291151\n",
            "Epoch 48, Step 104, Loss: 0.034049540758132935\n",
            "Epoch 48, Step 105, Loss: 0.07387018203735352\n",
            "Epoch 48, Step 106, Loss: 0.08394850045442581\n",
            "Epoch 48, Step 107, Loss: 0.04950752481818199\n",
            "Epoch 48, Step 108, Loss: 0.05635455995798111\n",
            "Epoch 48, Step 109, Loss: 0.07163415104150772\n",
            "Epoch 48, Step 110, Loss: 0.035942401736974716\n",
            "Epoch 48, Step 111, Loss: 0.05206751450896263\n",
            "Epoch 48, Step 112, Loss: 0.02792656049132347\n",
            "Epoch 48, Step 113, Loss: 0.0921434536576271\n",
            "Epoch 48, Step 114, Loss: 0.06200942397117615\n",
            "Epoch 48, Step 115, Loss: 0.10262104123830795\n",
            "Epoch 48, Step 116, Loss: 0.08005889505147934\n",
            "Epoch 48, Step 117, Loss: 0.09257131814956665\n",
            "Epoch 48, Step 118, Loss: 0.0924777239561081\n",
            "Epoch 48, Step 119, Loss: 0.020397180691361427\n",
            "Epoch 48, Step 120, Loss: 0.0768500342965126\n",
            "Epoch 48, Step 121, Loss: 0.06263064593076706\n",
            "Epoch 48, Step 122, Loss: 0.1111152246594429\n",
            "Epoch 48, Step 123, Loss: 0.056893836706876755\n",
            "Epoch 48, Step 124, Loss: 0.03919238969683647\n",
            "Epoch 48, Step 125, Loss: 0.07578911632299423\n",
            "Epoch 48, Step 126, Loss: 0.032890256494283676\n",
            "Epoch 48, Step 127, Loss: 0.04037642106413841\n",
            "Epoch 48, Step 128, Loss: 0.1008288785815239\n",
            "Epoch 48, Step 129, Loss: 0.09075377881526947\n",
            "Epoch 48, Step 130, Loss: 0.01854916661977768\n",
            "Epoch 48, Step 131, Loss: 0.03511611744761467\n",
            "Epoch 48, Step 132, Loss: 0.14678804576396942\n",
            "Epoch 48, Step 133, Loss: 0.024696404114365578\n",
            "Epoch 48, Step 134, Loss: 0.07380293309688568\n",
            "Epoch 48, Step 135, Loss: 0.1251479834318161\n",
            "Epoch 48, Step 136, Loss: 0.013852907344698906\n",
            "Epoch 48, Step 137, Loss: 0.042616747319698334\n",
            "Epoch 48, Step 138, Loss: 0.020287591964006424\n",
            "Epoch 48, Step 139, Loss: 0.012011848390102386\n",
            "Epoch 48, Step 140, Loss: 0.02912934124469757\n",
            "Epoch 48, Step 141, Loss: 0.03745922073721886\n",
            "Epoch 48, Step 142, Loss: 0.09230122715234756\n",
            "Epoch 48, Step 143, Loss: 0.014785143546760082\n",
            "Epoch 48, Step 144, Loss: 0.03243947774171829\n",
            "Epoch 48, Step 145, Loss: 0.04590826854109764\n",
            "Epoch 48, Step 146, Loss: 0.04140669107437134\n",
            "Epoch 48, Step 147, Loss: 0.03711302578449249\n",
            "Epoch 48, Step 148, Loss: 0.02437189593911171\n",
            "Epoch 48, Step 149, Loss: 0.03920609876513481\n",
            "Epoch 48, Step 150, Loss: 0.030397502705454826\n",
            "Epoch 48, Step 151, Loss: 0.01373964361846447\n",
            "Epoch 48, Step 152, Loss: 0.03602223843336105\n",
            "Epoch 48, Step 153, Loss: 0.04077864810824394\n",
            "Epoch 48, Step 154, Loss: 0.026454731822013855\n",
            "Epoch 48, Step 155, Loss: 0.035161666572093964\n",
            "Epoch 48, Step 156, Loss: 0.030088452622294426\n",
            "Epoch 48, Step 157, Loss: 0.021022025495767593\n",
            "Epoch 48, Step 158, Loss: 0.012108800932765007\n",
            "Epoch 48, Step 159, Loss: 0.019196687266230583\n",
            "Epoch 48, Step 160, Loss: 0.02353469841182232\n",
            "Epoch 48, Step 161, Loss: 0.030413392931222916\n",
            "Epoch 48, Step 162, Loss: 0.03833344951272011\n",
            "Epoch 48, Step 163, Loss: 0.008526830933988094\n",
            "Epoch 48, Step 164, Loss: 0.04728493466973305\n",
            "Epoch 48, Step 165, Loss: 0.04161533713340759\n",
            "Epoch 48, Step 166, Loss: 0.03594192489981651\n",
            "Epoch 48, Step 167, Loss: 0.026910729706287384\n",
            "Epoch 48, Step 168, Loss: 0.06552828848361969\n",
            "Epoch 48, Step 169, Loss: 0.02001437358558178\n",
            "Epoch 48, Step 170, Loss: 0.08161259442567825\n",
            "Epoch 48, Step 171, Loss: 0.036138396710157394\n",
            "Epoch 48, Step 172, Loss: 0.12722863256931305\n",
            "Epoch 48, Step 173, Loss: 0.03828546404838562\n",
            "Epoch 48, Step 174, Loss: 0.0595182441174984\n",
            "Epoch 48, Step 175, Loss: 0.037310533225536346\n",
            "Epoch 48, Step 176, Loss: 0.06990860402584076\n",
            "Epoch 48, Step 177, Loss: 0.024628516286611557\n",
            "Epoch 48, Step 178, Loss: 0.015922849997878075\n",
            "Epoch 48, Step 179, Loss: 0.06102263554930687\n",
            "Epoch 48, Step 180, Loss: 0.048138413578271866\n",
            "Epoch 48, Step 181, Loss: 0.021244460716843605\n",
            "Epoch 48, Step 182, Loss: 0.01594015583395958\n",
            "Epoch 48, Step 183, Loss: 0.03435678035020828\n",
            "Epoch 48, Step 184, Loss: 0.04300857335329056\n",
            "Epoch 48, Step 185, Loss: 0.051464956253767014\n",
            "Epoch 48, Step 186, Loss: 0.035938117653131485\n",
            "Epoch 48, Step 187, Loss: 0.03963126242160797\n",
            "Epoch 48, Step 188, Loss: 0.032132163643836975\n",
            "Epoch 48, Step 189, Loss: 0.022818395867943764\n",
            "Epoch 48, Step 190, Loss: 0.0312457624822855\n",
            "Epoch 48, Step 191, Loss: 0.07178450375795364\n",
            "Epoch 48, Step 192, Loss: 0.025864431634545326\n",
            "Epoch 48, Step 193, Loss: 0.024553682655096054\n",
            "Epoch 48, Step 194, Loss: 0.07210919260978699\n",
            "Epoch 48, Step 195, Loss: 0.05463862791657448\n",
            "Epoch 48, Step 196, Loss: 0.0206118393689394\n",
            "Epoch 48, Step 197, Loss: 0.04945576190948486\n",
            "Epoch 48, Step 198, Loss: 0.010021291673183441\n",
            "Epoch 48, Step 199, Loss: 0.04611196368932724\n",
            "Epoch 48, Step 200, Loss: 0.043812096118927\n",
            "Epoch 48, Step 201, Loss: 0.028153399005532265\n",
            "Epoch 48, Step 202, Loss: 0.01567128673195839\n",
            "Epoch 48, Step 203, Loss: 0.02161514386534691\n",
            "Epoch 48, Step 204, Loss: 0.03266657888889313\n",
            "Epoch 48, Step 205, Loss: 0.03446722775697708\n",
            "Epoch 48, Step 206, Loss: 0.018708806484937668\n",
            "Epoch 48, Step 207, Loss: 0.02207610011100769\n",
            "Epoch 48, Step 208, Loss: 0.05774511769413948\n",
            "Epoch 48, Step 209, Loss: 0.03147241100668907\n",
            "Epoch 48, Step 210, Loss: 0.01081398967653513\n",
            "Epoch 48, Step 211, Loss: 0.03125104308128357\n",
            "Epoch 48, Step 212, Loss: 0.052948951721191406\n",
            "Epoch 48, Step 213, Loss: 0.02493819035589695\n",
            "Epoch 48, Step 214, Loss: 0.06726203858852386\n",
            "Epoch 48, Step 215, Loss: 0.06892970949411392\n",
            "Epoch 48, Step 216, Loss: 0.05616070702672005\n",
            "Epoch 48, Step 217, Loss: 0.015533411875367165\n",
            "Epoch 48, Step 218, Loss: 0.02187618426978588\n",
            "Epoch 48, Step 219, Loss: 0.013611779548227787\n",
            "Epoch 48, Step 220, Loss: 0.032032329589128494\n",
            "Epoch 48, Step 221, Loss: 0.02655751444399357\n",
            "Epoch 48, Step 222, Loss: 0.04017515853047371\n",
            "Epoch 48, Step 223, Loss: 0.03646222874522209\n",
            "Epoch 48, Step 224, Loss: 0.0221620611846447\n",
            "Epoch 48, Step 225, Loss: 0.03771970421075821\n",
            "Epoch 48, Step 226, Loss: 0.014686454087495804\n",
            "Epoch 48, Step 227, Loss: 0.017556944862008095\n",
            "Epoch 48, Step 228, Loss: 0.04462389647960663\n",
            "Epoch 48, Step 229, Loss: 0.012862509116530418\n",
            "Epoch 48, Step 230, Loss: 0.07247061282396317\n",
            "Epoch 48, Step 231, Loss: 0.015909366309642792\n",
            "Epoch 48, Step 232, Loss: 0.03963775560259819\n",
            "Epoch 48, Step 233, Loss: 0.04680333659052849\n",
            "Epoch 48, Step 234, Loss: 0.03944220021367073\n",
            "Epoch 48, Step 235, Loss: 0.05467328429222107\n",
            "Epoch 48, Step 236, Loss: 0.11851140111684799\n",
            "Epoch 48, Step 237, Loss: 0.033585455268621445\n",
            "Epoch 48, Step 238, Loss: 0.013415410183370113\n",
            "Epoch 48, Step 239, Loss: 0.0569271519780159\n",
            "Epoch 48, Step 240, Loss: 0.02612190507352352\n",
            "Epoch 48, Step 241, Loss: 0.06130081042647362\n",
            "Epoch 48, Step 242, Loss: 0.06826207041740417\n",
            "Epoch 48, Step 243, Loss: 0.028788279742002487\n",
            "Epoch 48, Step 244, Loss: 0.018550969660282135\n",
            "Epoch 48, Step 245, Loss: 0.024421539157629013\n",
            "Epoch 48, Step 246, Loss: 0.03131074830889702\n",
            "Epoch 48, Step 247, Loss: 0.0420311763882637\n",
            "Epoch 48, Step 248, Loss: 0.028322026133537292\n",
            "Epoch 48, Step 249, Loss: 0.060085345059633255\n",
            "Epoch 48, Step 250, Loss: 0.049025654792785645\n",
            "Epoch 48, Step 251, Loss: 0.07244795560836792\n",
            "Epoch 48, Step 252, Loss: 0.06042046099901199\n",
            "Epoch 48, Step 253, Loss: 0.06550479680299759\n",
            "Epoch 48, Step 254, Loss: 0.05542135238647461\n",
            "Epoch 48, Step 255, Loss: 0.035454366356134415\n",
            "Epoch 48, Step 256, Loss: 0.036948539316654205\n",
            "Epoch 48, Step 257, Loss: 0.04095150902867317\n",
            "Epoch 48, Step 258, Loss: 0.06618782877922058\n",
            "Epoch 48, Step 259, Loss: 0.04416975751519203\n",
            "Epoch 48, Step 260, Loss: 0.06985983997583389\n",
            "Epoch 48, Step 261, Loss: 0.005250696092844009\n",
            "Epoch 48, Step 262, Loss: 0.0666126236319542\n",
            "Epoch 48, Step 263, Loss: 0.03052910976111889\n",
            "Epoch 48, Step 264, Loss: 0.04453297331929207\n",
            "Epoch 48, Step 265, Loss: 0.011515339836478233\n",
            "Epoch 48, Step 266, Loss: 0.05710771679878235\n",
            "Epoch 48, Step 267, Loss: 0.04779363051056862\n",
            "Epoch 48, Step 268, Loss: 0.02525239624083042\n",
            "Epoch 48, Step 269, Loss: 0.03944225609302521\n",
            "Epoch 48, Step 270, Loss: 0.06457103043794632\n",
            "Epoch 48, Step 271, Loss: 0.04714272916316986\n",
            "Epoch 48, Step 272, Loss: 0.021712882444262505\n",
            "Epoch 48, Step 273, Loss: 0.022000644356012344\n",
            "Epoch 48, Step 274, Loss: 0.0921006128191948\n",
            "Epoch 48, Step 275, Loss: 0.12436967343091965\n",
            "Epoch 48, Step 276, Loss: 0.06263145804405212\n",
            "Epoch 48, Step 277, Loss: 0.03506460785865784\n",
            "Epoch 48, Step 278, Loss: 0.035862717777490616\n",
            "Epoch 48, Step 279, Loss: 0.02914540469646454\n",
            "Epoch 48, Step 280, Loss: 0.05557810887694359\n",
            "Epoch 48, Step 281, Loss: 0.10834071040153503\n",
            "Epoch 48, Step 282, Loss: 0.07190630584955215\n",
            "Epoch 48, Step 283, Loss: 0.02318624034523964\n",
            "Epoch 48, Step 284, Loss: 0.11861610412597656\n",
            "Epoch 48, Step 285, Loss: 0.012558400630950928\n",
            "Epoch 48, Step 286, Loss: 0.07837042957544327\n",
            "Epoch 48, Step 287, Loss: 0.03831064701080322\n",
            "Epoch 48, Step 288, Loss: 0.021355947479605675\n",
            "Epoch 48, Step 289, Loss: 0.03368118405342102\n",
            "Epoch 48, Step 290, Loss: 0.06257106363773346\n",
            "Epoch 48, Step 291, Loss: 0.06493593007326126\n",
            "Epoch 48, Step 292, Loss: 0.04003503546118736\n",
            "Epoch 48, Step 293, Loss: 0.06306978315114975\n",
            "Epoch 48, Step 294, Loss: 0.015465885400772095\n",
            "Epoch 48, Step 295, Loss: 0.054877329617738724\n",
            "Epoch 48, Step 296, Loss: 0.04288574680685997\n",
            "Epoch 48, Step 297, Loss: 0.023596834391355515\n",
            "Epoch 48, Step 298, Loss: 0.05474955588579178\n",
            "Epoch 48, Step 299, Loss: 0.03797782212495804\n",
            "Epoch 48, Step 300, Loss: 0.03076365776360035\n",
            "Epoch 48, Step 301, Loss: 0.025813736021518707\n",
            "Epoch 48, Step 302, Loss: 0.016539545729756355\n",
            "Epoch 48, Step 303, Loss: 0.10079839825630188\n",
            "Epoch 48, Step 304, Loss: 0.04849470406770706\n",
            "Epoch 48, Step 305, Loss: 0.04141074791550636\n",
            "Epoch 48, Step 306, Loss: 0.018691543489694595\n",
            "Epoch 48, Step 307, Loss: 0.045744091272354126\n",
            "Epoch 48, Step 308, Loss: 0.05785909667611122\n",
            "Epoch 48, Step 309, Loss: 0.03359050676226616\n",
            "Epoch 48, Step 310, Loss: 0.013603268191218376\n",
            "Epoch 48, Step 311, Loss: 0.02553243190050125\n",
            "Epoch 48, Step 312, Loss: 0.03844369947910309\n",
            "Epoch 48 end, avg train loss: 0.05035350129853327\n",
            "Epoch 48 end, avg val loss: 0.3723495544134816, accuracy: 91.50%\n",
            "Epoch 49, Step 0, Loss: 0.028472909703850746\n",
            "Epoch 49, Step 1, Loss: 0.014195568859577179\n",
            "Epoch 49, Step 2, Loss: 0.029102284461259842\n",
            "Epoch 49, Step 3, Loss: 0.024553027004003525\n",
            "Epoch 49, Step 4, Loss: 0.048062752932310104\n",
            "Epoch 49, Step 5, Loss: 0.07031036913394928\n",
            "Epoch 49, Step 6, Loss: 0.050899386405944824\n",
            "Epoch 49, Step 7, Loss: 0.0422225184738636\n",
            "Epoch 49, Step 8, Loss: 0.08126406371593475\n",
            "Epoch 49, Step 9, Loss: 0.06020057573914528\n",
            "Epoch 49, Step 10, Loss: 0.027314046397805214\n",
            "Epoch 49, Step 11, Loss: 0.00523935304954648\n",
            "Epoch 49, Step 12, Loss: 0.13039530813694\n",
            "Epoch 49, Step 13, Loss: 0.0514189675450325\n",
            "Epoch 49, Step 14, Loss: 0.0557628758251667\n",
            "Epoch 49, Step 15, Loss: 0.03773215040564537\n",
            "Epoch 49, Step 16, Loss: 0.0325549878180027\n",
            "Epoch 49, Step 17, Loss: 0.008989443071186543\n",
            "Epoch 49, Step 18, Loss: 0.03599836677312851\n",
            "Epoch 49, Step 19, Loss: 0.02823185920715332\n",
            "Epoch 49, Step 20, Loss: 0.027728550136089325\n",
            "Epoch 49, Step 21, Loss: 0.09319959580898285\n",
            "Epoch 49, Step 22, Loss: 0.030679257586598396\n",
            "Epoch 49, Step 23, Loss: 0.012114227749407291\n",
            "Epoch 49, Step 24, Loss: 0.002404901897534728\n",
            "Epoch 49, Step 25, Loss: 0.026118533685803413\n",
            "Epoch 49, Step 26, Loss: 0.055033858865499496\n",
            "Epoch 49, Step 27, Loss: 0.046777449548244476\n",
            "Epoch 49, Step 28, Loss: 0.02371179684996605\n",
            "Epoch 49, Step 29, Loss: 0.10403534024953842\n",
            "Epoch 49, Step 30, Loss: 0.05549784377217293\n",
            "Epoch 49, Step 31, Loss: 0.04378737509250641\n",
            "Epoch 49, Step 32, Loss: 0.07039350271224976\n",
            "Epoch 49, Step 33, Loss: 0.029595384374260902\n",
            "Epoch 49, Step 34, Loss: 0.05636925995349884\n",
            "Epoch 49, Step 35, Loss: 0.04248423874378204\n",
            "Epoch 49, Step 36, Loss: 0.033445101231336594\n",
            "Epoch 49, Step 37, Loss: 0.039390284568071365\n",
            "Epoch 49, Step 38, Loss: 0.026827864348888397\n",
            "Epoch 49, Step 39, Loss: 0.029062367975711823\n",
            "Epoch 49, Step 40, Loss: 0.03288796916604042\n",
            "Epoch 49, Step 41, Loss: 0.049255989491939545\n",
            "Epoch 49, Step 42, Loss: 0.06419851630926132\n",
            "Epoch 49, Step 43, Loss: 0.03478896617889404\n",
            "Epoch 49, Step 44, Loss: 0.027680380269885063\n",
            "Epoch 49, Step 45, Loss: 0.051686372607946396\n",
            "Epoch 49, Step 46, Loss: 0.05497812479734421\n",
            "Epoch 49, Step 47, Loss: 0.07194263488054276\n",
            "Epoch 49, Step 48, Loss: 0.014512145891785622\n",
            "Epoch 49, Step 49, Loss: 0.008188480511307716\n",
            "Epoch 49, Step 50, Loss: 0.05461598187685013\n",
            "Epoch 49, Step 51, Loss: 0.03403050824999809\n",
            "Epoch 49, Step 52, Loss: 0.029961910098791122\n",
            "Epoch 49, Step 53, Loss: 0.07529821246862411\n",
            "Epoch 49, Step 54, Loss: 0.023172885179519653\n",
            "Epoch 49, Step 55, Loss: 0.03984867036342621\n",
            "Epoch 49, Step 56, Loss: 0.027017876505851746\n",
            "Epoch 49, Step 57, Loss: 0.015292225405573845\n",
            "Epoch 49, Step 58, Loss: 0.04273611307144165\n",
            "Epoch 49, Step 59, Loss: 0.05762689933180809\n",
            "Epoch 49, Step 60, Loss: 0.04213061183691025\n",
            "Epoch 49, Step 61, Loss: 0.038463372737169266\n",
            "Epoch 49, Step 62, Loss: 0.05612571910023689\n",
            "Epoch 49, Step 63, Loss: 0.060682687908411026\n",
            "Epoch 49, Step 64, Loss: 0.05976320803165436\n",
            "Epoch 49, Step 65, Loss: 0.0879381075501442\n",
            "Epoch 49, Step 66, Loss: 0.0430343933403492\n",
            "Epoch 49, Step 67, Loss: 0.02918095327913761\n",
            "Epoch 49, Step 68, Loss: 0.07717843353748322\n",
            "Epoch 49, Step 69, Loss: 0.05674169957637787\n",
            "Epoch 49, Step 70, Loss: 0.03665999695658684\n",
            "Epoch 49, Step 71, Loss: 0.03696729987859726\n",
            "Epoch 49, Step 72, Loss: 0.017863601446151733\n",
            "Epoch 49, Step 73, Loss: 0.08936610817909241\n",
            "Epoch 49, Step 74, Loss: 0.005966835655272007\n",
            "Epoch 49, Step 75, Loss: 0.10107361525297165\n",
            "Epoch 49, Step 76, Loss: 0.047811973839998245\n",
            "Epoch 49, Step 77, Loss: 0.060733236372470856\n",
            "Epoch 49, Step 78, Loss: 0.015657303854823112\n",
            "Epoch 49, Step 79, Loss: 0.011620068922638893\n",
            "Epoch 49, Step 80, Loss: 0.023105893284082413\n",
            "Epoch 49, Step 81, Loss: 0.0441642664372921\n",
            "Epoch 49, Step 82, Loss: 0.033092182129621506\n",
            "Epoch 49, Step 83, Loss: 0.044021446257829666\n",
            "Epoch 49, Step 84, Loss: 0.07824857532978058\n",
            "Epoch 49, Step 85, Loss: 0.10679828375577927\n",
            "Epoch 49, Step 86, Loss: 0.047848958522081375\n",
            "Epoch 49, Step 87, Loss: 0.08477194607257843\n",
            "Epoch 49, Step 88, Loss: 0.020692462101578712\n",
            "Epoch 49, Step 89, Loss: 0.010673382319509983\n",
            "Epoch 49, Step 90, Loss: 0.02354339510202408\n",
            "Epoch 49, Step 91, Loss: 0.018635468557476997\n",
            "Epoch 49, Step 92, Loss: 0.051068585366010666\n",
            "Epoch 49, Step 93, Loss: 0.033393051475286484\n",
            "Epoch 49, Step 94, Loss: 0.007853876799345016\n",
            "Epoch 49, Step 95, Loss: 0.010570468381047249\n",
            "Epoch 49, Step 96, Loss: 0.03377705067396164\n",
            "Epoch 49, Step 97, Loss: 0.015074511989951134\n",
            "Epoch 49, Step 98, Loss: 0.04010330140590668\n",
            "Epoch 49, Step 99, Loss: 0.021983707323670387\n",
            "Epoch 49, Step 100, Loss: 0.03872092813253403\n",
            "Epoch 49, Step 101, Loss: 0.054282695055007935\n",
            "Epoch 49, Step 102, Loss: 0.08103565126657486\n",
            "Epoch 49, Step 103, Loss: 0.08425984531641006\n",
            "Epoch 49, Step 104, Loss: 0.03319037705659866\n",
            "Epoch 49, Step 105, Loss: 0.1052146777510643\n",
            "Epoch 49, Step 106, Loss: 0.03137456253170967\n",
            "Epoch 49, Step 107, Loss: 0.036855291575193405\n",
            "Epoch 49, Step 108, Loss: 0.04249873384833336\n",
            "Epoch 49, Step 109, Loss: 0.013618948869407177\n",
            "Epoch 49, Step 110, Loss: 0.03375213220715523\n",
            "Epoch 49, Step 111, Loss: 0.06227594614028931\n",
            "Epoch 49, Step 112, Loss: 0.017237745225429535\n",
            "Epoch 49, Step 113, Loss: 0.08207041025161743\n",
            "Epoch 49, Step 114, Loss: 0.015223092399537563\n",
            "Epoch 49, Step 115, Loss: 0.036812640726566315\n",
            "Epoch 49, Step 116, Loss: 0.03146554157137871\n",
            "Epoch 49, Step 117, Loss: 0.07323408871889114\n",
            "Epoch 49, Step 118, Loss: 0.07121565192937851\n",
            "Epoch 49, Step 119, Loss: 0.09379243105649948\n",
            "Epoch 49, Step 120, Loss: 0.05336249992251396\n",
            "Epoch 49, Step 121, Loss: 0.047968681901693344\n",
            "Epoch 49, Step 122, Loss: 0.07119067013263702\n",
            "Epoch 49, Step 123, Loss: 0.07858619838953018\n",
            "Epoch 49, Step 124, Loss: 0.10041645914316177\n",
            "Epoch 49, Step 125, Loss: 0.004895152524113655\n",
            "Epoch 49, Step 126, Loss: 0.05687760189175606\n",
            "Epoch 49, Step 127, Loss: 0.05678577348589897\n",
            "Epoch 49, Step 128, Loss: 0.007075094617903233\n",
            "Epoch 49, Step 129, Loss: 0.03252037614583969\n",
            "Epoch 49, Step 130, Loss: 0.03397560864686966\n",
            "Epoch 49, Step 131, Loss: 0.10715367645025253\n",
            "Epoch 49, Step 132, Loss: 0.07065624743700027\n",
            "Epoch 49, Step 133, Loss: 0.005778012331575155\n",
            "Epoch 49, Step 134, Loss: 0.042942605912685394\n",
            "Epoch 49, Step 135, Loss: 0.024496566504240036\n",
            "Epoch 49, Step 136, Loss: 0.03744680806994438\n",
            "Epoch 49, Step 137, Loss: 0.05474397912621498\n",
            "Epoch 49, Step 138, Loss: 0.10443756729364395\n",
            "Epoch 49, Step 139, Loss: 0.060438938438892365\n",
            "Epoch 49, Step 140, Loss: 0.15144501626491547\n",
            "Epoch 49, Step 141, Loss: 0.026592683047056198\n",
            "Epoch 49, Step 142, Loss: 0.060201551765203476\n",
            "Epoch 49, Step 143, Loss: 0.021230462938547134\n",
            "Epoch 49, Step 144, Loss: 0.03752089664340019\n",
            "Epoch 49, Step 145, Loss: 0.04372313991189003\n",
            "Epoch 49, Step 146, Loss: 0.05070305988192558\n",
            "Epoch 49, Step 147, Loss: 0.052432943135499954\n",
            "Epoch 49, Step 148, Loss: 0.037935081869363785\n",
            "Epoch 49, Step 149, Loss: 0.04884844645857811\n",
            "Epoch 49, Step 150, Loss: 0.040760815143585205\n",
            "Epoch 49, Step 151, Loss: 0.057305529713630676\n",
            "Epoch 49, Step 152, Loss: 0.0234354417771101\n",
            "Epoch 49, Step 153, Loss: 0.019259106367826462\n",
            "Epoch 49, Step 154, Loss: 0.07020675390958786\n",
            "Epoch 49, Step 155, Loss: 0.07621455937623978\n",
            "Epoch 49, Step 156, Loss: 0.035871315747499466\n",
            "Epoch 49, Step 157, Loss: 0.07020947337150574\n",
            "Epoch 49, Step 158, Loss: 0.06200636178255081\n",
            "Epoch 49, Step 159, Loss: 0.017454760149121284\n",
            "Epoch 49, Step 160, Loss: 0.09877339005470276\n",
            "Epoch 49, Step 161, Loss: 0.04262903332710266\n",
            "Epoch 49, Step 162, Loss: 0.0961209237575531\n",
            "Epoch 49, Step 163, Loss: 0.049805015325546265\n",
            "Epoch 49, Step 164, Loss: 0.061075542122125626\n",
            "Epoch 49, Step 165, Loss: 0.07557318359613419\n",
            "Epoch 49, Step 166, Loss: 0.07221907377243042\n",
            "Epoch 49, Step 167, Loss: 0.1213926300406456\n",
            "Epoch 49, Step 168, Loss: 0.058538809418678284\n",
            "Epoch 49, Step 169, Loss: 0.03014742210507393\n",
            "Epoch 49, Step 170, Loss: 0.06904689967632294\n",
            "Epoch 49, Step 171, Loss: 0.16182783246040344\n",
            "Epoch 49, Step 172, Loss: 0.05079083889722824\n",
            "Epoch 49, Step 173, Loss: 0.0545167438685894\n",
            "Epoch 49, Step 174, Loss: 0.07144639641046524\n",
            "Epoch 49, Step 175, Loss: 0.02889200486242771\n",
            "Epoch 49, Step 176, Loss: 0.07309833914041519\n",
            "Epoch 49, Step 177, Loss: 0.04125746339559555\n",
            "Epoch 49, Step 178, Loss: 0.03904658555984497\n",
            "Epoch 49, Step 179, Loss: 0.06663034856319427\n",
            "Epoch 49, Step 180, Loss: 0.13205215334892273\n",
            "Epoch 49, Step 181, Loss: 0.05921831727027893\n",
            "Epoch 49, Step 182, Loss: 0.05175488814711571\n",
            "Epoch 49, Step 183, Loss: 0.09620938450098038\n",
            "Epoch 49, Step 184, Loss: 0.05055081844329834\n",
            "Epoch 49, Step 185, Loss: 0.05126179754734039\n",
            "Epoch 49, Step 186, Loss: 0.07645173370838165\n",
            "Epoch 49, Step 187, Loss: 0.03917580097913742\n",
            "Epoch 49, Step 188, Loss: 0.04862750694155693\n",
            "Epoch 49, Step 189, Loss: 0.02412918210029602\n",
            "Epoch 49, Step 190, Loss: 0.07299051433801651\n",
            "Epoch 49, Step 191, Loss: 0.035398222506046295\n",
            "Epoch 49, Step 192, Loss: 0.06494523584842682\n",
            "Epoch 49, Step 193, Loss: 0.0781300961971283\n",
            "Epoch 49, Step 194, Loss: 0.08344962447881699\n",
            "Epoch 49, Step 195, Loss: 0.059129372239112854\n",
            "Epoch 49, Step 196, Loss: 0.039922043681144714\n",
            "Epoch 49, Step 197, Loss: 0.029286816716194153\n",
            "Epoch 49, Step 198, Loss: 0.030557023361325264\n",
            "Epoch 49, Step 199, Loss: 0.03305216133594513\n",
            "Epoch 49, Step 200, Loss: 0.05987264961004257\n",
            "Epoch 49, Step 201, Loss: 0.056544024497270584\n",
            "Epoch 49, Step 202, Loss: 0.04740544781088829\n",
            "Epoch 49, Step 203, Loss: 0.10013960301876068\n",
            "Epoch 49, Step 204, Loss: 0.0446496307849884\n",
            "Epoch 49, Step 205, Loss: 0.07778311520814896\n",
            "Epoch 49, Step 206, Loss: 0.11612234264612198\n",
            "Epoch 49, Step 207, Loss: 0.03701204061508179\n",
            "Epoch 49, Step 208, Loss: 0.028444599360227585\n",
            "Epoch 49, Step 209, Loss: 0.1398717612028122\n",
            "Epoch 49, Step 210, Loss: 0.014005285687744617\n",
            "Epoch 49, Step 211, Loss: 0.028035422787070274\n",
            "Epoch 49, Step 212, Loss: 0.04957396909594536\n",
            "Epoch 49, Step 213, Loss: 0.07329210638999939\n",
            "Epoch 49, Step 214, Loss: 0.03644617646932602\n",
            "Epoch 49, Step 215, Loss: 0.08795944601297379\n",
            "Epoch 49, Step 216, Loss: 0.06945798546075821\n",
            "Epoch 49, Step 217, Loss: 0.053522977977991104\n",
            "Epoch 49, Step 218, Loss: 0.053388409316539764\n",
            "Epoch 49, Step 219, Loss: 0.030934344977140427\n",
            "Epoch 49, Step 220, Loss: 0.04988868534564972\n",
            "Epoch 49, Step 221, Loss: 0.09181846678256989\n",
            "Epoch 49, Step 222, Loss: 0.02585187740623951\n",
            "Epoch 49, Step 223, Loss: 0.041313041001558304\n",
            "Epoch 49, Step 224, Loss: 0.11714881658554077\n",
            "Epoch 49, Step 225, Loss: 0.07673509418964386\n",
            "Epoch 49, Step 226, Loss: 0.017240649089217186\n",
            "Epoch 49, Step 227, Loss: 0.07189445197582245\n",
            "Epoch 49, Step 228, Loss: 0.10178175568580627\n",
            "Epoch 49, Step 229, Loss: 0.012945784255862236\n",
            "Epoch 49, Step 230, Loss: 0.0701184943318367\n",
            "Epoch 49, Step 231, Loss: 0.03006140887737274\n",
            "Epoch 49, Step 232, Loss: 0.02720102295279503\n",
            "Epoch 49, Step 233, Loss: 0.0565832145512104\n",
            "Epoch 49, Step 234, Loss: 0.0696561262011528\n",
            "Epoch 49, Step 235, Loss: 0.03234086185693741\n",
            "Epoch 49, Step 236, Loss: 0.0651625394821167\n",
            "Epoch 49, Step 237, Loss: 0.049237124621868134\n",
            "Epoch 49, Step 238, Loss: 0.027744559571146965\n",
            "Epoch 49, Step 239, Loss: 0.0361257940530777\n",
            "Epoch 49, Step 240, Loss: 0.07639127969741821\n",
            "Epoch 49, Step 241, Loss: 0.02761337347328663\n",
            "Epoch 49, Step 242, Loss: 0.11657184362411499\n",
            "Epoch 49, Step 243, Loss: 0.022600511088967323\n",
            "Epoch 49, Step 244, Loss: 0.01462326105684042\n",
            "Epoch 49, Step 245, Loss: 0.02961130253970623\n",
            "Epoch 49, Step 246, Loss: 0.05709145590662956\n",
            "Epoch 49, Step 247, Loss: 0.027586081996560097\n",
            "Epoch 49, Step 248, Loss: 0.026784006506204605\n",
            "Epoch 49, Step 249, Loss: 0.13304805755615234\n",
            "Epoch 49, Step 250, Loss: 0.008045962080359459\n",
            "Epoch 49, Step 251, Loss: 0.051704779267311096\n",
            "Epoch 49, Step 252, Loss: 0.05756063386797905\n",
            "Epoch 49, Step 253, Loss: 0.009793451987206936\n",
            "Epoch 49, Step 254, Loss: 0.10521692037582397\n",
            "Epoch 49, Step 255, Loss: 0.03246811032295227\n",
            "Epoch 49, Step 256, Loss: 0.032039739191532135\n",
            "Epoch 49, Step 257, Loss: 0.0634288564324379\n",
            "Epoch 49, Step 258, Loss: 0.07373218983411789\n",
            "Epoch 49, Step 259, Loss: 0.0136110819876194\n",
            "Epoch 49, Step 260, Loss: 0.033965352922677994\n",
            "Epoch 49, Step 261, Loss: 0.05731451138854027\n",
            "Epoch 49, Step 262, Loss: 0.14535610377788544\n",
            "Epoch 49, Step 263, Loss: 0.0280511025339365\n",
            "Epoch 49, Step 264, Loss: 0.0703214555978775\n",
            "Epoch 49, Step 265, Loss: 0.03227762505412102\n",
            "Epoch 49, Step 266, Loss: 0.06604368984699249\n",
            "Epoch 49, Step 267, Loss: 0.04988214001059532\n",
            "Epoch 49, Step 268, Loss: 0.12745784223079681\n",
            "Epoch 49, Step 269, Loss: 0.04161776602268219\n",
            "Epoch 49, Step 270, Loss: 0.09768261760473251\n",
            "Epoch 49, Step 271, Loss: 0.021816588938236237\n",
            "Epoch 49, Step 272, Loss: 0.0326634980738163\n",
            "Epoch 49, Step 273, Loss: 0.1188402995467186\n",
            "Epoch 49, Step 274, Loss: 0.08641918748617172\n",
            "Epoch 49, Step 275, Loss: 0.05313806235790253\n",
            "Epoch 49, Step 276, Loss: 0.05145420879125595\n",
            "Epoch 49, Step 277, Loss: 0.0550389438867569\n",
            "Epoch 49, Step 278, Loss: 0.0405246838927269\n",
            "Epoch 49, Step 279, Loss: 0.042313605546951294\n",
            "Epoch 49, Step 280, Loss: 0.07169546186923981\n",
            "Epoch 49, Step 281, Loss: 0.053940705955028534\n",
            "Epoch 49, Step 282, Loss: 0.05455105006694794\n",
            "Epoch 49, Step 283, Loss: 0.05180687457323074\n",
            "Epoch 49, Step 284, Loss: 0.05290026590228081\n",
            "Epoch 49, Step 285, Loss: 0.07249581068754196\n",
            "Epoch 49, Step 286, Loss: 0.024145934730768204\n",
            "Epoch 49, Step 287, Loss: 0.05347074568271637\n",
            "Epoch 49, Step 288, Loss: 0.10290742665529251\n",
            "Epoch 49, Step 289, Loss: 0.07879830151796341\n",
            "Epoch 49, Step 290, Loss: 0.05207720771431923\n",
            "Epoch 49, Step 291, Loss: 0.03355075418949127\n",
            "Epoch 49, Step 292, Loss: 0.003311614040285349\n",
            "Epoch 49, Step 293, Loss: 0.02966454066336155\n",
            "Epoch 49, Step 294, Loss: 0.045795440673828125\n",
            "Epoch 49, Step 295, Loss: 0.02890092507004738\n",
            "Epoch 49, Step 296, Loss: 0.028819533064961433\n",
            "Epoch 49, Step 297, Loss: 0.07532145828008652\n",
            "Epoch 49, Step 298, Loss: 0.04680163785815239\n",
            "Epoch 49, Step 299, Loss: 0.019665872678160667\n",
            "Epoch 49, Step 300, Loss: 0.09079913049936295\n",
            "Epoch 49, Step 301, Loss: 0.06820400059223175\n",
            "Epoch 49, Step 302, Loss: 0.048054296523332596\n",
            "Epoch 49, Step 303, Loss: 0.051056914031505585\n",
            "Epoch 49, Step 304, Loss: 0.06412849575281143\n",
            "Epoch 49, Step 305, Loss: 0.0732271745800972\n",
            "Epoch 49, Step 306, Loss: 0.03744370862841606\n",
            "Epoch 49, Step 307, Loss: 0.06380271911621094\n",
            "Epoch 49, Step 308, Loss: 0.038981616497039795\n",
            "Epoch 49, Step 309, Loss: 0.049593258649110794\n",
            "Epoch 49, Step 310, Loss: 0.020475149154663086\n",
            "Epoch 49, Step 311, Loss: 0.04344236105680466\n",
            "Epoch 49, Step 312, Loss: 0.08173214644193649\n",
            "Epoch 49 end, avg train loss: 0.051362980056714753\n",
            "Epoch 49 end, avg val loss: 0.44005680367161953, accuracy: 90.46%\n",
            "Epoch 50, Step 0, Loss: 0.044148460030555725\n",
            "Epoch 50, Step 1, Loss: 0.0593889094889164\n",
            "Epoch 50, Step 2, Loss: 0.11878746747970581\n",
            "Epoch 50, Step 3, Loss: 0.05182277038693428\n",
            "Epoch 50, Step 4, Loss: 0.0702579990029335\n",
            "Epoch 50, Step 5, Loss: 0.023610591888427734\n",
            "Epoch 50, Step 6, Loss: 0.043020348995923996\n",
            "Epoch 50, Step 7, Loss: 0.006323755718767643\n",
            "Epoch 50, Step 8, Loss: 0.06308699399232864\n",
            "Epoch 50, Step 9, Loss: 0.057596947997808456\n",
            "Epoch 50, Step 10, Loss: 0.037215009331703186\n",
            "Epoch 50, Step 11, Loss: 0.02430771104991436\n",
            "Epoch 50, Step 12, Loss: 0.01009536162018776\n",
            "Epoch 50, Step 13, Loss: 0.01515551470220089\n",
            "Epoch 50, Step 14, Loss: 0.09999440610408783\n",
            "Epoch 50, Step 15, Loss: 0.09197232872247696\n",
            "Epoch 50, Step 16, Loss: 0.07861528545618057\n",
            "Epoch 50, Step 17, Loss: 0.04162588715553284\n",
            "Epoch 50, Step 18, Loss: 0.0507192499935627\n",
            "Epoch 50, Step 19, Loss: 0.02478530816733837\n",
            "Epoch 50, Step 20, Loss: 0.11550547927618027\n",
            "Epoch 50, Step 21, Loss: 0.030215976759791374\n",
            "Epoch 50, Step 22, Loss: 0.024981308728456497\n",
            "Epoch 50, Step 23, Loss: 0.029228657484054565\n",
            "Epoch 50, Step 24, Loss: 0.09653966128826141\n",
            "Epoch 50, Step 25, Loss: 0.11236763000488281\n",
            "Epoch 50, Step 26, Loss: 0.04257930815219879\n",
            "Epoch 50, Step 27, Loss: 0.013325524516403675\n",
            "Epoch 50, Step 28, Loss: 0.02420848421752453\n",
            "Epoch 50, Step 29, Loss: 0.08126948028802872\n",
            "Epoch 50, Step 30, Loss: 0.05153558775782585\n",
            "Epoch 50, Step 31, Loss: 0.035039033740758896\n",
            "Epoch 50, Step 32, Loss: 0.03566417843103409\n",
            "Epoch 50, Step 33, Loss: 0.02244340442121029\n",
            "Epoch 50, Step 34, Loss: 0.03522741049528122\n",
            "Epoch 50, Step 35, Loss: 0.08949926495552063\n",
            "Epoch 50, Step 36, Loss: 0.032136429101228714\n",
            "Epoch 50, Step 37, Loss: 0.02265709452331066\n",
            "Epoch 50, Step 38, Loss: 0.07378675043582916\n",
            "Epoch 50, Step 39, Loss: 0.08533163368701935\n",
            "Epoch 50, Step 40, Loss: 0.009063541889190674\n",
            "Epoch 50, Step 41, Loss: 0.0925275981426239\n",
            "Epoch 50, Step 42, Loss: 0.01901037059724331\n",
            "Epoch 50, Step 43, Loss: 0.03952864557504654\n",
            "Epoch 50, Step 44, Loss: 0.03386758640408516\n",
            "Epoch 50, Step 45, Loss: 0.01734263263642788\n",
            "Epoch 50, Step 46, Loss: 0.053890421986579895\n",
            "Epoch 50, Step 47, Loss: 0.06731980293989182\n",
            "Epoch 50, Step 48, Loss: 0.03180442750453949\n",
            "Epoch 50, Step 49, Loss: 0.04222773388028145\n",
            "Epoch 50, Step 50, Loss: 0.04298507422208786\n",
            "Epoch 50, Step 51, Loss: 0.0293104350566864\n",
            "Epoch 50, Step 52, Loss: 0.06683235615491867\n",
            "Epoch 50, Step 53, Loss: 0.01936347968876362\n",
            "Epoch 50, Step 54, Loss: 0.017937231808900833\n",
            "Epoch 50, Step 55, Loss: 0.06362541764974594\n",
            "Epoch 50, Step 56, Loss: 0.03035157360136509\n",
            "Epoch 50, Step 57, Loss: 0.02817382663488388\n",
            "Epoch 50, Step 58, Loss: 0.04283551499247551\n",
            "Epoch 50, Step 59, Loss: 0.06861221045255661\n",
            "Epoch 50, Step 60, Loss: 0.10415643453598022\n",
            "Epoch 50, Step 61, Loss: 0.04364084452390671\n",
            "Epoch 50, Step 62, Loss: 0.042082104831933975\n",
            "Epoch 50, Step 63, Loss: 0.011724436655640602\n",
            "Epoch 50, Step 64, Loss: 0.08307725191116333\n",
            "Epoch 50, Step 65, Loss: 0.04707076773047447\n",
            "Epoch 50, Step 66, Loss: 0.02266843430697918\n",
            "Epoch 50, Step 67, Loss: 0.06201634556055069\n",
            "Epoch 50, Step 68, Loss: 0.04015278071165085\n",
            "Epoch 50, Step 69, Loss: 0.027095073834061623\n",
            "Epoch 50, Step 70, Loss: 0.054677825421094894\n",
            "Epoch 50, Step 71, Loss: 0.06408017128705978\n",
            "Epoch 50, Step 72, Loss: 0.08214244246482849\n",
            "Epoch 50, Step 73, Loss: 0.04052886366844177\n",
            "Epoch 50, Step 74, Loss: 0.08136901259422302\n",
            "Epoch 50, Step 75, Loss: 0.03454291820526123\n",
            "Epoch 50, Step 76, Loss: 0.07101316750049591\n",
            "Epoch 50, Step 77, Loss: 0.08534582704305649\n",
            "Epoch 50, Step 78, Loss: 0.03626067936420441\n",
            "Epoch 50, Step 79, Loss: 0.09236063063144684\n",
            "Epoch 50, Step 80, Loss: 0.06942547857761383\n",
            "Epoch 50, Step 81, Loss: 0.09169860184192657\n",
            "Epoch 50, Step 82, Loss: 0.0792371854186058\n",
            "Epoch 50, Step 83, Loss: 0.014735778793692589\n",
            "Epoch 50, Step 84, Loss: 0.09860226511955261\n",
            "Epoch 50, Step 85, Loss: 0.05926143750548363\n",
            "Epoch 50, Step 86, Loss: 0.06791119277477264\n",
            "Epoch 50, Step 87, Loss: 0.039913956075906754\n",
            "Epoch 50, Step 88, Loss: 0.025423165410757065\n",
            "Epoch 50, Step 89, Loss: 0.03404432162642479\n",
            "Epoch 50, Step 90, Loss: 0.024611065164208412\n",
            "Epoch 50, Step 91, Loss: 0.03107307478785515\n",
            "Epoch 50, Step 92, Loss: 0.055419616401195526\n",
            "Epoch 50, Step 93, Loss: 0.03128601983189583\n",
            "Epoch 50, Step 94, Loss: 0.041861046105623245\n",
            "Epoch 50, Step 95, Loss: 0.029774731025099754\n",
            "Epoch 50, Step 96, Loss: 0.047789230942726135\n",
            "Epoch 50, Step 97, Loss: 0.015351524576544762\n",
            "Epoch 50, Step 98, Loss: 0.05166929215192795\n",
            "Epoch 50, Step 99, Loss: 0.06005271151661873\n",
            "Epoch 50, Step 100, Loss: 0.05303066968917847\n",
            "Epoch 50, Step 101, Loss: 0.01599165052175522\n",
            "Epoch 50, Step 102, Loss: 0.014299508184194565\n",
            "Epoch 50, Step 103, Loss: 0.02351411245763302\n",
            "Epoch 50, Step 104, Loss: 0.04013652354478836\n",
            "Epoch 50, Step 105, Loss: 0.05076894536614418\n",
            "Epoch 50, Step 106, Loss: 0.0196102112531662\n",
            "Epoch 50, Step 107, Loss: 0.07039503008127213\n",
            "Epoch 50, Step 108, Loss: 0.022151127457618713\n",
            "Epoch 50, Step 109, Loss: 0.05326876416802406\n",
            "Epoch 50, Step 110, Loss: 0.057229891419410706\n",
            "Epoch 50, Step 111, Loss: 0.019311964511871338\n",
            "Epoch 50, Step 112, Loss: 0.013032118789851665\n",
            "Epoch 50, Step 113, Loss: 0.034137848764657974\n",
            "Epoch 50, Step 114, Loss: 0.029758071526885033\n",
            "Epoch 50, Step 115, Loss: 0.05503207817673683\n",
            "Epoch 50, Step 116, Loss: 0.07027079910039902\n",
            "Epoch 50, Step 117, Loss: 0.029277920722961426\n",
            "Epoch 50, Step 118, Loss: 0.01084898505359888\n",
            "Epoch 50, Step 119, Loss: 0.043117355555295944\n",
            "Epoch 50, Step 120, Loss: 0.028995072469115257\n",
            "Epoch 50, Step 121, Loss: 0.05372520163655281\n",
            "Epoch 50, Step 122, Loss: 0.019716812297701836\n",
            "Epoch 50, Step 123, Loss: 0.02782941423356533\n",
            "Epoch 50, Step 124, Loss: 0.09569969773292542\n",
            "Epoch 50, Step 125, Loss: 0.05148377642035484\n",
            "Epoch 50, Step 126, Loss: 0.011853484436869621\n",
            "Epoch 50, Step 127, Loss: 0.04924656078219414\n",
            "Epoch 50, Step 128, Loss: 0.005561420693993568\n",
            "Epoch 50, Step 129, Loss: 0.013265777379274368\n",
            "Epoch 50, Step 130, Loss: 0.06004714593291283\n",
            "Epoch 50, Step 131, Loss: 0.023328449577093124\n",
            "Epoch 50, Step 132, Loss: 0.03508894145488739\n",
            "Epoch 50, Step 133, Loss: 0.04248220473527908\n",
            "Epoch 50, Step 134, Loss: 0.042244624346494675\n",
            "Epoch 50, Step 135, Loss: 0.03003242239356041\n",
            "Epoch 50, Step 136, Loss: 0.011584669351577759\n",
            "Epoch 50, Step 137, Loss: 0.021667858585715294\n",
            "Epoch 50, Step 138, Loss: 0.057018861174583435\n",
            "Epoch 50, Step 139, Loss: 0.03466568887233734\n",
            "Epoch 50, Step 140, Loss: 0.0570024736225605\n",
            "Epoch 50, Step 141, Loss: 0.02287987619638443\n",
            "Epoch 50, Step 142, Loss: 0.0411447137594223\n",
            "Epoch 50, Step 143, Loss: 0.015857882797718048\n",
            "Epoch 50, Step 144, Loss: 0.06700439751148224\n",
            "Epoch 50, Step 145, Loss: 0.06307992339134216\n",
            "Epoch 50, Step 146, Loss: 0.014524496160447598\n",
            "Epoch 50, Step 147, Loss: 0.04586132988333702\n",
            "Epoch 50, Step 148, Loss: 0.03486144542694092\n",
            "Epoch 50, Step 149, Loss: 0.01713389903306961\n",
            "Epoch 50, Step 150, Loss: 0.019232921302318573\n",
            "Epoch 50, Step 151, Loss: 0.014279630966484547\n",
            "Epoch 50, Step 152, Loss: 0.06653914600610733\n",
            "Epoch 50, Step 153, Loss: 0.03420913219451904\n",
            "Epoch 50, Step 154, Loss: 0.01765517331659794\n",
            "Epoch 50, Step 155, Loss: 0.07978704571723938\n",
            "Epoch 50, Step 156, Loss: 0.041692350059747696\n",
            "Epoch 50, Step 157, Loss: 0.012333525344729424\n",
            "Epoch 50, Step 158, Loss: 0.038268715143203735\n",
            "Epoch 50, Step 159, Loss: 0.028180059045553207\n",
            "Epoch 50, Step 160, Loss: 0.04896167665719986\n",
            "Epoch 50, Step 161, Loss: 0.08244256675243378\n",
            "Epoch 50, Step 162, Loss: 0.09579642117023468\n",
            "Epoch 50, Step 163, Loss: 0.02851816639304161\n",
            "Epoch 50, Step 164, Loss: 0.08723297715187073\n",
            "Epoch 50, Step 165, Loss: 0.028139382600784302\n",
            "Epoch 50, Step 166, Loss: 0.05713266134262085\n",
            "Epoch 50, Step 167, Loss: 0.014066362753510475\n",
            "Epoch 50, Step 168, Loss: 0.020997224375605583\n",
            "Epoch 50, Step 169, Loss: 0.060508955270051956\n",
            "Epoch 50, Step 170, Loss: 0.043885521590709686\n",
            "Epoch 50, Step 171, Loss: 0.043414369225502014\n",
            "Epoch 50, Step 172, Loss: 0.019326942041516304\n",
            "Epoch 50, Step 173, Loss: 0.038412634283304214\n",
            "Epoch 50, Step 174, Loss: 0.08092113584280014\n",
            "Epoch 50, Step 175, Loss: 0.04149993881583214\n",
            "Epoch 50, Step 176, Loss: 0.0779605358839035\n",
            "Epoch 50, Step 177, Loss: 0.03175484016537666\n",
            "Epoch 50, Step 178, Loss: 0.03922538459300995\n",
            "Epoch 50, Step 179, Loss: 0.020686428993940353\n",
            "Epoch 50, Step 180, Loss: 0.014627608470618725\n",
            "Epoch 50, Step 181, Loss: 0.02390887588262558\n",
            "Epoch 50, Step 182, Loss: 0.050215765833854675\n",
            "Epoch 50, Step 183, Loss: 0.028636764734983444\n",
            "Epoch 50, Step 184, Loss: 0.05518578365445137\n",
            "Epoch 50, Step 185, Loss: 0.11289405077695847\n",
            "Epoch 50, Step 186, Loss: 0.019971637055277824\n",
            "Epoch 50, Step 187, Loss: 0.021912256255745888\n",
            "Epoch 50, Step 188, Loss: 0.1023111641407013\n",
            "Epoch 50, Step 189, Loss: 0.05467381328344345\n",
            "Epoch 50, Step 190, Loss: 0.04366298392415047\n",
            "Epoch 50, Step 191, Loss: 0.025882618501782417\n",
            "Epoch 50, Step 192, Loss: 0.028790704905986786\n",
            "Epoch 50, Step 193, Loss: 0.02087501995265484\n",
            "Epoch 50, Step 194, Loss: 0.009894313290715218\n",
            "Epoch 50, Step 195, Loss: 0.09638144820928574\n",
            "Epoch 50, Step 196, Loss: 0.021506231278181076\n",
            "Epoch 50, Step 197, Loss: 0.04690276086330414\n",
            "Epoch 50, Step 198, Loss: 0.03540337085723877\n",
            "Epoch 50, Step 199, Loss: 0.01203424483537674\n",
            "Epoch 50, Step 200, Loss: 0.08301154524087906\n",
            "Epoch 50, Step 201, Loss: 0.045371200889348984\n",
            "Epoch 50, Step 202, Loss: 0.066921167075634\n",
            "Epoch 50, Step 203, Loss: 0.021032636985182762\n",
            "Epoch 50, Step 204, Loss: 0.04212569817900658\n",
            "Epoch 50, Step 205, Loss: 0.04456350579857826\n",
            "Epoch 50, Step 206, Loss: 0.0518503300845623\n",
            "Epoch 50, Step 207, Loss: 0.03261692821979523\n",
            "Epoch 50, Step 208, Loss: 0.08299804478883743\n",
            "Epoch 50, Step 209, Loss: 0.04414442554116249\n",
            "Epoch 50, Step 210, Loss: 0.09189265966415405\n",
            "Epoch 50, Step 211, Loss: 0.04385652765631676\n",
            "Epoch 50, Step 212, Loss: 0.06290359050035477\n",
            "Epoch 50, Step 213, Loss: 0.03235309571027756\n",
            "Epoch 50, Step 214, Loss: 0.03211512789130211\n",
            "Epoch 50, Step 215, Loss: 0.024718986824154854\n",
            "Epoch 50, Step 216, Loss: 0.036794357001781464\n",
            "Epoch 50, Step 217, Loss: 0.032868217676877975\n",
            "Epoch 50, Step 218, Loss: 0.016723472625017166\n",
            "Epoch 50, Step 219, Loss: 0.019731484353542328\n",
            "Epoch 50, Step 220, Loss: 0.028891025111079216\n",
            "Epoch 50, Step 221, Loss: 0.03932861238718033\n",
            "Epoch 50, Step 222, Loss: 0.05727272480726242\n",
            "Epoch 50, Step 223, Loss: 0.03849762678146362\n",
            "Epoch 50, Step 224, Loss: 0.028893599286675453\n",
            "Epoch 50, Step 225, Loss: 0.056327760219573975\n",
            "Epoch 50, Step 226, Loss: 0.044276315718889236\n",
            "Epoch 50, Step 227, Loss: 0.06978354603052139\n",
            "Epoch 50, Step 228, Loss: 0.0825740247964859\n",
            "Epoch 50, Step 229, Loss: 0.03468772768974304\n",
            "Epoch 50, Step 230, Loss: 0.018312636762857437\n",
            "Epoch 50, Step 231, Loss: 0.03028441034257412\n",
            "Epoch 50, Step 232, Loss: 0.057682208716869354\n",
            "Epoch 50, Step 233, Loss: 0.020458148792386055\n",
            "Epoch 50, Step 234, Loss: 0.03418967127799988\n",
            "Epoch 50, Step 235, Loss: 0.04992150515317917\n",
            "Epoch 50, Step 236, Loss: 0.021222015842795372\n",
            "Epoch 50, Step 237, Loss: 0.09580064564943314\n",
            "Epoch 50, Step 238, Loss: 0.03408224508166313\n",
            "Epoch 50, Step 239, Loss: 0.026231152936816216\n",
            "Epoch 50, Step 240, Loss: 0.01873108372092247\n",
            "Epoch 50, Step 241, Loss: 0.024538977071642876\n",
            "Epoch 50, Step 242, Loss: 0.05284902825951576\n",
            "Epoch 50, Step 243, Loss: 0.064072385430336\n",
            "Epoch 50, Step 244, Loss: 0.043739110231399536\n",
            "Epoch 50, Step 245, Loss: 0.0729573518037796\n",
            "Epoch 50, Step 246, Loss: 0.007940160110592842\n",
            "Epoch 50, Step 247, Loss: 0.035048846155405045\n",
            "Epoch 50, Step 248, Loss: 0.08105028420686722\n",
            "Epoch 50, Step 249, Loss: 0.0740690752863884\n",
            "Epoch 50, Step 250, Loss: 0.07003816217184067\n",
            "Epoch 50, Step 251, Loss: 0.05558134242892265\n",
            "Epoch 50, Step 252, Loss: 0.1025564968585968\n",
            "Epoch 50, Step 253, Loss: 0.038425054401159286\n",
            "Epoch 50, Step 254, Loss: 0.050891559571027756\n",
            "Epoch 50, Step 255, Loss: 0.05110231786966324\n",
            "Epoch 50, Step 256, Loss: 0.012337373569607735\n",
            "Epoch 50, Step 257, Loss: 0.055883899331092834\n",
            "Epoch 50, Step 258, Loss: 0.04720376431941986\n",
            "Epoch 50, Step 259, Loss: 0.061790622770786285\n",
            "Epoch 50, Step 260, Loss: 0.05956001952290535\n",
            "Epoch 50, Step 261, Loss: 0.025705762207508087\n",
            "Epoch 50, Step 262, Loss: 0.032839491963386536\n",
            "Epoch 50, Step 263, Loss: 0.018995681777596474\n",
            "Epoch 50, Step 264, Loss: 0.03521342575550079\n",
            "Epoch 50, Step 265, Loss: 0.03344234079122543\n",
            "Epoch 50, Step 266, Loss: 0.06710115820169449\n",
            "Epoch 50, Step 267, Loss: 0.02901666797697544\n",
            "Epoch 50, Step 268, Loss: 0.05336499214172363\n",
            "Epoch 50, Step 269, Loss: 0.021298227831721306\n",
            "Epoch 50, Step 270, Loss: 0.14545342326164246\n",
            "Epoch 50, Step 271, Loss: 0.02337614633142948\n",
            "Epoch 50, Step 272, Loss: 0.11217831075191498\n",
            "Epoch 50, Step 273, Loss: 0.0324002243578434\n",
            "Epoch 50, Step 274, Loss: 0.008539903908967972\n",
            "Epoch 50, Step 275, Loss: 0.007376825902611017\n",
            "Epoch 50, Step 276, Loss: 0.0447908416390419\n",
            "Epoch 50, Step 277, Loss: 0.061208341270685196\n",
            "Epoch 50, Step 278, Loss: 0.070655457675457\n",
            "Epoch 50, Step 279, Loss: 0.023971179500222206\n",
            "Epoch 50, Step 280, Loss: 0.05978497490286827\n",
            "Epoch 50, Step 281, Loss: 0.01934424415230751\n",
            "Epoch 50, Step 282, Loss: 0.10446369647979736\n",
            "Epoch 50, Step 283, Loss: 0.06719765812158585\n",
            "Epoch 50, Step 284, Loss: 0.04396107420325279\n",
            "Epoch 50, Step 285, Loss: 0.020925506949424744\n",
            "Epoch 50, Step 286, Loss: 0.03536190837621689\n",
            "Epoch 50, Step 287, Loss: 0.023240407928824425\n",
            "Epoch 50, Step 288, Loss: 0.038790326565504074\n",
            "Epoch 50, Step 289, Loss: 0.0427541621029377\n",
            "Epoch 50, Step 290, Loss: 0.025108791887760162\n",
            "Epoch 50, Step 291, Loss: 0.04190395027399063\n",
            "Epoch 50, Step 292, Loss: 0.07299214601516724\n",
            "Epoch 50, Step 293, Loss: 0.029310010373592377\n",
            "Epoch 50, Step 294, Loss: 0.06592711806297302\n",
            "Epoch 50, Step 295, Loss: 0.07145913690328598\n",
            "Epoch 50, Step 296, Loss: 0.11485458165407181\n",
            "Epoch 50, Step 297, Loss: 0.017399974167346954\n",
            "Epoch 50, Step 298, Loss: 0.08933057636022568\n",
            "Epoch 50, Step 299, Loss: 0.019134128466248512\n",
            "Epoch 50, Step 300, Loss: 0.0566495917737484\n",
            "Epoch 50, Step 301, Loss: 0.04165695235133171\n",
            "Epoch 50, Step 302, Loss: 0.03669416904449463\n",
            "Epoch 50, Step 303, Loss: 0.05565071105957031\n",
            "Epoch 50, Step 304, Loss: 0.08225490897893906\n",
            "Epoch 50, Step 305, Loss: 0.03959561884403229\n",
            "Epoch 50, Step 306, Loss: 0.03112846240401268\n",
            "Epoch 50, Step 307, Loss: 0.017301268875598907\n",
            "Epoch 50, Step 308, Loss: 0.018890852108597755\n",
            "Epoch 50, Step 309, Loss: 0.05039683356881142\n",
            "Epoch 50, Step 310, Loss: 0.016410451382398605\n",
            "Epoch 50, Step 311, Loss: 0.08113802969455719\n",
            "Epoch 50, Step 312, Loss: 0.012100882828235626\n",
            "Epoch 50 end, avg train loss: 0.045317426733018015\n",
            "Epoch 50 end, avg val loss: 0.41688682082333145, accuracy: 90.98%\n",
            "GPU memory allocated: 0.38 GB\n",
            "GPU memory reserved: 0.44 GB\n",
            "Training complete.\n"
          ]
        }
      ],
      "source": [
        "adamModel = PretrainedResNet18().to(device)\n",
        "adamOptimizer = torch.optim.Adam(adamModel.parameters(), lr=1e-3)\n",
        "train(adamModel, adamOptimizer, epochs=epochs)\n",
        "adamModel = adamModel.cpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "mqweVqXS24Oz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52b4a9fc-b3cf-46b2-88dd-c4ce4d8a2862"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 35, Step 44, Loss: 0.5764535069465637\n",
            "Epoch 35, Step 45, Loss: 0.47446489334106445\n",
            "Epoch 35, Step 46, Loss: 0.6042150855064392\n",
            "Epoch 35, Step 47, Loss: 0.5940466523170471\n",
            "Epoch 35, Step 48, Loss: 0.5155647993087769\n",
            "Epoch 35, Step 49, Loss: 0.6421558856964111\n",
            "Epoch 35, Step 50, Loss: 0.6040827631950378\n",
            "Epoch 35, Step 51, Loss: 0.4156787395477295\n",
            "Epoch 35, Step 52, Loss: 0.5216549634933472\n",
            "Epoch 35, Step 53, Loss: 0.34698864817619324\n",
            "Epoch 35, Step 54, Loss: 0.6035316586494446\n",
            "Epoch 35, Step 55, Loss: 0.50554358959198\n",
            "Epoch 35, Step 56, Loss: 0.5459439754486084\n",
            "Epoch 35, Step 57, Loss: 0.6145793199539185\n",
            "Epoch 35, Step 58, Loss: 0.49276819825172424\n",
            "Epoch 35, Step 59, Loss: 0.4842020571231842\n",
            "Epoch 35, Step 60, Loss: 0.4895155429840088\n",
            "Epoch 35, Step 61, Loss: 0.6356222629547119\n",
            "Epoch 35, Step 62, Loss: 0.5242933034896851\n",
            "Epoch 35, Step 63, Loss: 0.5574606657028198\n",
            "Epoch 35, Step 64, Loss: 0.5186846852302551\n",
            "Epoch 35, Step 65, Loss: 0.6295098066329956\n",
            "Epoch 35, Step 66, Loss: 0.620934009552002\n",
            "Epoch 35, Step 67, Loss: 0.592384934425354\n",
            "Epoch 35, Step 68, Loss: 0.5319374799728394\n",
            "Epoch 35, Step 69, Loss: 0.7474554181098938\n",
            "Epoch 35, Step 70, Loss: 0.6175201535224915\n",
            "Epoch 35, Step 71, Loss: 0.4312272369861603\n",
            "Epoch 35, Step 72, Loss: 0.5853439569473267\n",
            "Epoch 35, Step 73, Loss: 0.5401005744934082\n",
            "Epoch 35, Step 74, Loss: 0.5460332632064819\n",
            "Epoch 35, Step 75, Loss: 0.44640058279037476\n",
            "Epoch 35, Step 76, Loss: 0.5450820326805115\n",
            "Epoch 35, Step 77, Loss: 0.5037866830825806\n",
            "Epoch 35, Step 78, Loss: 0.7819908261299133\n",
            "Epoch 35, Step 79, Loss: 0.5122430324554443\n",
            "Epoch 35, Step 80, Loss: 0.6747462749481201\n",
            "Epoch 35, Step 81, Loss: 0.4783439040184021\n",
            "Epoch 35, Step 82, Loss: 0.5451266765594482\n",
            "Epoch 35, Step 83, Loss: 0.6499391794204712\n",
            "Epoch 35, Step 84, Loss: 0.48061850666999817\n",
            "Epoch 35, Step 85, Loss: 0.713577151298523\n",
            "Epoch 35, Step 86, Loss: 0.45581501722335815\n",
            "Epoch 35, Step 87, Loss: 0.5021978616714478\n",
            "Epoch 35, Step 88, Loss: 0.5514217615127563\n",
            "Epoch 35, Step 89, Loss: 0.4948986768722534\n",
            "Epoch 35, Step 90, Loss: 0.5602902770042419\n",
            "Epoch 35, Step 91, Loss: 0.5692091584205627\n",
            "Epoch 35, Step 92, Loss: 0.5664753913879395\n",
            "Epoch 35, Step 93, Loss: 0.575747013092041\n",
            "Epoch 35, Step 94, Loss: 0.5426486730575562\n",
            "Epoch 35, Step 95, Loss: 0.539852499961853\n",
            "Epoch 35, Step 96, Loss: 0.5016355514526367\n",
            "Epoch 35, Step 97, Loss: 0.6162519454956055\n",
            "Epoch 35, Step 98, Loss: 0.6840472221374512\n",
            "Epoch 35, Step 99, Loss: 0.5655809640884399\n",
            "Epoch 35, Step 100, Loss: 0.643933117389679\n",
            "Epoch 35, Step 101, Loss: 0.5245484709739685\n",
            "Epoch 35, Step 102, Loss: 0.4876880645751953\n",
            "Epoch 35, Step 103, Loss: 0.46059954166412354\n",
            "Epoch 35, Step 104, Loss: 0.5234829783439636\n",
            "Epoch 35, Step 105, Loss: 0.5604992508888245\n",
            "Epoch 35, Step 106, Loss: 0.570551335811615\n",
            "Epoch 35, Step 107, Loss: 0.49381300806999207\n",
            "Epoch 35, Step 108, Loss: 0.7276325821876526\n",
            "Epoch 35, Step 109, Loss: 0.5599044561386108\n",
            "Epoch 35, Step 110, Loss: 0.5615153908729553\n",
            "Epoch 35, Step 111, Loss: 0.5678386688232422\n",
            "Epoch 35, Step 112, Loss: 0.5268383622169495\n",
            "Epoch 35, Step 113, Loss: 0.4825585186481476\n",
            "Epoch 35, Step 114, Loss: 0.604847252368927\n",
            "Epoch 35, Step 115, Loss: 0.6719198226928711\n",
            "Epoch 35, Step 116, Loss: 0.5389581918716431\n",
            "Epoch 35, Step 117, Loss: 0.5914446711540222\n",
            "Epoch 35, Step 118, Loss: 0.4263904094696045\n",
            "Epoch 35, Step 119, Loss: 0.6212146282196045\n",
            "Epoch 35, Step 120, Loss: 0.5029804110527039\n",
            "Epoch 35, Step 121, Loss: 0.4190617501735687\n",
            "Epoch 35, Step 122, Loss: 0.6263279914855957\n",
            "Epoch 35, Step 123, Loss: 0.5181295871734619\n",
            "Epoch 35, Step 124, Loss: 0.5435691475868225\n",
            "Epoch 35, Step 125, Loss: 0.5320693850517273\n",
            "Epoch 35, Step 126, Loss: 0.5937212109565735\n",
            "Epoch 35, Step 127, Loss: 0.5687593221664429\n",
            "Epoch 35, Step 128, Loss: 0.581434428691864\n",
            "Epoch 35, Step 129, Loss: 0.5976322293281555\n",
            "Epoch 35, Step 130, Loss: 0.6094644665718079\n",
            "Epoch 35, Step 131, Loss: 0.5274363160133362\n",
            "Epoch 35, Step 132, Loss: 0.6601376533508301\n",
            "Epoch 35, Step 133, Loss: 0.5411357283592224\n",
            "Epoch 35, Step 134, Loss: 0.46023112535476685\n",
            "Epoch 35, Step 135, Loss: 0.3807390034198761\n",
            "Epoch 35, Step 136, Loss: 0.5954692959785461\n",
            "Epoch 35, Step 137, Loss: 0.5228044986724854\n",
            "Epoch 35, Step 138, Loss: 0.513201892375946\n",
            "Epoch 35, Step 139, Loss: 0.749232292175293\n",
            "Epoch 35, Step 140, Loss: 0.4882762134075165\n",
            "Epoch 35, Step 141, Loss: 0.58470618724823\n",
            "Epoch 35, Step 142, Loss: 0.5454123020172119\n",
            "Epoch 35, Step 143, Loss: 0.6290575861930847\n",
            "Epoch 35, Step 144, Loss: 0.42835533618927\n",
            "Epoch 35, Step 145, Loss: 0.7577967643737793\n",
            "Epoch 35, Step 146, Loss: 0.6360574960708618\n",
            "Epoch 35, Step 147, Loss: 0.5450511574745178\n",
            "Epoch 35, Step 148, Loss: 0.485500693321228\n",
            "Epoch 35, Step 149, Loss: 0.5723184943199158\n",
            "Epoch 35, Step 150, Loss: 0.4299400746822357\n",
            "Epoch 35, Step 151, Loss: 0.5079130530357361\n",
            "Epoch 35, Step 152, Loss: 0.4867376387119293\n",
            "Epoch 35, Step 153, Loss: 0.6131302118301392\n",
            "Epoch 35, Step 154, Loss: 0.4862230718135834\n",
            "Epoch 35, Step 155, Loss: 0.5180830359458923\n",
            "Epoch 35, Step 156, Loss: 0.4801124036312103\n",
            "Epoch 35, Step 157, Loss: 0.7864522933959961\n",
            "Epoch 35, Step 158, Loss: 0.5494523048400879\n",
            "Epoch 35, Step 159, Loss: 0.655151903629303\n",
            "Epoch 35, Step 160, Loss: 0.5118556022644043\n",
            "Epoch 35, Step 161, Loss: 0.5092066526412964\n",
            "Epoch 35, Step 162, Loss: 0.5411965250968933\n",
            "Epoch 35, Step 163, Loss: 0.5497479438781738\n",
            "Epoch 35, Step 164, Loss: 0.5527569651603699\n",
            "Epoch 35, Step 165, Loss: 0.6289793252944946\n",
            "Epoch 35, Step 166, Loss: 0.7263546586036682\n",
            "Epoch 35, Step 167, Loss: 0.5684577822685242\n",
            "Epoch 35, Step 168, Loss: 0.502997636795044\n",
            "Epoch 35, Step 169, Loss: 0.5264145731925964\n",
            "Epoch 35, Step 170, Loss: 0.6755610704421997\n",
            "Epoch 35, Step 171, Loss: 0.6020689010620117\n",
            "Epoch 35, Step 172, Loss: 0.4570572078227997\n",
            "Epoch 35, Step 173, Loss: 0.45682913064956665\n",
            "Epoch 35, Step 174, Loss: 0.5096213221549988\n",
            "Epoch 35, Step 175, Loss: 0.5974763631820679\n",
            "Epoch 35, Step 176, Loss: 0.5764030814170837\n",
            "Epoch 35, Step 177, Loss: 0.637497067451477\n",
            "Epoch 35, Step 178, Loss: 0.5509903430938721\n",
            "Epoch 35, Step 179, Loss: 0.5589190125465393\n",
            "Epoch 35, Step 180, Loss: 0.6470060348510742\n",
            "Epoch 35, Step 181, Loss: 0.5419414639472961\n",
            "Epoch 35, Step 182, Loss: 0.6756699085235596\n",
            "Epoch 35, Step 183, Loss: 0.7791413068771362\n",
            "Epoch 35, Step 184, Loss: 0.6456595063209534\n",
            "Epoch 35, Step 185, Loss: 0.5045742392539978\n",
            "Epoch 35, Step 186, Loss: 0.3892914354801178\n",
            "Epoch 35, Step 187, Loss: 0.5368512868881226\n",
            "Epoch 35, Step 188, Loss: 0.46851786971092224\n",
            "Epoch 35, Step 189, Loss: 0.5513952374458313\n",
            "Epoch 35, Step 190, Loss: 0.6238548159599304\n",
            "Epoch 35, Step 191, Loss: 0.38782092928886414\n",
            "Epoch 35, Step 192, Loss: 0.4931696057319641\n",
            "Epoch 35, Step 193, Loss: 0.5118131041526794\n",
            "Epoch 35, Step 194, Loss: 0.5805295705795288\n",
            "Epoch 35, Step 195, Loss: 0.45818471908569336\n",
            "Epoch 35, Step 196, Loss: 0.4513309597969055\n",
            "Epoch 35, Step 197, Loss: 0.49234089255332947\n",
            "Epoch 35, Step 198, Loss: 0.5822376608848572\n",
            "Epoch 35, Step 199, Loss: 0.6062510013580322\n",
            "Epoch 35, Step 200, Loss: 0.44644322991371155\n",
            "Epoch 35, Step 201, Loss: 0.6961790323257446\n",
            "Epoch 35, Step 202, Loss: 0.5219203233718872\n",
            "Epoch 35, Step 203, Loss: 0.5138330459594727\n",
            "Epoch 35, Step 204, Loss: 0.6222513318061829\n",
            "Epoch 35, Step 205, Loss: 0.7361835241317749\n",
            "Epoch 35, Step 206, Loss: 0.5327386260032654\n",
            "Epoch 35, Step 207, Loss: 0.6146551966667175\n",
            "Epoch 35, Step 208, Loss: 0.4256616532802582\n",
            "Epoch 35, Step 209, Loss: 0.694761335849762\n",
            "Epoch 35, Step 210, Loss: 0.5367531776428223\n",
            "Epoch 35, Step 211, Loss: 0.46517282724380493\n",
            "Epoch 35, Step 212, Loss: 0.6870943903923035\n",
            "Epoch 35, Step 213, Loss: 0.6209295392036438\n",
            "Epoch 35, Step 214, Loss: 0.407130628824234\n",
            "Epoch 35, Step 215, Loss: 0.5879819393157959\n",
            "Epoch 35, Step 216, Loss: 0.5954477787017822\n",
            "Epoch 35, Step 217, Loss: 0.4472961127758026\n",
            "Epoch 35, Step 218, Loss: 0.45979785919189453\n",
            "Epoch 35, Step 219, Loss: 0.5063852071762085\n",
            "Epoch 35, Step 220, Loss: 0.6686758995056152\n",
            "Epoch 35, Step 221, Loss: 0.5600905418395996\n",
            "Epoch 35, Step 222, Loss: 0.6434223055839539\n",
            "Epoch 35, Step 223, Loss: 0.47909781336784363\n",
            "Epoch 35, Step 224, Loss: 0.6014715433120728\n",
            "Epoch 35, Step 225, Loss: 0.5167993307113647\n",
            "Epoch 35, Step 226, Loss: 0.4255102276802063\n",
            "Epoch 35, Step 227, Loss: 0.4749049246311188\n",
            "Epoch 35, Step 228, Loss: 0.6038726568222046\n",
            "Epoch 35, Step 229, Loss: 0.51772141456604\n",
            "Epoch 35, Step 230, Loss: 0.508375346660614\n",
            "Epoch 35, Step 231, Loss: 0.5107291340827942\n",
            "Epoch 35, Step 232, Loss: 0.5133936405181885\n",
            "Epoch 35, Step 233, Loss: 0.6052923798561096\n",
            "Epoch 35, Step 234, Loss: 0.6020466685295105\n",
            "Epoch 35, Step 235, Loss: 0.6056818962097168\n",
            "Epoch 35, Step 236, Loss: 0.46941450238227844\n",
            "Epoch 35, Step 237, Loss: 0.502154529094696\n",
            "Epoch 35, Step 238, Loss: 0.5187978744506836\n",
            "Epoch 35, Step 239, Loss: 0.5601633787155151\n",
            "Epoch 35, Step 240, Loss: 0.40036293864250183\n",
            "Epoch 35, Step 241, Loss: 0.4854313135147095\n",
            "Epoch 35, Step 242, Loss: 0.7224292159080505\n",
            "Epoch 35, Step 243, Loss: 0.8328217267990112\n",
            "Epoch 35, Step 244, Loss: 0.48887911438941956\n",
            "Epoch 35, Step 245, Loss: 0.5516842603683472\n",
            "Epoch 35, Step 246, Loss: 0.5633862018585205\n",
            "Epoch 35, Step 247, Loss: 0.5365565419197083\n",
            "Epoch 35, Step 248, Loss: 0.5011013150215149\n",
            "Epoch 35, Step 249, Loss: 0.7103826999664307\n",
            "Epoch 35, Step 250, Loss: 0.7009071111679077\n",
            "Epoch 35, Step 251, Loss: 0.6003314852714539\n",
            "Epoch 35, Step 252, Loss: 0.5891361832618713\n",
            "Epoch 35, Step 253, Loss: 0.5078521966934204\n",
            "Epoch 35, Step 254, Loss: 0.5084353089332581\n",
            "Epoch 35, Step 255, Loss: 0.6768915057182312\n",
            "Epoch 35, Step 256, Loss: 0.5649647116661072\n",
            "Epoch 35, Step 257, Loss: 0.6219345331192017\n",
            "Epoch 35, Step 258, Loss: 0.49317389726638794\n",
            "Epoch 35, Step 259, Loss: 0.5401630997657776\n",
            "Epoch 35, Step 260, Loss: 0.6637534499168396\n",
            "Epoch 35, Step 261, Loss: 0.5828876495361328\n",
            "Epoch 35, Step 262, Loss: 0.7034951448440552\n",
            "Epoch 35, Step 263, Loss: 0.5924764275550842\n",
            "Epoch 35, Step 264, Loss: 0.47993725538253784\n",
            "Epoch 35, Step 265, Loss: 0.5375267863273621\n",
            "Epoch 35, Step 266, Loss: 0.6069254875183105\n",
            "Epoch 35, Step 267, Loss: 0.5260873436927795\n",
            "Epoch 35, Step 268, Loss: 0.6528185606002808\n",
            "Epoch 35, Step 269, Loss: 0.5739885568618774\n",
            "Epoch 35, Step 270, Loss: 0.6178543567657471\n",
            "Epoch 35, Step 271, Loss: 0.5132607817649841\n",
            "Epoch 35, Step 272, Loss: 0.5090694427490234\n",
            "Epoch 35, Step 273, Loss: 0.5364499092102051\n",
            "Epoch 35, Step 274, Loss: 0.6249222755432129\n",
            "Epoch 35, Step 275, Loss: 0.5433058738708496\n",
            "Epoch 35, Step 276, Loss: 0.4652728736400604\n",
            "Epoch 35, Step 277, Loss: 0.5394554138183594\n",
            "Epoch 35, Step 278, Loss: 0.4816771447658539\n",
            "Epoch 35, Step 279, Loss: 0.5947326421737671\n",
            "Epoch 35, Step 280, Loss: 0.5791990160942078\n",
            "Epoch 35, Step 281, Loss: 0.46776795387268066\n",
            "Epoch 35, Step 282, Loss: 0.49814245104789734\n",
            "Epoch 35, Step 283, Loss: 0.4403765797615051\n",
            "Epoch 35, Step 284, Loss: 0.6057273745536804\n",
            "Epoch 35, Step 285, Loss: 0.5273234248161316\n",
            "Epoch 35, Step 286, Loss: 0.4998270571231842\n",
            "Epoch 35, Step 287, Loss: 0.5730813145637512\n",
            "Epoch 35, Step 288, Loss: 0.6416584849357605\n",
            "Epoch 35, Step 289, Loss: 0.6943545341491699\n",
            "Epoch 35, Step 290, Loss: 0.5956161618232727\n",
            "Epoch 35, Step 291, Loss: 0.5555838942527771\n",
            "Epoch 35, Step 292, Loss: 0.5868116021156311\n",
            "Epoch 35, Step 293, Loss: 0.7228409051895142\n",
            "Epoch 35, Step 294, Loss: 0.681922972202301\n",
            "Epoch 35, Step 295, Loss: 0.7207822799682617\n",
            "Epoch 35, Step 296, Loss: 0.4668920040130615\n",
            "Epoch 35, Step 297, Loss: 0.4855293333530426\n",
            "Epoch 35, Step 298, Loss: 0.6493697762489319\n",
            "Epoch 35, Step 299, Loss: 0.46444180607795715\n",
            "Epoch 35, Step 300, Loss: 0.5593885779380798\n",
            "Epoch 35, Step 301, Loss: 0.6747540831565857\n",
            "Epoch 35, Step 302, Loss: 0.6763684749603271\n",
            "Epoch 35, Step 303, Loss: 0.4657210111618042\n",
            "Epoch 35, Step 304, Loss: 0.5210256576538086\n",
            "Epoch 35, Step 305, Loss: 0.5093702077865601\n",
            "Epoch 35, Step 306, Loss: 0.4891837537288666\n",
            "Epoch 35, Step 307, Loss: 0.5290101170539856\n",
            "Epoch 35, Step 308, Loss: 0.529053807258606\n",
            "Epoch 35, Step 309, Loss: 0.49439898133277893\n",
            "Epoch 35, Step 310, Loss: 0.5255685448646545\n",
            "Epoch 35, Step 311, Loss: 0.4495238959789276\n",
            "Epoch 35, Step 312, Loss: 0.5065658092498779\n",
            "Epoch 35 end, avg train loss: 0.5592576279617346\n",
            "Epoch 35 end, avg val loss: 0.5966183622426624, accuracy: 79.05%\n",
            "Epoch 36, Step 0, Loss: 0.477647066116333\n",
            "Epoch 36, Step 1, Loss: 0.5119801759719849\n",
            "Epoch 36, Step 2, Loss: 0.5359010100364685\n",
            "Epoch 36, Step 3, Loss: 0.5898913741111755\n",
            "Epoch 36, Step 4, Loss: 0.5523040294647217\n",
            "Epoch 36, Step 5, Loss: 0.5409467220306396\n",
            "Epoch 36, Step 6, Loss: 0.4426669776439667\n",
            "Epoch 36, Step 7, Loss: 0.580004870891571\n",
            "Epoch 36, Step 8, Loss: 0.4730364680290222\n",
            "Epoch 36, Step 9, Loss: 0.5887116193771362\n",
            "Epoch 36, Step 10, Loss: 0.6398213505744934\n",
            "Epoch 36, Step 11, Loss: 0.6184966564178467\n",
            "Epoch 36, Step 12, Loss: 0.42867574095726013\n",
            "Epoch 36, Step 13, Loss: 0.5136293172836304\n",
            "Epoch 36, Step 14, Loss: 0.5800590515136719\n",
            "Epoch 36, Step 15, Loss: 0.6715759634971619\n",
            "Epoch 36, Step 16, Loss: 0.5673205852508545\n",
            "Epoch 36, Step 17, Loss: 0.5384752750396729\n",
            "Epoch 36, Step 18, Loss: 0.5574588775634766\n",
            "Epoch 36, Step 19, Loss: 0.5639645457267761\n",
            "Epoch 36, Step 20, Loss: 0.5481657981872559\n",
            "Epoch 36, Step 21, Loss: 0.5790355801582336\n",
            "Epoch 36, Step 22, Loss: 0.6481044292449951\n",
            "Epoch 36, Step 23, Loss: 0.6423565149307251\n",
            "Epoch 36, Step 24, Loss: 0.4651138484477997\n",
            "Epoch 36, Step 25, Loss: 0.701646625995636\n",
            "Epoch 36, Step 26, Loss: 0.4244503974914551\n",
            "Epoch 36, Step 27, Loss: 0.4868401885032654\n",
            "Epoch 36, Step 28, Loss: 0.5741949081420898\n",
            "Epoch 36, Step 29, Loss: 0.5831531882286072\n",
            "Epoch 36, Step 30, Loss: 0.5508480668067932\n",
            "Epoch 36, Step 31, Loss: 0.43516138195991516\n",
            "Epoch 36, Step 32, Loss: 0.5096524357795715\n",
            "Epoch 36, Step 33, Loss: 0.7531482577323914\n",
            "Epoch 36, Step 34, Loss: 0.5675359964370728\n",
            "Epoch 36, Step 35, Loss: 0.4695834219455719\n",
            "Epoch 36, Step 36, Loss: 0.7369984984397888\n",
            "Epoch 36, Step 37, Loss: 0.592344343662262\n",
            "Epoch 36, Step 38, Loss: 0.6516252160072327\n",
            "Epoch 36, Step 39, Loss: 0.608549952507019\n",
            "Epoch 36, Step 40, Loss: 0.7768444418907166\n",
            "Epoch 36, Step 41, Loss: 0.6073989868164062\n",
            "Epoch 36, Step 42, Loss: 0.5387003421783447\n",
            "Epoch 36, Step 43, Loss: 0.5819297432899475\n",
            "Epoch 36, Step 44, Loss: 0.5991860032081604\n",
            "Epoch 36, Step 45, Loss: 0.5218420028686523\n",
            "Epoch 36, Step 46, Loss: 0.794686496257782\n",
            "Epoch 36, Step 47, Loss: 0.5768074989318848\n",
            "Epoch 36, Step 48, Loss: 0.6051598787307739\n",
            "Epoch 36, Step 49, Loss: 0.4921881854534149\n",
            "Epoch 36, Step 50, Loss: 0.45475101470947266\n",
            "Epoch 36, Step 51, Loss: 0.5081890225410461\n",
            "Epoch 36, Step 52, Loss: 0.5408278703689575\n",
            "Epoch 36, Step 53, Loss: 0.5433194637298584\n",
            "Epoch 36, Step 54, Loss: 0.5670627355575562\n",
            "Epoch 36, Step 55, Loss: 0.5828660726547241\n",
            "Epoch 36, Step 56, Loss: 0.6151522397994995\n",
            "Epoch 36, Step 57, Loss: 0.5967202186584473\n",
            "Epoch 36, Step 58, Loss: 0.5326070189476013\n",
            "Epoch 36, Step 59, Loss: 0.5999014973640442\n",
            "Epoch 36, Step 60, Loss: 0.6956548690795898\n",
            "Epoch 36, Step 61, Loss: 0.6021134853363037\n",
            "Epoch 36, Step 62, Loss: 0.5437756180763245\n",
            "Epoch 36, Step 63, Loss: 0.5875328779220581\n",
            "Epoch 36, Step 64, Loss: 0.5768218040466309\n",
            "Epoch 36, Step 65, Loss: 0.5646928548812866\n",
            "Epoch 36, Step 66, Loss: 0.5881353616714478\n",
            "Epoch 36, Step 67, Loss: 0.43937796354293823\n",
            "Epoch 36, Step 68, Loss: 0.4725995659828186\n",
            "Epoch 36, Step 69, Loss: 0.42873847484588623\n",
            "Epoch 36, Step 70, Loss: 0.6523046493530273\n",
            "Epoch 36, Step 71, Loss: 0.6113782525062561\n",
            "Epoch 36, Step 72, Loss: 0.6047970056533813\n",
            "Epoch 36, Step 73, Loss: 0.5516142249107361\n",
            "Epoch 36, Step 74, Loss: 0.4799962341785431\n",
            "Epoch 36, Step 75, Loss: 0.4773681163787842\n",
            "Epoch 36, Step 76, Loss: 0.6374437212944031\n",
            "Epoch 36, Step 77, Loss: 0.5695891976356506\n",
            "Epoch 36, Step 78, Loss: 0.637144148349762\n",
            "Epoch 36, Step 79, Loss: 0.599157989025116\n",
            "Epoch 36, Step 80, Loss: 0.6739428639411926\n",
            "Epoch 36, Step 81, Loss: 0.5416310429573059\n",
            "Epoch 36, Step 82, Loss: 0.5377815961837769\n",
            "Epoch 36, Step 83, Loss: 0.6187252998352051\n",
            "Epoch 36, Step 84, Loss: 0.7015007734298706\n",
            "Epoch 36, Step 85, Loss: 0.47140148282051086\n",
            "Epoch 36, Step 86, Loss: 0.5243378281593323\n",
            "Epoch 36, Step 87, Loss: 0.578454852104187\n",
            "Epoch 36, Step 88, Loss: 0.43197789788246155\n",
            "Epoch 36, Step 89, Loss: 0.44557949900627136\n",
            "Epoch 36, Step 90, Loss: 0.5518693923950195\n",
            "Epoch 36, Step 91, Loss: 0.5415834188461304\n",
            "Epoch 36, Step 92, Loss: 0.5260437726974487\n",
            "Epoch 36, Step 93, Loss: 0.6145273447036743\n",
            "Epoch 36, Step 94, Loss: 0.5078670978546143\n",
            "Epoch 36, Step 95, Loss: 0.4842616021633148\n",
            "Epoch 36, Step 96, Loss: 0.5708252787590027\n",
            "Epoch 36, Step 97, Loss: 0.6070816516876221\n",
            "Epoch 36, Step 98, Loss: 0.5328750610351562\n",
            "Epoch 36, Step 99, Loss: 0.4456769824028015\n",
            "Epoch 36, Step 100, Loss: 0.44755280017852783\n",
            "Epoch 36, Step 101, Loss: 0.5826719999313354\n",
            "Epoch 36, Step 102, Loss: 0.5801647305488586\n",
            "Epoch 36, Step 103, Loss: 0.6635100841522217\n",
            "Epoch 36, Step 104, Loss: 0.4395301342010498\n",
            "Epoch 36, Step 105, Loss: 0.6524684429168701\n",
            "Epoch 36, Step 106, Loss: 0.5384134650230408\n",
            "Epoch 36, Step 107, Loss: 0.7066797018051147\n",
            "Epoch 36, Step 108, Loss: 0.47162914276123047\n",
            "Epoch 36, Step 109, Loss: 0.45480823516845703\n",
            "Epoch 36, Step 110, Loss: 0.5172736644744873\n",
            "Epoch 36, Step 111, Loss: 0.538163423538208\n",
            "Epoch 36, Step 112, Loss: 0.7174212336540222\n",
            "Epoch 36, Step 113, Loss: 0.5612800121307373\n",
            "Epoch 36, Step 114, Loss: 0.6122667193412781\n",
            "Epoch 36, Step 115, Loss: 0.4578131139278412\n",
            "Epoch 36, Step 116, Loss: 0.6839970350265503\n",
            "Epoch 36, Step 117, Loss: 0.69977867603302\n",
            "Epoch 36, Step 118, Loss: 0.39925551414489746\n",
            "Epoch 36, Step 119, Loss: 0.43664664030075073\n",
            "Epoch 36, Step 120, Loss: 0.43424150347709656\n",
            "Epoch 36, Step 121, Loss: 0.5796160101890564\n",
            "Epoch 36, Step 122, Loss: 0.4400339722633362\n",
            "Epoch 36, Step 123, Loss: 0.6035013198852539\n",
            "Epoch 36, Step 124, Loss: 0.5975502133369446\n",
            "Epoch 36, Step 125, Loss: 0.5921015739440918\n",
            "Epoch 36, Step 126, Loss: 0.5811905264854431\n",
            "Epoch 36, Step 127, Loss: 0.6038830876350403\n",
            "Epoch 36, Step 128, Loss: 0.6555731892585754\n",
            "Epoch 36, Step 129, Loss: 0.6561031341552734\n",
            "Epoch 36, Step 130, Loss: 0.5821343064308167\n",
            "Epoch 36, Step 131, Loss: 0.5631899237632751\n",
            "Epoch 36, Step 132, Loss: 0.5885303616523743\n",
            "Epoch 36, Step 133, Loss: 0.4882810711860657\n",
            "Epoch 36, Step 134, Loss: 0.4918867349624634\n",
            "Epoch 36, Step 135, Loss: 0.6200594902038574\n",
            "Epoch 36, Step 136, Loss: 0.4868268668651581\n",
            "Epoch 36, Step 137, Loss: 0.47914260625839233\n",
            "Epoch 36, Step 138, Loss: 0.6617612838745117\n",
            "Epoch 36, Step 139, Loss: 0.5264407992362976\n",
            "Epoch 36, Step 140, Loss: 0.5284952521324158\n",
            "Epoch 36, Step 141, Loss: 0.5384678244590759\n",
            "Epoch 36, Step 142, Loss: 0.5404724478721619\n",
            "Epoch 36, Step 143, Loss: 0.6626377701759338\n",
            "Epoch 36, Step 144, Loss: 0.4555615782737732\n",
            "Epoch 36, Step 145, Loss: 0.5326471328735352\n",
            "Epoch 36, Step 146, Loss: 0.4334997236728668\n",
            "Epoch 36, Step 147, Loss: 0.5561658143997192\n",
            "Epoch 36, Step 148, Loss: 0.5844551920890808\n",
            "Epoch 36, Step 149, Loss: 0.49972793459892273\n",
            "Epoch 36, Step 150, Loss: 0.5082792043685913\n",
            "Epoch 36, Step 151, Loss: 0.5807404518127441\n",
            "Epoch 36, Step 152, Loss: 0.5097001791000366\n",
            "Epoch 36, Step 153, Loss: 0.48435041308403015\n",
            "Epoch 36, Step 154, Loss: 0.6004157066345215\n",
            "Epoch 36, Step 155, Loss: 0.5161523818969727\n",
            "Epoch 36, Step 156, Loss: 0.5280147194862366\n",
            "Epoch 36, Step 157, Loss: 0.5048930048942566\n",
            "Epoch 36, Step 158, Loss: 0.47316861152648926\n",
            "Epoch 36, Step 159, Loss: 0.6510820984840393\n",
            "Epoch 36, Step 160, Loss: 0.46631142497062683\n",
            "Epoch 36, Step 161, Loss: 0.47257736325263977\n",
            "Epoch 36, Step 162, Loss: 0.5427667498588562\n",
            "Epoch 36, Step 163, Loss: 0.502558171749115\n",
            "Epoch 36, Step 164, Loss: 0.5286554098129272\n",
            "Epoch 36, Step 165, Loss: 0.5639646053314209\n",
            "Epoch 36, Step 166, Loss: 0.5189331769943237\n",
            "Epoch 36, Step 167, Loss: 0.6048683524131775\n",
            "Epoch 36, Step 168, Loss: 0.5746189951896667\n",
            "Epoch 36, Step 169, Loss: 0.48420241475105286\n",
            "Epoch 36, Step 170, Loss: 0.6571033000946045\n",
            "Epoch 36, Step 171, Loss: 0.4642238914966583\n",
            "Epoch 36, Step 172, Loss: 0.5492960214614868\n",
            "Epoch 36, Step 173, Loss: 0.47955381870269775\n",
            "Epoch 36, Step 174, Loss: 0.7271709442138672\n",
            "Epoch 36, Step 175, Loss: 0.4232375919818878\n",
            "Epoch 36, Step 176, Loss: 0.6811936497688293\n",
            "Epoch 36, Step 177, Loss: 0.6662203669548035\n",
            "Epoch 36, Step 178, Loss: 0.49889281392097473\n",
            "Epoch 36, Step 179, Loss: 0.5266857147216797\n",
            "Epoch 36, Step 180, Loss: 0.5477551817893982\n",
            "Epoch 36, Step 181, Loss: 0.48045048117637634\n",
            "Epoch 36, Step 182, Loss: 0.6081885695457458\n",
            "Epoch 36, Step 183, Loss: 0.440510094165802\n",
            "Epoch 36, Step 184, Loss: 0.581730306148529\n",
            "Epoch 36, Step 185, Loss: 0.5992114543914795\n",
            "Epoch 36, Step 186, Loss: 0.6101668477058411\n",
            "Epoch 36, Step 187, Loss: 0.6213319897651672\n",
            "Epoch 36, Step 188, Loss: 0.5111328363418579\n",
            "Epoch 36, Step 189, Loss: 0.5121071934700012\n",
            "Epoch 36, Step 190, Loss: 0.4265754222869873\n",
            "Epoch 36, Step 191, Loss: 0.593821108341217\n",
            "Epoch 36, Step 192, Loss: 0.6334528923034668\n",
            "Epoch 36, Step 193, Loss: 0.5933955907821655\n",
            "Epoch 36, Step 194, Loss: 0.5178446173667908\n",
            "Epoch 36, Step 195, Loss: 0.57110595703125\n",
            "Epoch 36, Step 196, Loss: 0.45059818029403687\n",
            "Epoch 36, Step 197, Loss: 0.7216207981109619\n",
            "Epoch 36, Step 198, Loss: 0.5737671256065369\n",
            "Epoch 36, Step 199, Loss: 0.6306906342506409\n",
            "Epoch 36, Step 200, Loss: 0.558109700679779\n",
            "Epoch 36, Step 201, Loss: 0.45024263858795166\n",
            "Epoch 36, Step 202, Loss: 0.5819340348243713\n",
            "Epoch 36, Step 203, Loss: 0.5725422501564026\n",
            "Epoch 36, Step 204, Loss: 0.6420867443084717\n",
            "Epoch 36, Step 205, Loss: 0.5407354235649109\n",
            "Epoch 36, Step 206, Loss: 0.5695876479148865\n",
            "Epoch 36, Step 207, Loss: 0.5289292335510254\n",
            "Epoch 36, Step 208, Loss: 0.6096230745315552\n",
            "Epoch 36, Step 209, Loss: 0.6327553987503052\n",
            "Epoch 36, Step 210, Loss: 0.5456366539001465\n",
            "Epoch 36, Step 211, Loss: 0.5457152724266052\n",
            "Epoch 36, Step 212, Loss: 0.5318413376808167\n",
            "Epoch 36, Step 213, Loss: 0.45838308334350586\n",
            "Epoch 36, Step 214, Loss: 0.5324002504348755\n",
            "Epoch 36, Step 215, Loss: 0.4730910062789917\n",
            "Epoch 36, Step 216, Loss: 0.3711867928504944\n",
            "Epoch 36, Step 217, Loss: 0.5667137503623962\n",
            "Epoch 36, Step 218, Loss: 0.5987807512283325\n",
            "Epoch 36, Step 219, Loss: 0.5572226643562317\n",
            "Epoch 36, Step 220, Loss: 0.6455034613609314\n",
            "Epoch 36, Step 221, Loss: 0.5101498365402222\n",
            "Epoch 36, Step 222, Loss: 0.8213071823120117\n",
            "Epoch 36, Step 223, Loss: 0.572931170463562\n",
            "Epoch 36, Step 224, Loss: 0.4902370274066925\n",
            "Epoch 36, Step 225, Loss: 0.5200248956680298\n",
            "Epoch 36, Step 226, Loss: 0.5767564177513123\n",
            "Epoch 36, Step 227, Loss: 0.6944612860679626\n",
            "Epoch 36, Step 228, Loss: 0.567126989364624\n",
            "Epoch 36, Step 229, Loss: 0.5975310206413269\n",
            "Epoch 36, Step 230, Loss: 0.4879588186740875\n",
            "Epoch 36, Step 231, Loss: 0.46417924761772156\n",
            "Epoch 36, Step 232, Loss: 0.5302526354789734\n",
            "Epoch 36, Step 233, Loss: 0.5834364295005798\n",
            "Epoch 36, Step 234, Loss: 0.4284798800945282\n",
            "Epoch 36, Step 235, Loss: 0.5686597228050232\n",
            "Epoch 36, Step 236, Loss: 0.6534116864204407\n",
            "Epoch 36, Step 237, Loss: 0.5533478856086731\n",
            "Epoch 36, Step 238, Loss: 0.47520166635513306\n",
            "Epoch 36, Step 239, Loss: 0.5643869042396545\n",
            "Epoch 36, Step 240, Loss: 0.6811351180076599\n",
            "Epoch 36, Step 241, Loss: 0.6680495142936707\n",
            "Epoch 36, Step 242, Loss: 0.5444455742835999\n",
            "Epoch 36, Step 243, Loss: 0.517653226852417\n",
            "Epoch 36, Step 244, Loss: 0.37376755475997925\n",
            "Epoch 36, Step 245, Loss: 0.593919038772583\n",
            "Epoch 36, Step 246, Loss: 0.607244074344635\n",
            "Epoch 36, Step 247, Loss: 0.49598851799964905\n",
            "Epoch 36, Step 248, Loss: 0.5754027366638184\n",
            "Epoch 36, Step 249, Loss: 0.5080553889274597\n",
            "Epoch 36, Step 250, Loss: 0.5746804475784302\n",
            "Epoch 36, Step 251, Loss: 0.4554436504840851\n",
            "Epoch 36, Step 252, Loss: 0.5069993734359741\n",
            "Epoch 36, Step 253, Loss: 0.4395061135292053\n",
            "Epoch 36, Step 254, Loss: 0.5144739151000977\n",
            "Epoch 36, Step 255, Loss: 0.6709825396537781\n",
            "Epoch 36, Step 256, Loss: 0.6725349426269531\n",
            "Epoch 36, Step 257, Loss: 0.45109033584594727\n",
            "Epoch 36, Step 258, Loss: 0.5170348882675171\n",
            "Epoch 36, Step 259, Loss: 0.5784786939620972\n",
            "Epoch 36, Step 260, Loss: 0.5016996264457703\n",
            "Epoch 36, Step 261, Loss: 0.5646892786026001\n",
            "Epoch 36, Step 262, Loss: 0.733177661895752\n",
            "Epoch 36, Step 263, Loss: 0.69577556848526\n",
            "Epoch 36, Step 264, Loss: 0.5077728629112244\n",
            "Epoch 36, Step 265, Loss: 0.8036216497421265\n",
            "Epoch 36, Step 266, Loss: 0.40158623456954956\n",
            "Epoch 36, Step 267, Loss: 0.5115190148353577\n",
            "Epoch 36, Step 268, Loss: 0.6321333050727844\n",
            "Epoch 36, Step 269, Loss: 0.626532256603241\n",
            "Epoch 36, Step 270, Loss: 0.4366261661052704\n",
            "Epoch 36, Step 271, Loss: 0.5909040570259094\n",
            "Epoch 36, Step 272, Loss: 0.5380229353904724\n",
            "Epoch 36, Step 273, Loss: 0.42524823546409607\n",
            "Epoch 36, Step 274, Loss: 0.5729382038116455\n",
            "Epoch 36, Step 275, Loss: 0.4764866232872009\n",
            "Epoch 36, Step 276, Loss: 0.5065541863441467\n",
            "Epoch 36, Step 277, Loss: 0.6624183058738708\n",
            "Epoch 36, Step 278, Loss: 0.7191154360771179\n",
            "Epoch 36, Step 279, Loss: 0.6461277008056641\n",
            "Epoch 36, Step 280, Loss: 0.4615939259529114\n",
            "Epoch 36, Step 281, Loss: 0.5326846837997437\n",
            "Epoch 36, Step 282, Loss: 0.5865715146064758\n",
            "Epoch 36, Step 283, Loss: 0.7193623781204224\n",
            "Epoch 36, Step 284, Loss: 0.6890143156051636\n",
            "Epoch 36, Step 285, Loss: 0.5996807217597961\n",
            "Epoch 36, Step 286, Loss: 0.6315190196037292\n",
            "Epoch 36, Step 287, Loss: 0.6016550064086914\n",
            "Epoch 36, Step 288, Loss: 0.4302060008049011\n",
            "Epoch 36, Step 289, Loss: 0.517851710319519\n",
            "Epoch 36, Step 290, Loss: 0.5570831298828125\n",
            "Epoch 36, Step 291, Loss: 0.5696370601654053\n",
            "Epoch 36, Step 292, Loss: 0.5204785466194153\n",
            "Epoch 36, Step 293, Loss: 0.534621000289917\n",
            "Epoch 36, Step 294, Loss: 0.5414628386497498\n",
            "Epoch 36, Step 295, Loss: 0.5275071859359741\n",
            "Epoch 36, Step 296, Loss: 0.5910339951515198\n",
            "Epoch 36, Step 297, Loss: 0.5143913626670837\n",
            "Epoch 36, Step 298, Loss: 0.410740464925766\n",
            "Epoch 36, Step 299, Loss: 0.5040137767791748\n",
            "Epoch 36, Step 300, Loss: 0.5741518139839172\n",
            "Epoch 36, Step 301, Loss: 0.6850304007530212\n",
            "Epoch 36, Step 302, Loss: 0.5853622555732727\n",
            "Epoch 36, Step 303, Loss: 0.600553572177887\n",
            "Epoch 36, Step 304, Loss: 0.6227542161941528\n",
            "Epoch 36, Step 305, Loss: 0.5866841673851013\n",
            "Epoch 36, Step 306, Loss: 0.5935511589050293\n",
            "Epoch 36, Step 307, Loss: 0.6948965191841125\n",
            "Epoch 36, Step 308, Loss: 0.4490775465965271\n",
            "Epoch 36, Step 309, Loss: 0.6005392670631409\n",
            "Epoch 36, Step 310, Loss: 0.4668560028076172\n",
            "Epoch 36, Step 311, Loss: 0.4885292649269104\n",
            "Epoch 36, Step 312, Loss: 0.6743890047073364\n",
            "Epoch 36 end, avg train loss: 0.55892131475214\n",
            "Epoch 36 end, avg val loss: 0.6009775105910965, accuracy: 79.07%\n",
            "Epoch 37, Step 0, Loss: 0.7142165899276733\n",
            "Epoch 37, Step 1, Loss: 0.4364662170410156\n",
            "Epoch 37, Step 2, Loss: 0.41355693340301514\n",
            "Epoch 37, Step 3, Loss: 0.5086032152175903\n",
            "Epoch 37, Step 4, Loss: 0.46928584575653076\n",
            "Epoch 37, Step 5, Loss: 0.5477065443992615\n",
            "Epoch 37, Step 6, Loss: 0.6557343602180481\n",
            "Epoch 37, Step 7, Loss: 0.7665032744407654\n",
            "Epoch 37, Step 8, Loss: 0.6169732213020325\n",
            "Epoch 37, Step 9, Loss: 0.6112926006317139\n",
            "Epoch 37, Step 10, Loss: 0.5239008069038391\n",
            "Epoch 37, Step 11, Loss: 0.5511266589164734\n",
            "Epoch 37, Step 12, Loss: 0.46075448393821716\n",
            "Epoch 37, Step 13, Loss: 0.6173644065856934\n",
            "Epoch 37, Step 14, Loss: 0.5524172782897949\n",
            "Epoch 37, Step 15, Loss: 0.6556670665740967\n",
            "Epoch 37, Step 16, Loss: 0.5006285905838013\n",
            "Epoch 37, Step 17, Loss: 0.5921838283538818\n",
            "Epoch 37, Step 18, Loss: 0.5218352675437927\n",
            "Epoch 37, Step 19, Loss: 0.5073246955871582\n",
            "Epoch 37, Step 20, Loss: 0.5369796752929688\n",
            "Epoch 37, Step 21, Loss: 0.555985152721405\n",
            "Epoch 37, Step 22, Loss: 0.5010778307914734\n",
            "Epoch 37, Step 23, Loss: 0.5988497138023376\n",
            "Epoch 37, Step 24, Loss: 0.6183038353919983\n",
            "Epoch 37, Step 25, Loss: 0.5435577630996704\n",
            "Epoch 37, Step 26, Loss: 0.6190904974937439\n",
            "Epoch 37, Step 27, Loss: 0.559964120388031\n",
            "Epoch 37, Step 28, Loss: 0.47673219442367554\n",
            "Epoch 37, Step 29, Loss: 0.6066893339157104\n",
            "Epoch 37, Step 30, Loss: 0.40934377908706665\n",
            "Epoch 37, Step 31, Loss: 0.622329592704773\n",
            "Epoch 37, Step 32, Loss: 0.5259581804275513\n",
            "Epoch 37, Step 33, Loss: 0.5194127559661865\n",
            "Epoch 37, Step 34, Loss: 0.6494963765144348\n",
            "Epoch 37, Step 35, Loss: 0.6088284850120544\n",
            "Epoch 37, Step 36, Loss: 0.5847058892250061\n",
            "Epoch 37, Step 37, Loss: 0.5450409054756165\n",
            "Epoch 37, Step 38, Loss: 0.6065232753753662\n",
            "Epoch 37, Step 39, Loss: 0.6155351996421814\n",
            "Epoch 37, Step 40, Loss: 0.6188658475875854\n",
            "Epoch 37, Step 41, Loss: 0.5892379879951477\n",
            "Epoch 37, Step 42, Loss: 0.46082860231399536\n",
            "Epoch 37, Step 43, Loss: 0.43623533844947815\n",
            "Epoch 37, Step 44, Loss: 0.7449463605880737\n",
            "Epoch 37, Step 45, Loss: 0.5729281902313232\n",
            "Epoch 37, Step 46, Loss: 0.5615066885948181\n",
            "Epoch 37, Step 47, Loss: 0.5544413924217224\n",
            "Epoch 37, Step 48, Loss: 0.5267793536186218\n",
            "Epoch 37, Step 49, Loss: 0.5631166100502014\n",
            "Epoch 37, Step 50, Loss: 0.6172225475311279\n",
            "Epoch 37, Step 51, Loss: 0.5676506161689758\n",
            "Epoch 37, Step 52, Loss: 0.5613881945610046\n",
            "Epoch 37, Step 53, Loss: 0.4514160454273224\n",
            "Epoch 37, Step 54, Loss: 0.5431236624717712\n",
            "Epoch 37, Step 55, Loss: 0.5180579423904419\n",
            "Epoch 37, Step 56, Loss: 0.4884628355503082\n",
            "Epoch 37, Step 57, Loss: 0.5820496082305908\n",
            "Epoch 37, Step 58, Loss: 0.5566263198852539\n",
            "Epoch 37, Step 59, Loss: 0.6090574860572815\n",
            "Epoch 37, Step 60, Loss: 0.5561267137527466\n",
            "Epoch 37, Step 61, Loss: 0.4780972898006439\n",
            "Epoch 37, Step 62, Loss: 0.4424920678138733\n",
            "Epoch 37, Step 63, Loss: 0.530434787273407\n",
            "Epoch 37, Step 64, Loss: 0.5642024278640747\n",
            "Epoch 37, Step 65, Loss: 0.5780077576637268\n",
            "Epoch 37, Step 66, Loss: 0.5163896083831787\n",
            "Epoch 37, Step 67, Loss: 0.47860321402549744\n",
            "Epoch 37, Step 68, Loss: 0.4895693361759186\n",
            "Epoch 37, Step 69, Loss: 0.712666392326355\n",
            "Epoch 37, Step 70, Loss: 0.5339863300323486\n",
            "Epoch 37, Step 71, Loss: 0.5452089309692383\n",
            "Epoch 37, Step 72, Loss: 0.5172026753425598\n",
            "Epoch 37, Step 73, Loss: 0.5494087338447571\n",
            "Epoch 37, Step 74, Loss: 0.43848147988319397\n",
            "Epoch 37, Step 75, Loss: 0.6311757564544678\n",
            "Epoch 37, Step 76, Loss: 0.5079623460769653\n",
            "Epoch 37, Step 77, Loss: 0.43026044964790344\n",
            "Epoch 37, Step 78, Loss: 0.6149827837944031\n",
            "Epoch 37, Step 79, Loss: 0.6248801946640015\n",
            "Epoch 37, Step 80, Loss: 0.5518031716346741\n",
            "Epoch 37, Step 81, Loss: 0.5222489833831787\n",
            "Epoch 37, Step 82, Loss: 0.46902889013290405\n",
            "Epoch 37, Step 83, Loss: 0.5437455177307129\n",
            "Epoch 37, Step 84, Loss: 0.5891713500022888\n",
            "Epoch 37, Step 85, Loss: 0.5197504758834839\n",
            "Epoch 37, Step 86, Loss: 0.5595878958702087\n",
            "Epoch 37, Step 87, Loss: 0.5503454208374023\n",
            "Epoch 37, Step 88, Loss: 0.4977428913116455\n",
            "Epoch 37, Step 89, Loss: 0.5544081330299377\n",
            "Epoch 37, Step 90, Loss: 0.5634335279464722\n",
            "Epoch 37, Step 91, Loss: 0.5970122218132019\n",
            "Epoch 37, Step 92, Loss: 0.4200035333633423\n",
            "Epoch 37, Step 93, Loss: 0.5019991993904114\n",
            "Epoch 37, Step 94, Loss: 0.6490511894226074\n",
            "Epoch 37, Step 95, Loss: 0.5979966521263123\n",
            "Epoch 37, Step 96, Loss: 0.4612658619880676\n",
            "Epoch 37, Step 97, Loss: 0.530937671661377\n",
            "Epoch 37, Step 98, Loss: 0.5310769081115723\n",
            "Epoch 37, Step 99, Loss: 0.5358823537826538\n",
            "Epoch 37, Step 100, Loss: 0.5178371667861938\n",
            "Epoch 37, Step 101, Loss: 0.541263222694397\n",
            "Epoch 37, Step 102, Loss: 0.5200018882751465\n",
            "Epoch 37, Step 103, Loss: 0.6153191328048706\n",
            "Epoch 37, Step 104, Loss: 0.5548084378242493\n",
            "Epoch 37, Step 105, Loss: 0.5244392156600952\n",
            "Epoch 37, Step 106, Loss: 0.5072205066680908\n",
            "Epoch 37, Step 107, Loss: 0.4686644375324249\n",
            "Epoch 37, Step 108, Loss: 0.6718485355377197\n",
            "Epoch 37, Step 109, Loss: 0.5837836861610413\n",
            "Epoch 37, Step 110, Loss: 0.6562469005584717\n",
            "Epoch 37, Step 111, Loss: 0.5690214037895203\n",
            "Epoch 37, Step 112, Loss: 0.5117848515510559\n",
            "Epoch 37, Step 113, Loss: 0.6291996240615845\n",
            "Epoch 37, Step 114, Loss: 0.6118083596229553\n",
            "Epoch 37, Step 115, Loss: 0.543751060962677\n",
            "Epoch 37, Step 116, Loss: 0.423406720161438\n",
            "Epoch 37, Step 117, Loss: 0.5894589424133301\n",
            "Epoch 37, Step 118, Loss: 0.44312024116516113\n",
            "Epoch 37, Step 119, Loss: 0.5856707692146301\n",
            "Epoch 37, Step 120, Loss: 0.487027645111084\n",
            "Epoch 37, Step 121, Loss: 0.6620453000068665\n",
            "Epoch 37, Step 122, Loss: 0.5603607892990112\n",
            "Epoch 37, Step 123, Loss: 0.5500661730766296\n",
            "Epoch 37, Step 124, Loss: 0.5292835235595703\n",
            "Epoch 37, Step 125, Loss: 0.470264732837677\n",
            "Epoch 37, Step 126, Loss: 0.6214984655380249\n",
            "Epoch 37, Step 127, Loss: 0.517163872718811\n",
            "Epoch 37, Step 128, Loss: 0.4938875436782837\n",
            "Epoch 37, Step 129, Loss: 0.5452755689620972\n",
            "Epoch 37, Step 130, Loss: 0.4305526316165924\n",
            "Epoch 37, Step 131, Loss: 0.5298599600791931\n",
            "Epoch 37, Step 132, Loss: 0.5180915594100952\n",
            "Epoch 37, Step 133, Loss: 0.4468931257724762\n",
            "Epoch 37, Step 134, Loss: 0.4603004455566406\n",
            "Epoch 37, Step 135, Loss: 0.5897290706634521\n",
            "Epoch 37, Step 136, Loss: 0.6781724095344543\n",
            "Epoch 37, Step 137, Loss: 0.618394672870636\n",
            "Epoch 37, Step 138, Loss: 0.4578729271888733\n",
            "Epoch 37, Step 139, Loss: 0.7289612889289856\n",
            "Epoch 37, Step 140, Loss: 0.573479175567627\n",
            "Epoch 37, Step 141, Loss: 0.5011104941368103\n",
            "Epoch 37, Step 142, Loss: 0.6602869629859924\n",
            "Epoch 37, Step 143, Loss: 0.5526884198188782\n",
            "Epoch 37, Step 144, Loss: 0.5503495931625366\n",
            "Epoch 37, Step 145, Loss: 0.5593886971473694\n",
            "Epoch 37, Step 146, Loss: 0.37381044030189514\n",
            "Epoch 37, Step 147, Loss: 0.8009523153305054\n",
            "Epoch 37, Step 148, Loss: 0.44446584582328796\n",
            "Epoch 37, Step 149, Loss: 0.4811663329601288\n",
            "Epoch 37, Step 150, Loss: 0.6038596034049988\n",
            "Epoch 37, Step 151, Loss: 0.5953659415245056\n",
            "Epoch 37, Step 152, Loss: 0.503147542476654\n",
            "Epoch 37, Step 153, Loss: 0.6071731448173523\n",
            "Epoch 37, Step 154, Loss: 0.6044725775718689\n",
            "Epoch 37, Step 155, Loss: 0.5965276956558228\n",
            "Epoch 37, Step 156, Loss: 0.6081035137176514\n",
            "Epoch 37, Step 157, Loss: 0.5401376485824585\n",
            "Epoch 37, Step 158, Loss: 0.5975967049598694\n",
            "Epoch 37, Step 159, Loss: 0.6948635578155518\n",
            "Epoch 37, Step 160, Loss: 0.5001886487007141\n",
            "Epoch 37, Step 161, Loss: 0.40339118242263794\n",
            "Epoch 37, Step 162, Loss: 0.45213738083839417\n",
            "Epoch 37, Step 163, Loss: 0.63339763879776\n",
            "Epoch 37, Step 164, Loss: 0.46821779012680054\n",
            "Epoch 37, Step 165, Loss: 0.4941253364086151\n",
            "Epoch 37, Step 166, Loss: 0.46076446771621704\n",
            "Epoch 37, Step 167, Loss: 0.5464043021202087\n",
            "Epoch 37, Step 168, Loss: 0.47054052352905273\n",
            "Epoch 37, Step 169, Loss: 0.6644207835197449\n",
            "Epoch 37, Step 170, Loss: 0.8283277750015259\n",
            "Epoch 37, Step 171, Loss: 0.5779708027839661\n",
            "Epoch 37, Step 172, Loss: 0.6676287055015564\n",
            "Epoch 37, Step 173, Loss: 0.6150338053703308\n",
            "Epoch 37, Step 174, Loss: 0.46836528182029724\n",
            "Epoch 37, Step 175, Loss: 0.5273049473762512\n",
            "Epoch 37, Step 176, Loss: 0.4162713885307312\n",
            "Epoch 37, Step 177, Loss: 0.5758273601531982\n",
            "Epoch 37, Step 178, Loss: 0.7113096117973328\n",
            "Epoch 37, Step 179, Loss: 0.7100011110305786\n",
            "Epoch 37, Step 180, Loss: 0.6014610528945923\n",
            "Epoch 37, Step 181, Loss: 0.6093580722808838\n",
            "Epoch 37, Step 182, Loss: 0.5863900184631348\n",
            "Epoch 37, Step 183, Loss: 0.4193289577960968\n",
            "Epoch 37, Step 184, Loss: 0.5172125101089478\n",
            "Epoch 37, Step 185, Loss: 0.4787498712539673\n",
            "Epoch 37, Step 186, Loss: 0.5292385816574097\n",
            "Epoch 37, Step 187, Loss: 0.6662862300872803\n",
            "Epoch 37, Step 188, Loss: 0.6285181045532227\n",
            "Epoch 37, Step 189, Loss: 0.49694082140922546\n",
            "Epoch 37, Step 190, Loss: 0.5782946348190308\n",
            "Epoch 37, Step 191, Loss: 0.4633345603942871\n",
            "Epoch 37, Step 192, Loss: 0.5716700553894043\n",
            "Epoch 37, Step 193, Loss: 0.46296125650405884\n",
            "Epoch 37, Step 194, Loss: 0.632805585861206\n",
            "Epoch 37, Step 195, Loss: 0.43292248249053955\n",
            "Epoch 37, Step 196, Loss: 0.5690494775772095\n",
            "Epoch 37, Step 197, Loss: 0.4211309552192688\n",
            "Epoch 37, Step 198, Loss: 0.4863562285900116\n",
            "Epoch 37, Step 199, Loss: 0.6441484093666077\n",
            "Epoch 37, Step 200, Loss: 0.5728508234024048\n",
            "Epoch 37, Step 201, Loss: 0.4231104850769043\n",
            "Epoch 37, Step 202, Loss: 0.768521785736084\n",
            "Epoch 37, Step 203, Loss: 0.47638049721717834\n",
            "Epoch 37, Step 204, Loss: 0.5856091976165771\n",
            "Epoch 37, Step 205, Loss: 0.5116864442825317\n",
            "Epoch 37, Step 206, Loss: 0.6017813086509705\n",
            "Epoch 37, Step 207, Loss: 0.5919390320777893\n",
            "Epoch 37, Step 208, Loss: 0.42511337995529175\n",
            "Epoch 37, Step 209, Loss: 0.44195717573165894\n",
            "Epoch 37, Step 210, Loss: 0.5427258610725403\n",
            "Epoch 37, Step 211, Loss: 0.4683625102043152\n",
            "Epoch 37, Step 212, Loss: 0.4751984775066376\n",
            "Epoch 37, Step 213, Loss: 0.5122823119163513\n",
            "Epoch 37, Step 214, Loss: 0.47457677125930786\n",
            "Epoch 37, Step 215, Loss: 0.49888768792152405\n",
            "Epoch 37, Step 216, Loss: 0.5587761402130127\n",
            "Epoch 37, Step 217, Loss: 0.5656219124794006\n",
            "Epoch 37, Step 218, Loss: 0.5798119306564331\n",
            "Epoch 37, Step 219, Loss: 0.3963044285774231\n",
            "Epoch 37, Step 220, Loss: 0.5037707090377808\n",
            "Epoch 37, Step 221, Loss: 0.6023118495941162\n",
            "Epoch 37, Step 222, Loss: 0.5070984959602356\n",
            "Epoch 37, Step 223, Loss: 0.45491254329681396\n",
            "Epoch 37, Step 224, Loss: 0.6711463928222656\n",
            "Epoch 37, Step 225, Loss: 0.5325469970703125\n",
            "Epoch 37, Step 226, Loss: 0.46216216683387756\n",
            "Epoch 37, Step 227, Loss: 0.5681633949279785\n",
            "Epoch 37, Step 228, Loss: 0.5714568495750427\n",
            "Epoch 37, Step 229, Loss: 0.6561687588691711\n",
            "Epoch 37, Step 230, Loss: 0.5198416709899902\n",
            "Epoch 37, Step 231, Loss: 0.5289713740348816\n",
            "Epoch 37, Step 232, Loss: 0.6352026462554932\n",
            "Epoch 37, Step 233, Loss: 0.3929961025714874\n",
            "Epoch 37, Step 234, Loss: 0.44572725892066956\n",
            "Epoch 37, Step 235, Loss: 0.5649616122245789\n",
            "Epoch 37, Step 236, Loss: 0.5668003559112549\n",
            "Epoch 37, Step 237, Loss: 0.5270408987998962\n",
            "Epoch 37, Step 238, Loss: 0.6075787544250488\n",
            "Epoch 37, Step 239, Loss: 0.4976440966129303\n",
            "Epoch 37, Step 240, Loss: 0.520534098148346\n",
            "Epoch 37, Step 241, Loss: 0.5386262536048889\n",
            "Epoch 37, Step 242, Loss: 0.30387136340141296\n",
            "Epoch 37, Step 243, Loss: 0.47575485706329346\n",
            "Epoch 37, Step 244, Loss: 0.5527076721191406\n",
            "Epoch 37, Step 245, Loss: 0.526586651802063\n",
            "Epoch 37, Step 246, Loss: 0.539195716381073\n",
            "Epoch 37, Step 247, Loss: 0.4683104157447815\n",
            "Epoch 37, Step 248, Loss: 0.5014933347702026\n",
            "Epoch 37, Step 249, Loss: 0.6982083916664124\n",
            "Epoch 37, Step 250, Loss: 0.42462998628616333\n",
            "Epoch 37, Step 251, Loss: 0.5927103757858276\n",
            "Epoch 37, Step 252, Loss: 0.5306114554405212\n",
            "Epoch 37, Step 253, Loss: 0.5151309967041016\n",
            "Epoch 37, Step 254, Loss: 0.6504639387130737\n",
            "Epoch 37, Step 255, Loss: 0.5441960692405701\n",
            "Epoch 37, Step 256, Loss: 0.575133204460144\n",
            "Epoch 37, Step 257, Loss: 0.7455235719680786\n",
            "Epoch 37, Step 258, Loss: 0.5631842017173767\n",
            "Epoch 37, Step 259, Loss: 0.5263655185699463\n",
            "Epoch 37, Step 260, Loss: 0.4989803433418274\n",
            "Epoch 37, Step 261, Loss: 0.46526533365249634\n",
            "Epoch 37, Step 262, Loss: 0.5893786549568176\n",
            "Epoch 37, Step 263, Loss: 0.5730463862419128\n",
            "Epoch 37, Step 264, Loss: 0.6029312610626221\n",
            "Epoch 37, Step 265, Loss: 0.524453341960907\n",
            "Epoch 37, Step 266, Loss: 0.5716307759284973\n",
            "Epoch 37, Step 267, Loss: 0.6303638815879822\n",
            "Epoch 37, Step 268, Loss: 0.5191990733146667\n",
            "Epoch 37, Step 269, Loss: 0.5300008058547974\n",
            "Epoch 37, Step 270, Loss: 0.6215601563453674\n",
            "Epoch 37, Step 271, Loss: 0.7463547587394714\n",
            "Epoch 37, Step 272, Loss: 0.6101523041725159\n",
            "Epoch 37, Step 273, Loss: 0.46833571791648865\n",
            "Epoch 37, Step 274, Loss: 0.4706590175628662\n",
            "Epoch 37, Step 275, Loss: 0.5751079320907593\n",
            "Epoch 37, Step 276, Loss: 0.5267241597175598\n",
            "Epoch 37, Step 277, Loss: 0.6052924990653992\n",
            "Epoch 37, Step 278, Loss: 0.5835539698600769\n",
            "Epoch 37, Step 279, Loss: 0.5190849304199219\n",
            "Epoch 37, Step 280, Loss: 0.511421263217926\n",
            "Epoch 37, Step 281, Loss: 0.4000207185745239\n",
            "Epoch 37, Step 282, Loss: 0.642065167427063\n",
            "Epoch 37, Step 283, Loss: 0.5484979748725891\n",
            "Epoch 37, Step 284, Loss: 0.5872182846069336\n",
            "Epoch 37, Step 285, Loss: 0.7711302638053894\n",
            "Epoch 37, Step 286, Loss: 0.673980176448822\n",
            "Epoch 37, Step 287, Loss: 0.5817054510116577\n",
            "Epoch 37, Step 288, Loss: 0.48798874020576477\n",
            "Epoch 37, Step 289, Loss: 0.6265736222267151\n",
            "Epoch 37, Step 290, Loss: 0.48753252625465393\n",
            "Epoch 37, Step 291, Loss: 0.4331299066543579\n",
            "Epoch 37, Step 292, Loss: 0.4569648206233978\n",
            "Epoch 37, Step 293, Loss: 0.6124253869056702\n",
            "Epoch 37, Step 294, Loss: 0.4767557680606842\n",
            "Epoch 37, Step 295, Loss: 0.45186302065849304\n",
            "Epoch 37, Step 296, Loss: 0.5769073367118835\n",
            "Epoch 37, Step 297, Loss: 0.5292122960090637\n",
            "Epoch 37, Step 298, Loss: 0.57157963514328\n",
            "Epoch 37, Step 299, Loss: 0.5282500386238098\n",
            "Epoch 37, Step 300, Loss: 0.4447851777076721\n",
            "Epoch 37, Step 301, Loss: 0.5463991761207581\n",
            "Epoch 37, Step 302, Loss: 0.6147158145904541\n",
            "Epoch 37, Step 303, Loss: 0.47868645191192627\n",
            "Epoch 37, Step 304, Loss: 0.4433315098285675\n",
            "Epoch 37, Step 305, Loss: 0.5123969316482544\n",
            "Epoch 37, Step 306, Loss: 0.6739298701286316\n",
            "Epoch 37, Step 307, Loss: 0.6433118581771851\n",
            "Epoch 37, Step 308, Loss: 0.49956294894218445\n",
            "Epoch 37, Step 309, Loss: 0.5358452200889587\n",
            "Epoch 37, Step 310, Loss: 0.45298218727111816\n",
            "Epoch 37, Step 311, Loss: 0.8490033745765686\n",
            "Epoch 37, Step 312, Loss: 0.6344924569129944\n",
            "Epoch 37 end, avg train loss: 0.5499603475054232\n",
            "Epoch 37 end, avg val loss: 0.616017280877391, accuracy: 78.66%\n",
            "Epoch 38, Step 0, Loss: 0.5528977513313293\n",
            "Epoch 38, Step 1, Loss: 0.5413910150527954\n",
            "Epoch 38, Step 2, Loss: 0.7144986391067505\n",
            "Epoch 38, Step 3, Loss: 0.575501561164856\n",
            "Epoch 38, Step 4, Loss: 0.5484644174575806\n",
            "Epoch 38, Step 5, Loss: 0.6387436389923096\n",
            "Epoch 38, Step 6, Loss: 0.48735764622688293\n",
            "Epoch 38, Step 7, Loss: 0.43323206901550293\n",
            "Epoch 38, Step 8, Loss: 0.564532995223999\n",
            "Epoch 38, Step 9, Loss: 0.5947077870368958\n",
            "Epoch 38, Step 10, Loss: 0.5026867389678955\n",
            "Epoch 38, Step 11, Loss: 0.6802922487258911\n",
            "Epoch 38, Step 12, Loss: 0.6213884949684143\n",
            "Epoch 38, Step 13, Loss: 0.6776259541511536\n",
            "Epoch 38, Step 14, Loss: 0.6296299695968628\n",
            "Epoch 38, Step 15, Loss: 0.6183538436889648\n",
            "Epoch 38, Step 16, Loss: 0.5928676724433899\n",
            "Epoch 38, Step 17, Loss: 0.5427969694137573\n",
            "Epoch 38, Step 18, Loss: 0.5368958115577698\n",
            "Epoch 38, Step 19, Loss: 0.49758854508399963\n",
            "Epoch 38, Step 20, Loss: 0.5604677796363831\n",
            "Epoch 38, Step 21, Loss: 0.612317681312561\n",
            "Epoch 38, Step 22, Loss: 0.58141028881073\n",
            "Epoch 38, Step 23, Loss: 0.41026702523231506\n",
            "Epoch 38, Step 24, Loss: 0.4562811553478241\n",
            "Epoch 38, Step 25, Loss: 0.5250560641288757\n",
            "Epoch 38, Step 26, Loss: 0.5273423194885254\n",
            "Epoch 38, Step 27, Loss: 0.5919612646102905\n",
            "Epoch 38, Step 28, Loss: 0.3846650719642639\n",
            "Epoch 38, Step 29, Loss: 0.4097570478916168\n",
            "Epoch 38, Step 30, Loss: 0.4585159718990326\n",
            "Epoch 38, Step 31, Loss: 0.6451416015625\n",
            "Epoch 38, Step 32, Loss: 0.5066079497337341\n",
            "Epoch 38, Step 33, Loss: 0.5771898627281189\n",
            "Epoch 38, Step 34, Loss: 0.5461484789848328\n",
            "Epoch 38, Step 35, Loss: 0.5404208898544312\n",
            "Epoch 38, Step 36, Loss: 0.4124429225921631\n",
            "Epoch 38, Step 37, Loss: 0.4354246258735657\n",
            "Epoch 38, Step 38, Loss: 0.37380385398864746\n",
            "Epoch 38, Step 39, Loss: 0.6396645903587341\n",
            "Epoch 38, Step 40, Loss: 0.6772430539131165\n",
            "Epoch 38, Step 41, Loss: 0.5846308469772339\n",
            "Epoch 38, Step 42, Loss: 0.7052939534187317\n",
            "Epoch 38, Step 43, Loss: 0.38197603821754456\n",
            "Epoch 38, Step 44, Loss: 0.5020359754562378\n",
            "Epoch 38, Step 45, Loss: 0.44370943307876587\n",
            "Epoch 38, Step 46, Loss: 0.5796223878860474\n",
            "Epoch 38, Step 47, Loss: 0.3319956660270691\n",
            "Epoch 38, Step 48, Loss: 0.46139901876449585\n",
            "Epoch 38, Step 49, Loss: 0.5398836731910706\n",
            "Epoch 38, Step 50, Loss: 0.46249815821647644\n",
            "Epoch 38, Step 51, Loss: 0.6076409816741943\n",
            "Epoch 38, Step 52, Loss: 0.5780779719352722\n",
            "Epoch 38, Step 53, Loss: 0.5021936893463135\n",
            "Epoch 38, Step 54, Loss: 0.5286823511123657\n",
            "Epoch 38, Step 55, Loss: 0.6011661291122437\n",
            "Epoch 38, Step 56, Loss: 0.4848683774471283\n",
            "Epoch 38, Step 57, Loss: 0.7152442336082458\n",
            "Epoch 38, Step 58, Loss: 0.5868078470230103\n",
            "Epoch 38, Step 59, Loss: 0.45664742588996887\n",
            "Epoch 38, Step 60, Loss: 0.5660266280174255\n",
            "Epoch 38, Step 61, Loss: 0.5682022571563721\n",
            "Epoch 38, Step 62, Loss: 0.5684652328491211\n",
            "Epoch 38, Step 63, Loss: 0.6179348230361938\n",
            "Epoch 38, Step 64, Loss: 0.6002376675605774\n",
            "Epoch 38, Step 65, Loss: 0.5016062259674072\n",
            "Epoch 38, Step 66, Loss: 0.5553351640701294\n",
            "Epoch 38, Step 67, Loss: 0.6328687071800232\n",
            "Epoch 38, Step 68, Loss: 0.6300477981567383\n",
            "Epoch 38, Step 69, Loss: 0.43715953826904297\n",
            "Epoch 38, Step 70, Loss: 0.44286927580833435\n",
            "Epoch 38, Step 71, Loss: 0.5632708668708801\n",
            "Epoch 38, Step 72, Loss: 0.5235151648521423\n",
            "Epoch 38, Step 73, Loss: 0.5350923538208008\n",
            "Epoch 38, Step 74, Loss: 0.5216493606567383\n",
            "Epoch 38, Step 75, Loss: 0.5965439081192017\n",
            "Epoch 38, Step 76, Loss: 0.664924681186676\n",
            "Epoch 38, Step 77, Loss: 0.7238316535949707\n",
            "Epoch 38, Step 78, Loss: 0.5503087639808655\n",
            "Epoch 38, Step 79, Loss: 0.48337388038635254\n",
            "Epoch 38, Step 80, Loss: 0.46424156427383423\n",
            "Epoch 38, Step 81, Loss: 0.5063502192497253\n",
            "Epoch 38, Step 82, Loss: 0.5834605693817139\n",
            "Epoch 38, Step 83, Loss: 0.4824563264846802\n",
            "Epoch 38, Step 84, Loss: 0.4022083878517151\n",
            "Epoch 38, Step 85, Loss: 0.4732685685157776\n",
            "Epoch 38, Step 86, Loss: 0.6111941933631897\n",
            "Epoch 38, Step 87, Loss: 0.4836848974227905\n",
            "Epoch 38, Step 88, Loss: 0.5581034421920776\n",
            "Epoch 38, Step 89, Loss: 0.5352458357810974\n",
            "Epoch 38, Step 90, Loss: 0.4935874938964844\n",
            "Epoch 38, Step 91, Loss: 0.37479716539382935\n",
            "Epoch 38, Step 92, Loss: 0.624940037727356\n",
            "Epoch 38, Step 93, Loss: 0.5269887447357178\n",
            "Epoch 38, Step 94, Loss: 0.4953000247478485\n",
            "Epoch 38, Step 95, Loss: 0.6840776205062866\n",
            "Epoch 38, Step 96, Loss: 0.4734616279602051\n",
            "Epoch 38, Step 97, Loss: 0.6644598841667175\n",
            "Epoch 38, Step 98, Loss: 0.645560085773468\n",
            "Epoch 38, Step 99, Loss: 0.5901197195053101\n",
            "Epoch 38, Step 100, Loss: 0.47799748182296753\n",
            "Epoch 38, Step 101, Loss: 0.5985073447227478\n",
            "Epoch 38, Step 102, Loss: 0.6274932622909546\n",
            "Epoch 38, Step 103, Loss: 0.4197826087474823\n",
            "Epoch 38, Step 104, Loss: 0.7109801769256592\n",
            "Epoch 38, Step 105, Loss: 0.4367707669734955\n",
            "Epoch 38, Step 106, Loss: 0.36646512150764465\n",
            "Epoch 38, Step 107, Loss: 0.6310606598854065\n",
            "Epoch 38, Step 108, Loss: 0.4356897473335266\n",
            "Epoch 38, Step 109, Loss: 0.6643604636192322\n",
            "Epoch 38, Step 110, Loss: 0.45359379053115845\n",
            "Epoch 38, Step 111, Loss: 0.5592949390411377\n",
            "Epoch 38, Step 112, Loss: 0.5655463933944702\n",
            "Epoch 38, Step 113, Loss: 0.5592511296272278\n",
            "Epoch 38, Step 114, Loss: 0.4681870937347412\n",
            "Epoch 38, Step 115, Loss: 0.6251091361045837\n",
            "Epoch 38, Step 116, Loss: 0.49106529355049133\n",
            "Epoch 38, Step 117, Loss: 0.4780317544937134\n",
            "Epoch 38, Step 118, Loss: 0.3427802324295044\n",
            "Epoch 38, Step 119, Loss: 0.506350576877594\n",
            "Epoch 38, Step 120, Loss: 0.5188185572624207\n",
            "Epoch 38, Step 121, Loss: 0.6385149359703064\n",
            "Epoch 38, Step 122, Loss: 0.5595267415046692\n",
            "Epoch 38, Step 123, Loss: 0.4833047389984131\n",
            "Epoch 38, Step 124, Loss: 0.6165458559989929\n",
            "Epoch 38, Step 125, Loss: 0.5547516345977783\n",
            "Epoch 38, Step 126, Loss: 0.5237534642219543\n",
            "Epoch 38, Step 127, Loss: 0.5601391792297363\n",
            "Epoch 38, Step 128, Loss: 0.5525805354118347\n",
            "Epoch 38, Step 129, Loss: 0.6354682445526123\n",
            "Epoch 38, Step 130, Loss: 0.7907226085662842\n",
            "Epoch 38, Step 131, Loss: 0.5399394035339355\n",
            "Epoch 38, Step 132, Loss: 0.6013624668121338\n",
            "Epoch 38, Step 133, Loss: 0.6643365025520325\n",
            "Epoch 38, Step 134, Loss: 0.8447110652923584\n",
            "Epoch 38, Step 135, Loss: 0.5682983994483948\n",
            "Epoch 38, Step 136, Loss: 0.4098860025405884\n",
            "Epoch 38, Step 137, Loss: 0.5230486392974854\n",
            "Epoch 38, Step 138, Loss: 0.41365742683410645\n",
            "Epoch 38, Step 139, Loss: 0.6289606690406799\n",
            "Epoch 38, Step 140, Loss: 0.5256458520889282\n",
            "Epoch 38, Step 141, Loss: 0.631807804107666\n",
            "Epoch 38, Step 142, Loss: 0.5431816577911377\n",
            "Epoch 38, Step 143, Loss: 0.6039866805076599\n",
            "Epoch 38, Step 144, Loss: 0.5064318776130676\n",
            "Epoch 38, Step 145, Loss: 0.7164521813392639\n",
            "Epoch 38, Step 146, Loss: 0.5182987451553345\n",
            "Epoch 38, Step 147, Loss: 0.4819672405719757\n",
            "Epoch 38, Step 148, Loss: 0.5902528166770935\n",
            "Epoch 38, Step 149, Loss: 0.4813959300518036\n",
            "Epoch 38, Step 150, Loss: 0.5844255089759827\n",
            "Epoch 38, Step 151, Loss: 0.4669850170612335\n",
            "Epoch 38, Step 152, Loss: 0.5419038534164429\n",
            "Epoch 38, Step 153, Loss: 0.5291922092437744\n",
            "Epoch 38, Step 154, Loss: 0.5032064318656921\n",
            "Epoch 38, Step 155, Loss: 0.5503872632980347\n",
            "Epoch 38, Step 156, Loss: 0.4938587546348572\n",
            "Epoch 38, Step 157, Loss: 0.5539135336875916\n",
            "Epoch 38, Step 158, Loss: 0.7871052622795105\n",
            "Epoch 38, Step 159, Loss: 0.4598861336708069\n",
            "Epoch 38, Step 160, Loss: 0.4876896142959595\n",
            "Epoch 38, Step 161, Loss: 0.5041645169258118\n",
            "Epoch 38, Step 162, Loss: 0.4373660683631897\n",
            "Epoch 38, Step 163, Loss: 0.6552562117576599\n",
            "Epoch 38, Step 164, Loss: 0.39855876564979553\n",
            "Epoch 38, Step 165, Loss: 0.5159825682640076\n",
            "Epoch 38, Step 166, Loss: 0.7322142124176025\n",
            "Epoch 38, Step 167, Loss: 0.5659164786338806\n",
            "Epoch 38, Step 168, Loss: 0.5945126414299011\n",
            "Epoch 38, Step 169, Loss: 0.5740570425987244\n",
            "Epoch 38, Step 170, Loss: 0.6786945462226868\n",
            "Epoch 38, Step 171, Loss: 0.4499521851539612\n",
            "Epoch 38, Step 172, Loss: 0.5804846286773682\n",
            "Epoch 38, Step 173, Loss: 0.6557013392448425\n",
            "Epoch 38, Step 174, Loss: 0.4201556146144867\n",
            "Epoch 38, Step 175, Loss: 0.46821796894073486\n",
            "Epoch 38, Step 176, Loss: 0.5582953095436096\n",
            "Epoch 38, Step 177, Loss: 0.4911177456378937\n",
            "Epoch 38, Step 178, Loss: 0.4440910220146179\n",
            "Epoch 38, Step 179, Loss: 0.5914671421051025\n",
            "Epoch 38, Step 180, Loss: 0.5537405610084534\n",
            "Epoch 38, Step 181, Loss: 0.7032880187034607\n",
            "Epoch 38, Step 182, Loss: 0.6092016100883484\n",
            "Epoch 38, Step 183, Loss: 0.5110710263252258\n",
            "Epoch 38, Step 184, Loss: 0.5298722982406616\n",
            "Epoch 38, Step 185, Loss: 0.4999809265136719\n",
            "Epoch 38, Step 186, Loss: 0.563869297504425\n",
            "Epoch 38, Step 187, Loss: 0.5486043691635132\n",
            "Epoch 38, Step 188, Loss: 0.49820423126220703\n",
            "Epoch 38, Step 189, Loss: 0.542536735534668\n",
            "Epoch 38, Step 190, Loss: 0.4207746386528015\n",
            "Epoch 38, Step 191, Loss: 0.6393696665763855\n",
            "Epoch 38, Step 192, Loss: 0.5238128900527954\n",
            "Epoch 38, Step 193, Loss: 0.5069016814231873\n",
            "Epoch 38, Step 194, Loss: 0.6301535367965698\n",
            "Epoch 38, Step 195, Loss: 0.47749850153923035\n",
            "Epoch 38, Step 196, Loss: 0.5363280177116394\n",
            "Epoch 38, Step 197, Loss: 0.6012036800384521\n",
            "Epoch 38, Step 198, Loss: 0.5688480734825134\n",
            "Epoch 38, Step 199, Loss: 0.5181061029434204\n",
            "Epoch 38, Step 200, Loss: 0.43280863761901855\n",
            "Epoch 38, Step 201, Loss: 0.7087568044662476\n",
            "Epoch 38, Step 202, Loss: 0.38537052273750305\n",
            "Epoch 38, Step 203, Loss: 0.6038779020309448\n",
            "Epoch 38, Step 204, Loss: 0.5165082216262817\n",
            "Epoch 38, Step 205, Loss: 0.3709799647331238\n",
            "Epoch 38, Step 206, Loss: 0.47649645805358887\n",
            "Epoch 38, Step 207, Loss: 0.613825798034668\n",
            "Epoch 38, Step 208, Loss: 0.6920605897903442\n",
            "Epoch 38, Step 209, Loss: 0.5646058320999146\n",
            "Epoch 38, Step 210, Loss: 0.4898684322834015\n",
            "Epoch 38, Step 211, Loss: 0.5426045656204224\n",
            "Epoch 38, Step 212, Loss: 0.4518231451511383\n",
            "Epoch 38, Step 213, Loss: 0.5492851138114929\n",
            "Epoch 38, Step 214, Loss: 0.585860550403595\n",
            "Epoch 38, Step 215, Loss: 0.5490196943283081\n",
            "Epoch 38, Step 216, Loss: 0.6262535452842712\n",
            "Epoch 38, Step 217, Loss: 0.361764520406723\n",
            "Epoch 38, Step 218, Loss: 0.5343594551086426\n",
            "Epoch 38, Step 219, Loss: 0.6245619058609009\n",
            "Epoch 38, Step 220, Loss: 0.47952550649642944\n",
            "Epoch 38, Step 221, Loss: 0.6121456027030945\n",
            "Epoch 38, Step 222, Loss: 0.4741929769515991\n",
            "Epoch 38, Step 223, Loss: 0.6893001794815063\n",
            "Epoch 38, Step 224, Loss: 0.4952389895915985\n",
            "Epoch 38, Step 225, Loss: 0.5136916637420654\n",
            "Epoch 38, Step 226, Loss: 0.5803432464599609\n",
            "Epoch 38, Step 227, Loss: 0.6206309795379639\n",
            "Epoch 38, Step 228, Loss: 0.5519542694091797\n",
            "Epoch 38, Step 229, Loss: 0.5548504590988159\n",
            "Epoch 38, Step 230, Loss: 0.40450218319892883\n",
            "Epoch 38, Step 231, Loss: 0.43640464544296265\n",
            "Epoch 38, Step 232, Loss: 0.5061553716659546\n",
            "Epoch 38, Step 233, Loss: 0.6107454895973206\n",
            "Epoch 38, Step 234, Loss: 0.4415336847305298\n",
            "Epoch 38, Step 235, Loss: 0.5974278450012207\n",
            "Epoch 38, Step 236, Loss: 0.5561534762382507\n",
            "Epoch 38, Step 237, Loss: 0.5708379745483398\n",
            "Epoch 38, Step 238, Loss: 0.587308943271637\n",
            "Epoch 38, Step 239, Loss: 0.5608764290809631\n",
            "Epoch 38, Step 240, Loss: 0.6283137798309326\n",
            "Epoch 38, Step 241, Loss: 0.5096923112869263\n",
            "Epoch 38, Step 242, Loss: 0.5688890814781189\n",
            "Epoch 38, Step 243, Loss: 0.4274232089519501\n",
            "Epoch 38, Step 244, Loss: 0.5316077470779419\n",
            "Epoch 38, Step 245, Loss: 0.4772604703903198\n",
            "Epoch 38, Step 246, Loss: 0.5124177932739258\n",
            "Epoch 38, Step 247, Loss: 0.5909256339073181\n",
            "Epoch 38, Step 248, Loss: 0.37604761123657227\n",
            "Epoch 38, Step 249, Loss: 0.5388500094413757\n",
            "Epoch 38, Step 250, Loss: 0.4398998022079468\n",
            "Epoch 38, Step 251, Loss: 0.47466760873794556\n",
            "Epoch 38, Step 252, Loss: 0.5526247024536133\n",
            "Epoch 38, Step 253, Loss: 0.45965486764907837\n",
            "Epoch 38, Step 254, Loss: 0.5583518743515015\n",
            "Epoch 38, Step 255, Loss: 0.4822175204753876\n",
            "Epoch 38, Step 256, Loss: 0.602370023727417\n",
            "Epoch 38, Step 257, Loss: 0.5914429426193237\n",
            "Epoch 38, Step 258, Loss: 0.5744614601135254\n",
            "Epoch 38, Step 259, Loss: 0.506247878074646\n",
            "Epoch 38, Step 260, Loss: 0.6106120944023132\n",
            "Epoch 38, Step 261, Loss: 0.48692992329597473\n",
            "Epoch 38, Step 262, Loss: 0.41536906361579895\n",
            "Epoch 38, Step 263, Loss: 0.5328958034515381\n",
            "Epoch 38, Step 264, Loss: 0.5666021704673767\n",
            "Epoch 38, Step 265, Loss: 0.6430442333221436\n",
            "Epoch 38, Step 266, Loss: 0.6246755123138428\n",
            "Epoch 38, Step 267, Loss: 0.6251401305198669\n",
            "Epoch 38, Step 268, Loss: 0.5087277889251709\n",
            "Epoch 38, Step 269, Loss: 0.6315827369689941\n",
            "Epoch 38, Step 270, Loss: 0.5656261444091797\n",
            "Epoch 38, Step 271, Loss: 0.6042608022689819\n",
            "Epoch 38, Step 272, Loss: 0.5813729763031006\n",
            "Epoch 38, Step 273, Loss: 0.5493802428245544\n",
            "Epoch 38, Step 274, Loss: 0.5176294445991516\n",
            "Epoch 38, Step 275, Loss: 0.5058996081352234\n",
            "Epoch 38, Step 276, Loss: 0.5784550905227661\n",
            "Epoch 38, Step 277, Loss: 0.578112781047821\n",
            "Epoch 38, Step 278, Loss: 0.46050339937210083\n",
            "Epoch 38, Step 279, Loss: 0.38187891244888306\n",
            "Epoch 38, Step 280, Loss: 0.3950381875038147\n",
            "Epoch 38, Step 281, Loss: 0.5472108125686646\n",
            "Epoch 38, Step 282, Loss: 0.5369287729263306\n",
            "Epoch 38, Step 283, Loss: 0.5631222128868103\n",
            "Epoch 38, Step 284, Loss: 0.5733357071876526\n",
            "Epoch 38, Step 285, Loss: 0.6336138844490051\n",
            "Epoch 38, Step 286, Loss: 0.5641382932662964\n",
            "Epoch 38, Step 287, Loss: 0.5717533230781555\n",
            "Epoch 38, Step 288, Loss: 0.5981708765029907\n",
            "Epoch 38, Step 289, Loss: 0.5670051574707031\n",
            "Epoch 38, Step 290, Loss: 0.6304362416267395\n",
            "Epoch 38, Step 291, Loss: 0.5863370299339294\n",
            "Epoch 38, Step 292, Loss: 0.43778467178344727\n",
            "Epoch 38, Step 293, Loss: 0.5888259410858154\n",
            "Epoch 38, Step 294, Loss: 0.6853005290031433\n",
            "Epoch 38, Step 295, Loss: 0.5206510424613953\n",
            "Epoch 38, Step 296, Loss: 0.6512805223464966\n",
            "Epoch 38, Step 297, Loss: 0.6114725470542908\n",
            "Epoch 38, Step 298, Loss: 0.481993705034256\n",
            "Epoch 38, Step 299, Loss: 0.5638636946678162\n",
            "Epoch 38, Step 300, Loss: 0.577580988407135\n",
            "Epoch 38, Step 301, Loss: 0.5990394353866577\n",
            "Epoch 38, Step 302, Loss: 0.6762734651565552\n",
            "Epoch 38, Step 303, Loss: 0.6463650465011597\n",
            "Epoch 38, Step 304, Loss: 0.5077645778656006\n",
            "Epoch 38, Step 305, Loss: 0.606422483921051\n",
            "Epoch 38, Step 306, Loss: 0.5328094363212585\n",
            "Epoch 38, Step 307, Loss: 0.5653756260871887\n",
            "Epoch 38, Step 308, Loss: 0.4145064949989319\n",
            "Epoch 38, Step 309, Loss: 0.41987326741218567\n",
            "Epoch 38, Step 310, Loss: 0.5395745038986206\n",
            "Epoch 38, Step 311, Loss: 0.5124671459197998\n",
            "Epoch 38, Step 312, Loss: 0.5776919722557068\n",
            "Epoch 38 end, avg train loss: 0.5454297234265568\n",
            "Epoch 38 end, avg val loss: 0.5816392713709723, accuracy: 79.69%\n",
            "Epoch 39, Step 0, Loss: 0.5223380327224731\n",
            "Epoch 39, Step 1, Loss: 0.5632129311561584\n",
            "Epoch 39, Step 2, Loss: 0.5265551805496216\n",
            "Epoch 39, Step 3, Loss: 0.5323101282119751\n",
            "Epoch 39, Step 4, Loss: 0.5928376913070679\n",
            "Epoch 39, Step 5, Loss: 0.5191010236740112\n",
            "Epoch 39, Step 6, Loss: 0.5018579363822937\n",
            "Epoch 39, Step 7, Loss: 0.6478095054626465\n",
            "Epoch 39, Step 8, Loss: 0.4750944972038269\n",
            "Epoch 39, Step 9, Loss: 0.684649646282196\n",
            "Epoch 39, Step 10, Loss: 0.5083408355712891\n",
            "Epoch 39, Step 11, Loss: 0.5843181610107422\n",
            "Epoch 39, Step 12, Loss: 0.4379064738750458\n",
            "Epoch 39, Step 13, Loss: 0.5424906015396118\n",
            "Epoch 39, Step 14, Loss: 0.5244994163513184\n",
            "Epoch 39, Step 15, Loss: 0.5232307314872742\n",
            "Epoch 39, Step 16, Loss: 0.518480122089386\n",
            "Epoch 39, Step 17, Loss: 0.5809577107429504\n",
            "Epoch 39, Step 18, Loss: 0.5273149609565735\n",
            "Epoch 39, Step 19, Loss: 0.4753241240978241\n",
            "Epoch 39, Step 20, Loss: 0.5905086994171143\n",
            "Epoch 39, Step 21, Loss: 0.4460335373878479\n",
            "Epoch 39, Step 22, Loss: 0.4825579524040222\n",
            "Epoch 39, Step 23, Loss: 0.5070770978927612\n",
            "Epoch 39, Step 24, Loss: 0.532734751701355\n",
            "Epoch 39, Step 25, Loss: 0.43666312098503113\n",
            "Epoch 39, Step 26, Loss: 0.4736398160457611\n",
            "Epoch 39, Step 27, Loss: 0.4284842908382416\n",
            "Epoch 39, Step 28, Loss: 0.38860487937927246\n",
            "Epoch 39, Step 29, Loss: 0.6159908771514893\n",
            "Epoch 39, Step 30, Loss: 0.6644538044929504\n",
            "Epoch 39, Step 31, Loss: 0.47023776173591614\n",
            "Epoch 39, Step 32, Loss: 0.605994701385498\n",
            "Epoch 39, Step 33, Loss: 0.4544343054294586\n",
            "Epoch 39, Step 34, Loss: 0.4920690655708313\n",
            "Epoch 39, Step 35, Loss: 0.4614209532737732\n",
            "Epoch 39, Step 36, Loss: 0.5188326239585876\n",
            "Epoch 39, Step 37, Loss: 0.5317266583442688\n",
            "Epoch 39, Step 38, Loss: 0.6060423254966736\n",
            "Epoch 39, Step 39, Loss: 0.37069085240364075\n",
            "Epoch 39, Step 40, Loss: 0.42120036482810974\n",
            "Epoch 39, Step 41, Loss: 0.5853601694107056\n",
            "Epoch 39, Step 42, Loss: 0.6628831028938293\n",
            "Epoch 39, Step 43, Loss: 0.4369715750217438\n",
            "Epoch 39, Step 44, Loss: 0.5210371017456055\n",
            "Epoch 39, Step 45, Loss: 0.4947514235973358\n",
            "Epoch 39, Step 46, Loss: 0.6115924715995789\n",
            "Epoch 39, Step 47, Loss: 0.4317825138568878\n",
            "Epoch 39, Step 48, Loss: 0.5200642347335815\n",
            "Epoch 39, Step 49, Loss: 0.5108793377876282\n",
            "Epoch 39, Step 50, Loss: 0.6860717535018921\n",
            "Epoch 39, Step 51, Loss: 0.651651918888092\n",
            "Epoch 39, Step 52, Loss: 0.6474276185035706\n",
            "Epoch 39, Step 53, Loss: 0.4773917496204376\n",
            "Epoch 39, Step 54, Loss: 0.6033846735954285\n",
            "Epoch 39, Step 55, Loss: 0.45613834261894226\n",
            "Epoch 39, Step 56, Loss: 0.5218290090560913\n",
            "Epoch 39, Step 57, Loss: 0.4400714039802551\n",
            "Epoch 39, Step 58, Loss: 0.5072055459022522\n",
            "Epoch 39, Step 59, Loss: 0.5833483338356018\n",
            "Epoch 39, Step 60, Loss: 0.5659434199333191\n",
            "Epoch 39, Step 61, Loss: 0.4288785457611084\n",
            "Epoch 39, Step 62, Loss: 0.5318601131439209\n",
            "Epoch 39, Step 63, Loss: 0.41857674717903137\n",
            "Epoch 39, Step 64, Loss: 0.539343535900116\n",
            "Epoch 39, Step 65, Loss: 0.6257234215736389\n",
            "Epoch 39, Step 66, Loss: 0.5512142181396484\n",
            "Epoch 39, Step 67, Loss: 0.5531420707702637\n",
            "Epoch 39, Step 68, Loss: 0.645492434501648\n",
            "Epoch 39, Step 69, Loss: 0.566232442855835\n",
            "Epoch 39, Step 70, Loss: 0.6360896229743958\n",
            "Epoch 39, Step 71, Loss: 0.6267775297164917\n",
            "Epoch 39, Step 72, Loss: 0.4120694100856781\n",
            "Epoch 39, Step 73, Loss: 0.5217793583869934\n",
            "Epoch 39, Step 74, Loss: 0.5637081861495972\n",
            "Epoch 39, Step 75, Loss: 0.4126845896244049\n",
            "Epoch 39, Step 76, Loss: 0.45922791957855225\n",
            "Epoch 39, Step 77, Loss: 0.5508137941360474\n",
            "Epoch 39, Step 78, Loss: 0.46624860167503357\n",
            "Epoch 39, Step 79, Loss: 0.5791526436805725\n",
            "Epoch 39, Step 80, Loss: 0.5886452198028564\n",
            "Epoch 39, Step 81, Loss: 0.4505217969417572\n",
            "Epoch 39, Step 82, Loss: 0.5563166737556458\n",
            "Epoch 39, Step 83, Loss: 0.4690822660923004\n",
            "Epoch 39, Step 84, Loss: 0.6064375042915344\n",
            "Epoch 39, Step 85, Loss: 0.626049816608429\n",
            "Epoch 39, Step 86, Loss: 0.5853419303894043\n",
            "Epoch 39, Step 87, Loss: 0.5214141607284546\n",
            "Epoch 39, Step 88, Loss: 0.5082813501358032\n",
            "Epoch 39, Step 89, Loss: 0.48561811447143555\n",
            "Epoch 39, Step 90, Loss: 0.5453655123710632\n",
            "Epoch 39, Step 91, Loss: 0.41880711913108826\n",
            "Epoch 39, Step 92, Loss: 0.5822195410728455\n",
            "Epoch 39, Step 93, Loss: 0.6547577977180481\n",
            "Epoch 39, Step 94, Loss: 0.4663081169128418\n",
            "Epoch 39, Step 95, Loss: 0.5503377318382263\n",
            "Epoch 39, Step 96, Loss: 0.550051748752594\n",
            "Epoch 39, Step 97, Loss: 0.6153526306152344\n",
            "Epoch 39, Step 98, Loss: 0.5427616834640503\n",
            "Epoch 39, Step 99, Loss: 0.50077223777771\n",
            "Epoch 39, Step 100, Loss: 0.5156145095825195\n",
            "Epoch 39, Step 101, Loss: 0.4759627878665924\n",
            "Epoch 39, Step 102, Loss: 0.5508819222450256\n",
            "Epoch 39, Step 103, Loss: 0.5819498896598816\n",
            "Epoch 39, Step 104, Loss: 0.40850433707237244\n",
            "Epoch 39, Step 105, Loss: 0.46579304337501526\n",
            "Epoch 39, Step 106, Loss: 0.5158445835113525\n",
            "Epoch 39, Step 107, Loss: 0.5558158159255981\n",
            "Epoch 39, Step 108, Loss: 0.45578905940055847\n",
            "Epoch 39, Step 109, Loss: 0.4677194654941559\n",
            "Epoch 39, Step 110, Loss: 0.6750801205635071\n",
            "Epoch 39, Step 111, Loss: 0.595548689365387\n",
            "Epoch 39, Step 112, Loss: 0.5385861992835999\n",
            "Epoch 39, Step 113, Loss: 0.5678032040596008\n",
            "Epoch 39, Step 114, Loss: 0.610868513584137\n",
            "Epoch 39, Step 115, Loss: 0.4050182104110718\n",
            "Epoch 39, Step 116, Loss: 0.4756384789943695\n",
            "Epoch 39, Step 117, Loss: 0.44883912801742554\n",
            "Epoch 39, Step 118, Loss: 0.5933910012245178\n",
            "Epoch 39, Step 119, Loss: 0.49199920892715454\n",
            "Epoch 39, Step 120, Loss: 0.7128122448921204\n",
            "Epoch 39, Step 121, Loss: 0.500082790851593\n",
            "Epoch 39, Step 122, Loss: 0.5383576154708862\n",
            "Epoch 39, Step 123, Loss: 0.652330219745636\n",
            "Epoch 39, Step 124, Loss: 0.49173951148986816\n",
            "Epoch 39, Step 125, Loss: 0.4052508771419525\n",
            "Epoch 39, Step 126, Loss: 0.5186043381690979\n",
            "Epoch 39, Step 127, Loss: 0.5655485987663269\n",
            "Epoch 39, Step 128, Loss: 0.5546426177024841\n",
            "Epoch 39, Step 129, Loss: 0.5366197228431702\n",
            "Epoch 39, Step 130, Loss: 0.5135802030563354\n",
            "Epoch 39, Step 131, Loss: 0.4428929388523102\n",
            "Epoch 39, Step 132, Loss: 0.4840219020843506\n",
            "Epoch 39, Step 133, Loss: 0.6063778400421143\n",
            "Epoch 39, Step 134, Loss: 0.5918412804603577\n",
            "Epoch 39, Step 135, Loss: 0.4426289200782776\n",
            "Epoch 39, Step 136, Loss: 0.543692409992218\n",
            "Epoch 39, Step 137, Loss: 0.5189394950866699\n",
            "Epoch 39, Step 138, Loss: 0.507464587688446\n",
            "Epoch 39, Step 139, Loss: 0.4982241988182068\n",
            "Epoch 39, Step 140, Loss: 0.5002192258834839\n",
            "Epoch 39, Step 141, Loss: 0.6283208131790161\n",
            "Epoch 39, Step 142, Loss: 0.5110042691230774\n",
            "Epoch 39, Step 143, Loss: 0.49605754017829895\n",
            "Epoch 39, Step 144, Loss: 0.5273962616920471\n",
            "Epoch 39, Step 145, Loss: 0.49888676404953003\n",
            "Epoch 39, Step 146, Loss: 0.5736088156700134\n",
            "Epoch 39, Step 147, Loss: 0.6037885546684265\n",
            "Epoch 39, Step 148, Loss: 0.7381473779678345\n",
            "Epoch 39, Step 149, Loss: 0.5205589532852173\n",
            "Epoch 39, Step 150, Loss: 0.4537147283554077\n",
            "Epoch 39, Step 151, Loss: 0.5853981375694275\n",
            "Epoch 39, Step 152, Loss: 0.5374101996421814\n",
            "Epoch 39, Step 153, Loss: 0.5717629194259644\n",
            "Epoch 39, Step 154, Loss: 0.48758769035339355\n",
            "Epoch 39, Step 155, Loss: 0.4419228434562683\n",
            "Epoch 39, Step 156, Loss: 0.6075385808944702\n",
            "Epoch 39, Step 157, Loss: 0.549125611782074\n",
            "Epoch 39, Step 158, Loss: 0.5571976900100708\n",
            "Epoch 39, Step 159, Loss: 0.4801620543003082\n",
            "Epoch 39, Step 160, Loss: 0.6063511967658997\n",
            "Epoch 39, Step 161, Loss: 0.4796321988105774\n",
            "Epoch 39, Step 162, Loss: 0.6226611733436584\n",
            "Epoch 39, Step 163, Loss: 0.5047632455825806\n",
            "Epoch 39, Step 164, Loss: 0.5651746988296509\n",
            "Epoch 39, Step 165, Loss: 0.5502150058746338\n",
            "Epoch 39, Step 166, Loss: 0.4844719171524048\n",
            "Epoch 39, Step 167, Loss: 0.6144542098045349\n",
            "Epoch 39, Step 168, Loss: 0.5694394707679749\n",
            "Epoch 39, Step 169, Loss: 0.5013042688369751\n",
            "Epoch 39, Step 170, Loss: 0.7041792273521423\n",
            "Epoch 39, Step 171, Loss: 0.7044080495834351\n",
            "Epoch 39, Step 172, Loss: 0.673209547996521\n",
            "Epoch 39, Step 173, Loss: 0.6416938900947571\n",
            "Epoch 39, Step 174, Loss: 0.4735492169857025\n",
            "Epoch 39, Step 175, Loss: 0.40001580119132996\n",
            "Epoch 39, Step 176, Loss: 0.40188783407211304\n",
            "Epoch 39, Step 177, Loss: 0.69050532579422\n",
            "Epoch 39, Step 178, Loss: 0.45894211530685425\n",
            "Epoch 39, Step 179, Loss: 0.5741759538650513\n",
            "Epoch 39, Step 180, Loss: 0.6665827631950378\n",
            "Epoch 39, Step 181, Loss: 0.505987286567688\n",
            "Epoch 39, Step 182, Loss: 0.4806479811668396\n",
            "Epoch 39, Step 183, Loss: 0.4167206585407257\n",
            "Epoch 39, Step 184, Loss: 0.5148669481277466\n",
            "Epoch 39, Step 185, Loss: 0.6396247744560242\n",
            "Epoch 39, Step 186, Loss: 0.6024723052978516\n",
            "Epoch 39, Step 187, Loss: 0.6156569123268127\n",
            "Epoch 39, Step 188, Loss: 0.6932592391967773\n",
            "Epoch 39, Step 189, Loss: 0.5602838397026062\n",
            "Epoch 39, Step 190, Loss: 0.5290804505348206\n",
            "Epoch 39, Step 191, Loss: 0.5362539887428284\n",
            "Epoch 39, Step 192, Loss: 0.3936474621295929\n",
            "Epoch 39, Step 193, Loss: 0.5095059275627136\n",
            "Epoch 39, Step 194, Loss: 0.6105071306228638\n",
            "Epoch 39, Step 195, Loss: 0.5487684607505798\n",
            "Epoch 39, Step 196, Loss: 0.5945380926132202\n",
            "Epoch 39, Step 197, Loss: 0.5781345367431641\n",
            "Epoch 39, Step 198, Loss: 0.42894190549850464\n",
            "Epoch 39, Step 199, Loss: 0.5764627456665039\n",
            "Epoch 39, Step 200, Loss: 0.5843206644058228\n",
            "Epoch 39, Step 201, Loss: 0.5540768504142761\n",
            "Epoch 39, Step 202, Loss: 0.48333969712257385\n",
            "Epoch 39, Step 203, Loss: 0.5316576957702637\n",
            "Epoch 39, Step 204, Loss: 0.666732132434845\n",
            "Epoch 39, Step 205, Loss: 0.5086677670478821\n",
            "Epoch 39, Step 206, Loss: 0.4594898521900177\n",
            "Epoch 39, Step 207, Loss: 0.5504791736602783\n",
            "Epoch 39, Step 208, Loss: 0.5782362222671509\n",
            "Epoch 39, Step 209, Loss: 0.4687662422657013\n",
            "Epoch 39, Step 210, Loss: 0.49237895011901855\n",
            "Epoch 39, Step 211, Loss: 0.5028638243675232\n",
            "Epoch 39, Step 212, Loss: 0.5502517223358154\n",
            "Epoch 39, Step 213, Loss: 0.44745370745658875\n",
            "Epoch 39, Step 214, Loss: 0.6067478656768799\n",
            "Epoch 39, Step 215, Loss: 0.5516228675842285\n",
            "Epoch 39, Step 216, Loss: 0.6184070706367493\n",
            "Epoch 39, Step 217, Loss: 0.5413275361061096\n",
            "Epoch 39, Step 218, Loss: 0.409513384103775\n",
            "Epoch 39, Step 219, Loss: 0.7046759128570557\n",
            "Epoch 39, Step 220, Loss: 0.619777500629425\n",
            "Epoch 39, Step 221, Loss: 0.5852237939834595\n",
            "Epoch 39, Step 222, Loss: 0.5666394829750061\n",
            "Epoch 39, Step 223, Loss: 0.4789665639400482\n",
            "Epoch 39, Step 224, Loss: 0.47430285811424255\n",
            "Epoch 39, Step 225, Loss: 0.647395133972168\n",
            "Epoch 39, Step 226, Loss: 0.5396463871002197\n",
            "Epoch 39, Step 227, Loss: 0.5444062352180481\n",
            "Epoch 39, Step 228, Loss: 0.609938383102417\n",
            "Epoch 39, Step 229, Loss: 0.5664255619049072\n",
            "Epoch 39, Step 230, Loss: 0.48589128255844116\n",
            "Epoch 39, Step 231, Loss: 0.47677820920944214\n",
            "Epoch 39, Step 232, Loss: 0.46330079436302185\n",
            "Epoch 39, Step 233, Loss: 0.5775826573371887\n",
            "Epoch 39, Step 234, Loss: 0.49835097789764404\n",
            "Epoch 39, Step 235, Loss: 0.643230140209198\n",
            "Epoch 39, Step 236, Loss: 0.5954816341400146\n",
            "Epoch 39, Step 237, Loss: 0.46518442034721375\n",
            "Epoch 39, Step 238, Loss: 0.6004863977432251\n",
            "Epoch 39, Step 239, Loss: 0.4889260232448578\n",
            "Epoch 39, Step 240, Loss: 0.5609992146492004\n",
            "Epoch 39, Step 241, Loss: 0.6419376730918884\n",
            "Epoch 39, Step 242, Loss: 0.5564936995506287\n",
            "Epoch 39, Step 243, Loss: 0.6007317304611206\n",
            "Epoch 39, Step 244, Loss: 0.5956276059150696\n",
            "Epoch 39, Step 245, Loss: 0.6926969885826111\n",
            "Epoch 39, Step 246, Loss: 0.5701401233673096\n",
            "Epoch 39, Step 247, Loss: 0.6082184910774231\n",
            "Epoch 39, Step 248, Loss: 0.6745713949203491\n",
            "Epoch 39, Step 249, Loss: 0.8053819537162781\n",
            "Epoch 39, Step 250, Loss: 0.5898633003234863\n",
            "Epoch 39, Step 251, Loss: 0.43966472148895264\n",
            "Epoch 39, Step 252, Loss: 0.4593854546546936\n",
            "Epoch 39, Step 253, Loss: 0.37134137749671936\n",
            "Epoch 39, Step 254, Loss: 0.5304709672927856\n",
            "Epoch 39, Step 255, Loss: 0.5564283132553101\n",
            "Epoch 39, Step 256, Loss: 0.6274201273918152\n",
            "Epoch 39, Step 257, Loss: 0.6696620583534241\n",
            "Epoch 39, Step 258, Loss: 0.502784013748169\n",
            "Epoch 39, Step 259, Loss: 0.5119092464447021\n",
            "Epoch 39, Step 260, Loss: 0.4790666699409485\n",
            "Epoch 39, Step 261, Loss: 0.5696863532066345\n",
            "Epoch 39, Step 262, Loss: 0.6007096767425537\n",
            "Epoch 39, Step 263, Loss: 0.6147920489311218\n",
            "Epoch 39, Step 264, Loss: 0.5676242113113403\n",
            "Epoch 39, Step 265, Loss: 0.47087517380714417\n",
            "Epoch 39, Step 266, Loss: 0.44977378845214844\n",
            "Epoch 39, Step 267, Loss: 0.41035372018814087\n",
            "Epoch 39, Step 268, Loss: 0.5499027371406555\n",
            "Epoch 39, Step 269, Loss: 0.3991425335407257\n",
            "Epoch 39, Step 270, Loss: 0.4034899175167084\n",
            "Epoch 39, Step 271, Loss: 0.4885498881340027\n",
            "Epoch 39, Step 272, Loss: 0.6577813625335693\n",
            "Epoch 39, Step 273, Loss: 0.49713924527168274\n",
            "Epoch 39, Step 274, Loss: 0.5472658276557922\n",
            "Epoch 39, Step 275, Loss: 0.6422306299209595\n",
            "Epoch 39, Step 276, Loss: 0.5409106016159058\n",
            "Epoch 39, Step 277, Loss: 0.415459543466568\n",
            "Epoch 39, Step 278, Loss: 0.5993413329124451\n",
            "Epoch 39, Step 279, Loss: 0.5626808404922485\n",
            "Epoch 39, Step 280, Loss: 0.470568984746933\n",
            "Epoch 39, Step 281, Loss: 0.42910799384117126\n",
            "Epoch 39, Step 282, Loss: 0.5354121327400208\n",
            "Epoch 39, Step 283, Loss: 0.5399380326271057\n",
            "Epoch 39, Step 284, Loss: 0.5042786002159119\n",
            "Epoch 39, Step 285, Loss: 0.5037176609039307\n",
            "Epoch 39, Step 286, Loss: 0.6118351817131042\n",
            "Epoch 39, Step 287, Loss: 0.5196853280067444\n",
            "Epoch 39, Step 288, Loss: 0.4813341200351715\n",
            "Epoch 39, Step 289, Loss: 0.5591498017311096\n",
            "Epoch 39, Step 290, Loss: 0.5163129568099976\n",
            "Epoch 39, Step 291, Loss: 0.5311752557754517\n",
            "Epoch 39, Step 292, Loss: 0.48218780755996704\n",
            "Epoch 39, Step 293, Loss: 0.5451815724372864\n",
            "Epoch 39, Step 294, Loss: 0.5626495480537415\n",
            "Epoch 39, Step 295, Loss: 0.5799344182014465\n",
            "Epoch 39, Step 296, Loss: 0.7470915913581848\n",
            "Epoch 39, Step 297, Loss: 0.4922851324081421\n",
            "Epoch 39, Step 298, Loss: 0.5320485234260559\n",
            "Epoch 39, Step 299, Loss: 0.6098796725273132\n",
            "Epoch 39, Step 300, Loss: 0.48006999492645264\n",
            "Epoch 39, Step 301, Loss: 0.6997136473655701\n",
            "Epoch 39, Step 302, Loss: 0.676715075969696\n",
            "Epoch 39, Step 303, Loss: 0.5276927351951599\n",
            "Epoch 39, Step 304, Loss: 0.5013766884803772\n",
            "Epoch 39, Step 305, Loss: 0.5565555095672607\n",
            "Epoch 39, Step 306, Loss: 0.6250787973403931\n",
            "Epoch 39, Step 307, Loss: 0.5530256628990173\n",
            "Epoch 39, Step 308, Loss: 0.5196869373321533\n",
            "Epoch 39, Step 309, Loss: 0.3897639811038971\n",
            "Epoch 39, Step 310, Loss: 0.586795449256897\n",
            "Epoch 39, Step 311, Loss: 0.3613731861114502\n",
            "Epoch 39, Step 312, Loss: 0.6192196607589722\n",
            "Epoch 39 end, avg train loss: 0.5394717221633314\n",
            "Epoch 39 end, avg val loss: 0.5846110280556015, accuracy: 79.53%\n",
            "Epoch 40, Step 0, Loss: 0.7379521727561951\n",
            "Epoch 40, Step 1, Loss: 0.48159730434417725\n",
            "Epoch 40, Step 2, Loss: 0.5471563935279846\n",
            "Epoch 40, Step 3, Loss: 0.5155701637268066\n",
            "Epoch 40, Step 4, Loss: 0.5005252361297607\n",
            "Epoch 40, Step 5, Loss: 0.44870954751968384\n",
            "Epoch 40, Step 6, Loss: 0.6991185545921326\n",
            "Epoch 40, Step 7, Loss: 0.5928195714950562\n",
            "Epoch 40, Step 8, Loss: 0.3842756450176239\n",
            "Epoch 40, Step 9, Loss: 0.4811250865459442\n",
            "Epoch 40, Step 10, Loss: 0.6067931652069092\n",
            "Epoch 40, Step 11, Loss: 0.44375112652778625\n",
            "Epoch 40, Step 12, Loss: 0.4932387173175812\n",
            "Epoch 40, Step 13, Loss: 0.535175085067749\n",
            "Epoch 40, Step 14, Loss: 0.4515165388584137\n",
            "Epoch 40, Step 15, Loss: 0.5311267375946045\n",
            "Epoch 40, Step 16, Loss: 0.5862593650817871\n",
            "Epoch 40, Step 17, Loss: 0.5705199241638184\n",
            "Epoch 40, Step 18, Loss: 0.5098532438278198\n",
            "Epoch 40, Step 19, Loss: 0.5351017117500305\n",
            "Epoch 40, Step 20, Loss: 0.42033275961875916\n",
            "Epoch 40, Step 21, Loss: 0.6632303595542908\n",
            "Epoch 40, Step 22, Loss: 0.722422182559967\n",
            "Epoch 40, Step 23, Loss: 0.4080731272697449\n",
            "Epoch 40, Step 24, Loss: 0.5428920388221741\n",
            "Epoch 40, Step 25, Loss: 0.479989618062973\n",
            "Epoch 40, Step 26, Loss: 0.5107696056365967\n",
            "Epoch 40, Step 27, Loss: 0.4877965450286865\n",
            "Epoch 40, Step 28, Loss: 0.4417184889316559\n",
            "Epoch 40, Step 29, Loss: 0.4880497455596924\n",
            "Epoch 40, Step 30, Loss: 0.43687430024147034\n",
            "Epoch 40, Step 31, Loss: 0.4587298631668091\n",
            "Epoch 40, Step 32, Loss: 0.6192156076431274\n",
            "Epoch 40, Step 33, Loss: 0.5708265900611877\n",
            "Epoch 40, Step 34, Loss: 0.6476742625236511\n",
            "Epoch 40, Step 35, Loss: 0.5007737278938293\n",
            "Epoch 40, Step 36, Loss: 0.5554317831993103\n",
            "Epoch 40, Step 37, Loss: 0.38108816742897034\n",
            "Epoch 40, Step 38, Loss: 0.5972243547439575\n",
            "Epoch 40, Step 39, Loss: 0.5479924082756042\n",
            "Epoch 40, Step 40, Loss: 0.5851895213127136\n",
            "Epoch 40, Step 41, Loss: 0.6540894508361816\n",
            "Epoch 40, Step 42, Loss: 0.6498169302940369\n",
            "Epoch 40, Step 43, Loss: 0.529270350933075\n",
            "Epoch 40, Step 44, Loss: 0.539476752281189\n",
            "Epoch 40, Step 45, Loss: 0.4922448396682739\n",
            "Epoch 40, Step 46, Loss: 0.4441283345222473\n",
            "Epoch 40, Step 47, Loss: 0.43130478262901306\n",
            "Epoch 40, Step 48, Loss: 0.49036991596221924\n",
            "Epoch 40, Step 49, Loss: 0.47274577617645264\n",
            "Epoch 40, Step 50, Loss: 0.5309640765190125\n",
            "Epoch 40, Step 51, Loss: 0.6195127367973328\n",
            "Epoch 40, Step 52, Loss: 0.3834255337715149\n",
            "Epoch 40, Step 53, Loss: 0.7553799748420715\n",
            "Epoch 40, Step 54, Loss: 0.7175429463386536\n",
            "Epoch 40, Step 55, Loss: 0.42138972878456116\n",
            "Epoch 40, Step 56, Loss: 0.5198874473571777\n",
            "Epoch 40, Step 57, Loss: 0.6291826963424683\n",
            "Epoch 40, Step 58, Loss: 0.5530198812484741\n",
            "Epoch 40, Step 59, Loss: 0.5783805847167969\n",
            "Epoch 40, Step 60, Loss: 0.5583776831626892\n",
            "Epoch 40, Step 61, Loss: 0.5733885765075684\n",
            "Epoch 40, Step 62, Loss: 0.5127938389778137\n",
            "Epoch 40, Step 63, Loss: 0.5117098689079285\n",
            "Epoch 40, Step 64, Loss: 0.48331648111343384\n",
            "Epoch 40, Step 65, Loss: 0.4971444606781006\n",
            "Epoch 40, Step 66, Loss: 0.5489788055419922\n",
            "Epoch 40, Step 67, Loss: 0.5599383115768433\n",
            "Epoch 40, Step 68, Loss: 0.4683692753314972\n",
            "Epoch 40, Step 69, Loss: 0.5230254530906677\n",
            "Epoch 40, Step 70, Loss: 0.7128982543945312\n",
            "Epoch 40, Step 71, Loss: 0.5989494919776917\n",
            "Epoch 40, Step 72, Loss: 0.6392437219619751\n",
            "Epoch 40, Step 73, Loss: 0.5695446133613586\n",
            "Epoch 40, Step 74, Loss: 0.639480471611023\n",
            "Epoch 40, Step 75, Loss: 0.43765130639076233\n",
            "Epoch 40, Step 76, Loss: 0.5269827246665955\n",
            "Epoch 40, Step 77, Loss: 0.5030849575996399\n",
            "Epoch 40, Step 78, Loss: 0.4079147279262543\n",
            "Epoch 40, Step 79, Loss: 0.562402606010437\n",
            "Epoch 40, Step 80, Loss: 0.40141212940216064\n",
            "Epoch 40, Step 81, Loss: 0.6026038527488708\n",
            "Epoch 40, Step 82, Loss: 0.45447832345962524\n",
            "Epoch 40, Step 83, Loss: 0.45426279306411743\n",
            "Epoch 40, Step 84, Loss: 0.6462947130203247\n",
            "Epoch 40, Step 85, Loss: 0.4111842215061188\n",
            "Epoch 40, Step 86, Loss: 0.4979341924190521\n",
            "Epoch 40, Step 87, Loss: 0.49221745133399963\n",
            "Epoch 40, Step 88, Loss: 0.5783584117889404\n",
            "Epoch 40, Step 89, Loss: 0.5363429188728333\n",
            "Epoch 40, Step 90, Loss: 0.5387794971466064\n",
            "Epoch 40, Step 91, Loss: 0.43193256855010986\n",
            "Epoch 40, Step 92, Loss: 0.6146728992462158\n",
            "Epoch 40, Step 93, Loss: 0.529509961605072\n",
            "Epoch 40, Step 94, Loss: 0.6287429332733154\n",
            "Epoch 40, Step 95, Loss: 0.5792272090911865\n",
            "Epoch 40, Step 96, Loss: 0.46408572793006897\n",
            "Epoch 40, Step 97, Loss: 0.48742297291755676\n",
            "Epoch 40, Step 98, Loss: 0.486815869808197\n",
            "Epoch 40, Step 99, Loss: 0.5799657106399536\n",
            "Epoch 40, Step 100, Loss: 0.48228877782821655\n",
            "Epoch 40, Step 101, Loss: 0.6201592087745667\n",
            "Epoch 40, Step 102, Loss: 0.392354279756546\n",
            "Epoch 40, Step 103, Loss: 0.47359809279441833\n",
            "Epoch 40, Step 104, Loss: 0.6788107752799988\n",
            "Epoch 40, Step 105, Loss: 0.5213221907615662\n",
            "Epoch 40, Step 106, Loss: 0.4039846658706665\n",
            "Epoch 40, Step 107, Loss: 0.43376386165618896\n",
            "Epoch 40, Step 108, Loss: 0.628912627696991\n",
            "Epoch 40, Step 109, Loss: 0.6070486307144165\n",
            "Epoch 40, Step 110, Loss: 0.643818199634552\n",
            "Epoch 40, Step 111, Loss: 0.6122538447380066\n",
            "Epoch 40, Step 112, Loss: 0.524961531162262\n",
            "Epoch 40, Step 113, Loss: 0.5111390352249146\n",
            "Epoch 40, Step 114, Loss: 0.4670692980289459\n",
            "Epoch 40, Step 115, Loss: 0.5226486921310425\n",
            "Epoch 40, Step 116, Loss: 0.7166731357574463\n",
            "Epoch 40, Step 117, Loss: 0.32754749059677124\n",
            "Epoch 40, Step 118, Loss: 0.556547224521637\n",
            "Epoch 40, Step 119, Loss: 0.4201424717903137\n",
            "Epoch 40, Step 120, Loss: 0.6436467170715332\n",
            "Epoch 40, Step 121, Loss: 0.4581470191478729\n",
            "Epoch 40, Step 122, Loss: 0.5116064548492432\n",
            "Epoch 40, Step 123, Loss: 0.4297298789024353\n",
            "Epoch 40, Step 124, Loss: 0.4527489244937897\n",
            "Epoch 40, Step 125, Loss: 0.6266568303108215\n",
            "Epoch 40, Step 126, Loss: 0.6146529316902161\n",
            "Epoch 40, Step 127, Loss: 0.5296802520751953\n",
            "Epoch 40, Step 128, Loss: 0.44871285557746887\n",
            "Epoch 40, Step 129, Loss: 0.472607284784317\n",
            "Epoch 40, Step 130, Loss: 0.5939264893531799\n",
            "Epoch 40, Step 131, Loss: 0.406451553106308\n",
            "Epoch 40, Step 132, Loss: 0.532386064529419\n",
            "Epoch 40, Step 133, Loss: 0.6263551712036133\n",
            "Epoch 40, Step 134, Loss: 0.5395618081092834\n",
            "Epoch 40, Step 135, Loss: 0.5786736011505127\n",
            "Epoch 40, Step 136, Loss: 0.6233299374580383\n",
            "Epoch 40, Step 137, Loss: 0.549575924873352\n",
            "Epoch 40, Step 138, Loss: 0.48789140582084656\n",
            "Epoch 40, Step 139, Loss: 0.4971940815448761\n",
            "Epoch 40, Step 140, Loss: 0.5770207643508911\n",
            "Epoch 40, Step 141, Loss: 0.5531630516052246\n",
            "Epoch 40, Step 142, Loss: 0.528127133846283\n",
            "Epoch 40, Step 143, Loss: 0.5052228569984436\n",
            "Epoch 40, Step 144, Loss: 0.6401172876358032\n",
            "Epoch 40, Step 145, Loss: 0.6401098370552063\n",
            "Epoch 40, Step 146, Loss: 0.5082903504371643\n",
            "Epoch 40, Step 147, Loss: 0.5449665784835815\n",
            "Epoch 40, Step 148, Loss: 0.6037597060203552\n",
            "Epoch 40, Step 149, Loss: 0.6774192452430725\n",
            "Epoch 40, Step 150, Loss: 0.6534047722816467\n",
            "Epoch 40, Step 151, Loss: 0.42955511808395386\n",
            "Epoch 40, Step 152, Loss: 0.41636937856674194\n",
            "Epoch 40, Step 153, Loss: 0.5757477283477783\n",
            "Epoch 40, Step 154, Loss: 0.6066716313362122\n",
            "Epoch 40, Step 155, Loss: 0.7520312666893005\n",
            "Epoch 40, Step 156, Loss: 0.42885997891426086\n",
            "Epoch 40, Step 157, Loss: 0.5598887205123901\n",
            "Epoch 40, Step 158, Loss: 0.5753783583641052\n",
            "Epoch 40, Step 159, Loss: 0.4926208555698395\n",
            "Epoch 40, Step 160, Loss: 0.5337003469467163\n",
            "Epoch 40, Step 161, Loss: 0.6152021288871765\n",
            "Epoch 40, Step 162, Loss: 0.5524852871894836\n",
            "Epoch 40, Step 163, Loss: 0.4449455738067627\n",
            "Epoch 40, Step 164, Loss: 0.6049069762229919\n",
            "Epoch 40, Step 165, Loss: 0.5615003108978271\n",
            "Epoch 40, Step 166, Loss: 0.5352288484573364\n",
            "Epoch 40, Step 167, Loss: 0.5637949705123901\n",
            "Epoch 40, Step 168, Loss: 0.5032522082328796\n",
            "Epoch 40, Step 169, Loss: 0.49514293670654297\n",
            "Epoch 40, Step 170, Loss: 0.4034131169319153\n",
            "Epoch 40, Step 171, Loss: 0.5011416673660278\n",
            "Epoch 40, Step 172, Loss: 0.4571816325187683\n",
            "Epoch 40, Step 173, Loss: 0.5066004991531372\n",
            "Epoch 40, Step 174, Loss: 0.5545873045921326\n",
            "Epoch 40, Step 175, Loss: 0.616679847240448\n",
            "Epoch 40, Step 176, Loss: 0.5459787845611572\n",
            "Epoch 40, Step 177, Loss: 0.4722316563129425\n",
            "Epoch 40, Step 178, Loss: 0.5925375819206238\n",
            "Epoch 40, Step 179, Loss: 0.6273413300514221\n",
            "Epoch 40, Step 180, Loss: 0.4749299883842468\n",
            "Epoch 40, Step 181, Loss: 0.4681893289089203\n",
            "Epoch 40, Step 182, Loss: 0.3992299735546112\n",
            "Epoch 40, Step 183, Loss: 0.5148652195930481\n",
            "Epoch 40, Step 184, Loss: 0.5187019109725952\n",
            "Epoch 40, Step 185, Loss: 0.46437951922416687\n",
            "Epoch 40, Step 186, Loss: 0.5864549875259399\n",
            "Epoch 40, Step 187, Loss: 0.5117719173431396\n",
            "Epoch 40, Step 188, Loss: 0.6616427898406982\n",
            "Epoch 40, Step 189, Loss: 0.5603692531585693\n",
            "Epoch 40, Step 190, Loss: 0.48838308453559875\n",
            "Epoch 40, Step 191, Loss: 0.5380548238754272\n",
            "Epoch 40, Step 192, Loss: 0.5134751200675964\n",
            "Epoch 40, Step 193, Loss: 0.3546595871448517\n",
            "Epoch 40, Step 194, Loss: 0.5273715853691101\n",
            "Epoch 40, Step 195, Loss: 0.4299750328063965\n",
            "Epoch 40, Step 196, Loss: 0.5305798053741455\n",
            "Epoch 40, Step 197, Loss: 0.4876077473163605\n",
            "Epoch 40, Step 198, Loss: 0.5759905576705933\n",
            "Epoch 40, Step 199, Loss: 0.44052112102508545\n",
            "Epoch 40, Step 200, Loss: 0.5526464581489563\n",
            "Epoch 40, Step 201, Loss: 0.5487180948257446\n",
            "Epoch 40, Step 202, Loss: 0.5532381534576416\n",
            "Epoch 40, Step 203, Loss: 0.5717616677284241\n",
            "Epoch 40, Step 204, Loss: 0.3766079843044281\n",
            "Epoch 40, Step 205, Loss: 0.6073921918869019\n",
            "Epoch 40, Step 206, Loss: 0.603249728679657\n",
            "Epoch 40, Step 207, Loss: 0.64864581823349\n",
            "Epoch 40, Step 208, Loss: 0.5381969213485718\n",
            "Epoch 40, Step 209, Loss: 0.6145206689834595\n",
            "Epoch 40, Step 210, Loss: 0.5215450525283813\n",
            "Epoch 40, Step 211, Loss: 0.5910739898681641\n",
            "Epoch 40, Step 212, Loss: 0.5146019458770752\n",
            "Epoch 40, Step 213, Loss: 0.4689376652240753\n",
            "Epoch 40, Step 214, Loss: 0.500840961933136\n",
            "Epoch 40, Step 215, Loss: 0.4554623067378998\n",
            "Epoch 40, Step 216, Loss: 0.6354737877845764\n",
            "Epoch 40, Step 217, Loss: 0.5544560551643372\n",
            "Epoch 40, Step 218, Loss: 0.4914623200893402\n",
            "Epoch 40, Step 219, Loss: 0.6525768041610718\n",
            "Epoch 40, Step 220, Loss: 0.533186674118042\n",
            "Epoch 40, Step 221, Loss: 0.5611203908920288\n",
            "Epoch 40, Step 222, Loss: 0.3644803762435913\n",
            "Epoch 40, Step 223, Loss: 0.5029304623603821\n",
            "Epoch 40, Step 224, Loss: 0.6041053533554077\n",
            "Epoch 40, Step 225, Loss: 0.5461083650588989\n",
            "Epoch 40, Step 226, Loss: 0.4461464285850525\n",
            "Epoch 40, Step 227, Loss: 0.397086501121521\n",
            "Epoch 40, Step 228, Loss: 0.4402153789997101\n",
            "Epoch 40, Step 229, Loss: 0.5865558385848999\n",
            "Epoch 40, Step 230, Loss: 0.4822532534599304\n",
            "Epoch 40, Step 231, Loss: 0.6243619322776794\n",
            "Epoch 40, Step 232, Loss: 0.5020743012428284\n",
            "Epoch 40, Step 233, Loss: 0.5741894245147705\n",
            "Epoch 40, Step 234, Loss: 0.5741950869560242\n",
            "Epoch 40, Step 235, Loss: 0.6563763618469238\n",
            "Epoch 40, Step 236, Loss: 0.7132658958435059\n",
            "Epoch 40, Step 237, Loss: 0.48048144578933716\n",
            "Epoch 40, Step 238, Loss: 0.5396133661270142\n",
            "Epoch 40, Step 239, Loss: 0.5543314218521118\n",
            "Epoch 40, Step 240, Loss: 0.5155081152915955\n",
            "Epoch 40, Step 241, Loss: 0.6407104730606079\n",
            "Epoch 40, Step 242, Loss: 0.5632687211036682\n",
            "Epoch 40, Step 243, Loss: 0.5804247260093689\n",
            "Epoch 40, Step 244, Loss: 0.5253534317016602\n",
            "Epoch 40, Step 245, Loss: 0.5264641642570496\n",
            "Epoch 40, Step 246, Loss: 0.5273821949958801\n",
            "Epoch 40, Step 247, Loss: 0.4436689019203186\n",
            "Epoch 40, Step 248, Loss: 0.6461209058761597\n",
            "Epoch 40, Step 249, Loss: 0.5662549734115601\n",
            "Epoch 40, Step 250, Loss: 0.43608126044273376\n",
            "Epoch 40, Step 251, Loss: 0.48715847730636597\n",
            "Epoch 40, Step 252, Loss: 0.6343062520027161\n",
            "Epoch 40, Step 253, Loss: 0.39387768507003784\n",
            "Epoch 40, Step 254, Loss: 0.5613909959793091\n",
            "Epoch 40, Step 255, Loss: 0.5615878105163574\n",
            "Epoch 40, Step 256, Loss: 0.6422845125198364\n",
            "Epoch 40, Step 257, Loss: 0.49363231658935547\n",
            "Epoch 40, Step 258, Loss: 0.5869125723838806\n",
            "Epoch 40, Step 259, Loss: 0.6404693126678467\n",
            "Epoch 40, Step 260, Loss: 0.6582013964653015\n",
            "Epoch 40, Step 261, Loss: 0.5114795565605164\n",
            "Epoch 40, Step 262, Loss: 0.5343625545501709\n",
            "Epoch 40, Step 263, Loss: 0.5751097798347473\n",
            "Epoch 40, Step 264, Loss: 0.56792813539505\n",
            "Epoch 40, Step 265, Loss: 0.5018331408500671\n",
            "Epoch 40, Step 266, Loss: 0.5507465600967407\n",
            "Epoch 40, Step 267, Loss: 0.6977705955505371\n",
            "Epoch 40, Step 268, Loss: 0.5342015027999878\n",
            "Epoch 40, Step 269, Loss: 0.5562158226966858\n",
            "Epoch 40, Step 270, Loss: 0.49305281043052673\n",
            "Epoch 40, Step 271, Loss: 0.5794808268547058\n",
            "Epoch 40, Step 272, Loss: 0.4809788465499878\n",
            "Epoch 40, Step 273, Loss: 0.5524959564208984\n",
            "Epoch 40, Step 274, Loss: 0.5178281664848328\n",
            "Epoch 40, Step 275, Loss: 0.5475451350212097\n",
            "Epoch 40, Step 276, Loss: 0.47364524006843567\n",
            "Epoch 40, Step 277, Loss: 0.6347214579582214\n",
            "Epoch 40, Step 278, Loss: 0.46377381682395935\n",
            "Epoch 40, Step 279, Loss: 0.5520553588867188\n",
            "Epoch 40, Step 280, Loss: 0.5794692039489746\n",
            "Epoch 40, Step 281, Loss: 0.4968235194683075\n",
            "Epoch 40, Step 282, Loss: 0.6352967023849487\n",
            "Epoch 40, Step 283, Loss: 0.4257052540779114\n",
            "Epoch 40, Step 284, Loss: 0.546360194683075\n",
            "Epoch 40, Step 285, Loss: 0.661040723323822\n",
            "Epoch 40, Step 286, Loss: 0.6420708298683167\n",
            "Epoch 40, Step 287, Loss: 0.5182147026062012\n",
            "Epoch 40, Step 288, Loss: 0.5569589138031006\n",
            "Epoch 40, Step 289, Loss: 0.5564812421798706\n",
            "Epoch 40, Step 290, Loss: 0.5227605700492859\n",
            "Epoch 40, Step 291, Loss: 0.39512503147125244\n",
            "Epoch 40, Step 292, Loss: 0.5483582019805908\n",
            "Epoch 40, Step 293, Loss: 0.669996440410614\n",
            "Epoch 40, Step 294, Loss: 0.5269159078598022\n",
            "Epoch 40, Step 295, Loss: 0.5177907347679138\n",
            "Epoch 40, Step 296, Loss: 0.4947342276573181\n",
            "Epoch 40, Step 297, Loss: 0.47642844915390015\n",
            "Epoch 40, Step 298, Loss: 0.549081027507782\n",
            "Epoch 40, Step 299, Loss: 0.6273293495178223\n",
            "Epoch 40, Step 300, Loss: 0.5252724289894104\n",
            "Epoch 40, Step 301, Loss: 0.42954766750335693\n",
            "Epoch 40, Step 302, Loss: 0.5903899669647217\n",
            "Epoch 40, Step 303, Loss: 0.45938441157341003\n",
            "Epoch 40, Step 304, Loss: 0.5300819277763367\n",
            "Epoch 40, Step 305, Loss: 0.4628787934780121\n",
            "Epoch 40, Step 306, Loss: 0.419062077999115\n",
            "Epoch 40, Step 307, Loss: 0.6113755702972412\n",
            "Epoch 40, Step 308, Loss: 0.5784668922424316\n",
            "Epoch 40, Step 309, Loss: 0.7731360197067261\n",
            "Epoch 40, Step 310, Loss: 0.515832781791687\n",
            "Epoch 40, Step 311, Loss: 0.4397820830345154\n",
            "Epoch 40, Step 312, Loss: 0.4652775824069977\n",
            "Epoch 40 end, avg train loss: 0.536557712493994\n",
            "Epoch 40 end, avg val loss: 0.5824458414240729, accuracy: 79.81%\n",
            "Epoch 41, Step 0, Loss: 0.4344140291213989\n",
            "Epoch 41, Step 1, Loss: 0.42592698335647583\n",
            "Epoch 41, Step 2, Loss: 0.5221423506736755\n",
            "Epoch 41, Step 3, Loss: 0.7305760383605957\n",
            "Epoch 41, Step 4, Loss: 0.6008412837982178\n",
            "Epoch 41, Step 5, Loss: 0.5972326993942261\n",
            "Epoch 41, Step 6, Loss: 0.39850375056266785\n",
            "Epoch 41, Step 7, Loss: 0.531570315361023\n",
            "Epoch 41, Step 8, Loss: 0.5244048237800598\n",
            "Epoch 41, Step 9, Loss: 0.5481569170951843\n",
            "Epoch 41, Step 10, Loss: 0.5361419916152954\n",
            "Epoch 41, Step 11, Loss: 0.5817678570747375\n",
            "Epoch 41, Step 12, Loss: 0.5606895685195923\n",
            "Epoch 41, Step 13, Loss: 0.626579999923706\n",
            "Epoch 41, Step 14, Loss: 0.4994168281555176\n",
            "Epoch 41, Step 15, Loss: 0.4978526532649994\n",
            "Epoch 41, Step 16, Loss: 0.4608250558376312\n",
            "Epoch 41, Step 17, Loss: 0.5668987035751343\n",
            "Epoch 41, Step 18, Loss: 0.4293210804462433\n",
            "Epoch 41, Step 19, Loss: 0.5355989933013916\n",
            "Epoch 41, Step 20, Loss: 0.3211694359779358\n",
            "Epoch 41, Step 21, Loss: 0.5524216294288635\n",
            "Epoch 41, Step 22, Loss: 0.47935041785240173\n",
            "Epoch 41, Step 23, Loss: 0.5882174372673035\n",
            "Epoch 41, Step 24, Loss: 0.5926823019981384\n",
            "Epoch 41, Step 25, Loss: 0.5287910103797913\n",
            "Epoch 41, Step 26, Loss: 0.5005596876144409\n",
            "Epoch 41, Step 27, Loss: 0.601047933101654\n",
            "Epoch 41, Step 28, Loss: 0.6002655029296875\n",
            "Epoch 41, Step 29, Loss: 0.5184316039085388\n",
            "Epoch 41, Step 30, Loss: 0.639532208442688\n",
            "Epoch 41, Step 31, Loss: 0.5877337455749512\n",
            "Epoch 41, Step 32, Loss: 0.5822269320487976\n",
            "Epoch 41, Step 33, Loss: 0.5241844654083252\n",
            "Epoch 41, Step 34, Loss: 0.46757784485816956\n",
            "Epoch 41, Step 35, Loss: 0.4899974465370178\n",
            "Epoch 41, Step 36, Loss: 0.6309067010879517\n",
            "Epoch 41, Step 37, Loss: 0.5094769597053528\n",
            "Epoch 41, Step 38, Loss: 0.30558690428733826\n",
            "Epoch 41, Step 39, Loss: 0.5399928092956543\n",
            "Epoch 41, Step 40, Loss: 0.5629769563674927\n",
            "Epoch 41, Step 41, Loss: 0.5276463031768799\n",
            "Epoch 41, Step 42, Loss: 0.63140869140625\n",
            "Epoch 41, Step 43, Loss: 0.6599650979042053\n",
            "Epoch 41, Step 44, Loss: 0.5427320003509521\n",
            "Epoch 41, Step 45, Loss: 0.3899949789047241\n",
            "Epoch 41, Step 46, Loss: 0.433177649974823\n",
            "Epoch 41, Step 47, Loss: 0.5793219208717346\n",
            "Epoch 41, Step 48, Loss: 0.5529394149780273\n",
            "Epoch 41, Step 49, Loss: 0.4126964211463928\n",
            "Epoch 41, Step 50, Loss: 0.4767926335334778\n",
            "Epoch 41, Step 51, Loss: 0.5147533416748047\n",
            "Epoch 41, Step 52, Loss: 0.4147663116455078\n",
            "Epoch 41, Step 53, Loss: 0.60821932554245\n",
            "Epoch 41, Step 54, Loss: 0.49913451075553894\n",
            "Epoch 41, Step 55, Loss: 0.5110820531845093\n",
            "Epoch 41, Step 56, Loss: 0.5114941596984863\n",
            "Epoch 41, Step 57, Loss: 0.5858871936798096\n",
            "Epoch 41, Step 58, Loss: 0.6406920552253723\n",
            "Epoch 41, Step 59, Loss: 0.47525733709335327\n",
            "Epoch 41, Step 60, Loss: 0.49251803755760193\n",
            "Epoch 41, Step 61, Loss: 0.5407654047012329\n",
            "Epoch 41, Step 62, Loss: 0.4515659511089325\n",
            "Epoch 41, Step 63, Loss: 0.6190997958183289\n",
            "Epoch 41, Step 64, Loss: 0.4515976309776306\n",
            "Epoch 41, Step 65, Loss: 0.5553581714630127\n",
            "Epoch 41, Step 66, Loss: 0.6191191077232361\n",
            "Epoch 41, Step 67, Loss: 0.46157169342041016\n",
            "Epoch 41, Step 68, Loss: 0.5071926116943359\n",
            "Epoch 41, Step 69, Loss: 0.6521216034889221\n",
            "Epoch 41, Step 70, Loss: 0.5015692114830017\n",
            "Epoch 41, Step 71, Loss: 0.5834231972694397\n",
            "Epoch 41, Step 72, Loss: 0.4875006675720215\n",
            "Epoch 41, Step 73, Loss: 0.578162431716919\n",
            "Epoch 41, Step 74, Loss: 0.5214259028434753\n",
            "Epoch 41, Step 75, Loss: 0.38696175813674927\n",
            "Epoch 41, Step 76, Loss: 0.4150245487689972\n",
            "Epoch 41, Step 77, Loss: 0.5535030364990234\n",
            "Epoch 41, Step 78, Loss: 0.5355415344238281\n",
            "Epoch 41, Step 79, Loss: 0.5335278511047363\n",
            "Epoch 41, Step 80, Loss: 0.4975120723247528\n",
            "Epoch 41, Step 81, Loss: 0.525148332118988\n",
            "Epoch 41, Step 82, Loss: 0.6733125448226929\n",
            "Epoch 41, Step 83, Loss: 0.6445334553718567\n",
            "Epoch 41, Step 84, Loss: 0.5456221103668213\n",
            "Epoch 41, Step 85, Loss: 0.49438950419425964\n",
            "Epoch 41, Step 86, Loss: 0.5484313368797302\n",
            "Epoch 41, Step 87, Loss: 0.4811646342277527\n",
            "Epoch 41, Step 88, Loss: 0.41149836778640747\n",
            "Epoch 41, Step 89, Loss: 0.41378918290138245\n",
            "Epoch 41, Step 90, Loss: 0.37770020961761475\n",
            "Epoch 41, Step 91, Loss: 0.45876508951187134\n",
            "Epoch 41, Step 92, Loss: 0.5941153764724731\n",
            "Epoch 41, Step 93, Loss: 0.5048962831497192\n",
            "Epoch 41, Step 94, Loss: 0.5742741227149963\n",
            "Epoch 41, Step 95, Loss: 0.6362737417221069\n",
            "Epoch 41, Step 96, Loss: 0.5464939475059509\n",
            "Epoch 41, Step 97, Loss: 0.5618346333503723\n",
            "Epoch 41, Step 98, Loss: 0.46867528557777405\n",
            "Epoch 41, Step 99, Loss: 0.6074873208999634\n",
            "Epoch 41, Step 100, Loss: 0.3758041560649872\n",
            "Epoch 41, Step 101, Loss: 0.43504345417022705\n",
            "Epoch 41, Step 102, Loss: 0.5346806049346924\n",
            "Epoch 41, Step 103, Loss: 0.4442918002605438\n",
            "Epoch 41, Step 104, Loss: 0.3440570533275604\n",
            "Epoch 41, Step 105, Loss: 0.6042780876159668\n",
            "Epoch 41, Step 106, Loss: 0.5685550570487976\n",
            "Epoch 41, Step 107, Loss: 0.5486663579940796\n",
            "Epoch 41, Step 108, Loss: 0.5206651091575623\n",
            "Epoch 41, Step 109, Loss: 0.6289783120155334\n",
            "Epoch 41, Step 110, Loss: 0.4771149158477783\n",
            "Epoch 41, Step 111, Loss: 0.520682692527771\n",
            "Epoch 41, Step 112, Loss: 0.456076979637146\n",
            "Epoch 41, Step 113, Loss: 0.5463029146194458\n",
            "Epoch 41, Step 114, Loss: 0.42421308159828186\n",
            "Epoch 41, Step 115, Loss: 0.6016072034835815\n",
            "Epoch 41, Step 116, Loss: 0.5751104354858398\n",
            "Epoch 41, Step 117, Loss: 0.48949772119522095\n",
            "Epoch 41, Step 118, Loss: 0.5601242780685425\n",
            "Epoch 41, Step 119, Loss: 0.6101199984550476\n",
            "Epoch 41, Step 120, Loss: 0.5572173595428467\n",
            "Epoch 41, Step 121, Loss: 0.46022289991378784\n",
            "Epoch 41, Step 122, Loss: 0.5470250844955444\n",
            "Epoch 41, Step 123, Loss: 0.5424456596374512\n",
            "Epoch 41, Step 124, Loss: 0.5789147615432739\n",
            "Epoch 41, Step 125, Loss: 0.48730209469795227\n",
            "Epoch 41, Step 126, Loss: 0.5437837243080139\n",
            "Epoch 41, Step 127, Loss: 0.5164026618003845\n",
            "Epoch 41, Step 128, Loss: 0.5372780561447144\n",
            "Epoch 41, Step 129, Loss: 0.47407257556915283\n",
            "Epoch 41, Step 130, Loss: 0.4845406115055084\n",
            "Epoch 41, Step 131, Loss: 0.6219102740287781\n",
            "Epoch 41, Step 132, Loss: 0.5651717185974121\n",
            "Epoch 41, Step 133, Loss: 0.5734564065933228\n",
            "Epoch 41, Step 134, Loss: 0.6485880613327026\n",
            "Epoch 41, Step 135, Loss: 0.5753636360168457\n",
            "Epoch 41, Step 136, Loss: 0.41755610704421997\n",
            "Epoch 41, Step 137, Loss: 0.6806927919387817\n",
            "Epoch 41, Step 138, Loss: 0.5718487501144409\n",
            "Epoch 41, Step 139, Loss: 0.6380548477172852\n",
            "Epoch 41, Step 140, Loss: 0.550758421421051\n",
            "Epoch 41, Step 141, Loss: 0.49001994729042053\n",
            "Epoch 41, Step 142, Loss: 0.41325393319129944\n",
            "Epoch 41, Step 143, Loss: 0.5479723811149597\n",
            "Epoch 41, Step 144, Loss: 0.5014818906784058\n",
            "Epoch 41, Step 145, Loss: 0.6109839081764221\n",
            "Epoch 41, Step 146, Loss: 0.6810904741287231\n",
            "Epoch 41, Step 147, Loss: 0.6144338250160217\n",
            "Epoch 41, Step 148, Loss: 0.5066182017326355\n",
            "Epoch 41, Step 149, Loss: 0.45976606011390686\n",
            "Epoch 41, Step 150, Loss: 0.5438003540039062\n",
            "Epoch 41, Step 151, Loss: 0.6002289652824402\n",
            "Epoch 41, Step 152, Loss: 0.44610366225242615\n",
            "Epoch 41, Step 153, Loss: 0.6526777148246765\n",
            "Epoch 41, Step 154, Loss: 0.46042415499687195\n",
            "Epoch 41, Step 155, Loss: 0.4501546323299408\n",
            "Epoch 41, Step 156, Loss: 0.40574905276298523\n",
            "Epoch 41, Step 157, Loss: 0.47851628065109253\n",
            "Epoch 41, Step 158, Loss: 0.6628172397613525\n",
            "Epoch 41, Step 159, Loss: 0.42965954542160034\n",
            "Epoch 41, Step 160, Loss: 0.4856463074684143\n",
            "Epoch 41, Step 161, Loss: 0.43523257970809937\n",
            "Epoch 41, Step 162, Loss: 0.5503378510475159\n",
            "Epoch 41, Step 163, Loss: 0.5141574144363403\n",
            "Epoch 41, Step 164, Loss: 0.4472939968109131\n",
            "Epoch 41, Step 165, Loss: 0.5078548192977905\n",
            "Epoch 41, Step 166, Loss: 0.4389917254447937\n",
            "Epoch 41, Step 167, Loss: 0.6001920700073242\n",
            "Epoch 41, Step 168, Loss: 0.6082955002784729\n",
            "Epoch 41, Step 169, Loss: 0.5662873387336731\n",
            "Epoch 41, Step 170, Loss: 0.48192694783210754\n",
            "Epoch 41, Step 171, Loss: 0.6320104598999023\n",
            "Epoch 41, Step 172, Loss: 0.3612436354160309\n",
            "Epoch 41, Step 173, Loss: 0.6201573014259338\n",
            "Epoch 41, Step 174, Loss: 0.44164153933525085\n",
            "Epoch 41, Step 175, Loss: 0.4955396056175232\n",
            "Epoch 41, Step 176, Loss: 0.5281863212585449\n",
            "Epoch 41, Step 177, Loss: 0.4902971684932709\n",
            "Epoch 41, Step 178, Loss: 0.540818452835083\n",
            "Epoch 41, Step 179, Loss: 0.5697202086448669\n",
            "Epoch 41, Step 180, Loss: 0.5671951174736023\n",
            "Epoch 41, Step 181, Loss: 0.3753674030303955\n",
            "Epoch 41, Step 182, Loss: 0.48054513335227966\n",
            "Epoch 41, Step 183, Loss: 0.5540934801101685\n",
            "Epoch 41, Step 184, Loss: 0.578149139881134\n",
            "Epoch 41, Step 185, Loss: 0.6587545275688171\n",
            "Epoch 41, Step 186, Loss: 0.5068221688270569\n",
            "Epoch 41, Step 187, Loss: 0.43216320872306824\n",
            "Epoch 41, Step 188, Loss: 0.6641753911972046\n",
            "Epoch 41, Step 189, Loss: 0.6361592411994934\n",
            "Epoch 41, Step 190, Loss: 0.6348248720169067\n",
            "Epoch 41, Step 191, Loss: 0.5271408557891846\n",
            "Epoch 41, Step 192, Loss: 0.3955831825733185\n",
            "Epoch 41, Step 193, Loss: 0.44447413086891174\n",
            "Epoch 41, Step 194, Loss: 0.5025792121887207\n",
            "Epoch 41, Step 195, Loss: 0.4434973895549774\n",
            "Epoch 41, Step 196, Loss: 0.48968228697776794\n",
            "Epoch 41, Step 197, Loss: 0.42006629705429077\n",
            "Epoch 41, Step 198, Loss: 0.5353386402130127\n",
            "Epoch 41, Step 199, Loss: 0.3640480935573578\n",
            "Epoch 41, Step 200, Loss: 0.5099341869354248\n",
            "Epoch 41, Step 201, Loss: 0.5941465497016907\n",
            "Epoch 41, Step 202, Loss: 0.5468594431877136\n",
            "Epoch 41, Step 203, Loss: 0.577480673789978\n",
            "Epoch 41, Step 204, Loss: 0.5837482213973999\n",
            "Epoch 41, Step 205, Loss: 0.46177810430526733\n",
            "Epoch 41, Step 206, Loss: 0.48911431431770325\n",
            "Epoch 41, Step 207, Loss: 0.5480560660362244\n",
            "Epoch 41, Step 208, Loss: 0.5901850461959839\n",
            "Epoch 41, Step 209, Loss: 0.5991753339767456\n",
            "Epoch 41, Step 210, Loss: 0.3970683813095093\n",
            "Epoch 41, Step 211, Loss: 0.6156787872314453\n",
            "Epoch 41, Step 212, Loss: 0.47346946597099304\n",
            "Epoch 41, Step 213, Loss: 0.5779967904090881\n",
            "Epoch 41, Step 214, Loss: 0.5154192447662354\n",
            "Epoch 41, Step 215, Loss: 0.6280516386032104\n",
            "Epoch 41, Step 216, Loss: 0.49718570709228516\n",
            "Epoch 41, Step 217, Loss: 0.4982534945011139\n",
            "Epoch 41, Step 218, Loss: 0.5903528332710266\n",
            "Epoch 41, Step 219, Loss: 0.5152801871299744\n",
            "Epoch 41, Step 220, Loss: 0.6193581819534302\n",
            "Epoch 41, Step 221, Loss: 0.4395763576030731\n",
            "Epoch 41, Step 222, Loss: 0.5856529474258423\n",
            "Epoch 41, Step 223, Loss: 0.5347971320152283\n",
            "Epoch 41, Step 224, Loss: 0.47586789727211\n",
            "Epoch 41, Step 225, Loss: 0.535711944103241\n",
            "Epoch 41, Step 226, Loss: 0.6494972109794617\n",
            "Epoch 41, Step 227, Loss: 0.5841303467750549\n",
            "Epoch 41, Step 228, Loss: 0.6111772060394287\n",
            "Epoch 41, Step 229, Loss: 0.5279362797737122\n",
            "Epoch 41, Step 230, Loss: 0.49954599142074585\n",
            "Epoch 41, Step 231, Loss: 0.573861300945282\n",
            "Epoch 41, Step 232, Loss: 0.5137870907783508\n",
            "Epoch 41, Step 233, Loss: 0.5174896121025085\n",
            "Epoch 41, Step 234, Loss: 0.5665721297264099\n",
            "Epoch 41, Step 235, Loss: 0.4862658679485321\n",
            "Epoch 41, Step 236, Loss: 0.5921544432640076\n",
            "Epoch 41, Step 237, Loss: 0.4788946509361267\n",
            "Epoch 41, Step 238, Loss: 0.4427153468132019\n",
            "Epoch 41, Step 239, Loss: 0.3880169987678528\n",
            "Epoch 41, Step 240, Loss: 0.5016036629676819\n",
            "Epoch 41, Step 241, Loss: 0.370788037776947\n",
            "Epoch 41, Step 242, Loss: 0.4966695010662079\n",
            "Epoch 41, Step 243, Loss: 0.4997345209121704\n",
            "Epoch 41, Step 244, Loss: 0.6786081194877625\n",
            "Epoch 41, Step 245, Loss: 0.587006151676178\n",
            "Epoch 41, Step 246, Loss: 0.47646409273147583\n",
            "Epoch 41, Step 247, Loss: 0.5640104413032532\n",
            "Epoch 41, Step 248, Loss: 0.5394904017448425\n",
            "Epoch 41, Step 249, Loss: 0.4787501394748688\n",
            "Epoch 41, Step 250, Loss: 0.4827733039855957\n",
            "Epoch 41, Step 251, Loss: 0.43330657482147217\n",
            "Epoch 41, Step 252, Loss: 0.4316556751728058\n",
            "Epoch 41, Step 253, Loss: 0.5257054567337036\n",
            "Epoch 41, Step 254, Loss: 0.6483838558197021\n",
            "Epoch 41, Step 255, Loss: 0.4379802346229553\n",
            "Epoch 41, Step 256, Loss: 0.5263673663139343\n",
            "Epoch 41, Step 257, Loss: 0.5422408580780029\n",
            "Epoch 41, Step 258, Loss: 0.610378623008728\n",
            "Epoch 41, Step 259, Loss: 0.5727499723434448\n",
            "Epoch 41, Step 260, Loss: 0.7579673528671265\n",
            "Epoch 41, Step 261, Loss: 0.4126766622066498\n",
            "Epoch 41, Step 262, Loss: 0.513191282749176\n",
            "Epoch 41, Step 263, Loss: 0.44877225160598755\n",
            "Epoch 41, Step 264, Loss: 0.49165794253349304\n",
            "Epoch 41, Step 265, Loss: 0.5050687789916992\n",
            "Epoch 41, Step 266, Loss: 0.5164393186569214\n",
            "Epoch 41, Step 267, Loss: 0.6429674625396729\n",
            "Epoch 41, Step 268, Loss: 0.4401857852935791\n",
            "Epoch 41, Step 269, Loss: 0.5292642116546631\n",
            "Epoch 41, Step 270, Loss: 0.6093183159828186\n",
            "Epoch 41, Step 271, Loss: 0.7525249719619751\n",
            "Epoch 41, Step 272, Loss: 0.48350316286087036\n",
            "Epoch 41, Step 273, Loss: 0.38016048073768616\n",
            "Epoch 41, Step 274, Loss: 0.5442638993263245\n",
            "Epoch 41, Step 275, Loss: 0.5259371399879456\n",
            "Epoch 41, Step 276, Loss: 0.5738109350204468\n",
            "Epoch 41, Step 277, Loss: 0.5516881346702576\n",
            "Epoch 41, Step 278, Loss: 0.5434386134147644\n",
            "Epoch 41, Step 279, Loss: 0.49038079380989075\n",
            "Epoch 41, Step 280, Loss: 0.48599523305892944\n",
            "Epoch 41, Step 281, Loss: 0.5852019190788269\n",
            "Epoch 41, Step 282, Loss: 0.45899373292922974\n",
            "Epoch 41, Step 283, Loss: 0.6533757448196411\n",
            "Epoch 41, Step 284, Loss: 0.6201865077018738\n",
            "Epoch 41, Step 285, Loss: 0.530288815498352\n",
            "Epoch 41, Step 286, Loss: 0.6070573329925537\n",
            "Epoch 41, Step 287, Loss: 0.5821961760520935\n",
            "Epoch 41, Step 288, Loss: 0.6303133368492126\n",
            "Epoch 41, Step 289, Loss: 0.6683939695358276\n",
            "Epoch 41, Step 290, Loss: 0.5149481892585754\n",
            "Epoch 41, Step 291, Loss: 0.4007301330566406\n",
            "Epoch 41, Step 292, Loss: 0.5800236463546753\n",
            "Epoch 41, Step 293, Loss: 0.5815356373786926\n",
            "Epoch 41, Step 294, Loss: 0.6070711016654968\n",
            "Epoch 41, Step 295, Loss: 0.4508315920829773\n",
            "Epoch 41, Step 296, Loss: 0.3487623333930969\n",
            "Epoch 41, Step 297, Loss: 0.6513056755065918\n",
            "Epoch 41, Step 298, Loss: 0.4867108464241028\n",
            "Epoch 41, Step 299, Loss: 0.5425311326980591\n",
            "Epoch 41, Step 300, Loss: 0.38922151923179626\n",
            "Epoch 41, Step 301, Loss: 0.4498840570449829\n",
            "Epoch 41, Step 302, Loss: 0.47894835472106934\n",
            "Epoch 41, Step 303, Loss: 0.5547345280647278\n",
            "Epoch 41, Step 304, Loss: 0.5414885878562927\n",
            "Epoch 41, Step 305, Loss: 0.6015571355819702\n",
            "Epoch 41, Step 306, Loss: 0.7224631905555725\n",
            "Epoch 41, Step 307, Loss: 0.6629661321640015\n",
            "Epoch 41, Step 308, Loss: 0.4700411260128021\n",
            "Epoch 41, Step 309, Loss: 0.5327284336090088\n",
            "Epoch 41, Step 310, Loss: 0.3807465434074402\n",
            "Epoch 41, Step 311, Loss: 0.4825372099876404\n",
            "Epoch 41, Step 312, Loss: 0.7436990737915039\n",
            "Epoch 41 end, avg train loss: 0.5290151366029685\n",
            "Epoch 41 end, avg val loss: 0.5936129994784729, accuracy: 79.15%\n",
            "Checkpoint saved: IPS_41.pth\n",
            "Epoch 42, Step 0, Loss: 0.3894912004470825\n",
            "Epoch 42, Step 1, Loss: 0.4433397650718689\n",
            "Epoch 42, Step 2, Loss: 0.6456362009048462\n",
            "Epoch 42, Step 3, Loss: 0.5882638096809387\n",
            "Epoch 42, Step 4, Loss: 0.5370814800262451\n",
            "Epoch 42, Step 5, Loss: 0.469281405210495\n",
            "Epoch 42, Step 6, Loss: 0.49702951312065125\n",
            "Epoch 42, Step 7, Loss: 0.5231018662452698\n",
            "Epoch 42, Step 8, Loss: 0.5689770579338074\n",
            "Epoch 42, Step 9, Loss: 0.6008875370025635\n",
            "Epoch 42, Step 10, Loss: 0.5536868572235107\n",
            "Epoch 42, Step 11, Loss: 0.4880966246128082\n",
            "Epoch 42, Step 12, Loss: 0.7795747518539429\n",
            "Epoch 42, Step 13, Loss: 0.6071505546569824\n",
            "Epoch 42, Step 14, Loss: 0.5169274210929871\n",
            "Epoch 42, Step 15, Loss: 0.43300825357437134\n",
            "Epoch 42, Step 16, Loss: 0.4503616392612457\n",
            "Epoch 42, Step 17, Loss: 0.4499610960483551\n",
            "Epoch 42, Step 18, Loss: 0.5000917315483093\n",
            "Epoch 42, Step 19, Loss: 0.5645533800125122\n",
            "Epoch 42, Step 20, Loss: 0.4884732961654663\n",
            "Epoch 42, Step 21, Loss: 0.43591269850730896\n",
            "Epoch 42, Step 22, Loss: 0.5761489868164062\n",
            "Epoch 42, Step 23, Loss: 0.4925701320171356\n",
            "Epoch 42, Step 24, Loss: 0.6155643463134766\n",
            "Epoch 42, Step 25, Loss: 0.5122076869010925\n",
            "Epoch 42, Step 26, Loss: 0.3939903676509857\n",
            "Epoch 42, Step 27, Loss: 0.4405217468738556\n",
            "Epoch 42, Step 28, Loss: 0.6398934721946716\n",
            "Epoch 42, Step 29, Loss: 0.6042577028274536\n",
            "Epoch 42, Step 30, Loss: 0.48304545879364014\n",
            "Epoch 42, Step 31, Loss: 0.4712230861186981\n",
            "Epoch 42, Step 32, Loss: 0.6264211535453796\n",
            "Epoch 42, Step 33, Loss: 0.5099535584449768\n",
            "Epoch 42, Step 34, Loss: 0.5033292770385742\n",
            "Epoch 42, Step 35, Loss: 0.4761870503425598\n",
            "Epoch 42, Step 36, Loss: 0.4421062767505646\n",
            "Epoch 42, Step 37, Loss: 0.5032890439033508\n",
            "Epoch 42, Step 38, Loss: 0.47479644417762756\n",
            "Epoch 42, Step 39, Loss: 0.4587417244911194\n",
            "Epoch 42, Step 40, Loss: 0.46666407585144043\n",
            "Epoch 42, Step 41, Loss: 0.48991379141807556\n",
            "Epoch 42, Step 42, Loss: 0.6863389611244202\n",
            "Epoch 42, Step 43, Loss: 0.6095874905586243\n",
            "Epoch 42, Step 44, Loss: 0.5259047746658325\n",
            "Epoch 42, Step 45, Loss: 0.6083524823188782\n",
            "Epoch 42, Step 46, Loss: 0.5631372928619385\n",
            "Epoch 42, Step 47, Loss: 0.5196316242218018\n",
            "Epoch 42, Step 48, Loss: 0.6173243522644043\n",
            "Epoch 42, Step 49, Loss: 0.6518700122833252\n",
            "Epoch 42, Step 50, Loss: 0.6057478785514832\n",
            "Epoch 42, Step 51, Loss: 0.4379555284976959\n",
            "Epoch 42, Step 52, Loss: 0.444219708442688\n",
            "Epoch 42, Step 53, Loss: 0.7659422159194946\n",
            "Epoch 42, Step 54, Loss: 0.5763698220252991\n",
            "Epoch 42, Step 55, Loss: 0.5308042764663696\n",
            "Epoch 42, Step 56, Loss: 0.49540939927101135\n",
            "Epoch 42, Step 57, Loss: 0.6442228555679321\n",
            "Epoch 42, Step 58, Loss: 0.5158758163452148\n",
            "Epoch 42, Step 59, Loss: 0.5319394469261169\n",
            "Epoch 42, Step 60, Loss: 0.5002758502960205\n",
            "Epoch 42, Step 61, Loss: 0.48245447874069214\n",
            "Epoch 42, Step 62, Loss: 0.5229165554046631\n",
            "Epoch 42, Step 63, Loss: 0.5829828977584839\n",
            "Epoch 42, Step 64, Loss: 0.573646605014801\n",
            "Epoch 42, Step 65, Loss: 0.4829334020614624\n",
            "Epoch 42, Step 66, Loss: 0.5429486632347107\n",
            "Epoch 42, Step 67, Loss: 0.577886700630188\n",
            "Epoch 42, Step 68, Loss: 0.5009809732437134\n",
            "Epoch 42, Step 69, Loss: 0.416348934173584\n",
            "Epoch 42, Step 70, Loss: 0.6272040605545044\n",
            "Epoch 42, Step 71, Loss: 0.5283153057098389\n",
            "Epoch 42, Step 72, Loss: 0.4373641610145569\n",
            "Epoch 42, Step 73, Loss: 0.5439995527267456\n",
            "Epoch 42, Step 74, Loss: 0.6373547911643982\n",
            "Epoch 42, Step 75, Loss: 0.5435631275177002\n",
            "Epoch 42, Step 76, Loss: 0.6393016576766968\n",
            "Epoch 42, Step 77, Loss: 0.4961308240890503\n",
            "Epoch 42, Step 78, Loss: 0.498529851436615\n",
            "Epoch 42, Step 79, Loss: 0.5855822563171387\n",
            "Epoch 42, Step 80, Loss: 0.5653784275054932\n",
            "Epoch 42, Step 81, Loss: 0.6996293067932129\n",
            "Epoch 42, Step 82, Loss: 0.6193037629127502\n",
            "Epoch 42, Step 83, Loss: 0.5518834590911865\n",
            "Epoch 42, Step 84, Loss: 0.5142795443534851\n",
            "Epoch 42, Step 85, Loss: 0.502217173576355\n",
            "Epoch 42, Step 86, Loss: 0.5602553486824036\n",
            "Epoch 42, Step 87, Loss: 0.5289813876152039\n",
            "Epoch 42, Step 88, Loss: 0.475299209356308\n",
            "Epoch 42, Step 89, Loss: 0.5871225595474243\n",
            "Epoch 42, Step 90, Loss: 0.42925941944122314\n",
            "Epoch 42, Step 91, Loss: 0.46855902671813965\n",
            "Epoch 42, Step 92, Loss: 0.466875821352005\n",
            "Epoch 42, Step 93, Loss: 0.45731061697006226\n",
            "Epoch 42, Step 94, Loss: 0.44462424516677856\n",
            "Epoch 42, Step 95, Loss: 0.4587184488773346\n",
            "Epoch 42, Step 96, Loss: 0.5049383044242859\n",
            "Epoch 42, Step 97, Loss: 0.49082911014556885\n",
            "Epoch 42, Step 98, Loss: 0.4790618121623993\n",
            "Epoch 42, Step 99, Loss: 0.5999788641929626\n",
            "Epoch 42, Step 100, Loss: 0.5432252287864685\n",
            "Epoch 42, Step 101, Loss: 0.5320868492126465\n",
            "Epoch 42, Step 102, Loss: 0.5136034488677979\n",
            "Epoch 42, Step 103, Loss: 0.452301025390625\n",
            "Epoch 42, Step 104, Loss: 0.5353468656539917\n",
            "Epoch 42, Step 105, Loss: 0.6981174349784851\n",
            "Epoch 42, Step 106, Loss: 0.5927406549453735\n",
            "Epoch 42, Step 107, Loss: 0.41778650879859924\n",
            "Epoch 42, Step 108, Loss: 0.5682799220085144\n",
            "Epoch 42, Step 109, Loss: 0.6083656549453735\n",
            "Epoch 42, Step 110, Loss: 0.5421324968338013\n",
            "Epoch 42, Step 111, Loss: 0.37906092405319214\n",
            "Epoch 42, Step 112, Loss: 0.5299829244613647\n",
            "Epoch 42, Step 113, Loss: 0.5160187482833862\n",
            "Epoch 42, Step 114, Loss: 0.5851181149482727\n",
            "Epoch 42, Step 115, Loss: 0.5757554769515991\n",
            "Epoch 42, Step 116, Loss: 0.5349751710891724\n",
            "Epoch 42, Step 117, Loss: 0.5376682281494141\n",
            "Epoch 42, Step 118, Loss: 0.37842655181884766\n",
            "Epoch 42, Step 119, Loss: 0.4924730360507965\n",
            "Epoch 42, Step 120, Loss: 0.4192051887512207\n",
            "Epoch 42, Step 121, Loss: 0.5133822560310364\n",
            "Epoch 42, Step 122, Loss: 0.46851682662963867\n",
            "Epoch 42, Step 123, Loss: 0.5151764154434204\n",
            "Epoch 42, Step 124, Loss: 0.5701587200164795\n",
            "Epoch 42, Step 125, Loss: 0.534595251083374\n",
            "Epoch 42, Step 126, Loss: 0.6417847275733948\n",
            "Epoch 42, Step 127, Loss: 0.7469633221626282\n",
            "Epoch 42, Step 128, Loss: 0.5687415599822998\n",
            "Epoch 42, Step 129, Loss: 0.6000795364379883\n",
            "Epoch 42, Step 130, Loss: 0.5038031935691833\n",
            "Epoch 42, Step 131, Loss: 0.4537462890148163\n",
            "Epoch 42, Step 132, Loss: 0.3578493893146515\n",
            "Epoch 42, Step 133, Loss: 0.39912042021751404\n",
            "Epoch 42, Step 134, Loss: 0.5979751944541931\n",
            "Epoch 42, Step 135, Loss: 0.48096713423728943\n",
            "Epoch 42, Step 136, Loss: 0.5665045976638794\n",
            "Epoch 42, Step 137, Loss: 0.6607916355133057\n",
            "Epoch 42, Step 138, Loss: 0.4466535449028015\n",
            "Epoch 42, Step 139, Loss: 0.5480634570121765\n",
            "Epoch 42, Step 140, Loss: 0.5181552767753601\n",
            "Epoch 42, Step 141, Loss: 0.43954193592071533\n",
            "Epoch 42, Step 142, Loss: 0.5011946558952332\n",
            "Epoch 42, Step 143, Loss: 0.643987774848938\n",
            "Epoch 42, Step 144, Loss: 0.5468774437904358\n",
            "Epoch 42, Step 145, Loss: 0.5782085061073303\n",
            "Epoch 42, Step 146, Loss: 0.6284828186035156\n",
            "Epoch 42, Step 147, Loss: 0.5828772187232971\n",
            "Epoch 42, Step 148, Loss: 0.549125075340271\n",
            "Epoch 42, Step 149, Loss: 0.5224996209144592\n",
            "Epoch 42, Step 150, Loss: 0.5758028626441956\n",
            "Epoch 42, Step 151, Loss: 0.6003832817077637\n",
            "Epoch 42, Step 152, Loss: 0.35342276096343994\n",
            "Epoch 42, Step 153, Loss: 0.5576465725898743\n",
            "Epoch 42, Step 154, Loss: 0.5113353133201599\n",
            "Epoch 42, Step 155, Loss: 0.712315559387207\n",
            "Epoch 42, Step 156, Loss: 0.4802355468273163\n",
            "Epoch 42, Step 157, Loss: 0.6652224063873291\n",
            "Epoch 42, Step 158, Loss: 0.6627386808395386\n",
            "Epoch 42, Step 159, Loss: 0.4857151210308075\n",
            "Epoch 42, Step 160, Loss: 0.5008131861686707\n",
            "Epoch 42, Step 161, Loss: 0.5356773138046265\n",
            "Epoch 42, Step 162, Loss: 0.5721378922462463\n",
            "Epoch 42, Step 163, Loss: 0.4279879629611969\n",
            "Epoch 42, Step 164, Loss: 0.4939960539340973\n",
            "Epoch 42, Step 165, Loss: 0.696091890335083\n",
            "Epoch 42, Step 166, Loss: 0.6812950372695923\n",
            "Epoch 42, Step 167, Loss: 0.523003876209259\n",
            "Epoch 42, Step 168, Loss: 0.455525279045105\n",
            "Epoch 42, Step 169, Loss: 0.4850893020629883\n",
            "Epoch 42, Step 170, Loss: 0.6828517317771912\n",
            "Epoch 42, Step 171, Loss: 0.49797090888023376\n",
            "Epoch 42, Step 172, Loss: 0.5957355499267578\n",
            "Epoch 42, Step 173, Loss: 0.4046218991279602\n",
            "Epoch 42, Step 174, Loss: 0.4688986539840698\n",
            "Epoch 42, Step 175, Loss: 0.48209261894226074\n",
            "Epoch 42, Step 176, Loss: 0.6012270450592041\n",
            "Epoch 42, Step 177, Loss: 0.479425847530365\n",
            "Epoch 42, Step 178, Loss: 0.6006320714950562\n",
            "Epoch 42, Step 179, Loss: 0.5733344554901123\n",
            "Epoch 42, Step 180, Loss: 0.4400549829006195\n",
            "Epoch 42, Step 181, Loss: 0.599281370639801\n",
            "Epoch 42, Step 182, Loss: 0.582496166229248\n",
            "Epoch 42, Step 183, Loss: 0.4878852665424347\n",
            "Epoch 42, Step 184, Loss: 0.4729710817337036\n",
            "Epoch 42, Step 185, Loss: 0.45989951491355896\n",
            "Epoch 42, Step 186, Loss: 0.527756929397583\n",
            "Epoch 42, Step 187, Loss: 0.5728055238723755\n",
            "Epoch 42, Step 188, Loss: 0.522817850112915\n",
            "Epoch 42, Step 189, Loss: 0.5476928949356079\n",
            "Epoch 42, Step 190, Loss: 0.6089242100715637\n",
            "Epoch 42, Step 191, Loss: 0.4362678527832031\n",
            "Epoch 42, Step 192, Loss: 0.582912027835846\n",
            "Epoch 42, Step 193, Loss: 0.6426749229431152\n",
            "Epoch 42, Step 194, Loss: 0.49914225935935974\n",
            "Epoch 42, Step 195, Loss: 0.6369160413742065\n",
            "Epoch 42, Step 196, Loss: 0.4582826793193817\n",
            "Epoch 42, Step 197, Loss: 0.476308137178421\n",
            "Epoch 42, Step 198, Loss: 0.3842586576938629\n",
            "Epoch 42, Step 199, Loss: 0.5699360966682434\n",
            "Epoch 42, Step 200, Loss: 0.4197792410850525\n",
            "Epoch 42, Step 201, Loss: 0.3667953312397003\n",
            "Epoch 42, Step 202, Loss: 0.5385360717773438\n",
            "Epoch 42, Step 203, Loss: 0.48375770449638367\n",
            "Epoch 42, Step 204, Loss: 0.5038949251174927\n",
            "Epoch 42, Step 205, Loss: 0.5141544342041016\n",
            "Epoch 42, Step 206, Loss: 0.5310884714126587\n",
            "Epoch 42, Step 207, Loss: 0.5512064099311829\n",
            "Epoch 42, Step 208, Loss: 0.4303540587425232\n",
            "Epoch 42, Step 209, Loss: 0.5058585405349731\n",
            "Epoch 42, Step 210, Loss: 0.5713363289833069\n",
            "Epoch 42, Step 211, Loss: 0.5117675065994263\n",
            "Epoch 42, Step 212, Loss: 0.41751641035079956\n",
            "Epoch 42, Step 213, Loss: 0.4923785924911499\n",
            "Epoch 42, Step 214, Loss: 0.4210655391216278\n",
            "Epoch 42, Step 215, Loss: 0.4559820592403412\n",
            "Epoch 42, Step 216, Loss: 0.553695797920227\n",
            "Epoch 42, Step 217, Loss: 0.6581963896751404\n",
            "Epoch 42, Step 218, Loss: 0.5954603552818298\n",
            "Epoch 42, Step 219, Loss: 0.42418172955513\n",
            "Epoch 42, Step 220, Loss: 0.5455091595649719\n",
            "Epoch 42, Step 221, Loss: 0.5708694458007812\n",
            "Epoch 42, Step 222, Loss: 0.539426863193512\n",
            "Epoch 42, Step 223, Loss: 0.4321947395801544\n",
            "Epoch 42, Step 224, Loss: 0.4289676249027252\n",
            "Epoch 42, Step 225, Loss: 0.4063301086425781\n",
            "Epoch 42, Step 226, Loss: 0.40963923931121826\n",
            "Epoch 42, Step 227, Loss: 0.6569398045539856\n",
            "Epoch 42, Step 228, Loss: 0.5414920449256897\n",
            "Epoch 42, Step 229, Loss: 0.5184763669967651\n",
            "Epoch 42, Step 230, Loss: 0.5443955063819885\n",
            "Epoch 42, Step 231, Loss: 0.57045978307724\n",
            "Epoch 42, Step 232, Loss: 0.41440415382385254\n",
            "Epoch 42, Step 233, Loss: 0.572350800037384\n",
            "Epoch 42, Step 234, Loss: 0.5179423093795776\n",
            "Epoch 42, Step 235, Loss: 0.7222221493721008\n",
            "Epoch 42, Step 236, Loss: 0.4348796606063843\n",
            "Epoch 42, Step 237, Loss: 0.5131011009216309\n",
            "Epoch 42, Step 238, Loss: 0.4637261629104614\n",
            "Epoch 42, Step 239, Loss: 0.3653777837753296\n",
            "Epoch 42, Step 240, Loss: 0.602095901966095\n",
            "Epoch 42, Step 241, Loss: 0.4856599271297455\n",
            "Epoch 42, Step 242, Loss: 0.5002954602241516\n",
            "Epoch 42, Step 243, Loss: 0.4283236861228943\n",
            "Epoch 42, Step 244, Loss: 0.4697475731372833\n",
            "Epoch 42, Step 245, Loss: 0.505957305431366\n",
            "Epoch 42, Step 246, Loss: 0.44464635848999023\n",
            "Epoch 42, Step 247, Loss: 0.7299313545227051\n",
            "Epoch 42, Step 248, Loss: 0.6260085701942444\n",
            "Epoch 42, Step 249, Loss: 0.4239792823791504\n",
            "Epoch 42, Step 250, Loss: 0.45267942547798157\n",
            "Epoch 42, Step 251, Loss: 0.44430074095726013\n",
            "Epoch 42, Step 252, Loss: 0.636634111404419\n",
            "Epoch 42, Step 253, Loss: 0.44120460748672485\n",
            "Epoch 42, Step 254, Loss: 0.5181296467781067\n",
            "Epoch 42, Step 255, Loss: 0.5433050394058228\n",
            "Epoch 42, Step 256, Loss: 0.5849165320396423\n",
            "Epoch 42, Step 257, Loss: 0.5760456919670105\n",
            "Epoch 42, Step 258, Loss: 0.45918554067611694\n",
            "Epoch 42, Step 259, Loss: 0.472051739692688\n",
            "Epoch 42, Step 260, Loss: 0.6188429594039917\n",
            "Epoch 42, Step 261, Loss: 0.48096010088920593\n",
            "Epoch 42, Step 262, Loss: 0.4664492905139923\n",
            "Epoch 42, Step 263, Loss: 0.5734784007072449\n",
            "Epoch 42, Step 264, Loss: 0.5188179016113281\n",
            "Epoch 42, Step 265, Loss: 0.5768409967422485\n",
            "Epoch 42, Step 266, Loss: 0.5611924529075623\n",
            "Epoch 42, Step 267, Loss: 0.45991945266723633\n",
            "Epoch 42, Step 268, Loss: 0.559357762336731\n",
            "Epoch 42, Step 269, Loss: 0.6693843603134155\n",
            "Epoch 42, Step 270, Loss: 0.6430008411407471\n",
            "Epoch 42, Step 271, Loss: 0.5880178809165955\n",
            "Epoch 42, Step 272, Loss: 0.504231870174408\n",
            "Epoch 42, Step 273, Loss: 0.48136818408966064\n",
            "Epoch 42, Step 274, Loss: 0.6183071136474609\n",
            "Epoch 42, Step 275, Loss: 0.5020982027053833\n",
            "Epoch 42, Step 276, Loss: 0.5939942598342896\n",
            "Epoch 42, Step 277, Loss: 0.34512436389923096\n",
            "Epoch 42, Step 278, Loss: 0.3196929693222046\n",
            "Epoch 42, Step 279, Loss: 0.4611590802669525\n",
            "Epoch 42, Step 280, Loss: 0.47961100935935974\n",
            "Epoch 42, Step 281, Loss: 0.5390996336936951\n",
            "Epoch 42, Step 282, Loss: 0.535123884677887\n",
            "Epoch 42, Step 283, Loss: 0.4711036682128906\n",
            "Epoch 42, Step 284, Loss: 0.7095231413841248\n",
            "Epoch 42, Step 285, Loss: 0.4887503981590271\n",
            "Epoch 42, Step 286, Loss: 0.415702223777771\n",
            "Epoch 42, Step 287, Loss: 0.646195113658905\n",
            "Epoch 42, Step 288, Loss: 0.5349934697151184\n",
            "Epoch 42, Step 289, Loss: 0.5562312006950378\n",
            "Epoch 42, Step 290, Loss: 0.34498798847198486\n",
            "Epoch 42, Step 291, Loss: 0.5254828929901123\n",
            "Epoch 42, Step 292, Loss: 0.5606622099876404\n",
            "Epoch 42, Step 293, Loss: 0.6707050204277039\n",
            "Epoch 42, Step 294, Loss: 0.5924779176712036\n",
            "Epoch 42, Step 295, Loss: 0.5850494503974915\n",
            "Epoch 42, Step 296, Loss: 0.5855222344398499\n",
            "Epoch 42, Step 297, Loss: 0.43716248869895935\n",
            "Epoch 42, Step 298, Loss: 0.420565128326416\n",
            "Epoch 42, Step 299, Loss: 0.4349864721298218\n",
            "Epoch 42, Step 300, Loss: 0.5455195903778076\n",
            "Epoch 42, Step 301, Loss: 0.4855315685272217\n",
            "Epoch 42, Step 302, Loss: 0.4686790406703949\n",
            "Epoch 42, Step 303, Loss: 0.5421181917190552\n",
            "Epoch 42, Step 304, Loss: 0.38383737206459045\n",
            "Epoch 42, Step 305, Loss: 0.5750444531440735\n",
            "Epoch 42, Step 306, Loss: 0.3924678862094879\n",
            "Epoch 42, Step 307, Loss: 0.5282416939735413\n",
            "Epoch 42, Step 308, Loss: 0.3930733799934387\n",
            "Epoch 42, Step 309, Loss: 0.5421267151832581\n",
            "Epoch 42, Step 310, Loss: 0.5777247548103333\n",
            "Epoch 42, Step 311, Loss: 0.475199818611145\n",
            "Epoch 42, Step 312, Loss: 0.6328792572021484\n",
            "Epoch 42 end, avg train loss: 0.5263834066284351\n",
            "Epoch 42 end, avg val loss: 0.5744909093349795, accuracy: 79.85%\n",
            "Epoch 43, Step 0, Loss: 0.6424353122711182\n",
            "Epoch 43, Step 1, Loss: 0.5253551006317139\n",
            "Epoch 43, Step 2, Loss: 0.474387526512146\n",
            "Epoch 43, Step 3, Loss: 0.49259257316589355\n",
            "Epoch 43, Step 4, Loss: 0.5382093787193298\n",
            "Epoch 43, Step 5, Loss: 0.585889458656311\n",
            "Epoch 43, Step 6, Loss: 0.5216476917266846\n",
            "Epoch 43, Step 7, Loss: 0.5740472078323364\n",
            "Epoch 43, Step 8, Loss: 0.6839714646339417\n",
            "Epoch 43, Step 9, Loss: 0.3800104856491089\n",
            "Epoch 43, Step 10, Loss: 0.4894070327281952\n",
            "Epoch 43, Step 11, Loss: 0.4829188287258148\n",
            "Epoch 43, Step 12, Loss: 0.5345798134803772\n",
            "Epoch 43, Step 13, Loss: 0.5174938440322876\n",
            "Epoch 43, Step 14, Loss: 0.5940329432487488\n",
            "Epoch 43, Step 15, Loss: 0.6149599552154541\n",
            "Epoch 43, Step 16, Loss: 0.5566072463989258\n",
            "Epoch 43, Step 17, Loss: 0.5348618030548096\n",
            "Epoch 43, Step 18, Loss: 0.4622218608856201\n",
            "Epoch 43, Step 19, Loss: 0.494181752204895\n",
            "Epoch 43, Step 20, Loss: 0.5024600028991699\n",
            "Epoch 43, Step 21, Loss: 0.505516529083252\n",
            "Epoch 43, Step 22, Loss: 0.5721738934516907\n",
            "Epoch 43, Step 23, Loss: 0.7881902456283569\n",
            "Epoch 43, Step 24, Loss: 0.4282093644142151\n",
            "Epoch 43, Step 25, Loss: 0.5738813877105713\n",
            "Epoch 43, Step 26, Loss: 0.500228226184845\n",
            "Epoch 43, Step 27, Loss: 0.4246906638145447\n",
            "Epoch 43, Step 28, Loss: 0.5398275256156921\n",
            "Epoch 43, Step 29, Loss: 0.46152058243751526\n",
            "Epoch 43, Step 30, Loss: 0.5839729905128479\n",
            "Epoch 43, Step 31, Loss: 0.5667321085929871\n",
            "Epoch 43, Step 32, Loss: 0.519355297088623\n",
            "Epoch 43, Step 33, Loss: 0.5631767511367798\n",
            "Epoch 43, Step 34, Loss: 0.705552875995636\n",
            "Epoch 43, Step 35, Loss: 0.5095548629760742\n",
            "Epoch 43, Step 36, Loss: 0.5238054990768433\n",
            "Epoch 43, Step 37, Loss: 0.5094281435012817\n",
            "Epoch 43, Step 38, Loss: 0.5927836298942566\n",
            "Epoch 43, Step 39, Loss: 0.29159975051879883\n",
            "Epoch 43, Step 40, Loss: 0.5455223321914673\n",
            "Epoch 43, Step 41, Loss: 0.5335639715194702\n",
            "Epoch 43, Step 42, Loss: 0.4924546182155609\n",
            "Epoch 43, Step 43, Loss: 0.4598533511161804\n",
            "Epoch 43, Step 44, Loss: 0.6038791537284851\n",
            "Epoch 43, Step 45, Loss: 0.5649164915084839\n",
            "Epoch 43, Step 46, Loss: 0.5433777570724487\n",
            "Epoch 43, Step 47, Loss: 0.3740554451942444\n",
            "Epoch 43, Step 48, Loss: 0.4220699071884155\n",
            "Epoch 43, Step 49, Loss: 0.43953457474708557\n",
            "Epoch 43, Step 50, Loss: 0.5200268626213074\n",
            "Epoch 43, Step 51, Loss: 0.47242674231529236\n",
            "Epoch 43, Step 52, Loss: 0.6024664640426636\n",
            "Epoch 43, Step 53, Loss: 0.4545398950576782\n",
            "Epoch 43, Step 54, Loss: 0.5736103653907776\n",
            "Epoch 43, Step 55, Loss: 0.43889400362968445\n",
            "Epoch 43, Step 56, Loss: 0.6481313109397888\n",
            "Epoch 43, Step 57, Loss: 0.3720744550228119\n",
            "Epoch 43, Step 58, Loss: 0.4343436062335968\n",
            "Epoch 43, Step 59, Loss: 0.47688865661621094\n",
            "Epoch 43, Step 60, Loss: 0.49396881461143494\n",
            "Epoch 43, Step 61, Loss: 0.570381760597229\n",
            "Epoch 43, Step 62, Loss: 0.517730176448822\n",
            "Epoch 43, Step 63, Loss: 0.5717250108718872\n",
            "Epoch 43, Step 64, Loss: 0.44415825605392456\n",
            "Epoch 43, Step 65, Loss: 0.4900343716144562\n",
            "Epoch 43, Step 66, Loss: 0.621166467666626\n",
            "Epoch 43, Step 67, Loss: 0.46759289503097534\n",
            "Epoch 43, Step 68, Loss: 0.49249184131622314\n",
            "Epoch 43, Step 69, Loss: 0.6007702946662903\n",
            "Epoch 43, Step 70, Loss: 0.4296255111694336\n",
            "Epoch 43, Step 71, Loss: 0.4599932134151459\n",
            "Epoch 43, Step 72, Loss: 0.5454055070877075\n",
            "Epoch 43, Step 73, Loss: 0.6089310646057129\n",
            "Epoch 43, Step 74, Loss: 0.5440313220024109\n",
            "Epoch 43, Step 75, Loss: 0.489221453666687\n",
            "Epoch 43, Step 76, Loss: 0.47900012135505676\n",
            "Epoch 43, Step 77, Loss: 0.45752930641174316\n",
            "Epoch 43, Step 78, Loss: 0.5584689378738403\n",
            "Epoch 43, Step 79, Loss: 0.48335716128349304\n",
            "Epoch 43, Step 80, Loss: 0.4148218035697937\n",
            "Epoch 43, Step 81, Loss: 0.5834693908691406\n",
            "Epoch 43, Step 82, Loss: 0.603813648223877\n",
            "Epoch 43, Step 83, Loss: 0.4912768304347992\n",
            "Epoch 43, Step 84, Loss: 0.7742992639541626\n",
            "Epoch 43, Step 85, Loss: 0.48616015911102295\n",
            "Epoch 43, Step 86, Loss: 0.5246955752372742\n",
            "Epoch 43, Step 87, Loss: 0.6230362057685852\n",
            "Epoch 43, Step 88, Loss: 0.4351184666156769\n",
            "Epoch 43, Step 89, Loss: 0.4890199601650238\n",
            "Epoch 43, Step 90, Loss: 0.4853229522705078\n",
            "Epoch 43, Step 91, Loss: 0.5818948149681091\n",
            "Epoch 43, Step 92, Loss: 0.45247921347618103\n",
            "Epoch 43, Step 93, Loss: 0.4208139181137085\n",
            "Epoch 43, Step 94, Loss: 0.49935540556907654\n",
            "Epoch 43, Step 95, Loss: 0.49543505907058716\n",
            "Epoch 43, Step 96, Loss: 0.5173391103744507\n",
            "Epoch 43, Step 97, Loss: 0.42763710021972656\n",
            "Epoch 43, Step 98, Loss: 0.4040442407131195\n",
            "Epoch 43, Step 99, Loss: 0.4105932116508484\n",
            "Epoch 43, Step 100, Loss: 0.5435196757316589\n",
            "Epoch 43, Step 101, Loss: 0.5792808532714844\n",
            "Epoch 43, Step 102, Loss: 0.5600790977478027\n",
            "Epoch 43, Step 103, Loss: 0.433211088180542\n",
            "Epoch 43, Step 104, Loss: 0.5060021877288818\n",
            "Epoch 43, Step 105, Loss: 0.6903024315834045\n",
            "Epoch 43, Step 106, Loss: 0.5412238240242004\n",
            "Epoch 43, Step 107, Loss: 0.5519554018974304\n",
            "Epoch 43, Step 108, Loss: 0.5288546085357666\n",
            "Epoch 43, Step 109, Loss: 0.4725539982318878\n",
            "Epoch 43, Step 110, Loss: 0.5172287821769714\n",
            "Epoch 43, Step 111, Loss: 0.46205174922943115\n",
            "Epoch 43, Step 112, Loss: 0.4400182068347931\n",
            "Epoch 43, Step 113, Loss: 0.5772691965103149\n",
            "Epoch 43, Step 114, Loss: 0.47699838876724243\n",
            "Epoch 43, Step 115, Loss: 0.40051621198654175\n",
            "Epoch 43, Step 116, Loss: 0.42513352632522583\n",
            "Epoch 43, Step 117, Loss: 0.46569889783859253\n",
            "Epoch 43, Step 118, Loss: 0.536961019039154\n",
            "Epoch 43, Step 119, Loss: 0.452301025390625\n",
            "Epoch 43, Step 120, Loss: 0.5333505868911743\n",
            "Epoch 43, Step 121, Loss: 0.5315724015235901\n",
            "Epoch 43, Step 122, Loss: 0.39052292704582214\n",
            "Epoch 43, Step 123, Loss: 0.35232630372047424\n",
            "Epoch 43, Step 124, Loss: 0.6226491928100586\n",
            "Epoch 43, Step 125, Loss: 0.5583429932594299\n",
            "Epoch 43, Step 126, Loss: 0.4447280168533325\n",
            "Epoch 43, Step 127, Loss: 0.44555702805519104\n",
            "Epoch 43, Step 128, Loss: 0.3624144494533539\n",
            "Epoch 43, Step 129, Loss: 0.44553205370903015\n",
            "Epoch 43, Step 130, Loss: 0.45153623819351196\n",
            "Epoch 43, Step 131, Loss: 0.49244096875190735\n",
            "Epoch 43, Step 132, Loss: 0.4249570667743683\n",
            "Epoch 43, Step 133, Loss: 0.6283785700798035\n",
            "Epoch 43, Step 134, Loss: 0.43494242429733276\n",
            "Epoch 43, Step 135, Loss: 0.5902346968650818\n",
            "Epoch 43, Step 136, Loss: 0.5114901661872864\n",
            "Epoch 43, Step 137, Loss: 0.6908400654792786\n",
            "Epoch 43, Step 138, Loss: 0.6872694492340088\n",
            "Epoch 43, Step 139, Loss: 0.5346346497535706\n",
            "Epoch 43, Step 140, Loss: 0.6809757351875305\n",
            "Epoch 43, Step 141, Loss: 0.5344367623329163\n",
            "Epoch 43, Step 142, Loss: 0.5459713935852051\n",
            "Epoch 43, Step 143, Loss: 0.6334950923919678\n",
            "Epoch 43, Step 144, Loss: 0.5886883735656738\n",
            "Epoch 43, Step 145, Loss: 0.6061969995498657\n",
            "Epoch 43, Step 146, Loss: 0.40296271443367004\n",
            "Epoch 43, Step 147, Loss: 0.472644567489624\n",
            "Epoch 43, Step 148, Loss: 0.5730756521224976\n",
            "Epoch 43, Step 149, Loss: 0.3968855142593384\n",
            "Epoch 43, Step 150, Loss: 0.4469730854034424\n",
            "Epoch 43, Step 151, Loss: 0.33705559372901917\n",
            "Epoch 43, Step 152, Loss: 0.6155543923377991\n",
            "Epoch 43, Step 153, Loss: 0.5326051115989685\n",
            "Epoch 43, Step 154, Loss: 0.3988158106803894\n",
            "Epoch 43, Step 155, Loss: 0.5771483778953552\n",
            "Epoch 43, Step 156, Loss: 0.41920536756515503\n",
            "Epoch 43, Step 157, Loss: 0.42182624340057373\n",
            "Epoch 43, Step 158, Loss: 0.5615584254264832\n",
            "Epoch 43, Step 159, Loss: 0.5708973407745361\n",
            "Epoch 43, Step 160, Loss: 0.4228764772415161\n",
            "Epoch 43, Step 161, Loss: 0.48853111267089844\n",
            "Epoch 43, Step 162, Loss: 0.42997074127197266\n",
            "Epoch 43, Step 163, Loss: 0.5830373764038086\n",
            "Epoch 43, Step 164, Loss: 0.3723744750022888\n",
            "Epoch 43, Step 165, Loss: 0.48243197798728943\n",
            "Epoch 43, Step 166, Loss: 0.49044448137283325\n",
            "Epoch 43, Step 167, Loss: 0.34618502855300903\n",
            "Epoch 43, Step 168, Loss: 0.6257281303405762\n",
            "Epoch 43, Step 169, Loss: 0.42210233211517334\n",
            "Epoch 43, Step 170, Loss: 0.5837224125862122\n",
            "Epoch 43, Step 171, Loss: 0.6289328336715698\n",
            "Epoch 43, Step 172, Loss: 0.6096765398979187\n",
            "Epoch 43, Step 173, Loss: 0.5317330956459045\n",
            "Epoch 43, Step 174, Loss: 0.5005595088005066\n",
            "Epoch 43, Step 175, Loss: 0.5530061721801758\n",
            "Epoch 43, Step 176, Loss: 0.5651878714561462\n",
            "Epoch 43, Step 177, Loss: 0.4797353744506836\n",
            "Epoch 43, Step 178, Loss: 0.5764558911323547\n",
            "Epoch 43, Step 179, Loss: 0.5483794212341309\n",
            "Epoch 43, Step 180, Loss: 0.510917603969574\n",
            "Epoch 43, Step 181, Loss: 0.4958384931087494\n",
            "Epoch 43, Step 182, Loss: 0.5032115578651428\n",
            "Epoch 43, Step 183, Loss: 0.514796257019043\n",
            "Epoch 43, Step 184, Loss: 0.5513579845428467\n",
            "Epoch 43, Step 185, Loss: 0.558907687664032\n",
            "Epoch 43, Step 186, Loss: 0.5454940795898438\n",
            "Epoch 43, Step 187, Loss: 0.47805818915367126\n",
            "Epoch 43, Step 188, Loss: 0.42088785767555237\n",
            "Epoch 43, Step 189, Loss: 0.566105306148529\n",
            "Epoch 43, Step 190, Loss: 0.5231105089187622\n",
            "Epoch 43, Step 191, Loss: 0.6525639891624451\n",
            "Epoch 43, Step 192, Loss: 0.5730971097946167\n",
            "Epoch 43, Step 193, Loss: 0.4905613958835602\n",
            "Epoch 43, Step 194, Loss: 0.49159470200538635\n",
            "Epoch 43, Step 195, Loss: 0.45629575848579407\n",
            "Epoch 43, Step 196, Loss: 0.40295806527137756\n",
            "Epoch 43, Step 197, Loss: 0.4289097785949707\n",
            "Epoch 43, Step 198, Loss: 0.503888726234436\n",
            "Epoch 43, Step 199, Loss: 0.46868881583213806\n",
            "Epoch 43, Step 200, Loss: 0.6536495089530945\n",
            "Epoch 43, Step 201, Loss: 0.5566332340240479\n",
            "Epoch 43, Step 202, Loss: 0.45626750588417053\n",
            "Epoch 43, Step 203, Loss: 0.505399227142334\n",
            "Epoch 43, Step 204, Loss: 0.522447943687439\n",
            "Epoch 43, Step 205, Loss: 0.462618350982666\n",
            "Epoch 43, Step 206, Loss: 0.5855307579040527\n",
            "Epoch 43, Step 207, Loss: 0.4285660684108734\n",
            "Epoch 43, Step 208, Loss: 0.5414143204689026\n",
            "Epoch 43, Step 209, Loss: 0.5982731580734253\n",
            "Epoch 43, Step 210, Loss: 0.46290355920791626\n",
            "Epoch 43, Step 211, Loss: 0.5065742135047913\n",
            "Epoch 43, Step 212, Loss: 0.5516943335533142\n",
            "Epoch 43, Step 213, Loss: 0.5944857597351074\n",
            "Epoch 43, Step 214, Loss: 0.43914708495140076\n",
            "Epoch 43, Step 215, Loss: 0.5132995843887329\n",
            "Epoch 43, Step 216, Loss: 0.46954968571662903\n",
            "Epoch 43, Step 217, Loss: 0.43001821637153625\n",
            "Epoch 43, Step 218, Loss: 0.5306167006492615\n",
            "Epoch 43, Step 219, Loss: 0.6270065903663635\n",
            "Epoch 43, Step 220, Loss: 0.6174043416976929\n",
            "Epoch 43, Step 221, Loss: 0.7012335658073425\n",
            "Epoch 43, Step 222, Loss: 0.628901481628418\n",
            "Epoch 43, Step 223, Loss: 0.5441913604736328\n",
            "Epoch 43, Step 224, Loss: 0.45592668652534485\n",
            "Epoch 43, Step 225, Loss: 0.5679462552070618\n",
            "Epoch 43, Step 226, Loss: 0.547580897808075\n",
            "Epoch 43, Step 227, Loss: 0.4896479845046997\n",
            "Epoch 43, Step 228, Loss: 0.6480031609535217\n",
            "Epoch 43, Step 229, Loss: 0.41513267159461975\n",
            "Epoch 43, Step 230, Loss: 0.5430423617362976\n",
            "Epoch 43, Step 231, Loss: 0.5174254775047302\n",
            "Epoch 43, Step 232, Loss: 0.42330142855644226\n",
            "Epoch 43, Step 233, Loss: 0.45870569348335266\n",
            "Epoch 43, Step 234, Loss: 0.4832686483860016\n",
            "Epoch 43, Step 235, Loss: 0.5353654026985168\n",
            "Epoch 43, Step 236, Loss: 0.49641847610473633\n",
            "Epoch 43, Step 237, Loss: 0.4422423541545868\n",
            "Epoch 43, Step 238, Loss: 0.5097190141677856\n",
            "Epoch 43, Step 239, Loss: 0.46934348344802856\n",
            "Epoch 43, Step 240, Loss: 0.5691069960594177\n",
            "Epoch 43, Step 241, Loss: 0.42404797673225403\n",
            "Epoch 43, Step 242, Loss: 0.680230438709259\n",
            "Epoch 43, Step 243, Loss: 0.5104056596755981\n",
            "Epoch 43, Step 244, Loss: 0.5237650871276855\n",
            "Epoch 43, Step 245, Loss: 0.5651688575744629\n",
            "Epoch 43, Step 246, Loss: 0.551857590675354\n",
            "Epoch 43, Step 247, Loss: 0.5149437785148621\n",
            "Epoch 43, Step 248, Loss: 0.39913755655288696\n",
            "Epoch 43, Step 249, Loss: 0.7985500693321228\n",
            "Epoch 43, Step 250, Loss: 0.5119479298591614\n",
            "Epoch 43, Step 251, Loss: 0.573819100856781\n",
            "Epoch 43, Step 252, Loss: 0.5701944828033447\n",
            "Epoch 43, Step 253, Loss: 0.5540599822998047\n",
            "Epoch 43, Step 254, Loss: 0.5903676748275757\n",
            "Epoch 43, Step 255, Loss: 0.6906101703643799\n",
            "Epoch 43, Step 256, Loss: 0.5268145203590393\n",
            "Epoch 43, Step 257, Loss: 0.5067750215530396\n",
            "Epoch 43, Step 258, Loss: 0.6325367093086243\n",
            "Epoch 43, Step 259, Loss: 0.44486451148986816\n",
            "Epoch 43, Step 260, Loss: 0.46334412693977356\n",
            "Epoch 43, Step 261, Loss: 0.42702528834342957\n",
            "Epoch 43, Step 262, Loss: 0.5253950357437134\n",
            "Epoch 43, Step 263, Loss: 0.6052625179290771\n",
            "Epoch 43, Step 264, Loss: 0.3968408703804016\n",
            "Epoch 43, Step 265, Loss: 0.7313564419746399\n",
            "Epoch 43, Step 266, Loss: 0.587856113910675\n",
            "Epoch 43, Step 267, Loss: 0.4653555452823639\n",
            "Epoch 43, Step 268, Loss: 0.6059769988059998\n",
            "Epoch 43, Step 269, Loss: 0.3500312864780426\n",
            "Epoch 43, Step 270, Loss: 0.6504497528076172\n",
            "Epoch 43, Step 271, Loss: 0.5406437516212463\n",
            "Epoch 43, Step 272, Loss: 0.6344528794288635\n",
            "Epoch 43, Step 273, Loss: 0.3508671224117279\n",
            "Epoch 43, Step 274, Loss: 0.5465370416641235\n",
            "Epoch 43, Step 275, Loss: 0.4122348129749298\n",
            "Epoch 43, Step 276, Loss: 0.4305403232574463\n",
            "Epoch 43, Step 277, Loss: 0.5825307369232178\n",
            "Epoch 43, Step 278, Loss: 0.5289040803909302\n",
            "Epoch 43, Step 279, Loss: 0.4667385518550873\n",
            "Epoch 43, Step 280, Loss: 0.41527625918388367\n",
            "Epoch 43, Step 281, Loss: 0.462162047624588\n",
            "Epoch 43, Step 282, Loss: 0.5044186115264893\n",
            "Epoch 43, Step 283, Loss: 0.44723013043403625\n",
            "Epoch 43, Step 284, Loss: 0.49905675649642944\n",
            "Epoch 43, Step 285, Loss: 0.641707181930542\n",
            "Epoch 43, Step 286, Loss: 0.596685528755188\n",
            "Epoch 43, Step 287, Loss: 0.383048415184021\n",
            "Epoch 43, Step 288, Loss: 0.435876727104187\n",
            "Epoch 43, Step 289, Loss: 0.39334267377853394\n",
            "Epoch 43, Step 290, Loss: 0.5951462984085083\n",
            "Epoch 43, Step 291, Loss: 0.3876439929008484\n",
            "Epoch 43, Step 292, Loss: 0.4981420040130615\n",
            "Epoch 43, Step 293, Loss: 0.5478854775428772\n",
            "Epoch 43, Step 294, Loss: 0.5593308806419373\n",
            "Epoch 43, Step 295, Loss: 0.6448224782943726\n",
            "Epoch 43, Step 296, Loss: 0.39707380533218384\n",
            "Epoch 43, Step 297, Loss: 0.5368841886520386\n",
            "Epoch 43, Step 298, Loss: 0.5102124214172363\n",
            "Epoch 43, Step 299, Loss: 0.635393500328064\n",
            "Epoch 43, Step 300, Loss: 0.45784053206443787\n",
            "Epoch 43, Step 301, Loss: 0.5710122585296631\n",
            "Epoch 43, Step 302, Loss: 0.5037643909454346\n",
            "Epoch 43, Step 303, Loss: 0.4909491539001465\n",
            "Epoch 43, Step 304, Loss: 0.5139333605766296\n",
            "Epoch 43, Step 305, Loss: 0.5317708849906921\n",
            "Epoch 43, Step 306, Loss: 0.5783275961875916\n",
            "Epoch 43, Step 307, Loss: 0.551306426525116\n",
            "Epoch 43, Step 308, Loss: 0.4983978271484375\n",
            "Epoch 43, Step 309, Loss: 0.5265968441963196\n",
            "Epoch 43, Step 310, Loss: 0.3411698341369629\n",
            "Epoch 43, Step 311, Loss: 0.5303570032119751\n",
            "Epoch 43, Step 312, Loss: 0.516745924949646\n",
            "Epoch 43 end, avg train loss: 0.5170844563851341\n",
            "Epoch 43 end, avg val loss: 0.5847250208070006, accuracy: 79.63%\n",
            "Epoch 44, Step 0, Loss: 0.6076732873916626\n",
            "Epoch 44, Step 1, Loss: 0.5400859713554382\n",
            "Epoch 44, Step 2, Loss: 0.6326451897621155\n",
            "Epoch 44, Step 3, Loss: 0.6236894130706787\n",
            "Epoch 44, Step 4, Loss: 0.5123138427734375\n",
            "Epoch 44, Step 5, Loss: 0.6056115031242371\n",
            "Epoch 44, Step 6, Loss: 0.6436981558799744\n",
            "Epoch 44, Step 7, Loss: 0.562217116355896\n",
            "Epoch 44, Step 8, Loss: 0.5828644633293152\n",
            "Epoch 44, Step 9, Loss: 0.68963623046875\n",
            "Epoch 44, Step 10, Loss: 0.5251926183700562\n",
            "Epoch 44, Step 11, Loss: 0.5036563873291016\n",
            "Epoch 44, Step 12, Loss: 0.5083063840866089\n",
            "Epoch 44, Step 13, Loss: 0.4652383327484131\n",
            "Epoch 44, Step 14, Loss: 0.5599503517150879\n",
            "Epoch 44, Step 15, Loss: 0.43061313033103943\n",
            "Epoch 44, Step 16, Loss: 0.5995954275131226\n",
            "Epoch 44, Step 17, Loss: 0.5068163871765137\n",
            "Epoch 44, Step 18, Loss: 0.4414147436618805\n",
            "Epoch 44, Step 19, Loss: 0.596256673336029\n",
            "Epoch 44, Step 20, Loss: 0.5349971055984497\n",
            "Epoch 44, Step 21, Loss: 0.49534302949905396\n",
            "Epoch 44, Step 22, Loss: 0.6905019879341125\n",
            "Epoch 44, Step 23, Loss: 0.5911468863487244\n",
            "Epoch 44, Step 24, Loss: 0.5178563594818115\n",
            "Epoch 44, Step 25, Loss: 0.5086807012557983\n",
            "Epoch 44, Step 26, Loss: 0.566127359867096\n",
            "Epoch 44, Step 27, Loss: 0.5361056327819824\n",
            "Epoch 44, Step 28, Loss: 0.5900252461433411\n",
            "Epoch 44, Step 29, Loss: 0.5999209880828857\n",
            "Epoch 44, Step 30, Loss: 0.7000371217727661\n",
            "Epoch 44, Step 31, Loss: 0.4572267532348633\n",
            "Epoch 44, Step 32, Loss: 0.5255286693572998\n",
            "Epoch 44, Step 33, Loss: 0.595880389213562\n",
            "Epoch 44, Step 34, Loss: 0.610987663269043\n",
            "Epoch 44, Step 35, Loss: 0.40224823355674744\n",
            "Epoch 44, Step 36, Loss: 0.6904858946800232\n",
            "Epoch 44, Step 37, Loss: 0.518273115158081\n",
            "Epoch 44, Step 38, Loss: 0.5619326233863831\n",
            "Epoch 44, Step 39, Loss: 0.45448100566864014\n",
            "Epoch 44, Step 40, Loss: 0.4862121045589447\n",
            "Epoch 44, Step 41, Loss: 0.4622232913970947\n",
            "Epoch 44, Step 42, Loss: 0.6187633275985718\n",
            "Epoch 44, Step 43, Loss: 0.5181467533111572\n",
            "Epoch 44, Step 44, Loss: 0.5176452398300171\n",
            "Epoch 44, Step 45, Loss: 0.4971919059753418\n",
            "Epoch 44, Step 46, Loss: 0.5096127986907959\n",
            "Epoch 44, Step 47, Loss: 0.4756448268890381\n",
            "Epoch 44, Step 48, Loss: 0.5209797620773315\n",
            "Epoch 44, Step 49, Loss: 0.46668365597724915\n",
            "Epoch 44, Step 50, Loss: 0.5412921905517578\n",
            "Epoch 44, Step 51, Loss: 0.4592163860797882\n",
            "Epoch 44, Step 52, Loss: 0.448355108499527\n",
            "Epoch 44, Step 53, Loss: 0.410376638174057\n",
            "Epoch 44, Step 54, Loss: 0.41924798488616943\n",
            "Epoch 44, Step 55, Loss: 0.488328218460083\n",
            "Epoch 44, Step 56, Loss: 0.4494938254356384\n",
            "Epoch 44, Step 57, Loss: 0.4856815040111542\n",
            "Epoch 44, Step 58, Loss: 0.5375699400901794\n",
            "Epoch 44, Step 59, Loss: 0.5124649405479431\n",
            "Epoch 44, Step 60, Loss: 0.4839015603065491\n",
            "Epoch 44, Step 61, Loss: 0.5804716944694519\n",
            "Epoch 44, Step 62, Loss: 0.5832335352897644\n",
            "Epoch 44, Step 63, Loss: 0.6068530678749084\n",
            "Epoch 44, Step 64, Loss: 0.568770706653595\n",
            "Epoch 44, Step 65, Loss: 0.5308783650398254\n",
            "Epoch 44, Step 66, Loss: 0.4963693916797638\n",
            "Epoch 44, Step 67, Loss: 0.4925612509250641\n",
            "Epoch 44, Step 68, Loss: 0.6053146719932556\n",
            "Epoch 44, Step 69, Loss: 0.4943130910396576\n",
            "Epoch 44, Step 70, Loss: 0.5199944972991943\n",
            "Epoch 44, Step 71, Loss: 0.4333815574645996\n",
            "Epoch 44, Step 72, Loss: 0.537375807762146\n",
            "Epoch 44, Step 73, Loss: 0.5036503672599792\n",
            "Epoch 44, Step 74, Loss: 0.4885736107826233\n",
            "Epoch 44, Step 75, Loss: 0.43931055068969727\n",
            "Epoch 44, Step 76, Loss: 0.46226704120635986\n",
            "Epoch 44, Step 77, Loss: 0.44155797362327576\n",
            "Epoch 44, Step 78, Loss: 0.4698517322540283\n",
            "Epoch 44, Step 79, Loss: 0.472115159034729\n",
            "Epoch 44, Step 80, Loss: 0.458517462015152\n",
            "Epoch 44, Step 81, Loss: 0.5915539264678955\n",
            "Epoch 44, Step 82, Loss: 0.5326314568519592\n",
            "Epoch 44, Step 83, Loss: 0.5398334860801697\n",
            "Epoch 44, Step 84, Loss: 0.4658178985118866\n",
            "Epoch 44, Step 85, Loss: 0.5840166211128235\n",
            "Epoch 44, Step 86, Loss: 0.5668745636940002\n",
            "Epoch 44, Step 87, Loss: 0.45645570755004883\n",
            "Epoch 44, Step 88, Loss: 0.4341220557689667\n",
            "Epoch 44, Step 89, Loss: 0.5594323873519897\n",
            "Epoch 44, Step 90, Loss: 0.3215188682079315\n",
            "Epoch 44, Step 91, Loss: 0.43083763122558594\n",
            "Epoch 44, Step 92, Loss: 0.6373547911643982\n",
            "Epoch 44, Step 93, Loss: 0.5427612662315369\n",
            "Epoch 44, Step 94, Loss: 0.6075696349143982\n",
            "Epoch 44, Step 95, Loss: 0.5632171034812927\n",
            "Epoch 44, Step 96, Loss: 0.478956401348114\n",
            "Epoch 44, Step 97, Loss: 0.6946989297866821\n",
            "Epoch 44, Step 98, Loss: 0.3998502790927887\n",
            "Epoch 44, Step 99, Loss: 0.5535547137260437\n",
            "Epoch 44, Step 100, Loss: 0.5927016139030457\n",
            "Epoch 44, Step 101, Loss: 0.5391490459442139\n",
            "Epoch 44, Step 102, Loss: 0.5451839566230774\n",
            "Epoch 44, Step 103, Loss: 0.5159685611724854\n",
            "Epoch 44, Step 104, Loss: 0.5934811234474182\n",
            "Epoch 44, Step 105, Loss: 0.563665509223938\n",
            "Epoch 44, Step 106, Loss: 0.5022763013839722\n",
            "Epoch 44, Step 107, Loss: 0.6033475995063782\n",
            "Epoch 44, Step 108, Loss: 0.6256012320518494\n",
            "Epoch 44, Step 109, Loss: 0.5053412318229675\n",
            "Epoch 44, Step 110, Loss: 0.41355934739112854\n",
            "Epoch 44, Step 111, Loss: 0.601692795753479\n",
            "Epoch 44, Step 112, Loss: 0.4744751751422882\n",
            "Epoch 44, Step 113, Loss: 0.46265900135040283\n",
            "Epoch 44, Step 114, Loss: 0.5083777904510498\n",
            "Epoch 44, Step 115, Loss: 0.4517328143119812\n",
            "Epoch 44, Step 116, Loss: 0.3803711235523224\n",
            "Epoch 44, Step 117, Loss: 0.5445253252983093\n",
            "Epoch 44, Step 118, Loss: 0.5764719247817993\n",
            "Epoch 44, Step 119, Loss: 0.5698338150978088\n",
            "Epoch 44, Step 120, Loss: 0.4388037919998169\n",
            "Epoch 44, Step 121, Loss: 0.5457136631011963\n",
            "Epoch 44, Step 122, Loss: 0.4613315165042877\n",
            "Epoch 44, Step 123, Loss: 0.48787185549736023\n",
            "Epoch 44, Step 124, Loss: 0.5763548016548157\n",
            "Epoch 44, Step 125, Loss: 0.6353927254676819\n",
            "Epoch 44, Step 126, Loss: 0.363340824842453\n",
            "Epoch 44, Step 127, Loss: 0.4315055310726166\n",
            "Epoch 44, Step 128, Loss: 0.4181269705295563\n",
            "Epoch 44, Step 129, Loss: 0.6052579879760742\n",
            "Epoch 44, Step 130, Loss: 0.5239150524139404\n",
            "Epoch 44, Step 131, Loss: 0.4980701208114624\n",
            "Epoch 44, Step 132, Loss: 0.5926055908203125\n",
            "Epoch 44, Step 133, Loss: 0.5724010467529297\n",
            "Epoch 44, Step 134, Loss: 0.48314741253852844\n",
            "Epoch 44, Step 135, Loss: 0.6475260853767395\n",
            "Epoch 44, Step 136, Loss: 0.3404596745967865\n",
            "Epoch 44, Step 137, Loss: 0.6211243867874146\n",
            "Epoch 44, Step 138, Loss: 0.4025879502296448\n",
            "Epoch 44, Step 139, Loss: 0.48078417778015137\n",
            "Epoch 44, Step 140, Loss: 0.3795322775840759\n",
            "Epoch 44, Step 141, Loss: 0.5799826979637146\n",
            "Epoch 44, Step 142, Loss: 0.5148577094078064\n",
            "Epoch 44, Step 143, Loss: 0.5637159943580627\n",
            "Epoch 44, Step 144, Loss: 0.4050089716911316\n",
            "Epoch 44, Step 145, Loss: 0.5178604125976562\n",
            "Epoch 44, Step 146, Loss: 0.4757663607597351\n",
            "Epoch 44, Step 147, Loss: 0.4244094491004944\n",
            "Epoch 44, Step 148, Loss: 0.44380152225494385\n",
            "Epoch 44, Step 149, Loss: 0.48543792963027954\n",
            "Epoch 44, Step 150, Loss: 0.5391589999198914\n",
            "Epoch 44, Step 151, Loss: 0.49336352944374084\n",
            "Epoch 44, Step 152, Loss: 0.507218599319458\n",
            "Epoch 44, Step 153, Loss: 0.4079318940639496\n",
            "Epoch 44, Step 154, Loss: 0.4896838665008545\n",
            "Epoch 44, Step 155, Loss: 0.49978554248809814\n",
            "Epoch 44, Step 156, Loss: 0.4835783541202545\n",
            "Epoch 44, Step 157, Loss: 0.4371848404407501\n",
            "Epoch 44, Step 158, Loss: 0.4142209589481354\n",
            "Epoch 44, Step 159, Loss: 0.5071804523468018\n",
            "Epoch 44, Step 160, Loss: 0.3982976973056793\n",
            "Epoch 44, Step 161, Loss: 0.5050198435783386\n",
            "Epoch 44, Step 162, Loss: 0.5544369220733643\n",
            "Epoch 44, Step 163, Loss: 0.4913467466831207\n",
            "Epoch 44, Step 164, Loss: 0.4258197844028473\n",
            "Epoch 44, Step 165, Loss: 0.5665119886398315\n",
            "Epoch 44, Step 166, Loss: 0.5219860672950745\n",
            "Epoch 44, Step 167, Loss: 0.4549388587474823\n",
            "Epoch 44, Step 168, Loss: 0.44238144159317017\n",
            "Epoch 44, Step 169, Loss: 0.6291937232017517\n",
            "Epoch 44, Step 170, Loss: 0.5129142999649048\n",
            "Epoch 44, Step 171, Loss: 0.4744311273097992\n",
            "Epoch 44, Step 172, Loss: 0.6016952395439148\n",
            "Epoch 44, Step 173, Loss: 0.5488969087600708\n",
            "Epoch 44, Step 174, Loss: 0.6686954498291016\n",
            "Epoch 44, Step 175, Loss: 0.3866252601146698\n",
            "Epoch 44, Step 176, Loss: 0.47615015506744385\n",
            "Epoch 44, Step 177, Loss: 0.4415947198867798\n",
            "Epoch 44, Step 178, Loss: 0.5730969309806824\n",
            "Epoch 44, Step 179, Loss: 0.486773282289505\n",
            "Epoch 44, Step 180, Loss: 0.5310958623886108\n",
            "Epoch 44, Step 181, Loss: 0.510304868221283\n",
            "Epoch 44, Step 182, Loss: 0.5162690877914429\n",
            "Epoch 44, Step 183, Loss: 0.47867774963378906\n",
            "Epoch 44, Step 184, Loss: 0.6321510672569275\n",
            "Epoch 44, Step 185, Loss: 0.4519231617450714\n",
            "Epoch 44, Step 186, Loss: 0.5130371451377869\n",
            "Epoch 44, Step 187, Loss: 0.6231569647789001\n",
            "Epoch 44, Step 188, Loss: 0.48453301191329956\n",
            "Epoch 44, Step 189, Loss: 0.5987483859062195\n",
            "Epoch 44, Step 190, Loss: 0.3961983919143677\n",
            "Epoch 44, Step 191, Loss: 0.43433210253715515\n",
            "Epoch 44, Step 192, Loss: 0.47019290924072266\n",
            "Epoch 44, Step 193, Loss: 0.4846862554550171\n",
            "Epoch 44, Step 194, Loss: 0.4267283082008362\n",
            "Epoch 44, Step 195, Loss: 0.5234158039093018\n",
            "Epoch 44, Step 196, Loss: 0.6432692408561707\n",
            "Epoch 44, Step 197, Loss: 0.5462543368339539\n",
            "Epoch 44, Step 198, Loss: 0.4308439791202545\n",
            "Epoch 44, Step 199, Loss: 0.4462074637413025\n",
            "Epoch 44, Step 200, Loss: 0.5319186449050903\n",
            "Epoch 44, Step 201, Loss: 0.6396036744117737\n",
            "Epoch 44, Step 202, Loss: 0.41332998871803284\n",
            "Epoch 44, Step 203, Loss: 0.5299425721168518\n",
            "Epoch 44, Step 204, Loss: 0.4864710867404938\n",
            "Epoch 44, Step 205, Loss: 0.5841813087463379\n",
            "Epoch 44, Step 206, Loss: 0.505541205406189\n",
            "Epoch 44, Step 207, Loss: 0.45342275500297546\n",
            "Epoch 44, Step 208, Loss: 0.3900182545185089\n",
            "Epoch 44, Step 209, Loss: 0.5787510871887207\n",
            "Epoch 44, Step 210, Loss: 0.5277077555656433\n",
            "Epoch 44, Step 211, Loss: 0.44193804264068604\n",
            "Epoch 44, Step 212, Loss: 0.6756168007850647\n",
            "Epoch 44, Step 213, Loss: 0.4833965301513672\n",
            "Epoch 44, Step 214, Loss: 0.6267925500869751\n",
            "Epoch 44, Step 215, Loss: 0.5347391366958618\n",
            "Epoch 44, Step 216, Loss: 0.5307210087776184\n",
            "Epoch 44, Step 217, Loss: 0.5090352296829224\n",
            "Epoch 44, Step 218, Loss: 0.3783484697341919\n",
            "Epoch 44, Step 219, Loss: 0.4951132833957672\n",
            "Epoch 44, Step 220, Loss: 0.47778305411338806\n",
            "Epoch 44, Step 221, Loss: 0.30680403113365173\n",
            "Epoch 44, Step 222, Loss: 0.40839439630508423\n",
            "Epoch 44, Step 223, Loss: 0.5822578072547913\n",
            "Epoch 44, Step 224, Loss: 0.3213399052619934\n",
            "Epoch 44, Step 225, Loss: 0.648188054561615\n",
            "Epoch 44, Step 226, Loss: 0.4843326807022095\n",
            "Epoch 44, Step 227, Loss: 0.6115076541900635\n",
            "Epoch 44, Step 228, Loss: 0.4869295358657837\n",
            "Epoch 44, Step 229, Loss: 0.6566610932350159\n",
            "Epoch 44, Step 230, Loss: 0.5161592960357666\n",
            "Epoch 44, Step 231, Loss: 0.538668692111969\n",
            "Epoch 44, Step 232, Loss: 0.5258603096008301\n",
            "Epoch 44, Step 233, Loss: 0.5083970427513123\n",
            "Epoch 44, Step 234, Loss: 0.5383560061454773\n",
            "Epoch 44, Step 235, Loss: 0.48220378160476685\n",
            "Epoch 44, Step 236, Loss: 0.41078612208366394\n",
            "Epoch 44, Step 237, Loss: 0.5477418303489685\n",
            "Epoch 44, Step 238, Loss: 0.31883037090301514\n",
            "Epoch 44, Step 239, Loss: 0.5915088653564453\n",
            "Epoch 44, Step 240, Loss: 0.4043327271938324\n",
            "Epoch 44, Step 241, Loss: 0.33222252130508423\n",
            "Epoch 44, Step 242, Loss: 0.540712296962738\n",
            "Epoch 44, Step 243, Loss: 0.4884154498577118\n",
            "Epoch 44, Step 244, Loss: 0.45763707160949707\n",
            "Epoch 44, Step 245, Loss: 0.43642985820770264\n",
            "Epoch 44, Step 246, Loss: 0.4028686285018921\n",
            "Epoch 44, Step 247, Loss: 0.507197916507721\n",
            "Epoch 44, Step 248, Loss: 0.3323063254356384\n",
            "Epoch 44, Step 249, Loss: 0.5749327540397644\n",
            "Epoch 44, Step 250, Loss: 0.4458407759666443\n",
            "Epoch 44, Step 251, Loss: 0.5547529458999634\n",
            "Epoch 44, Step 252, Loss: 0.5858861207962036\n",
            "Epoch 44, Step 253, Loss: 0.6194835305213928\n",
            "Epoch 44, Step 254, Loss: 0.5951460599899292\n",
            "Epoch 44, Step 255, Loss: 0.3819507956504822\n",
            "Epoch 44, Step 256, Loss: 0.5907551646232605\n",
            "Epoch 44, Step 257, Loss: 0.5459544062614441\n",
            "Epoch 44, Step 258, Loss: 0.5335135459899902\n",
            "Epoch 44, Step 259, Loss: 0.4074934422969818\n",
            "Epoch 44, Step 260, Loss: 0.5627465844154358\n",
            "Epoch 44, Step 261, Loss: 0.5341526865959167\n",
            "Epoch 44, Step 262, Loss: 0.5218851566314697\n",
            "Epoch 44, Step 263, Loss: 0.5875251889228821\n",
            "Epoch 44, Step 264, Loss: 0.5657552480697632\n",
            "Epoch 44, Step 265, Loss: 0.570683479309082\n",
            "Epoch 44, Step 266, Loss: 0.4643530249595642\n",
            "Epoch 44, Step 267, Loss: 0.6720564961433411\n",
            "Epoch 44, Step 268, Loss: 0.40651652216911316\n",
            "Epoch 44, Step 269, Loss: 0.48163557052612305\n",
            "Epoch 44, Step 270, Loss: 0.47258567810058594\n",
            "Epoch 44, Step 271, Loss: 0.5009831786155701\n",
            "Epoch 44, Step 272, Loss: 0.5846331715583801\n",
            "Epoch 44, Step 273, Loss: 0.5178729295730591\n",
            "Epoch 44, Step 274, Loss: 0.5456723570823669\n",
            "Epoch 44, Step 275, Loss: 0.41886231303215027\n",
            "Epoch 44, Step 276, Loss: 0.45238345861434937\n",
            "Epoch 44, Step 277, Loss: 0.4228591024875641\n",
            "Epoch 44, Step 278, Loss: 0.5747641921043396\n",
            "Epoch 44, Step 279, Loss: 0.471558541059494\n",
            "Epoch 44, Step 280, Loss: 0.5594521760940552\n",
            "Epoch 44, Step 281, Loss: 0.5102583169937134\n",
            "Epoch 44, Step 282, Loss: 0.518082857131958\n",
            "Epoch 44, Step 283, Loss: 0.42043906450271606\n",
            "Epoch 44, Step 284, Loss: 0.5893764495849609\n",
            "Epoch 44, Step 285, Loss: 0.5919174551963806\n",
            "Epoch 44, Step 286, Loss: 0.543938398361206\n",
            "Epoch 44, Step 287, Loss: 0.5788895487785339\n",
            "Epoch 44, Step 288, Loss: 0.45234525203704834\n",
            "Epoch 44, Step 289, Loss: 0.5480961799621582\n",
            "Epoch 44, Step 290, Loss: 0.6351184248924255\n",
            "Epoch 44, Step 291, Loss: 0.5191100239753723\n",
            "Epoch 44, Step 292, Loss: 0.5215778946876526\n",
            "Epoch 44, Step 293, Loss: 0.5681713819503784\n",
            "Epoch 44, Step 294, Loss: 0.5459553599357605\n",
            "Epoch 44, Step 295, Loss: 0.55952388048172\n",
            "Epoch 44, Step 296, Loss: 0.37405458092689514\n",
            "Epoch 44, Step 297, Loss: 0.642133891582489\n",
            "Epoch 44, Step 298, Loss: 0.44332587718963623\n",
            "Epoch 44, Step 299, Loss: 0.2945411801338196\n",
            "Epoch 44, Step 300, Loss: 0.6566913723945618\n",
            "Epoch 44, Step 301, Loss: 0.43138858675956726\n",
            "Epoch 44, Step 302, Loss: 0.5652604699134827\n",
            "Epoch 44, Step 303, Loss: 0.5603694319725037\n",
            "Epoch 44, Step 304, Loss: 0.5145309567451477\n",
            "Epoch 44, Step 305, Loss: 0.4443882405757904\n",
            "Epoch 44, Step 306, Loss: 0.4964410364627838\n",
            "Epoch 44, Step 307, Loss: 0.6087493300437927\n",
            "Epoch 44, Step 308, Loss: 0.5544608235359192\n",
            "Epoch 44, Step 309, Loss: 0.4596193730831146\n",
            "Epoch 44, Step 310, Loss: 0.6022771596908569\n",
            "Epoch 44, Step 311, Loss: 0.4777219593524933\n",
            "Epoch 44, Step 312, Loss: 0.4602707326412201\n",
            "Epoch 44 end, avg train loss: 0.5140736669587632\n",
            "Epoch 44 end, avg val loss: 0.5731474553482442, accuracy: 80.37%\n",
            "Epoch 45, Step 0, Loss: 0.45486560463905334\n",
            "Epoch 45, Step 1, Loss: 0.4340042173862457\n",
            "Epoch 45, Step 2, Loss: 0.5092085599899292\n",
            "Epoch 45, Step 3, Loss: 0.42653119564056396\n",
            "Epoch 45, Step 4, Loss: 0.4352051913738251\n",
            "Epoch 45, Step 5, Loss: 0.49763086438179016\n",
            "Epoch 45, Step 6, Loss: 0.5191410779953003\n",
            "Epoch 45, Step 7, Loss: 0.6021862626075745\n",
            "Epoch 45, Step 8, Loss: 0.5889743566513062\n",
            "Epoch 45, Step 9, Loss: 0.49626824259757996\n",
            "Epoch 45, Step 10, Loss: 0.46623703837394714\n",
            "Epoch 45, Step 11, Loss: 0.4964587688446045\n",
            "Epoch 45, Step 12, Loss: 0.3956398367881775\n",
            "Epoch 45, Step 13, Loss: 0.4212137758731842\n",
            "Epoch 45, Step 14, Loss: 0.5931503176689148\n",
            "Epoch 45, Step 15, Loss: 0.6399477124214172\n",
            "Epoch 45, Step 16, Loss: 0.32515570521354675\n",
            "Epoch 45, Step 17, Loss: 0.5404462814331055\n",
            "Epoch 45, Step 18, Loss: 0.3694114089012146\n",
            "Epoch 45, Step 19, Loss: 0.741309642791748\n",
            "Epoch 45, Step 20, Loss: 0.5171711444854736\n",
            "Epoch 45, Step 21, Loss: 0.45344164967536926\n",
            "Epoch 45, Step 22, Loss: 0.37321293354034424\n",
            "Epoch 45, Step 23, Loss: 0.42131099104881287\n",
            "Epoch 45, Step 24, Loss: 0.620604395866394\n",
            "Epoch 45, Step 25, Loss: 0.5873925685882568\n",
            "Epoch 45, Step 26, Loss: 0.6231821179389954\n",
            "Epoch 45, Step 27, Loss: 0.47784945368766785\n",
            "Epoch 45, Step 28, Loss: 0.5107791423797607\n",
            "Epoch 45, Step 29, Loss: 0.4881380498409271\n",
            "Epoch 45, Step 30, Loss: 0.5244114398956299\n",
            "Epoch 45, Step 31, Loss: 0.5631459355354309\n",
            "Epoch 45, Step 32, Loss: 0.47595852613449097\n",
            "Epoch 45, Step 33, Loss: 0.4582374393939972\n",
            "Epoch 45, Step 34, Loss: 0.4902827739715576\n",
            "Epoch 45, Step 35, Loss: 0.5187386274337769\n",
            "Epoch 45, Step 36, Loss: 0.4758458733558655\n",
            "Epoch 45, Step 37, Loss: 0.5394408702850342\n",
            "Epoch 45, Step 38, Loss: 0.5653245449066162\n",
            "Epoch 45, Step 39, Loss: 0.49619725346565247\n",
            "Epoch 45, Step 40, Loss: 0.44169729948043823\n",
            "Epoch 45, Step 41, Loss: 0.5810028910636902\n",
            "Epoch 45, Step 42, Loss: 0.46363601088523865\n",
            "Epoch 45, Step 43, Loss: 0.5788922309875488\n",
            "Epoch 45, Step 44, Loss: 0.47754228115081787\n",
            "Epoch 45, Step 45, Loss: 0.524886429309845\n",
            "Epoch 45, Step 46, Loss: 0.5123475193977356\n",
            "Epoch 45, Step 47, Loss: 0.38239890336990356\n",
            "Epoch 45, Step 48, Loss: 0.4612608850002289\n",
            "Epoch 45, Step 49, Loss: 0.4996432960033417\n",
            "Epoch 45, Step 50, Loss: 0.6147658824920654\n",
            "Epoch 45, Step 51, Loss: 0.46444278955459595\n",
            "Epoch 45, Step 52, Loss: 0.4780879020690918\n",
            "Epoch 45, Step 53, Loss: 0.4917154312133789\n",
            "Epoch 45, Step 54, Loss: 0.5238063335418701\n",
            "Epoch 45, Step 55, Loss: 0.6020293235778809\n",
            "Epoch 45, Step 56, Loss: 0.7012495994567871\n",
            "Epoch 45, Step 57, Loss: 0.3968560993671417\n",
            "Epoch 45, Step 58, Loss: 0.522505521774292\n",
            "Epoch 45, Step 59, Loss: 0.5533683896064758\n",
            "Epoch 45, Step 60, Loss: 0.5212982892990112\n",
            "Epoch 45, Step 61, Loss: 0.4788191318511963\n",
            "Epoch 45, Step 62, Loss: 0.5314387083053589\n",
            "Epoch 45, Step 63, Loss: 0.4740019738674164\n",
            "Epoch 45, Step 64, Loss: 0.5061189532279968\n",
            "Epoch 45, Step 65, Loss: 0.5127456784248352\n",
            "Epoch 45, Step 66, Loss: 0.5133922696113586\n",
            "Epoch 45, Step 67, Loss: 0.3795871138572693\n",
            "Epoch 45, Step 68, Loss: 0.4393526315689087\n",
            "Epoch 45, Step 69, Loss: 0.4693279564380646\n",
            "Epoch 45, Step 70, Loss: 0.3797999918460846\n",
            "Epoch 45, Step 71, Loss: 0.6228489279747009\n",
            "Epoch 45, Step 72, Loss: 0.6070184111595154\n",
            "Epoch 45, Step 73, Loss: 0.6248679161071777\n",
            "Epoch 45, Step 74, Loss: 0.6102457046508789\n",
            "Epoch 45, Step 75, Loss: 0.44229012727737427\n",
            "Epoch 45, Step 76, Loss: 0.42603597044944763\n",
            "Epoch 45, Step 77, Loss: 0.5039855241775513\n",
            "Epoch 45, Step 78, Loss: 0.5069631934165955\n",
            "Epoch 45, Step 79, Loss: 0.5721829533576965\n",
            "Epoch 45, Step 80, Loss: 0.4685390293598175\n",
            "Epoch 45, Step 81, Loss: 0.49438464641571045\n",
            "Epoch 45, Step 82, Loss: 0.5754719376564026\n",
            "Epoch 45, Step 83, Loss: 0.42549410462379456\n",
            "Epoch 45, Step 84, Loss: 0.4213138222694397\n",
            "Epoch 45, Step 85, Loss: 0.550728440284729\n",
            "Epoch 45, Step 86, Loss: 0.4443034827709198\n",
            "Epoch 45, Step 87, Loss: 0.5009014010429382\n",
            "Epoch 45, Step 88, Loss: 0.5725933313369751\n",
            "Epoch 45, Step 89, Loss: 0.5615116357803345\n",
            "Epoch 45, Step 90, Loss: 0.5634704828262329\n",
            "Epoch 45, Step 91, Loss: 0.38465553522109985\n",
            "Epoch 45, Step 92, Loss: 0.6672365665435791\n",
            "Epoch 45, Step 93, Loss: 0.6356591582298279\n",
            "Epoch 45, Step 94, Loss: 0.46163198351860046\n",
            "Epoch 45, Step 95, Loss: 0.47164487838745117\n",
            "Epoch 45, Step 96, Loss: 0.5010601282119751\n",
            "Epoch 45, Step 97, Loss: 0.5827240347862244\n",
            "Epoch 45, Step 98, Loss: 0.7050935626029968\n",
            "Epoch 45, Step 99, Loss: 0.4468533396720886\n",
            "Epoch 45, Step 100, Loss: 0.4466080963611603\n",
            "Epoch 45, Step 101, Loss: 0.4555850923061371\n",
            "Epoch 45, Step 102, Loss: 0.49389928579330444\n",
            "Epoch 45, Step 103, Loss: 0.330418199300766\n",
            "Epoch 45, Step 104, Loss: 0.5558185577392578\n",
            "Epoch 45, Step 105, Loss: 0.5666114687919617\n",
            "Epoch 45, Step 106, Loss: 0.3506765365600586\n",
            "Epoch 45, Step 107, Loss: 0.43791669607162476\n",
            "Epoch 45, Step 108, Loss: 0.5217587947845459\n",
            "Epoch 45, Step 109, Loss: 0.5567149519920349\n",
            "Epoch 45, Step 110, Loss: 0.550812840461731\n",
            "Epoch 45, Step 111, Loss: 0.6776045560836792\n",
            "Epoch 45, Step 112, Loss: 0.5345713496208191\n",
            "Epoch 45, Step 113, Loss: 0.46122047305107117\n",
            "Epoch 45, Step 114, Loss: 0.6716275215148926\n",
            "Epoch 45, Step 115, Loss: 0.5507140755653381\n",
            "Epoch 45, Step 116, Loss: 0.5262923240661621\n",
            "Epoch 45, Step 117, Loss: 0.4382396936416626\n",
            "Epoch 45, Step 118, Loss: 0.5538230538368225\n",
            "Epoch 45, Step 119, Loss: 0.6207230091094971\n",
            "Epoch 45, Step 120, Loss: 0.645707368850708\n",
            "Epoch 45, Step 121, Loss: 0.5709885954856873\n",
            "Epoch 45, Step 122, Loss: 0.5757286548614502\n",
            "Epoch 45, Step 123, Loss: 0.5615125894546509\n",
            "Epoch 45, Step 124, Loss: 0.5074288845062256\n",
            "Epoch 45, Step 125, Loss: 0.6548627614974976\n",
            "Epoch 45, Step 126, Loss: 0.47849923372268677\n",
            "Epoch 45, Step 127, Loss: 0.41830700635910034\n",
            "Epoch 45, Step 128, Loss: 0.5823564529418945\n",
            "Epoch 45, Step 129, Loss: 0.43130072951316833\n",
            "Epoch 45, Step 130, Loss: 0.48067864775657654\n",
            "Epoch 45, Step 131, Loss: 0.43953368067741394\n",
            "Epoch 45, Step 132, Loss: 0.5099698305130005\n",
            "Epoch 45, Step 133, Loss: 0.5215315222740173\n",
            "Epoch 45, Step 134, Loss: 0.4608875811100006\n",
            "Epoch 45, Step 135, Loss: 0.3907100558280945\n",
            "Epoch 45, Step 136, Loss: 0.4454472064971924\n",
            "Epoch 45, Step 137, Loss: 0.5881325006484985\n",
            "Epoch 45, Step 138, Loss: 0.7221935391426086\n",
            "Epoch 45, Step 139, Loss: 0.3844757676124573\n",
            "Epoch 45, Step 140, Loss: 0.47612303495407104\n",
            "Epoch 45, Step 141, Loss: 0.5786216259002686\n",
            "Epoch 45, Step 142, Loss: 0.4867648184299469\n",
            "Epoch 45, Step 143, Loss: 0.5197318196296692\n",
            "Epoch 45, Step 144, Loss: 0.5324565768241882\n",
            "Epoch 45, Step 145, Loss: 0.3959522843360901\n",
            "Epoch 45, Step 146, Loss: 0.36946067214012146\n",
            "Epoch 45, Step 147, Loss: 0.5430797934532166\n",
            "Epoch 45, Step 148, Loss: 0.5189046859741211\n",
            "Epoch 45, Step 149, Loss: 0.48101282119750977\n",
            "Epoch 45, Step 150, Loss: 0.45379430055618286\n",
            "Epoch 45, Step 151, Loss: 0.5812385082244873\n",
            "Epoch 45, Step 152, Loss: 0.41994863748550415\n",
            "Epoch 45, Step 153, Loss: 0.5791930556297302\n",
            "Epoch 45, Step 154, Loss: 0.42607319355010986\n",
            "Epoch 45, Step 155, Loss: 0.4247108995914459\n",
            "Epoch 45, Step 156, Loss: 0.38757264614105225\n",
            "Epoch 45, Step 157, Loss: 0.5479317903518677\n",
            "Epoch 45, Step 158, Loss: 0.583656907081604\n",
            "Epoch 45, Step 159, Loss: 0.4555715322494507\n",
            "Epoch 45, Step 160, Loss: 0.3819319009780884\n",
            "Epoch 45, Step 161, Loss: 0.490987628698349\n",
            "Epoch 45, Step 162, Loss: 0.7171823978424072\n",
            "Epoch 45, Step 163, Loss: 0.5519680976867676\n",
            "Epoch 45, Step 164, Loss: 0.5692225694656372\n",
            "Epoch 45, Step 165, Loss: 0.5891249775886536\n",
            "Epoch 45, Step 166, Loss: 0.5757565498352051\n",
            "Epoch 45, Step 167, Loss: 0.4632331132888794\n",
            "Epoch 45, Step 168, Loss: 0.4265240728855133\n",
            "Epoch 45, Step 169, Loss: 0.6189976930618286\n",
            "Epoch 45, Step 170, Loss: 0.5244761109352112\n",
            "Epoch 45, Step 171, Loss: 0.4217439293861389\n",
            "Epoch 45, Step 172, Loss: 0.43006736040115356\n",
            "Epoch 45, Step 173, Loss: 0.7077619433403015\n",
            "Epoch 45, Step 174, Loss: 0.5219442844390869\n",
            "Epoch 45, Step 175, Loss: 0.5016281604766846\n",
            "Epoch 45, Step 176, Loss: 0.5555127263069153\n",
            "Epoch 45, Step 177, Loss: 0.503852367401123\n",
            "Epoch 45, Step 178, Loss: 0.4040898084640503\n",
            "Epoch 45, Step 179, Loss: 0.7034043669700623\n",
            "Epoch 45, Step 180, Loss: 0.47492411732673645\n",
            "Epoch 45, Step 181, Loss: 0.40133896470069885\n",
            "Epoch 45, Step 182, Loss: 0.5501190423965454\n",
            "Epoch 45, Step 183, Loss: 0.39637047052383423\n",
            "Epoch 45, Step 184, Loss: 0.47046220302581787\n",
            "Epoch 45, Step 185, Loss: 0.416147381067276\n",
            "Epoch 45, Step 186, Loss: 0.41310515999794006\n",
            "Epoch 45, Step 187, Loss: 0.4192085564136505\n",
            "Epoch 45, Step 188, Loss: 0.6968975067138672\n",
            "Epoch 45, Step 189, Loss: 0.443646639585495\n",
            "Epoch 45, Step 190, Loss: 0.43591955304145813\n",
            "Epoch 45, Step 191, Loss: 0.5103287696838379\n",
            "Epoch 45, Step 192, Loss: 0.5800550580024719\n",
            "Epoch 45, Step 193, Loss: 0.6172932386398315\n",
            "Epoch 45, Step 194, Loss: 0.45487844944000244\n",
            "Epoch 45, Step 195, Loss: 0.41237783432006836\n",
            "Epoch 45, Step 196, Loss: 0.5021066069602966\n",
            "Epoch 45, Step 197, Loss: 0.4645451605319977\n",
            "Epoch 45, Step 198, Loss: 0.525842547416687\n",
            "Epoch 45, Step 199, Loss: 0.5228875875473022\n",
            "Epoch 45, Step 200, Loss: 0.38687431812286377\n",
            "Epoch 45, Step 201, Loss: 0.3535940647125244\n",
            "Epoch 45, Step 202, Loss: 0.41870155930519104\n",
            "Epoch 45, Step 203, Loss: 0.45798176527023315\n",
            "Epoch 45, Step 204, Loss: 0.45560842752456665\n",
            "Epoch 45, Step 205, Loss: 0.5052976012229919\n",
            "Epoch 45, Step 206, Loss: 0.534460186958313\n",
            "Epoch 45, Step 207, Loss: 0.550638735294342\n",
            "Epoch 45, Step 208, Loss: 0.584101140499115\n",
            "Epoch 45, Step 209, Loss: 0.5617087483406067\n",
            "Epoch 45, Step 210, Loss: 0.33833685517311096\n",
            "Epoch 45, Step 211, Loss: 0.42521509528160095\n",
            "Epoch 45, Step 212, Loss: 0.6815186142921448\n",
            "Epoch 45, Step 213, Loss: 0.3902215361595154\n",
            "Epoch 45, Step 214, Loss: 0.3432024419307709\n",
            "Epoch 45, Step 215, Loss: 0.5588527917861938\n",
            "Epoch 45, Step 216, Loss: 0.5592841506004333\n",
            "Epoch 45, Step 217, Loss: 0.6549974083900452\n",
            "Epoch 45, Step 218, Loss: 0.5316821932792664\n",
            "Epoch 45, Step 219, Loss: 0.5422813296318054\n",
            "Epoch 45, Step 220, Loss: 0.45471835136413574\n",
            "Epoch 45, Step 221, Loss: 0.5037313103675842\n",
            "Epoch 45, Step 222, Loss: 0.6376814246177673\n",
            "Epoch 45, Step 223, Loss: 0.547693133354187\n",
            "Epoch 45, Step 224, Loss: 0.5295504331588745\n",
            "Epoch 45, Step 225, Loss: 0.5313052535057068\n",
            "Epoch 45, Step 226, Loss: 0.6175866723060608\n",
            "Epoch 45, Step 227, Loss: 0.47684985399246216\n",
            "Epoch 45, Step 228, Loss: 0.5109790563583374\n",
            "Epoch 45, Step 229, Loss: 0.6546879410743713\n",
            "Epoch 45, Step 230, Loss: 0.5201693773269653\n",
            "Epoch 45, Step 231, Loss: 0.589830219745636\n",
            "Epoch 45, Step 232, Loss: 0.6036306619644165\n",
            "Epoch 45, Step 233, Loss: 0.4724199175834656\n",
            "Epoch 45, Step 234, Loss: 0.3928866982460022\n",
            "Epoch 45, Step 235, Loss: 0.48218151926994324\n",
            "Epoch 45, Step 236, Loss: 0.5663272738456726\n",
            "Epoch 45, Step 237, Loss: 0.5398459434509277\n",
            "Epoch 45, Step 238, Loss: 0.5247572064399719\n",
            "Epoch 45, Step 239, Loss: 0.4969645142555237\n",
            "Epoch 45, Step 240, Loss: 0.5243486166000366\n",
            "Epoch 45, Step 241, Loss: 0.611536979675293\n",
            "Epoch 45, Step 242, Loss: 0.6539137959480286\n",
            "Epoch 45, Step 243, Loss: 0.5349937677383423\n",
            "Epoch 45, Step 244, Loss: 0.5574581027030945\n",
            "Epoch 45, Step 245, Loss: 0.5424327254295349\n",
            "Epoch 45, Step 246, Loss: 0.4631084203720093\n",
            "Epoch 45, Step 247, Loss: 0.5566549897193909\n",
            "Epoch 45, Step 248, Loss: 0.46022817492485046\n",
            "Epoch 45, Step 249, Loss: 0.5106326937675476\n",
            "Epoch 45, Step 250, Loss: 0.5051395893096924\n",
            "Epoch 45, Step 251, Loss: 0.5913671255111694\n",
            "Epoch 45, Step 252, Loss: 0.6523272395133972\n",
            "Epoch 45, Step 253, Loss: 0.44426336884498596\n",
            "Epoch 45, Step 254, Loss: 0.6630129814147949\n",
            "Epoch 45, Step 255, Loss: 0.5544317960739136\n",
            "Epoch 45, Step 256, Loss: 0.4336794316768646\n",
            "Epoch 45, Step 257, Loss: 0.5670280456542969\n",
            "Epoch 45, Step 258, Loss: 0.6504784226417542\n",
            "Epoch 45, Step 259, Loss: 0.6385643482208252\n",
            "Epoch 45, Step 260, Loss: 0.48227056860923767\n",
            "Epoch 45, Step 261, Loss: 0.5676112771034241\n",
            "Epoch 45, Step 262, Loss: 0.5200585126876831\n",
            "Epoch 45, Step 263, Loss: 0.5023740530014038\n",
            "Epoch 45, Step 264, Loss: 0.6038767695426941\n",
            "Epoch 45, Step 265, Loss: 0.39274728298187256\n",
            "Epoch 45, Step 266, Loss: 0.4058956503868103\n",
            "Epoch 45, Step 267, Loss: 0.4646936058998108\n",
            "Epoch 45, Step 268, Loss: 0.4184783101081848\n",
            "Epoch 45, Step 269, Loss: 0.44315317273139954\n",
            "Epoch 45, Step 270, Loss: 0.6094180345535278\n",
            "Epoch 45, Step 271, Loss: 0.5684905648231506\n",
            "Epoch 45, Step 272, Loss: 0.5142970681190491\n",
            "Epoch 45, Step 273, Loss: 0.5232178568840027\n",
            "Epoch 45, Step 274, Loss: 0.4392954707145691\n",
            "Epoch 45, Step 275, Loss: 0.5360431671142578\n",
            "Epoch 45, Step 276, Loss: 0.4877454936504364\n",
            "Epoch 45, Step 277, Loss: 0.41249924898147583\n",
            "Epoch 45, Step 278, Loss: 0.5012152194976807\n",
            "Epoch 45, Step 279, Loss: 0.46016016602516174\n",
            "Epoch 45, Step 280, Loss: 0.5635651350021362\n",
            "Epoch 45, Step 281, Loss: 0.6190959215164185\n",
            "Epoch 45, Step 282, Loss: 0.4614924192428589\n",
            "Epoch 45, Step 283, Loss: 0.5928903222084045\n",
            "Epoch 45, Step 284, Loss: 0.41686004400253296\n",
            "Epoch 45, Step 285, Loss: 0.3539268970489502\n",
            "Epoch 45, Step 286, Loss: 0.48927393555641174\n",
            "Epoch 45, Step 287, Loss: 0.5547103881835938\n",
            "Epoch 45, Step 288, Loss: 0.45360681414604187\n",
            "Epoch 45, Step 289, Loss: 0.5406869053840637\n",
            "Epoch 45, Step 290, Loss: 0.6643886566162109\n",
            "Epoch 45, Step 291, Loss: 0.4583486318588257\n",
            "Epoch 45, Step 292, Loss: 0.3769165873527527\n",
            "Epoch 45, Step 293, Loss: 0.5096589922904968\n",
            "Epoch 45, Step 294, Loss: 0.5517870187759399\n",
            "Epoch 45, Step 295, Loss: 0.527771532535553\n",
            "Epoch 45, Step 296, Loss: 0.5101334452629089\n",
            "Epoch 45, Step 297, Loss: 0.46873581409454346\n",
            "Epoch 45, Step 298, Loss: 0.3759596347808838\n",
            "Epoch 45, Step 299, Loss: 0.4075797200202942\n",
            "Epoch 45, Step 300, Loss: 0.5589799880981445\n",
            "Epoch 45, Step 301, Loss: 0.6569469571113586\n",
            "Epoch 45, Step 302, Loss: 0.45107564330101013\n",
            "Epoch 45, Step 303, Loss: 0.3993200957775116\n",
            "Epoch 45, Step 304, Loss: 0.4417732357978821\n",
            "Epoch 45, Step 305, Loss: 0.5347201824188232\n",
            "Epoch 45, Step 306, Loss: 0.5177236199378967\n",
            "Epoch 45, Step 307, Loss: 0.37936270236968994\n",
            "Epoch 45, Step 308, Loss: 0.4498492479324341\n",
            "Epoch 45, Step 309, Loss: 0.5246779322624207\n",
            "Epoch 45, Step 310, Loss: 0.43521973490715027\n",
            "Epoch 45, Step 311, Loss: 0.4491764008998871\n",
            "Epoch 45, Step 312, Loss: 0.7935850620269775\n",
            "Epoch 45 end, avg train loss: 0.5102627185015632\n",
            "Epoch 45 end, avg val loss: 0.564445388468006, accuracy: 80.43%\n",
            "Epoch 46, Step 0, Loss: 0.6499781608581543\n",
            "Epoch 46, Step 1, Loss: 0.4388211667537689\n",
            "Epoch 46, Step 2, Loss: 0.5548956990242004\n",
            "Epoch 46, Step 3, Loss: 0.5554722547531128\n",
            "Epoch 46, Step 4, Loss: 0.5701738595962524\n",
            "Epoch 46, Step 5, Loss: 0.506584882736206\n",
            "Epoch 46, Step 6, Loss: 0.45538705587387085\n",
            "Epoch 46, Step 7, Loss: 0.40469521284103394\n",
            "Epoch 46, Step 8, Loss: 0.5764602422714233\n",
            "Epoch 46, Step 9, Loss: 0.6059360504150391\n",
            "Epoch 46, Step 10, Loss: 0.5542604327201843\n",
            "Epoch 46, Step 11, Loss: 0.5026326775550842\n",
            "Epoch 46, Step 12, Loss: 0.4940529465675354\n",
            "Epoch 46, Step 13, Loss: 0.45204171538352966\n",
            "Epoch 46, Step 14, Loss: 0.4060724377632141\n",
            "Epoch 46, Step 15, Loss: 0.5172662138938904\n",
            "Epoch 46, Step 16, Loss: 0.4914328455924988\n",
            "Epoch 46, Step 17, Loss: 0.5616920590400696\n",
            "Epoch 46, Step 18, Loss: 0.5085666179656982\n",
            "Epoch 46, Step 19, Loss: 0.5134374499320984\n",
            "Epoch 46, Step 20, Loss: 0.49997732043266296\n",
            "Epoch 46, Step 21, Loss: 0.4592517018318176\n",
            "Epoch 46, Step 22, Loss: 0.3455858528614044\n",
            "Epoch 46, Step 23, Loss: 0.5734782218933105\n",
            "Epoch 46, Step 24, Loss: 0.5288732647895813\n",
            "Epoch 46, Step 25, Loss: 0.41865667700767517\n",
            "Epoch 46, Step 26, Loss: 0.5433086156845093\n",
            "Epoch 46, Step 27, Loss: 0.40476515889167786\n",
            "Epoch 46, Step 28, Loss: 0.5248103737831116\n",
            "Epoch 46, Step 29, Loss: 0.5454931259155273\n",
            "Epoch 46, Step 30, Loss: 0.45748546719551086\n",
            "Epoch 46, Step 31, Loss: 0.5291866064071655\n",
            "Epoch 46, Step 32, Loss: 0.3744652271270752\n",
            "Epoch 46, Step 33, Loss: 0.6058394312858582\n",
            "Epoch 46, Step 34, Loss: 0.4050009548664093\n",
            "Epoch 46, Step 35, Loss: 0.44685637950897217\n",
            "Epoch 46, Step 36, Loss: 0.6133639216423035\n",
            "Epoch 46, Step 37, Loss: 0.4674188792705536\n",
            "Epoch 46, Step 38, Loss: 0.46876025199890137\n",
            "Epoch 46, Step 39, Loss: 0.5242141485214233\n",
            "Epoch 46, Step 40, Loss: 0.6007696390151978\n",
            "Epoch 46, Step 41, Loss: 0.6663493514060974\n",
            "Epoch 46, Step 42, Loss: 0.5879970788955688\n",
            "Epoch 46, Step 43, Loss: 0.4042993485927582\n",
            "Epoch 46, Step 44, Loss: 0.5995318293571472\n",
            "Epoch 46, Step 45, Loss: 0.5827535390853882\n",
            "Epoch 46, Step 46, Loss: 0.5181335806846619\n",
            "Epoch 46, Step 47, Loss: 0.4326438009738922\n",
            "Epoch 46, Step 48, Loss: 0.5559232831001282\n",
            "Epoch 46, Step 49, Loss: 0.5101413130760193\n",
            "Epoch 46, Step 50, Loss: 0.4412645697593689\n",
            "Epoch 46, Step 51, Loss: 0.5011250376701355\n",
            "Epoch 46, Step 52, Loss: 0.6749153137207031\n",
            "Epoch 46, Step 53, Loss: 0.3474661409854889\n",
            "Epoch 46, Step 54, Loss: 0.545095682144165\n",
            "Epoch 46, Step 55, Loss: 0.591031551361084\n",
            "Epoch 46, Step 56, Loss: 0.352791428565979\n",
            "Epoch 46, Step 57, Loss: 0.6029033660888672\n",
            "Epoch 46, Step 58, Loss: 0.6650888323783875\n",
            "Epoch 46, Step 59, Loss: 0.6000049114227295\n",
            "Epoch 46, Step 60, Loss: 0.3896753787994385\n",
            "Epoch 46, Step 61, Loss: 0.3531317710876465\n",
            "Epoch 46, Step 62, Loss: 0.437640905380249\n",
            "Epoch 46, Step 63, Loss: 0.5282699465751648\n",
            "Epoch 46, Step 64, Loss: 0.542509913444519\n",
            "Epoch 46, Step 65, Loss: 0.33404311537742615\n",
            "Epoch 46, Step 66, Loss: 0.41869667172431946\n",
            "Epoch 46, Step 67, Loss: 0.5245149731636047\n",
            "Epoch 46, Step 68, Loss: 0.3978649079799652\n",
            "Epoch 46, Step 69, Loss: 0.5285992622375488\n",
            "Epoch 46, Step 70, Loss: 0.4614686369895935\n",
            "Epoch 46, Step 71, Loss: 0.44624000787734985\n",
            "Epoch 46, Step 72, Loss: 0.404026597738266\n",
            "Epoch 46, Step 73, Loss: 0.5765573978424072\n",
            "Epoch 46, Step 74, Loss: 0.5354133248329163\n",
            "Epoch 46, Step 75, Loss: 0.5540070533752441\n",
            "Epoch 46, Step 76, Loss: 0.3969581127166748\n",
            "Epoch 46, Step 77, Loss: 0.47520211338996887\n",
            "Epoch 46, Step 78, Loss: 0.5929713249206543\n",
            "Epoch 46, Step 79, Loss: 0.5057913064956665\n",
            "Epoch 46, Step 80, Loss: 0.524413526058197\n",
            "Epoch 46, Step 81, Loss: 0.516434907913208\n",
            "Epoch 46, Step 82, Loss: 0.3914491832256317\n",
            "Epoch 46, Step 83, Loss: 0.3666914701461792\n",
            "Epoch 46, Step 84, Loss: 0.5228145122528076\n",
            "Epoch 46, Step 85, Loss: 0.46777594089508057\n",
            "Epoch 46, Step 86, Loss: 0.48835793137550354\n",
            "Epoch 46, Step 87, Loss: 0.4673880338668823\n",
            "Epoch 46, Step 88, Loss: 0.4027353823184967\n",
            "Epoch 46, Step 89, Loss: 0.5059380531311035\n",
            "Epoch 46, Step 90, Loss: 0.530164361000061\n",
            "Epoch 46, Step 91, Loss: 0.4776293933391571\n",
            "Epoch 46, Step 92, Loss: 0.50267094373703\n",
            "Epoch 46, Step 93, Loss: 0.547042727470398\n",
            "Epoch 46, Step 94, Loss: 0.5560318827629089\n",
            "Epoch 46, Step 95, Loss: 0.5547890663146973\n",
            "Epoch 46, Step 96, Loss: 0.42473486065864563\n",
            "Epoch 46, Step 97, Loss: 0.6353972554206848\n",
            "Epoch 46, Step 98, Loss: 0.5207053422927856\n",
            "Epoch 46, Step 99, Loss: 0.5053893327713013\n",
            "Epoch 46, Step 100, Loss: 0.4737207293510437\n",
            "Epoch 46, Step 101, Loss: 0.4498714506626129\n",
            "Epoch 46, Step 102, Loss: 0.36880993843078613\n",
            "Epoch 46, Step 103, Loss: 0.40570908784866333\n",
            "Epoch 46, Step 104, Loss: 0.49800533056259155\n",
            "Epoch 46, Step 105, Loss: 0.6117613315582275\n",
            "Epoch 46, Step 106, Loss: 0.5359917879104614\n",
            "Epoch 46, Step 107, Loss: 0.3491221070289612\n",
            "Epoch 46, Step 108, Loss: 0.5320287346839905\n",
            "Epoch 46, Step 109, Loss: 0.4146389961242676\n",
            "Epoch 46, Step 110, Loss: 0.5091786980628967\n",
            "Epoch 46, Step 111, Loss: 0.45300155878067017\n",
            "Epoch 46, Step 112, Loss: 0.46563488245010376\n",
            "Epoch 46, Step 113, Loss: 0.565415620803833\n",
            "Epoch 46, Step 114, Loss: 0.5046761631965637\n",
            "Epoch 46, Step 115, Loss: 0.4687053859233856\n",
            "Epoch 46, Step 116, Loss: 0.4585232138633728\n",
            "Epoch 46, Step 117, Loss: 0.5940513014793396\n",
            "Epoch 46, Step 118, Loss: 0.5357427597045898\n",
            "Epoch 46, Step 119, Loss: 0.4474121928215027\n",
            "Epoch 46, Step 120, Loss: 0.4428836703300476\n",
            "Epoch 46, Step 121, Loss: 0.6372190713882446\n",
            "Epoch 46, Step 122, Loss: 0.5768639445304871\n",
            "Epoch 46, Step 123, Loss: 0.5535243153572083\n",
            "Epoch 46, Step 124, Loss: 0.6762769222259521\n",
            "Epoch 46, Step 125, Loss: 0.4443620443344116\n",
            "Epoch 46, Step 126, Loss: 0.4997747838497162\n",
            "Epoch 46, Step 127, Loss: 0.5498945713043213\n",
            "Epoch 46, Step 128, Loss: 0.5408449172973633\n",
            "Epoch 46, Step 129, Loss: 0.3578534424304962\n",
            "Epoch 46, Step 130, Loss: 0.5177708864212036\n",
            "Epoch 46, Step 131, Loss: 0.5568440556526184\n",
            "Epoch 46, Step 132, Loss: 0.5615848302841187\n",
            "Epoch 46, Step 133, Loss: 0.5587822794914246\n",
            "Epoch 46, Step 134, Loss: 0.5583081841468811\n",
            "Epoch 46, Step 135, Loss: 0.5782399773597717\n",
            "Epoch 46, Step 136, Loss: 0.46378907561302185\n",
            "Epoch 46, Step 137, Loss: 0.5623716711997986\n",
            "Epoch 46, Step 138, Loss: 0.32756033539772034\n",
            "Epoch 46, Step 139, Loss: 0.5481039881706238\n",
            "Epoch 46, Step 140, Loss: 0.48508018255233765\n",
            "Epoch 46, Step 141, Loss: 0.5822239518165588\n",
            "Epoch 46, Step 142, Loss: 0.5781812071800232\n",
            "Epoch 46, Step 143, Loss: 0.6581240296363831\n",
            "Epoch 46, Step 144, Loss: 0.4617748558521271\n",
            "Epoch 46, Step 145, Loss: 0.49629703164100647\n",
            "Epoch 46, Step 146, Loss: 0.5814943313598633\n",
            "Epoch 46, Step 147, Loss: 0.4428051710128784\n",
            "Epoch 46, Step 148, Loss: 0.5310714244842529\n",
            "Epoch 46, Step 149, Loss: 0.599600613117218\n",
            "Epoch 46, Step 150, Loss: 0.41156965494155884\n",
            "Epoch 46, Step 151, Loss: 0.4287746250629425\n",
            "Epoch 46, Step 152, Loss: 0.6722642183303833\n",
            "Epoch 46, Step 153, Loss: 0.4139464497566223\n",
            "Epoch 46, Step 154, Loss: 0.4637988209724426\n",
            "Epoch 46, Step 155, Loss: 0.5297145843505859\n",
            "Epoch 46, Step 156, Loss: 0.47959956526756287\n",
            "Epoch 46, Step 157, Loss: 0.47427618503570557\n",
            "Epoch 46, Step 158, Loss: 0.6080887913703918\n",
            "Epoch 46, Step 159, Loss: 0.6286785006523132\n",
            "Epoch 46, Step 160, Loss: 0.4477604329586029\n",
            "Epoch 46, Step 161, Loss: 0.4560270309448242\n",
            "Epoch 46, Step 162, Loss: 0.5346654057502747\n",
            "Epoch 46, Step 163, Loss: 0.5353969931602478\n",
            "Epoch 46, Step 164, Loss: 0.5284048914909363\n",
            "Epoch 46, Step 165, Loss: 0.5836849212646484\n",
            "Epoch 46, Step 166, Loss: 0.5342515110969543\n",
            "Epoch 46, Step 167, Loss: 0.6165895462036133\n",
            "Epoch 46, Step 168, Loss: 0.4196893870830536\n",
            "Epoch 46, Step 169, Loss: 0.38120535016059875\n",
            "Epoch 46, Step 170, Loss: 0.4881283640861511\n",
            "Epoch 46, Step 171, Loss: 0.5207153558731079\n",
            "Epoch 46, Step 172, Loss: 0.49887192249298096\n",
            "Epoch 46, Step 173, Loss: 0.40424710512161255\n",
            "Epoch 46, Step 174, Loss: 0.4553202688694\n",
            "Epoch 46, Step 175, Loss: 0.5527876615524292\n",
            "Epoch 46, Step 176, Loss: 0.6300846934318542\n",
            "Epoch 46, Step 177, Loss: 0.5104089379310608\n",
            "Epoch 46, Step 178, Loss: 0.5788147449493408\n",
            "Epoch 46, Step 179, Loss: 0.48059195280075073\n",
            "Epoch 46, Step 180, Loss: 0.4662606120109558\n",
            "Epoch 46, Step 181, Loss: 0.6827192902565002\n",
            "Epoch 46, Step 182, Loss: 0.5923643112182617\n",
            "Epoch 46, Step 183, Loss: 0.5775150656700134\n",
            "Epoch 46, Step 184, Loss: 0.5387322306632996\n",
            "Epoch 46, Step 185, Loss: 0.40463995933532715\n",
            "Epoch 46, Step 186, Loss: 0.6044149994850159\n",
            "Epoch 46, Step 187, Loss: 0.37813782691955566\n",
            "Epoch 46, Step 188, Loss: 0.5951072573661804\n",
            "Epoch 46, Step 189, Loss: 0.4846208393573761\n",
            "Epoch 46, Step 190, Loss: 0.6722950339317322\n",
            "Epoch 46, Step 191, Loss: 0.4821823537349701\n",
            "Epoch 46, Step 192, Loss: 0.5081167221069336\n",
            "Epoch 46, Step 193, Loss: 0.5082328915596008\n",
            "Epoch 46, Step 194, Loss: 0.5973016619682312\n",
            "Epoch 46, Step 195, Loss: 0.4751894474029541\n",
            "Epoch 46, Step 196, Loss: 0.5685920119285583\n",
            "Epoch 46, Step 197, Loss: 0.4494296908378601\n",
            "Epoch 46, Step 198, Loss: 0.6242706775665283\n",
            "Epoch 46, Step 199, Loss: 0.3851800858974457\n",
            "Epoch 46, Step 200, Loss: 0.4265938699245453\n",
            "Epoch 46, Step 201, Loss: 0.42104098200798035\n",
            "Epoch 46, Step 202, Loss: 0.5613306760787964\n",
            "Epoch 46, Step 203, Loss: 0.565394401550293\n",
            "Epoch 46, Step 204, Loss: 0.5738415718078613\n",
            "Epoch 46, Step 205, Loss: 0.5545034408569336\n",
            "Epoch 46, Step 206, Loss: 0.39176705479621887\n",
            "Epoch 46, Step 207, Loss: 0.3762111961841583\n",
            "Epoch 46, Step 208, Loss: 0.5492730736732483\n",
            "Epoch 46, Step 209, Loss: 0.3425709903240204\n",
            "Epoch 46, Step 210, Loss: 0.5036547780036926\n",
            "Epoch 46, Step 211, Loss: 0.47235697507858276\n",
            "Epoch 46, Step 212, Loss: 0.3475356996059418\n",
            "Epoch 46, Step 213, Loss: 0.46579432487487793\n",
            "Epoch 46, Step 214, Loss: 0.4600764811038971\n",
            "Epoch 46, Step 215, Loss: 0.6122776865959167\n",
            "Epoch 46, Step 216, Loss: 0.6012493968009949\n",
            "Epoch 46, Step 217, Loss: 0.4704408347606659\n",
            "Epoch 46, Step 218, Loss: 0.49410292506217957\n",
            "Epoch 46, Step 219, Loss: 0.6954464316368103\n",
            "Epoch 46, Step 220, Loss: 0.5546546578407288\n",
            "Epoch 46, Step 221, Loss: 0.5516975522041321\n",
            "Epoch 46, Step 222, Loss: 0.44678995013237\n",
            "Epoch 46, Step 223, Loss: 0.48717600107192993\n",
            "Epoch 46, Step 224, Loss: 0.5822130441665649\n",
            "Epoch 46, Step 225, Loss: 0.49800148606300354\n",
            "Epoch 46, Step 226, Loss: 0.5721286535263062\n",
            "Epoch 46, Step 227, Loss: 0.5776454210281372\n",
            "Epoch 46, Step 228, Loss: 0.42122533917427063\n",
            "Epoch 46, Step 229, Loss: 0.5262203812599182\n",
            "Epoch 46, Step 230, Loss: 0.43223321437835693\n",
            "Epoch 46, Step 231, Loss: 0.48418137431144714\n",
            "Epoch 46, Step 232, Loss: 0.6173837184906006\n",
            "Epoch 46, Step 233, Loss: 0.5912889242172241\n",
            "Epoch 46, Step 234, Loss: 0.597588300704956\n",
            "Epoch 46, Step 235, Loss: 0.43567460775375366\n",
            "Epoch 46, Step 236, Loss: 0.49284127354621887\n",
            "Epoch 46, Step 237, Loss: 0.5278778672218323\n",
            "Epoch 46, Step 238, Loss: 0.46917402744293213\n",
            "Epoch 46, Step 239, Loss: 0.44972938299179077\n",
            "Epoch 46, Step 240, Loss: 0.44852596521377563\n",
            "Epoch 46, Step 241, Loss: 0.6470062136650085\n",
            "Epoch 46, Step 242, Loss: 0.4774321913719177\n",
            "Epoch 46, Step 243, Loss: 0.5356377363204956\n",
            "Epoch 46, Step 244, Loss: 0.5253675580024719\n",
            "Epoch 46, Step 245, Loss: 0.432367742061615\n",
            "Epoch 46, Step 246, Loss: 0.5713041424751282\n",
            "Epoch 46, Step 247, Loss: 0.5744547843933105\n",
            "Epoch 46, Step 248, Loss: 0.5380584597587585\n",
            "Epoch 46, Step 249, Loss: 0.596097469329834\n",
            "Epoch 46, Step 250, Loss: 0.4651711583137512\n",
            "Epoch 46, Step 251, Loss: 0.5377999544143677\n",
            "Epoch 46, Step 252, Loss: 0.43887293338775635\n",
            "Epoch 46, Step 253, Loss: 0.46138545870780945\n",
            "Epoch 46, Step 254, Loss: 0.45609936118125916\n",
            "Epoch 46, Step 255, Loss: 0.4319390058517456\n",
            "Epoch 46, Step 256, Loss: 0.658897876739502\n",
            "Epoch 46, Step 257, Loss: 0.3219328820705414\n",
            "Epoch 46, Step 258, Loss: 0.5552242398262024\n",
            "Epoch 46, Step 259, Loss: 0.43227577209472656\n",
            "Epoch 46, Step 260, Loss: 0.400585412979126\n",
            "Epoch 46, Step 261, Loss: 0.5015977025032043\n",
            "Epoch 46, Step 262, Loss: 0.4164475202560425\n",
            "Epoch 46, Step 263, Loss: 0.47099485993385315\n",
            "Epoch 46, Step 264, Loss: 0.5575375556945801\n",
            "Epoch 46, Step 265, Loss: 0.49062657356262207\n",
            "Epoch 46, Step 266, Loss: 0.47777044773101807\n",
            "Epoch 46, Step 267, Loss: 0.4267598092556\n",
            "Epoch 46, Step 268, Loss: 0.5278483033180237\n",
            "Epoch 46, Step 269, Loss: 0.41972261667251587\n",
            "Epoch 46, Step 270, Loss: 0.5265216827392578\n",
            "Epoch 46, Step 271, Loss: 0.4450336694717407\n",
            "Epoch 46, Step 272, Loss: 0.432209849357605\n",
            "Epoch 46, Step 273, Loss: 0.3374735414981842\n",
            "Epoch 46, Step 274, Loss: 0.3610894978046417\n",
            "Epoch 46, Step 275, Loss: 0.43701833486557007\n",
            "Epoch 46, Step 276, Loss: 0.514210045337677\n",
            "Epoch 46, Step 277, Loss: 0.4974544644355774\n",
            "Epoch 46, Step 278, Loss: 0.49220722913742065\n",
            "Epoch 46, Step 279, Loss: 0.4717274308204651\n",
            "Epoch 46, Step 280, Loss: 0.36339789628982544\n",
            "Epoch 46, Step 281, Loss: 0.48493692278862\n",
            "Epoch 46, Step 282, Loss: 0.4896117150783539\n",
            "Epoch 46, Step 283, Loss: 0.5624469518661499\n",
            "Epoch 46, Step 284, Loss: 0.5459629893302917\n",
            "Epoch 46, Step 285, Loss: 0.559109628200531\n",
            "Epoch 46, Step 286, Loss: 0.38250842690467834\n",
            "Epoch 46, Step 287, Loss: 0.4807959198951721\n",
            "Epoch 46, Step 288, Loss: 0.451354444026947\n",
            "Epoch 46, Step 289, Loss: 0.4331478476524353\n",
            "Epoch 46, Step 290, Loss: 0.5862860679626465\n",
            "Epoch 46, Step 291, Loss: 0.5439146161079407\n",
            "Epoch 46, Step 292, Loss: 0.5517239570617676\n",
            "Epoch 46, Step 293, Loss: 0.5395897030830383\n",
            "Epoch 46, Step 294, Loss: 0.559656023979187\n",
            "Epoch 46, Step 295, Loss: 0.47185593843460083\n",
            "Epoch 46, Step 296, Loss: 0.49919530749320984\n",
            "Epoch 46, Step 297, Loss: 0.5256595611572266\n",
            "Epoch 46, Step 298, Loss: 0.5106327533721924\n",
            "Epoch 46, Step 299, Loss: 0.4905104637145996\n",
            "Epoch 46, Step 300, Loss: 0.6022493839263916\n",
            "Epoch 46, Step 301, Loss: 0.5598587989807129\n",
            "Epoch 46, Step 302, Loss: 0.6192706227302551\n",
            "Epoch 46, Step 303, Loss: 0.602630078792572\n",
            "Epoch 46, Step 304, Loss: 0.4565729796886444\n",
            "Epoch 46, Step 305, Loss: 0.46888092160224915\n",
            "Epoch 46, Step 306, Loss: 0.5795542001724243\n",
            "Epoch 46, Step 307, Loss: 0.4878309965133667\n",
            "Epoch 46, Step 308, Loss: 0.4142610728740692\n",
            "Epoch 46, Step 309, Loss: 0.3792632520198822\n",
            "Epoch 46, Step 310, Loss: 0.5947249531745911\n",
            "Epoch 46, Step 311, Loss: 0.3101328909397125\n",
            "Epoch 46, Step 312, Loss: 0.4707582890987396\n",
            "Epoch 46 end, avg train loss: 0.503751906914452\n",
            "Epoch 46 end, avg val loss: 0.5594005067891712, accuracy: 80.75%\n",
            "Epoch 47, Step 0, Loss: 0.5369662642478943\n",
            "Epoch 47, Step 1, Loss: 0.5565130114555359\n",
            "Epoch 47, Step 2, Loss: 0.4932572543621063\n",
            "Epoch 47, Step 3, Loss: 0.5007225275039673\n",
            "Epoch 47, Step 4, Loss: 0.5741251111030579\n",
            "Epoch 47, Step 5, Loss: 0.5063794255256653\n",
            "Epoch 47, Step 6, Loss: 0.5136536955833435\n",
            "Epoch 47, Step 7, Loss: 0.5150349140167236\n",
            "Epoch 47, Step 8, Loss: 0.5131188631057739\n",
            "Epoch 47, Step 9, Loss: 0.6600056886672974\n",
            "Epoch 47, Step 10, Loss: 0.39887040853500366\n",
            "Epoch 47, Step 11, Loss: 0.573144257068634\n",
            "Epoch 47, Step 12, Loss: 0.5238064527511597\n",
            "Epoch 47, Step 13, Loss: 0.4493292272090912\n",
            "Epoch 47, Step 14, Loss: 0.665255606174469\n",
            "Epoch 47, Step 15, Loss: 0.6062914729118347\n",
            "Epoch 47, Step 16, Loss: 0.35988879203796387\n",
            "Epoch 47, Step 17, Loss: 0.49706923961639404\n",
            "Epoch 47, Step 18, Loss: 0.5311964154243469\n",
            "Epoch 47, Step 19, Loss: 0.3566740155220032\n",
            "Epoch 47, Step 20, Loss: 0.38285329937934875\n",
            "Epoch 47, Step 21, Loss: 0.45872682332992554\n",
            "Epoch 47, Step 22, Loss: 0.5823248624801636\n",
            "Epoch 47, Step 23, Loss: 0.4271611273288727\n",
            "Epoch 47, Step 24, Loss: 0.4993206858634949\n",
            "Epoch 47, Step 25, Loss: 0.5221123099327087\n",
            "Epoch 47, Step 26, Loss: 0.5769547820091248\n",
            "Epoch 47, Step 27, Loss: 0.5899985432624817\n",
            "Epoch 47, Step 28, Loss: 0.4883873164653778\n",
            "Epoch 47, Step 29, Loss: 0.49898192286491394\n",
            "Epoch 47, Step 30, Loss: 0.5879241228103638\n",
            "Epoch 47, Step 31, Loss: 0.5761231780052185\n",
            "Epoch 47, Step 32, Loss: 0.5523912906646729\n",
            "Epoch 47, Step 33, Loss: 0.5314895510673523\n",
            "Epoch 47, Step 34, Loss: 0.5378483533859253\n",
            "Epoch 47, Step 35, Loss: 0.4435710608959198\n",
            "Epoch 47, Step 36, Loss: 0.3410048484802246\n",
            "Epoch 47, Step 37, Loss: 0.5158098340034485\n",
            "Epoch 47, Step 38, Loss: 0.5845195651054382\n",
            "Epoch 47, Step 39, Loss: 0.4096747636795044\n",
            "Epoch 47, Step 40, Loss: 0.35323935747146606\n",
            "Epoch 47, Step 41, Loss: 0.4995672106742859\n",
            "Epoch 47, Step 42, Loss: 0.5288978815078735\n",
            "Epoch 47, Step 43, Loss: 0.6551867723464966\n",
            "Epoch 47, Step 44, Loss: 0.46748554706573486\n",
            "Epoch 47, Step 45, Loss: 0.4481006860733032\n",
            "Epoch 47, Step 46, Loss: 0.5225732922554016\n",
            "Epoch 47, Step 47, Loss: 0.35477009415626526\n",
            "Epoch 47, Step 48, Loss: 0.49732542037963867\n",
            "Epoch 47, Step 49, Loss: 0.4566408395767212\n",
            "Epoch 47, Step 50, Loss: 0.7419480681419373\n",
            "Epoch 47, Step 51, Loss: 0.4287276566028595\n",
            "Epoch 47, Step 52, Loss: 0.554772675037384\n",
            "Epoch 47, Step 53, Loss: 0.5682928562164307\n",
            "Epoch 47, Step 54, Loss: 0.39948976039886475\n",
            "Epoch 47, Step 55, Loss: 0.5104928016662598\n",
            "Epoch 47, Step 56, Loss: 0.495652973651886\n",
            "Epoch 47, Step 57, Loss: 0.4432275891304016\n",
            "Epoch 47, Step 58, Loss: 0.4948154091835022\n",
            "Epoch 47, Step 59, Loss: 0.42110639810562134\n",
            "Epoch 47, Step 60, Loss: 0.43593737483024597\n",
            "Epoch 47, Step 61, Loss: 0.4095012843608856\n",
            "Epoch 47, Step 62, Loss: 0.5096656084060669\n",
            "Epoch 47, Step 63, Loss: 0.5098403692245483\n",
            "Epoch 47, Step 64, Loss: 0.5405423641204834\n",
            "Epoch 47, Step 65, Loss: 0.5034591555595398\n",
            "Epoch 47, Step 66, Loss: 0.6033537983894348\n",
            "Epoch 47, Step 67, Loss: 0.518222987651825\n",
            "Epoch 47, Step 68, Loss: 0.5249574184417725\n",
            "Epoch 47, Step 69, Loss: 0.5094490051269531\n",
            "Epoch 47, Step 70, Loss: 0.5589743256568909\n",
            "Epoch 47, Step 71, Loss: 0.45818108320236206\n",
            "Epoch 47, Step 72, Loss: 0.6770330667495728\n",
            "Epoch 47, Step 73, Loss: 0.5847514271736145\n",
            "Epoch 47, Step 74, Loss: 0.5850971937179565\n",
            "Epoch 47, Step 75, Loss: 0.5071361064910889\n",
            "Epoch 47, Step 76, Loss: 0.4090225398540497\n",
            "Epoch 47, Step 77, Loss: 0.5580199956893921\n",
            "Epoch 47, Step 78, Loss: 0.3763849139213562\n",
            "Epoch 47, Step 79, Loss: 0.5879801511764526\n",
            "Epoch 47, Step 80, Loss: 0.4682362675666809\n",
            "Epoch 47, Step 81, Loss: 0.5315195322036743\n",
            "Epoch 47, Step 82, Loss: 0.588318407535553\n",
            "Epoch 47, Step 83, Loss: 0.4389483332633972\n",
            "Epoch 47, Step 84, Loss: 0.3459954559803009\n",
            "Epoch 47, Step 85, Loss: 0.4544941484928131\n",
            "Epoch 47, Step 86, Loss: 0.5058156251907349\n",
            "Epoch 47, Step 87, Loss: 0.45560288429260254\n",
            "Epoch 47, Step 88, Loss: 0.4794822633266449\n",
            "Epoch 47, Step 89, Loss: 0.6694304943084717\n",
            "Epoch 47, Step 90, Loss: 0.43876975774765015\n",
            "Epoch 47, Step 91, Loss: 0.4923054277896881\n",
            "Epoch 47, Step 92, Loss: 0.5128975510597229\n",
            "Epoch 47, Step 93, Loss: 0.3472391664981842\n",
            "Epoch 47, Step 94, Loss: 0.38744688034057617\n",
            "Epoch 47, Step 95, Loss: 0.4072015583515167\n",
            "Epoch 47, Step 96, Loss: 0.5136359930038452\n",
            "Epoch 47, Step 97, Loss: 0.46440139412879944\n",
            "Epoch 47, Step 98, Loss: 0.4702855348587036\n",
            "Epoch 47, Step 99, Loss: 0.4879142642021179\n",
            "Epoch 47, Step 100, Loss: 0.4778834283351898\n",
            "Epoch 47, Step 101, Loss: 0.4990324378013611\n",
            "Epoch 47, Step 102, Loss: 0.4544679820537567\n",
            "Epoch 47, Step 103, Loss: 0.4507676959037781\n",
            "Epoch 47, Step 104, Loss: 0.43773001432418823\n",
            "Epoch 47, Step 105, Loss: 0.3598830997943878\n",
            "Epoch 47, Step 106, Loss: 0.4245418906211853\n",
            "Epoch 47, Step 107, Loss: 0.39950111508369446\n",
            "Epoch 47, Step 108, Loss: 0.5999931693077087\n",
            "Epoch 47, Step 109, Loss: 0.3417143225669861\n",
            "Epoch 47, Step 110, Loss: 0.4492429494857788\n",
            "Epoch 47, Step 111, Loss: 0.5414955019950867\n",
            "Epoch 47, Step 112, Loss: 0.5701196789741516\n",
            "Epoch 47, Step 113, Loss: 0.4161617159843445\n",
            "Epoch 47, Step 114, Loss: 0.4818362593650818\n",
            "Epoch 47, Step 115, Loss: 0.4899539351463318\n",
            "Epoch 47, Step 116, Loss: 0.4991588890552521\n",
            "Epoch 47, Step 117, Loss: 0.6170749664306641\n",
            "Epoch 47, Step 118, Loss: 0.5536484122276306\n",
            "Epoch 47, Step 119, Loss: 0.3907175660133362\n",
            "Epoch 47, Step 120, Loss: 0.4510855972766876\n",
            "Epoch 47, Step 121, Loss: 0.45338085293769836\n",
            "Epoch 47, Step 122, Loss: 0.4013753831386566\n",
            "Epoch 47, Step 123, Loss: 0.4887751340866089\n",
            "Epoch 47, Step 124, Loss: 0.3950578570365906\n",
            "Epoch 47, Step 125, Loss: 0.6246927976608276\n",
            "Epoch 47, Step 126, Loss: 0.5714254975318909\n",
            "Epoch 47, Step 127, Loss: 0.554669976234436\n",
            "Epoch 47, Step 128, Loss: 0.5073546171188354\n",
            "Epoch 47, Step 129, Loss: 0.5158764123916626\n",
            "Epoch 47, Step 130, Loss: 0.4062963128089905\n",
            "Epoch 47, Step 131, Loss: 0.4660334289073944\n",
            "Epoch 47, Step 132, Loss: 0.6260924935340881\n",
            "Epoch 47, Step 133, Loss: 0.5262036919593811\n",
            "Epoch 47, Step 134, Loss: 0.5532712340354919\n",
            "Epoch 47, Step 135, Loss: 0.43879202008247375\n",
            "Epoch 47, Step 136, Loss: 0.6678239107131958\n",
            "Epoch 47, Step 137, Loss: 0.35852521657943726\n",
            "Epoch 47, Step 138, Loss: 0.529292106628418\n",
            "Epoch 47, Step 139, Loss: 0.5001438856124878\n",
            "Epoch 47, Step 140, Loss: 0.49283814430236816\n",
            "Epoch 47, Step 141, Loss: 0.41617485880851746\n",
            "Epoch 47, Step 142, Loss: 0.5770757794380188\n",
            "Epoch 47, Step 143, Loss: 0.3388476073741913\n",
            "Epoch 47, Step 144, Loss: 0.5222553014755249\n",
            "Epoch 47, Step 145, Loss: 0.45243752002716064\n",
            "Epoch 47, Step 146, Loss: 0.44478678703308105\n",
            "Epoch 47, Step 147, Loss: 0.5216190814971924\n",
            "Epoch 47, Step 148, Loss: 0.4370054602622986\n",
            "Epoch 47, Step 149, Loss: 0.4047299027442932\n",
            "Epoch 47, Step 150, Loss: 0.36820587515830994\n",
            "Epoch 47, Step 151, Loss: 0.4328171908855438\n",
            "Epoch 47, Step 152, Loss: 0.35226887464523315\n",
            "Epoch 47, Step 153, Loss: 0.47635412216186523\n",
            "Epoch 47, Step 154, Loss: 0.546539306640625\n",
            "Epoch 47, Step 155, Loss: 0.6071511507034302\n",
            "Epoch 47, Step 156, Loss: 0.4424000382423401\n",
            "Epoch 47, Step 157, Loss: 0.5625842809677124\n",
            "Epoch 47, Step 158, Loss: 0.6570133566856384\n",
            "Epoch 47, Step 159, Loss: 0.5373185276985168\n",
            "Epoch 47, Step 160, Loss: 0.5290482640266418\n",
            "Epoch 47, Step 161, Loss: 0.35145333409309387\n",
            "Epoch 47, Step 162, Loss: 0.5136556625366211\n",
            "Epoch 47, Step 163, Loss: 0.5466143488883972\n",
            "Epoch 47, Step 164, Loss: 0.49753183126449585\n",
            "Epoch 47, Step 165, Loss: 0.49569740891456604\n",
            "Epoch 47, Step 166, Loss: 0.6503171324729919\n",
            "Epoch 47, Step 167, Loss: 0.4845088720321655\n",
            "Epoch 47, Step 168, Loss: 0.48720782995224\n",
            "Epoch 47, Step 169, Loss: 0.40224623680114746\n",
            "Epoch 47, Step 170, Loss: 0.4178784489631653\n",
            "Epoch 47, Step 171, Loss: 0.4416378140449524\n",
            "Epoch 47, Step 172, Loss: 0.5340925455093384\n",
            "Epoch 47, Step 173, Loss: 0.5065737962722778\n",
            "Epoch 47, Step 174, Loss: 0.4417675733566284\n",
            "Epoch 47, Step 175, Loss: 0.4994641840457916\n",
            "Epoch 47, Step 176, Loss: 0.48342365026474\n",
            "Epoch 47, Step 177, Loss: 0.45378899574279785\n",
            "Epoch 47, Step 178, Loss: 0.420834481716156\n",
            "Epoch 47, Step 179, Loss: 0.45441240072250366\n",
            "Epoch 47, Step 180, Loss: 0.7027296423912048\n",
            "Epoch 47, Step 181, Loss: 0.4368472695350647\n",
            "Epoch 47, Step 182, Loss: 0.4419659972190857\n",
            "Epoch 47, Step 183, Loss: 0.43649521470069885\n",
            "Epoch 47, Step 184, Loss: 0.5991303324699402\n",
            "Epoch 47, Step 185, Loss: 0.5035568475723267\n",
            "Epoch 47, Step 186, Loss: 0.48130106925964355\n",
            "Epoch 47, Step 187, Loss: 0.581737756729126\n",
            "Epoch 47, Step 188, Loss: 0.3603721857070923\n",
            "Epoch 47, Step 189, Loss: 0.415382444858551\n",
            "Epoch 47, Step 190, Loss: 0.5610108971595764\n",
            "Epoch 47, Step 191, Loss: 0.4048362374305725\n",
            "Epoch 47, Step 192, Loss: 0.5762854218482971\n",
            "Epoch 47, Step 193, Loss: 0.4615524709224701\n",
            "Epoch 47, Step 194, Loss: 0.5586140155792236\n",
            "Epoch 47, Step 195, Loss: 0.34028130769729614\n",
            "Epoch 47, Step 196, Loss: 0.4145065248012543\n",
            "Epoch 47, Step 197, Loss: 0.6889427304267883\n",
            "Epoch 47, Step 198, Loss: 0.46399563550949097\n",
            "Epoch 47, Step 199, Loss: 0.48444297909736633\n",
            "Epoch 47, Step 200, Loss: 0.5095415115356445\n",
            "Epoch 47, Step 201, Loss: 0.4974985718727112\n",
            "Epoch 47, Step 202, Loss: 0.5979570746421814\n",
            "Epoch 47, Step 203, Loss: 0.37801969051361084\n",
            "Epoch 47, Step 204, Loss: 0.44624894857406616\n",
            "Epoch 47, Step 205, Loss: 0.6034431457519531\n",
            "Epoch 47, Step 206, Loss: 0.43984365463256836\n",
            "Epoch 47, Step 207, Loss: 0.4025079905986786\n",
            "Epoch 47, Step 208, Loss: 0.4990974962711334\n",
            "Epoch 47, Step 209, Loss: 0.4948711395263672\n",
            "Epoch 47, Step 210, Loss: 0.6005493402481079\n",
            "Epoch 47, Step 211, Loss: 0.5026133060455322\n",
            "Epoch 47, Step 212, Loss: 0.4530855715274811\n",
            "Epoch 47, Step 213, Loss: 0.47954869270324707\n",
            "Epoch 47, Step 214, Loss: 0.5098023414611816\n",
            "Epoch 47, Step 215, Loss: 0.5458899140357971\n",
            "Epoch 47, Step 216, Loss: 0.530360758304596\n",
            "Epoch 47, Step 217, Loss: 0.5496619343757629\n",
            "Epoch 47, Step 218, Loss: 0.5780176520347595\n",
            "Epoch 47, Step 219, Loss: 0.5409553647041321\n",
            "Epoch 47, Step 220, Loss: 0.6586005687713623\n",
            "Epoch 47, Step 221, Loss: 0.4685947299003601\n",
            "Epoch 47, Step 222, Loss: 0.5655238628387451\n",
            "Epoch 47, Step 223, Loss: 0.48925480246543884\n",
            "Epoch 47, Step 224, Loss: 0.34445640444755554\n",
            "Epoch 47, Step 225, Loss: 0.613370954990387\n",
            "Epoch 47, Step 226, Loss: 0.47763940691947937\n",
            "Epoch 47, Step 227, Loss: 0.42988768219947815\n",
            "Epoch 47, Step 228, Loss: 0.5127044916152954\n",
            "Epoch 47, Step 229, Loss: 0.4463772475719452\n",
            "Epoch 47, Step 230, Loss: 0.4906408488750458\n",
            "Epoch 47, Step 231, Loss: 0.5144941806793213\n",
            "Epoch 47, Step 232, Loss: 0.47284650802612305\n",
            "Epoch 47, Step 233, Loss: 0.5643730163574219\n",
            "Epoch 47, Step 234, Loss: 0.6619287729263306\n",
            "Epoch 47, Step 235, Loss: 0.38826075196266174\n",
            "Epoch 47, Step 236, Loss: 0.55619215965271\n",
            "Epoch 47, Step 237, Loss: 0.47995784878730774\n",
            "Epoch 47, Step 238, Loss: 0.42620590329170227\n",
            "Epoch 47, Step 239, Loss: 0.620039165019989\n",
            "Epoch 47, Step 240, Loss: 0.5548856854438782\n",
            "Epoch 47, Step 241, Loss: 0.4129113256931305\n",
            "Epoch 47, Step 242, Loss: 0.5513931512832642\n",
            "Epoch 47, Step 243, Loss: 0.4825449585914612\n",
            "Epoch 47, Step 244, Loss: 0.3076425790786743\n",
            "Epoch 47, Step 245, Loss: 0.49800530076026917\n",
            "Epoch 47, Step 246, Loss: 0.5295228958129883\n",
            "Epoch 47, Step 247, Loss: 0.47304821014404297\n",
            "Epoch 47, Step 248, Loss: 0.5068893432617188\n",
            "Epoch 47, Step 249, Loss: 0.5979241132736206\n",
            "Epoch 47, Step 250, Loss: 0.5257306694984436\n",
            "Epoch 47, Step 251, Loss: 0.42139145731925964\n",
            "Epoch 47, Step 252, Loss: 0.561564028263092\n",
            "Epoch 47, Step 253, Loss: 0.5405848026275635\n",
            "Epoch 47, Step 254, Loss: 0.4382641911506653\n",
            "Epoch 47, Step 255, Loss: 0.6837790012359619\n",
            "Epoch 47, Step 256, Loss: 0.5437994599342346\n",
            "Epoch 47, Step 257, Loss: 0.504288911819458\n",
            "Epoch 47, Step 258, Loss: 0.669987678527832\n",
            "Epoch 47, Step 259, Loss: 0.5067539215087891\n",
            "Epoch 47, Step 260, Loss: 0.4682472050189972\n",
            "Epoch 47, Step 261, Loss: 0.6143049597740173\n",
            "Epoch 47, Step 262, Loss: 0.493818461894989\n",
            "Epoch 47, Step 263, Loss: 0.5089522004127502\n",
            "Epoch 47, Step 264, Loss: 0.44273272156715393\n",
            "Epoch 47, Step 265, Loss: 0.4919683039188385\n",
            "Epoch 47, Step 266, Loss: 0.5624732971191406\n",
            "Epoch 47, Step 267, Loss: 0.42492300271987915\n",
            "Epoch 47, Step 268, Loss: 0.4101911187171936\n",
            "Epoch 47, Step 269, Loss: 0.3827104866504669\n",
            "Epoch 47, Step 270, Loss: 0.4384951889514923\n",
            "Epoch 47, Step 271, Loss: 0.4212816059589386\n",
            "Epoch 47, Step 272, Loss: 0.5901238918304443\n",
            "Epoch 47, Step 273, Loss: 0.5108221173286438\n",
            "Epoch 47, Step 274, Loss: 0.47195401787757874\n",
            "Epoch 47, Step 275, Loss: 0.5407381653785706\n",
            "Epoch 47, Step 276, Loss: 0.47869065403938293\n",
            "Epoch 47, Step 277, Loss: 0.3630596101284027\n",
            "Epoch 47, Step 278, Loss: 0.5096469521522522\n",
            "Epoch 47, Step 279, Loss: 0.5555535554885864\n",
            "Epoch 47, Step 280, Loss: 0.6949394345283508\n",
            "Epoch 47, Step 281, Loss: 0.5233466625213623\n",
            "Epoch 47, Step 282, Loss: 0.6463274955749512\n",
            "Epoch 47, Step 283, Loss: 0.46239978075027466\n",
            "Epoch 47, Step 284, Loss: 0.3718203902244568\n",
            "Epoch 47, Step 285, Loss: 0.4251173436641693\n",
            "Epoch 47, Step 286, Loss: 0.4629402756690979\n",
            "Epoch 47, Step 287, Loss: 0.5058714151382446\n",
            "Epoch 47, Step 288, Loss: 0.49553805589675903\n",
            "Epoch 47, Step 289, Loss: 0.462446928024292\n",
            "Epoch 47, Step 290, Loss: 0.480831116437912\n",
            "Epoch 47, Step 291, Loss: 0.5232606530189514\n",
            "Epoch 47, Step 292, Loss: 0.5532746315002441\n",
            "Epoch 47, Step 293, Loss: 0.516887366771698\n",
            "Epoch 47, Step 294, Loss: 0.6091320514678955\n",
            "Epoch 47, Step 295, Loss: 0.43322253227233887\n",
            "Epoch 47, Step 296, Loss: 0.5167024731636047\n",
            "Epoch 47, Step 297, Loss: 0.5646820068359375\n",
            "Epoch 47, Step 298, Loss: 0.47839003801345825\n",
            "Epoch 47, Step 299, Loss: 0.6124686598777771\n",
            "Epoch 47, Step 300, Loss: 0.5052650570869446\n",
            "Epoch 47, Step 301, Loss: 0.36487582325935364\n",
            "Epoch 47, Step 302, Loss: 0.5173293948173523\n",
            "Epoch 47, Step 303, Loss: 0.41082605719566345\n",
            "Epoch 47, Step 304, Loss: 0.5887486338615417\n",
            "Epoch 47, Step 305, Loss: 0.5475220084190369\n",
            "Epoch 47, Step 306, Loss: 0.6614351272583008\n",
            "Epoch 47, Step 307, Loss: 0.5470460057258606\n",
            "Epoch 47, Step 308, Loss: 0.6277367472648621\n",
            "Epoch 47, Step 309, Loss: 0.41619592905044556\n",
            "Epoch 47, Step 310, Loss: 0.3578769564628601\n",
            "Epoch 47, Step 311, Loss: 0.5589540004730225\n",
            "Epoch 47, Step 312, Loss: 0.4257112145423889\n",
            "Epoch 47 end, avg train loss: 0.4981389411341268\n",
            "Epoch 47 end, avg val loss: 0.5613189139698125, accuracy: 80.67%\n",
            "Epoch 48, Step 0, Loss: 0.6474024057388306\n",
            "Epoch 48, Step 1, Loss: 0.6269550323486328\n",
            "Epoch 48, Step 2, Loss: 0.51384437084198\n",
            "Epoch 48, Step 3, Loss: 0.4951120615005493\n",
            "Epoch 48, Step 4, Loss: 0.5474322438240051\n",
            "Epoch 48, Step 5, Loss: 0.401805579662323\n",
            "Epoch 48, Step 6, Loss: 0.43112316727638245\n",
            "Epoch 48, Step 7, Loss: 0.4738916754722595\n",
            "Epoch 48, Step 8, Loss: 0.40480661392211914\n",
            "Epoch 48, Step 9, Loss: 0.6011194586753845\n",
            "Epoch 48, Step 10, Loss: 0.5665441751480103\n",
            "Epoch 48, Step 11, Loss: 0.5925778150558472\n",
            "Epoch 48, Step 12, Loss: 0.5027114152908325\n",
            "Epoch 48, Step 13, Loss: 0.5781368613243103\n",
            "Epoch 48, Step 14, Loss: 0.43958795070648193\n",
            "Epoch 48, Step 15, Loss: 0.38608318567276\n",
            "Epoch 48, Step 16, Loss: 0.4062088131904602\n",
            "Epoch 48, Step 17, Loss: 0.39090949296951294\n",
            "Epoch 48, Step 18, Loss: 0.5981881618499756\n",
            "Epoch 48, Step 19, Loss: 0.5943734645843506\n",
            "Epoch 48, Step 20, Loss: 0.5510062575340271\n",
            "Epoch 48, Step 21, Loss: 0.6352530717849731\n",
            "Epoch 48, Step 22, Loss: 0.39304056763648987\n",
            "Epoch 48, Step 23, Loss: 0.3144081234931946\n",
            "Epoch 48, Step 24, Loss: 0.5811929702758789\n",
            "Epoch 48, Step 25, Loss: 0.4083949029445648\n",
            "Epoch 48, Step 26, Loss: 0.5214009284973145\n",
            "Epoch 48, Step 27, Loss: 0.4818590581417084\n",
            "Epoch 48, Step 28, Loss: 0.39828360080718994\n",
            "Epoch 48, Step 29, Loss: 0.5257402062416077\n",
            "Epoch 48, Step 30, Loss: 0.3931741416454315\n",
            "Epoch 48, Step 31, Loss: 0.44943663477897644\n",
            "Epoch 48, Step 32, Loss: 0.5969247221946716\n",
            "Epoch 48, Step 33, Loss: 0.49678242206573486\n",
            "Epoch 48, Step 34, Loss: 0.49650153517723083\n",
            "Epoch 48, Step 35, Loss: 0.5383898019790649\n",
            "Epoch 48, Step 36, Loss: 0.4822985529899597\n",
            "Epoch 48, Step 37, Loss: 0.4625447988510132\n",
            "Epoch 48, Step 38, Loss: 0.5411112308502197\n",
            "Epoch 48, Step 39, Loss: 0.6145666837692261\n",
            "Epoch 48, Step 40, Loss: 0.5468477010726929\n",
            "Epoch 48, Step 41, Loss: 0.4366375207901001\n",
            "Epoch 48, Step 42, Loss: 0.5444072484970093\n",
            "Epoch 48, Step 43, Loss: 0.5395033955574036\n",
            "Epoch 48, Step 44, Loss: 0.4140898585319519\n",
            "Epoch 48, Step 45, Loss: 0.44099119305610657\n",
            "Epoch 48, Step 46, Loss: 0.4961457848548889\n",
            "Epoch 48, Step 47, Loss: 0.5607626438140869\n",
            "Epoch 48, Step 48, Loss: 0.4417612850666046\n",
            "Epoch 48, Step 49, Loss: 0.44512009620666504\n",
            "Epoch 48, Step 50, Loss: 0.6369006633758545\n",
            "Epoch 48, Step 51, Loss: 0.5330117344856262\n",
            "Epoch 48, Step 52, Loss: 0.47463253140449524\n",
            "Epoch 48, Step 53, Loss: 0.5971154570579529\n",
            "Epoch 48, Step 54, Loss: 0.5225801467895508\n",
            "Epoch 48, Step 55, Loss: 0.5487746000289917\n",
            "Epoch 48, Step 56, Loss: 0.5416940450668335\n",
            "Epoch 48, Step 57, Loss: 0.3884866535663605\n",
            "Epoch 48, Step 58, Loss: 0.4556642174720764\n",
            "Epoch 48, Step 59, Loss: 0.4563651978969574\n",
            "Epoch 48, Step 60, Loss: 0.4517543613910675\n",
            "Epoch 48, Step 61, Loss: 0.49506768584251404\n",
            "Epoch 48, Step 62, Loss: 0.437374472618103\n",
            "Epoch 48, Step 63, Loss: 0.5621225833892822\n",
            "Epoch 48, Step 64, Loss: 0.48308733105659485\n",
            "Epoch 48, Step 65, Loss: 0.34348198771476746\n",
            "Epoch 48, Step 66, Loss: 0.48269784450531006\n",
            "Epoch 48, Step 67, Loss: 0.4163382053375244\n",
            "Epoch 48, Step 68, Loss: 0.5224395990371704\n",
            "Epoch 48, Step 69, Loss: 0.48065993189811707\n",
            "Epoch 48, Step 70, Loss: 0.5652196407318115\n",
            "Epoch 48, Step 71, Loss: 0.5847337245941162\n",
            "Epoch 48, Step 72, Loss: 0.3875819742679596\n",
            "Epoch 48, Step 73, Loss: 0.42306530475616455\n",
            "Epoch 48, Step 74, Loss: 0.5324833989143372\n",
            "Epoch 48, Step 75, Loss: 0.37598055601119995\n",
            "Epoch 48, Step 76, Loss: 0.4816958010196686\n",
            "Epoch 48, Step 77, Loss: 0.4739426076412201\n",
            "Epoch 48, Step 78, Loss: 0.40165427327156067\n",
            "Epoch 48, Step 79, Loss: 0.46608680486679077\n",
            "Epoch 48, Step 80, Loss: 0.6087637543678284\n",
            "Epoch 48, Step 81, Loss: 0.5398852825164795\n",
            "Epoch 48, Step 82, Loss: 0.44204118847846985\n",
            "Epoch 48, Step 83, Loss: 0.5432656407356262\n",
            "Epoch 48, Step 84, Loss: 0.46772661805152893\n",
            "Epoch 48, Step 85, Loss: 0.5910595655441284\n",
            "Epoch 48, Step 86, Loss: 0.4958038628101349\n",
            "Epoch 48, Step 87, Loss: 0.5055010318756104\n",
            "Epoch 48, Step 88, Loss: 0.6002129912376404\n",
            "Epoch 48, Step 89, Loss: 0.5784122943878174\n",
            "Epoch 48, Step 90, Loss: 0.48779362440109253\n",
            "Epoch 48, Step 91, Loss: 0.443271666765213\n",
            "Epoch 48, Step 92, Loss: 0.5211151838302612\n",
            "Epoch 48, Step 93, Loss: 0.5644538998603821\n",
            "Epoch 48, Step 94, Loss: 0.5512401461601257\n",
            "Epoch 48, Step 95, Loss: 0.5281422734260559\n",
            "Epoch 48, Step 96, Loss: 0.412598580121994\n",
            "Epoch 48, Step 97, Loss: 0.5403730273246765\n",
            "Epoch 48, Step 98, Loss: 0.6657854914665222\n",
            "Epoch 48, Step 99, Loss: 0.5305483341217041\n",
            "Epoch 48, Step 100, Loss: 0.5195445418357849\n",
            "Epoch 48, Step 101, Loss: 0.5051077008247375\n",
            "Epoch 48, Step 102, Loss: 0.49835842847824097\n",
            "Epoch 48, Step 103, Loss: 0.5411113500595093\n",
            "Epoch 48, Step 104, Loss: 0.3967265486717224\n",
            "Epoch 48, Step 105, Loss: 0.35696759819984436\n",
            "Epoch 48, Step 106, Loss: 0.5827568173408508\n",
            "Epoch 48, Step 107, Loss: 0.4915231466293335\n",
            "Epoch 48, Step 108, Loss: 0.37784698605537415\n",
            "Epoch 48, Step 109, Loss: 0.5563128590583801\n",
            "Epoch 48, Step 110, Loss: 0.3902897536754608\n",
            "Epoch 48, Step 111, Loss: 0.5881953239440918\n",
            "Epoch 48, Step 112, Loss: 0.6026301980018616\n",
            "Epoch 48, Step 113, Loss: 0.4433117210865021\n",
            "Epoch 48, Step 114, Loss: 0.32754236459732056\n",
            "Epoch 48, Step 115, Loss: 0.554045557975769\n",
            "Epoch 48, Step 116, Loss: 0.48920905590057373\n",
            "Epoch 48, Step 117, Loss: 0.5170373916625977\n",
            "Epoch 48, Step 118, Loss: 0.5082492828369141\n",
            "Epoch 48, Step 119, Loss: 0.4539065361022949\n",
            "Epoch 48, Step 120, Loss: 0.5730860233306885\n",
            "Epoch 48, Step 121, Loss: 0.5299152135848999\n",
            "Epoch 48, Step 122, Loss: 0.48229411244392395\n",
            "Epoch 48, Step 123, Loss: 0.41964390873908997\n",
            "Epoch 48, Step 124, Loss: 0.5595933198928833\n",
            "Epoch 48, Step 125, Loss: 0.46550777554512024\n",
            "Epoch 48, Step 126, Loss: 0.5134562253952026\n",
            "Epoch 48, Step 127, Loss: 0.5541454553604126\n",
            "Epoch 48, Step 128, Loss: 0.41542762517929077\n",
            "Epoch 48, Step 129, Loss: 0.5625470876693726\n",
            "Epoch 48, Step 130, Loss: 0.5210357308387756\n",
            "Epoch 48, Step 131, Loss: 0.49787023663520813\n",
            "Epoch 48, Step 132, Loss: 0.4175332486629486\n",
            "Epoch 48, Step 133, Loss: 0.5948587656021118\n",
            "Epoch 48, Step 134, Loss: 0.48927226662635803\n",
            "Epoch 48, Step 135, Loss: 0.39168083667755127\n",
            "Epoch 48, Step 136, Loss: 0.3121340274810791\n",
            "Epoch 48, Step 137, Loss: 0.5201613903045654\n",
            "Epoch 48, Step 138, Loss: 0.49332743883132935\n",
            "Epoch 48, Step 139, Loss: 0.5364022850990295\n",
            "Epoch 48, Step 140, Loss: 0.48949840664863586\n",
            "Epoch 48, Step 141, Loss: 0.4627954065799713\n",
            "Epoch 48, Step 142, Loss: 0.47512611746788025\n",
            "Epoch 48, Step 143, Loss: 0.5654209852218628\n",
            "Epoch 48, Step 144, Loss: 0.5345466136932373\n",
            "Epoch 48, Step 145, Loss: 0.506732702255249\n",
            "Epoch 48, Step 146, Loss: 0.6614482998847961\n",
            "Epoch 48, Step 147, Loss: 0.4722471237182617\n",
            "Epoch 48, Step 148, Loss: 0.5507030487060547\n",
            "Epoch 48, Step 149, Loss: 0.4443543553352356\n",
            "Epoch 48, Step 150, Loss: 0.5050118565559387\n",
            "Epoch 48, Step 151, Loss: 0.4776883125305176\n",
            "Epoch 48, Step 152, Loss: 0.49023184180259705\n",
            "Epoch 48, Step 153, Loss: 0.6282426118850708\n",
            "Epoch 48, Step 154, Loss: 0.45956188440322876\n",
            "Epoch 48, Step 155, Loss: 0.4758707880973816\n",
            "Epoch 48, Step 156, Loss: 0.4266810417175293\n",
            "Epoch 48, Step 157, Loss: 0.41883569955825806\n",
            "Epoch 48, Step 158, Loss: 0.46473708748817444\n",
            "Epoch 48, Step 159, Loss: 0.4214065372943878\n",
            "Epoch 48, Step 160, Loss: 0.5535645484924316\n",
            "Epoch 48, Step 161, Loss: 0.46235963702201843\n",
            "Epoch 48, Step 162, Loss: 0.3610650300979614\n",
            "Epoch 48, Step 163, Loss: 0.37133079767227173\n",
            "Epoch 48, Step 164, Loss: 0.588394045829773\n",
            "Epoch 48, Step 165, Loss: 0.4397146701812744\n",
            "Epoch 48, Step 166, Loss: 0.4260963201522827\n",
            "Epoch 48, Step 167, Loss: 0.5102017521858215\n",
            "Epoch 48, Step 168, Loss: 0.43392419815063477\n",
            "Epoch 48, Step 169, Loss: 0.44562792778015137\n",
            "Epoch 48, Step 170, Loss: 0.4572230279445648\n",
            "Epoch 48, Step 171, Loss: 0.5244321823120117\n",
            "Epoch 48, Step 172, Loss: 0.48673543334007263\n",
            "Epoch 48, Step 173, Loss: 0.5079485177993774\n",
            "Epoch 48, Step 174, Loss: 0.5020855665206909\n",
            "Epoch 48, Step 175, Loss: 0.5617609620094299\n",
            "Epoch 48, Step 176, Loss: 0.4989559054374695\n",
            "Epoch 48, Step 177, Loss: 0.4628699719905853\n",
            "Epoch 48, Step 178, Loss: 0.39924323558807373\n",
            "Epoch 48, Step 179, Loss: 0.47832974791526794\n",
            "Epoch 48, Step 180, Loss: 0.4972960650920868\n",
            "Epoch 48, Step 181, Loss: 0.5343245267868042\n",
            "Epoch 48, Step 182, Loss: 0.4254909157752991\n",
            "Epoch 48, Step 183, Loss: 0.46741750836372375\n",
            "Epoch 48, Step 184, Loss: 0.5139662623405457\n",
            "Epoch 48, Step 185, Loss: 0.4815203547477722\n",
            "Epoch 48, Step 186, Loss: 0.4347752034664154\n",
            "Epoch 48, Step 187, Loss: 0.5055439472198486\n",
            "Epoch 48, Step 188, Loss: 0.4866638779640198\n",
            "Epoch 48, Step 189, Loss: 0.40126973390579224\n",
            "Epoch 48, Step 190, Loss: 0.5353225469589233\n",
            "Epoch 48, Step 191, Loss: 0.47344282269477844\n",
            "Epoch 48, Step 192, Loss: 0.45620834827423096\n",
            "Epoch 48, Step 193, Loss: 0.5616008639335632\n",
            "Epoch 48, Step 194, Loss: 0.5351069569587708\n",
            "Epoch 48, Step 195, Loss: 0.5229106545448303\n",
            "Epoch 48, Step 196, Loss: 0.5364523530006409\n",
            "Epoch 48, Step 197, Loss: 0.4841609597206116\n",
            "Epoch 48, Step 198, Loss: 0.6799583435058594\n",
            "Epoch 48, Step 199, Loss: 0.4698668122291565\n",
            "Epoch 48, Step 200, Loss: 0.5608639717102051\n",
            "Epoch 48, Step 201, Loss: 0.5322072505950928\n",
            "Epoch 48, Step 202, Loss: 0.4895510673522949\n",
            "Epoch 48, Step 203, Loss: 0.6259482502937317\n",
            "Epoch 48, Step 204, Loss: 0.46810388565063477\n",
            "Epoch 48, Step 205, Loss: 0.42723730206489563\n",
            "Epoch 48, Step 206, Loss: 0.5242925882339478\n",
            "Epoch 48, Step 207, Loss: 0.4623304009437561\n",
            "Epoch 48, Step 208, Loss: 0.5177915692329407\n",
            "Epoch 48, Step 209, Loss: 0.5405994653701782\n",
            "Epoch 48, Step 210, Loss: 0.499101459980011\n",
            "Epoch 48, Step 211, Loss: 0.4589383602142334\n",
            "Epoch 48, Step 212, Loss: 0.5391165018081665\n",
            "Epoch 48, Step 213, Loss: 0.5441001653671265\n",
            "Epoch 48, Step 214, Loss: 0.3512474596500397\n",
            "Epoch 48, Step 215, Loss: 0.42577308416366577\n",
            "Epoch 48, Step 216, Loss: 0.49077218770980835\n",
            "Epoch 48, Step 217, Loss: 0.34831786155700684\n",
            "Epoch 48, Step 218, Loss: 0.36684101819992065\n",
            "Epoch 48, Step 219, Loss: 0.6137593984603882\n",
            "Epoch 48, Step 220, Loss: 0.5971335172653198\n",
            "Epoch 48, Step 221, Loss: 0.6371439695358276\n",
            "Epoch 48, Step 222, Loss: 0.5689960718154907\n",
            "Epoch 48, Step 223, Loss: 0.7487331032752991\n",
            "Epoch 48, Step 224, Loss: 0.47544965147972107\n",
            "Epoch 48, Step 225, Loss: 0.517449140548706\n",
            "Epoch 48, Step 226, Loss: 0.38737472891807556\n",
            "Epoch 48, Step 227, Loss: 0.6943715810775757\n",
            "Epoch 48, Step 228, Loss: 0.342265784740448\n",
            "Epoch 48, Step 229, Loss: 0.4224761128425598\n",
            "Epoch 48, Step 230, Loss: 0.5525354743003845\n",
            "Epoch 48, Step 231, Loss: 0.5893455147743225\n",
            "Epoch 48, Step 232, Loss: 0.3347059488296509\n",
            "Epoch 48, Step 233, Loss: 0.4888473153114319\n",
            "Epoch 48, Step 234, Loss: 0.5653470754623413\n",
            "Epoch 48, Step 235, Loss: 0.5164295434951782\n",
            "Epoch 48, Step 236, Loss: 0.5329534411430359\n",
            "Epoch 48, Step 237, Loss: 0.7373135685920715\n",
            "Epoch 48, Step 238, Loss: 0.5849732756614685\n",
            "Epoch 48, Step 239, Loss: 0.46623390913009644\n",
            "Epoch 48, Step 240, Loss: 0.51805579662323\n",
            "Epoch 48, Step 241, Loss: 0.4386048913002014\n",
            "Epoch 48, Step 242, Loss: 0.46206292510032654\n",
            "Epoch 48, Step 243, Loss: 0.4497850835323334\n",
            "Epoch 48, Step 244, Loss: 0.5772632360458374\n",
            "Epoch 48, Step 245, Loss: 0.3608010709285736\n",
            "Epoch 48, Step 246, Loss: 0.5062631964683533\n",
            "Epoch 48, Step 247, Loss: 0.592801034450531\n",
            "Epoch 48, Step 248, Loss: 0.4885183870792389\n",
            "Epoch 48, Step 249, Loss: 0.51371830701828\n",
            "Epoch 48, Step 250, Loss: 0.4292152225971222\n",
            "Epoch 48, Step 251, Loss: 0.5962725281715393\n",
            "Epoch 48, Step 252, Loss: 0.5758105516433716\n",
            "Epoch 48, Step 253, Loss: 0.4507024884223938\n",
            "Epoch 48, Step 254, Loss: 0.5178598761558533\n",
            "Epoch 48, Step 255, Loss: 0.6602677702903748\n",
            "Epoch 48, Step 256, Loss: 0.5358343124389648\n",
            "Epoch 48, Step 257, Loss: 0.572948694229126\n",
            "Epoch 48, Step 258, Loss: 0.4933851957321167\n",
            "Epoch 48, Step 259, Loss: 0.3632912039756775\n",
            "Epoch 48, Step 260, Loss: 0.515961229801178\n",
            "Epoch 48, Step 261, Loss: 0.5075092315673828\n",
            "Epoch 48, Step 262, Loss: 0.3949832618236542\n",
            "Epoch 48, Step 263, Loss: 0.37033164501190186\n",
            "Epoch 48, Step 264, Loss: 0.5217134356498718\n",
            "Epoch 48, Step 265, Loss: 0.5743877291679382\n",
            "Epoch 48, Step 266, Loss: 0.4565962553024292\n",
            "Epoch 48, Step 267, Loss: 0.35488975048065186\n",
            "Epoch 48, Step 268, Loss: 0.44250768423080444\n",
            "Epoch 48, Step 269, Loss: 0.4599578380584717\n",
            "Epoch 48, Step 270, Loss: 0.48871496319770813\n",
            "Epoch 48, Step 271, Loss: 0.43631961941719055\n",
            "Epoch 48, Step 272, Loss: 0.5245323777198792\n",
            "Epoch 48, Step 273, Loss: 0.39091214537620544\n",
            "Epoch 48, Step 274, Loss: 0.5565276145935059\n",
            "Epoch 48, Step 275, Loss: 0.5097395181655884\n",
            "Epoch 48, Step 276, Loss: 0.5408306121826172\n",
            "Epoch 48, Step 277, Loss: 0.607160747051239\n",
            "Epoch 48, Step 278, Loss: 0.5806354284286499\n",
            "Epoch 48, Step 279, Loss: 0.5029488801956177\n",
            "Epoch 48, Step 280, Loss: 0.4330703020095825\n",
            "Epoch 48, Step 281, Loss: 0.43174636363983154\n",
            "Epoch 48, Step 282, Loss: 0.48083990812301636\n",
            "Epoch 48, Step 283, Loss: 0.3856382668018341\n",
            "Epoch 48, Step 284, Loss: 0.4914228916168213\n",
            "Epoch 48, Step 285, Loss: 0.414213091135025\n",
            "Epoch 48, Step 286, Loss: 0.4842054545879364\n",
            "Epoch 48, Step 287, Loss: 0.7024867534637451\n",
            "Epoch 48, Step 288, Loss: 0.44395214319229126\n",
            "Epoch 48, Step 289, Loss: 0.3821045160293579\n",
            "Epoch 48, Step 290, Loss: 0.4872419834136963\n",
            "Epoch 48, Step 291, Loss: 0.5073896050453186\n",
            "Epoch 48, Step 292, Loss: 0.45411941409111023\n",
            "Epoch 48, Step 293, Loss: 0.5615804195404053\n",
            "Epoch 48, Step 294, Loss: 0.5014485716819763\n",
            "Epoch 48, Step 295, Loss: 0.49661850929260254\n",
            "Epoch 48, Step 296, Loss: 0.4431723654270172\n",
            "Epoch 48, Step 297, Loss: 0.5401057004928589\n",
            "Epoch 48, Step 298, Loss: 0.6143133044242859\n",
            "Epoch 48, Step 299, Loss: 0.5836851596832275\n",
            "Epoch 48, Step 300, Loss: 0.5801426768302917\n",
            "Epoch 48, Step 301, Loss: 0.631054699420929\n",
            "Epoch 48, Step 302, Loss: 0.5955924987792969\n",
            "Epoch 48, Step 303, Loss: 0.5116532444953918\n",
            "Epoch 48, Step 304, Loss: 0.38920196890830994\n",
            "Epoch 48, Step 305, Loss: 0.5172232389450073\n",
            "Epoch 48, Step 306, Loss: 0.5129193067550659\n",
            "Epoch 48, Step 307, Loss: 0.5018283724784851\n",
            "Epoch 48, Step 308, Loss: 0.428379088640213\n",
            "Epoch 48, Step 309, Loss: 0.5489882826805115\n",
            "Epoch 48, Step 310, Loss: 0.34838542342185974\n",
            "Epoch 48, Step 311, Loss: 0.6233959197998047\n",
            "Epoch 48, Step 312, Loss: 0.38632187247276306\n",
            "Epoch 48 end, avg train loss: 0.4979136840413554\n",
            "Epoch 48 end, avg val loss: 0.5513543011266974, accuracy: 80.92%\n",
            "Epoch 49, Step 0, Loss: 0.4173469543457031\n",
            "Epoch 49, Step 1, Loss: 0.5131690502166748\n",
            "Epoch 49, Step 2, Loss: 0.4849310517311096\n",
            "Epoch 49, Step 3, Loss: 0.4173719584941864\n",
            "Epoch 49, Step 4, Loss: 0.5350240468978882\n",
            "Epoch 49, Step 5, Loss: 0.6072573065757751\n",
            "Epoch 49, Step 6, Loss: 0.45928773283958435\n",
            "Epoch 49, Step 7, Loss: 0.576263964176178\n",
            "Epoch 49, Step 8, Loss: 0.5262562036514282\n",
            "Epoch 49, Step 9, Loss: 0.5550283789634705\n",
            "Epoch 49, Step 10, Loss: 0.5254273414611816\n",
            "Epoch 49, Step 11, Loss: 0.43841543793678284\n",
            "Epoch 49, Step 12, Loss: 0.43353283405303955\n",
            "Epoch 49, Step 13, Loss: 0.44381842017173767\n",
            "Epoch 49, Step 14, Loss: 0.5834272503852844\n",
            "Epoch 49, Step 15, Loss: 0.421357661485672\n",
            "Epoch 49, Step 16, Loss: 0.437822550535202\n",
            "Epoch 49, Step 17, Loss: 0.4501834213733673\n",
            "Epoch 49, Step 18, Loss: 0.4731122553348541\n",
            "Epoch 49, Step 19, Loss: 0.38262200355529785\n",
            "Epoch 49, Step 20, Loss: 0.42540961503982544\n",
            "Epoch 49, Step 21, Loss: 0.4827151894569397\n",
            "Epoch 49, Step 22, Loss: 0.32035043835639954\n",
            "Epoch 49, Step 23, Loss: 0.4424756169319153\n",
            "Epoch 49, Step 24, Loss: 0.5388241410255432\n",
            "Epoch 49, Step 25, Loss: 0.3494175374507904\n",
            "Epoch 49, Step 26, Loss: 0.44091448187828064\n",
            "Epoch 49, Step 27, Loss: 0.377735435962677\n",
            "Epoch 49, Step 28, Loss: 0.5797730684280396\n",
            "Epoch 49, Step 29, Loss: 0.49995726346969604\n",
            "Epoch 49, Step 30, Loss: 0.5073071718215942\n",
            "Epoch 49, Step 31, Loss: 0.4817645251750946\n",
            "Epoch 49, Step 32, Loss: 0.5193513035774231\n",
            "Epoch 49, Step 33, Loss: 0.5048477053642273\n",
            "Epoch 49, Step 34, Loss: 0.5008213520050049\n",
            "Epoch 49, Step 35, Loss: 0.5722066164016724\n",
            "Epoch 49, Step 36, Loss: 0.42017343640327454\n",
            "Epoch 49, Step 37, Loss: 0.4104574918746948\n",
            "Epoch 49, Step 38, Loss: 0.5003655552864075\n",
            "Epoch 49, Step 39, Loss: 0.42792442440986633\n",
            "Epoch 49, Step 40, Loss: 0.4116179049015045\n",
            "Epoch 49, Step 41, Loss: 0.5771070122718811\n",
            "Epoch 49, Step 42, Loss: 0.5382269024848938\n",
            "Epoch 49, Step 43, Loss: 0.38311877846717834\n",
            "Epoch 49, Step 44, Loss: 0.4453243613243103\n",
            "Epoch 49, Step 45, Loss: 0.5151738524436951\n",
            "Epoch 49, Step 46, Loss: 0.6237733960151672\n",
            "Epoch 49, Step 47, Loss: 0.5335567593574524\n",
            "Epoch 49, Step 48, Loss: 0.5046989321708679\n",
            "Epoch 49, Step 49, Loss: 0.6417620778083801\n",
            "Epoch 49, Step 50, Loss: 0.3724713921546936\n",
            "Epoch 49, Step 51, Loss: 0.39285382628440857\n",
            "Epoch 49, Step 52, Loss: 0.5542072057723999\n",
            "Epoch 49, Step 53, Loss: 0.49313732981681824\n",
            "Epoch 49, Step 54, Loss: 0.35856515169143677\n",
            "Epoch 49, Step 55, Loss: 0.5853994488716125\n",
            "Epoch 49, Step 56, Loss: 0.42152509093284607\n",
            "Epoch 49, Step 57, Loss: 0.47453609108924866\n",
            "Epoch 49, Step 58, Loss: 0.4275549054145813\n",
            "Epoch 49, Step 59, Loss: 0.4329366087913513\n",
            "Epoch 49, Step 60, Loss: 0.5914716124534607\n",
            "Epoch 49, Step 61, Loss: 0.5215193033218384\n",
            "Epoch 49, Step 62, Loss: 0.4107685983181\n",
            "Epoch 49, Step 63, Loss: 0.5619987845420837\n",
            "Epoch 49, Step 64, Loss: 0.4592718482017517\n",
            "Epoch 49, Step 65, Loss: 0.4900225102901459\n",
            "Epoch 49, Step 66, Loss: 0.4535022974014282\n",
            "Epoch 49, Step 67, Loss: 0.5020002722740173\n",
            "Epoch 49, Step 68, Loss: 0.4667414724826813\n",
            "Epoch 49, Step 69, Loss: 0.5104624629020691\n",
            "Epoch 49, Step 70, Loss: 0.6414119601249695\n",
            "Epoch 49, Step 71, Loss: 0.4782266616821289\n",
            "Epoch 49, Step 72, Loss: 0.45770367980003357\n",
            "Epoch 49, Step 73, Loss: 0.4216541051864624\n",
            "Epoch 49, Step 74, Loss: 0.42260560393333435\n",
            "Epoch 49, Step 75, Loss: 0.5120226740837097\n",
            "Epoch 49, Step 76, Loss: 0.45615115761756897\n",
            "Epoch 49, Step 77, Loss: 0.5466598272323608\n",
            "Epoch 49, Step 78, Loss: 0.4741094708442688\n",
            "Epoch 49, Step 79, Loss: 0.6218185424804688\n",
            "Epoch 49, Step 80, Loss: 0.6116514205932617\n",
            "Epoch 49, Step 81, Loss: 0.5150267481803894\n",
            "Epoch 49, Step 82, Loss: 0.5921947956085205\n",
            "Epoch 49, Step 83, Loss: 0.48127827048301697\n",
            "Epoch 49, Step 84, Loss: 0.4769945740699768\n",
            "Epoch 49, Step 85, Loss: 0.4417784810066223\n",
            "Epoch 49, Step 86, Loss: 0.6026383638381958\n",
            "Epoch 49, Step 87, Loss: 0.5171228051185608\n",
            "Epoch 49, Step 88, Loss: 0.43429210782051086\n",
            "Epoch 49, Step 89, Loss: 0.541947603225708\n",
            "Epoch 49, Step 90, Loss: 0.44468584656715393\n",
            "Epoch 49, Step 91, Loss: 0.5472001433372498\n",
            "Epoch 49, Step 92, Loss: 0.40928512811660767\n",
            "Epoch 49, Step 93, Loss: 0.4955773949623108\n",
            "Epoch 49, Step 94, Loss: 0.49692991375923157\n",
            "Epoch 49, Step 95, Loss: 0.5716935396194458\n",
            "Epoch 49, Step 96, Loss: 0.5773648023605347\n",
            "Epoch 49, Step 97, Loss: 0.42500561475753784\n",
            "Epoch 49, Step 98, Loss: 0.4217592179775238\n",
            "Epoch 49, Step 99, Loss: 0.5605900883674622\n",
            "Epoch 49, Step 100, Loss: 0.5735250115394592\n",
            "Epoch 49, Step 101, Loss: 0.538061797618866\n",
            "Epoch 49, Step 102, Loss: 0.4398385286331177\n",
            "Epoch 49, Step 103, Loss: 0.45867979526519775\n",
            "Epoch 49, Step 104, Loss: 0.42376813292503357\n",
            "Epoch 49, Step 105, Loss: 0.42318207025527954\n",
            "Epoch 49, Step 106, Loss: 0.39866670966148376\n",
            "Epoch 49, Step 107, Loss: 0.47680357098579407\n",
            "Epoch 49, Step 108, Loss: 0.6816330552101135\n",
            "Epoch 49, Step 109, Loss: 0.5710391998291016\n",
            "Epoch 49, Step 110, Loss: 0.6329617500305176\n",
            "Epoch 49, Step 111, Loss: 0.37835749983787537\n",
            "Epoch 49, Step 112, Loss: 0.5726074576377869\n",
            "Epoch 49, Step 113, Loss: 0.554125964641571\n",
            "Epoch 49, Step 114, Loss: 0.5582332015037537\n",
            "Epoch 49, Step 115, Loss: 0.42079463601112366\n",
            "Epoch 49, Step 116, Loss: 0.4992811679840088\n",
            "Epoch 49, Step 117, Loss: 0.5148789286613464\n",
            "Epoch 49, Step 118, Loss: 0.43811437487602234\n",
            "Epoch 49, Step 119, Loss: 0.5388978719711304\n",
            "Epoch 49, Step 120, Loss: 0.44275349378585815\n",
            "Epoch 49, Step 121, Loss: 0.6751861572265625\n",
            "Epoch 49, Step 122, Loss: 0.47677502036094666\n",
            "Epoch 49, Step 123, Loss: 0.6462956666946411\n",
            "Epoch 49, Step 124, Loss: 0.5423886179924011\n",
            "Epoch 49, Step 125, Loss: 0.38449472188949585\n",
            "Epoch 49, Step 126, Loss: 0.38824859261512756\n",
            "Epoch 49, Step 127, Loss: 0.5815444588661194\n",
            "Epoch 49, Step 128, Loss: 0.5210790634155273\n",
            "Epoch 49, Step 129, Loss: 0.41366052627563477\n",
            "Epoch 49, Step 130, Loss: 0.5103086233139038\n",
            "Epoch 49, Step 131, Loss: 0.43569859862327576\n",
            "Epoch 49, Step 132, Loss: 0.506320059299469\n",
            "Epoch 49, Step 133, Loss: 0.39994022250175476\n",
            "Epoch 49, Step 134, Loss: 0.44812077283859253\n",
            "Epoch 49, Step 135, Loss: 0.5254654884338379\n",
            "Epoch 49, Step 136, Loss: 0.5329149961471558\n",
            "Epoch 49, Step 137, Loss: 0.5168238282203674\n",
            "Epoch 49, Step 138, Loss: 0.39616262912750244\n",
            "Epoch 49, Step 139, Loss: 0.6429096460342407\n",
            "Epoch 49, Step 140, Loss: 0.6664015054702759\n",
            "Epoch 49, Step 141, Loss: 0.5248715281486511\n",
            "Epoch 49, Step 142, Loss: 0.4841594099998474\n",
            "Epoch 49, Step 143, Loss: 0.321632444858551\n",
            "Epoch 49, Step 144, Loss: 0.5217370986938477\n",
            "Epoch 49, Step 145, Loss: 0.5753138065338135\n",
            "Epoch 49, Step 146, Loss: 0.3761872947216034\n",
            "Epoch 49, Step 147, Loss: 0.5027877688407898\n",
            "Epoch 49, Step 148, Loss: 0.5019389390945435\n",
            "Epoch 49, Step 149, Loss: 0.5731176137924194\n",
            "Epoch 49, Step 150, Loss: 0.38285383582115173\n",
            "Epoch 49, Step 151, Loss: 0.5111105442047119\n",
            "Epoch 49, Step 152, Loss: 0.5053432583808899\n",
            "Epoch 49, Step 153, Loss: 0.6918954253196716\n",
            "Epoch 49, Step 154, Loss: 0.5229376554489136\n",
            "Epoch 49, Step 155, Loss: 0.43833357095718384\n",
            "Epoch 49, Step 156, Loss: 0.6850587725639343\n",
            "Epoch 49, Step 157, Loss: 0.5291064381599426\n",
            "Epoch 49, Step 158, Loss: 0.5019813179969788\n",
            "Epoch 49, Step 159, Loss: 0.6508199572563171\n",
            "Epoch 49, Step 160, Loss: 0.5040033459663391\n",
            "Epoch 49, Step 161, Loss: 0.3940160274505615\n",
            "Epoch 49, Step 162, Loss: 0.43102285265922546\n",
            "Epoch 49, Step 163, Loss: 0.3774970471858978\n",
            "Epoch 49, Step 164, Loss: 0.487481027841568\n",
            "Epoch 49, Step 165, Loss: 0.6064437627792358\n",
            "Epoch 49, Step 166, Loss: 0.5954151749610901\n",
            "Epoch 49, Step 167, Loss: 0.44765034317970276\n",
            "Epoch 49, Step 168, Loss: 0.4061349332332611\n",
            "Epoch 49, Step 169, Loss: 0.5100486278533936\n",
            "Epoch 49, Step 170, Loss: 0.5727546215057373\n",
            "Epoch 49, Step 171, Loss: 0.4889226257801056\n",
            "Epoch 49, Step 172, Loss: 0.39738503098487854\n",
            "Epoch 49, Step 173, Loss: 0.4510954022407532\n",
            "Epoch 49, Step 174, Loss: 0.475913941860199\n",
            "Epoch 49, Step 175, Loss: 0.48190346360206604\n",
            "Epoch 49, Step 176, Loss: 0.4101555049419403\n",
            "Epoch 49, Step 177, Loss: 0.5394258499145508\n",
            "Epoch 49, Step 178, Loss: 0.3869628608226776\n",
            "Epoch 49, Step 179, Loss: 0.32670825719833374\n",
            "Epoch 49, Step 180, Loss: 0.5544776320457458\n",
            "Epoch 49, Step 181, Loss: 0.45313340425491333\n",
            "Epoch 49, Step 182, Loss: 0.5153660178184509\n",
            "Epoch 49, Step 183, Loss: 0.44525575637817383\n",
            "Epoch 49, Step 184, Loss: 0.5103027820587158\n",
            "Epoch 49, Step 185, Loss: 0.4683660864830017\n",
            "Epoch 49, Step 186, Loss: 0.46186262369155884\n",
            "Epoch 49, Step 187, Loss: 0.61693274974823\n",
            "Epoch 49, Step 188, Loss: 0.5232278108596802\n",
            "Epoch 49, Step 189, Loss: 0.4096311032772064\n",
            "Epoch 49, Step 190, Loss: 0.4683656692504883\n",
            "Epoch 49, Step 191, Loss: 0.5384218096733093\n",
            "Epoch 49, Step 192, Loss: 0.5230186581611633\n",
            "Epoch 49, Step 193, Loss: 0.6269440650939941\n",
            "Epoch 49, Step 194, Loss: 0.45227840542793274\n",
            "Epoch 49, Step 195, Loss: 0.49048227071762085\n",
            "Epoch 49, Step 196, Loss: 0.44428497552871704\n",
            "Epoch 49, Step 197, Loss: 0.5167384743690491\n",
            "Epoch 49, Step 198, Loss: 0.5186560750007629\n",
            "Epoch 49, Step 199, Loss: 0.6873390674591064\n",
            "Epoch 49, Step 200, Loss: 0.6169724464416504\n",
            "Epoch 49, Step 201, Loss: 0.4824259877204895\n",
            "Epoch 49, Step 202, Loss: 0.6211943030357361\n",
            "Epoch 49, Step 203, Loss: 0.41335415840148926\n",
            "Epoch 49, Step 204, Loss: 0.4192425012588501\n",
            "Epoch 49, Step 205, Loss: 0.4737125635147095\n",
            "Epoch 49, Step 206, Loss: 0.40401744842529297\n",
            "Epoch 49, Step 207, Loss: 0.6055277585983276\n",
            "Epoch 49, Step 208, Loss: 0.5991247296333313\n",
            "Epoch 49, Step 209, Loss: 0.39230838418006897\n",
            "Epoch 49, Step 210, Loss: 0.6174222826957703\n",
            "Epoch 49, Step 211, Loss: 0.5160315036773682\n",
            "Epoch 49, Step 212, Loss: 0.48996487259864807\n",
            "Epoch 49, Step 213, Loss: 0.5177696347236633\n",
            "Epoch 49, Step 214, Loss: 0.44264310598373413\n",
            "Epoch 49, Step 215, Loss: 0.47764861583709717\n",
            "Epoch 49, Step 216, Loss: 0.6455831527709961\n",
            "Epoch 49, Step 217, Loss: 0.5034812688827515\n",
            "Epoch 49, Step 218, Loss: 0.5924178957939148\n",
            "Epoch 49, Step 219, Loss: 0.42730778455734253\n",
            "Epoch 49, Step 220, Loss: 0.5883936882019043\n",
            "Epoch 49, Step 221, Loss: 0.40008753538131714\n",
            "Epoch 49, Step 222, Loss: 0.43049514293670654\n",
            "Epoch 49, Step 223, Loss: 0.43316733837127686\n",
            "Epoch 49, Step 224, Loss: 0.639318585395813\n",
            "Epoch 49, Step 225, Loss: 0.42828914523124695\n",
            "Epoch 49, Step 226, Loss: 0.3609960675239563\n",
            "Epoch 49, Step 227, Loss: 0.47212332487106323\n",
            "Epoch 49, Step 228, Loss: 0.47505635023117065\n",
            "Epoch 49, Step 229, Loss: 0.5118269324302673\n",
            "Epoch 49, Step 230, Loss: 0.4648711383342743\n",
            "Epoch 49, Step 231, Loss: 0.5211501717567444\n",
            "Epoch 49, Step 232, Loss: 0.5739732980728149\n",
            "Epoch 49, Step 233, Loss: 0.44626158475875854\n",
            "Epoch 49, Step 234, Loss: 0.42508673667907715\n",
            "Epoch 49, Step 235, Loss: 0.5386953949928284\n",
            "Epoch 49, Step 236, Loss: 0.3951624035835266\n",
            "Epoch 49, Step 237, Loss: 0.6129896640777588\n",
            "Epoch 49, Step 238, Loss: 0.6066669821739197\n",
            "Epoch 49, Step 239, Loss: 0.6623988747596741\n",
            "Epoch 49, Step 240, Loss: 0.4514283239841461\n",
            "Epoch 49, Step 241, Loss: 0.4578240215778351\n",
            "Epoch 49, Step 242, Loss: 0.5488284230232239\n",
            "Epoch 49, Step 243, Loss: 0.4564552903175354\n",
            "Epoch 49, Step 244, Loss: 0.4667673707008362\n",
            "Epoch 49, Step 245, Loss: 0.5734624862670898\n",
            "Epoch 49, Step 246, Loss: 0.45629802346229553\n",
            "Epoch 49, Step 247, Loss: 0.5393151044845581\n",
            "Epoch 49, Step 248, Loss: 0.5538635849952698\n",
            "Epoch 49, Step 249, Loss: 0.576726496219635\n",
            "Epoch 49, Step 250, Loss: 0.4154800772666931\n",
            "Epoch 49, Step 251, Loss: 0.5455127358436584\n",
            "Epoch 49, Step 252, Loss: 0.5633974075317383\n",
            "Epoch 49, Step 253, Loss: 0.5675751566886902\n",
            "Epoch 49, Step 254, Loss: 0.44736653566360474\n",
            "Epoch 49, Step 255, Loss: 0.47617197036743164\n",
            "Epoch 49, Step 256, Loss: 0.5842073559761047\n",
            "Epoch 49, Step 257, Loss: 0.48395243287086487\n",
            "Epoch 49, Step 258, Loss: 0.5013184547424316\n",
            "Epoch 49, Step 259, Loss: 0.48285138607025146\n",
            "Epoch 49, Step 260, Loss: 0.43879395723342896\n",
            "Epoch 49, Step 261, Loss: 0.3448178470134735\n",
            "Epoch 49, Step 262, Loss: 0.379902184009552\n",
            "Epoch 49, Step 263, Loss: 0.576158344745636\n",
            "Epoch 49, Step 264, Loss: 0.4603022038936615\n",
            "Epoch 49, Step 265, Loss: 0.5562297105789185\n",
            "Epoch 49, Step 266, Loss: 0.6081836819648743\n",
            "Epoch 49, Step 267, Loss: 0.42647749185562134\n",
            "Epoch 49, Step 268, Loss: 0.5348994135856628\n",
            "Epoch 49, Step 269, Loss: 0.5257102847099304\n",
            "Epoch 49, Step 270, Loss: 0.4744280278682709\n",
            "Epoch 49, Step 271, Loss: 0.3702223300933838\n",
            "Epoch 49, Step 272, Loss: 0.47451791167259216\n",
            "Epoch 49, Step 273, Loss: 0.467093288898468\n",
            "Epoch 49, Step 274, Loss: 0.3582516312599182\n",
            "Epoch 49, Step 275, Loss: 0.46950066089630127\n",
            "Epoch 49, Step 276, Loss: 0.3682243525981903\n",
            "Epoch 49, Step 277, Loss: 0.49780282378196716\n",
            "Epoch 49, Step 278, Loss: 0.4196578860282898\n",
            "Epoch 49, Step 279, Loss: 0.390865683555603\n",
            "Epoch 49, Step 280, Loss: 0.4485871493816376\n",
            "Epoch 49, Step 281, Loss: 0.5015017986297607\n",
            "Epoch 49, Step 282, Loss: 0.43042296171188354\n",
            "Epoch 49, Step 283, Loss: 0.5378468036651611\n",
            "Epoch 49, Step 284, Loss: 0.5028691291809082\n",
            "Epoch 49, Step 285, Loss: 0.4602736234664917\n",
            "Epoch 49, Step 286, Loss: 0.5494299530982971\n",
            "Epoch 49, Step 287, Loss: 0.49225443601608276\n",
            "Epoch 49, Step 288, Loss: 0.30638161301612854\n",
            "Epoch 49, Step 289, Loss: 0.5352851748466492\n",
            "Epoch 49, Step 290, Loss: 0.4312957227230072\n",
            "Epoch 49, Step 291, Loss: 0.48075392842292786\n",
            "Epoch 49, Step 292, Loss: 0.5417952537536621\n",
            "Epoch 49, Step 293, Loss: 0.5694380402565002\n",
            "Epoch 49, Step 294, Loss: 0.4489530920982361\n",
            "Epoch 49, Step 295, Loss: 0.38607358932495117\n",
            "Epoch 49, Step 296, Loss: 0.4809974133968353\n",
            "Epoch 49, Step 297, Loss: 0.4404713809490204\n",
            "Epoch 49, Step 298, Loss: 0.42287659645080566\n",
            "Epoch 49, Step 299, Loss: 0.46128034591674805\n",
            "Epoch 49, Step 300, Loss: 0.40419360995292664\n",
            "Epoch 49, Step 301, Loss: 0.533646285533905\n",
            "Epoch 49, Step 302, Loss: 0.526779055595398\n",
            "Epoch 49, Step 303, Loss: 0.36397451162338257\n",
            "Epoch 49, Step 304, Loss: 0.5878421068191528\n",
            "Epoch 49, Step 305, Loss: 0.4161480963230133\n",
            "Epoch 49, Step 306, Loss: 0.49232301115989685\n",
            "Epoch 49, Step 307, Loss: 0.4152842164039612\n",
            "Epoch 49, Step 308, Loss: 0.4187370240688324\n",
            "Epoch 49, Step 309, Loss: 0.5562103986740112\n",
            "Epoch 49, Step 310, Loss: 0.32841718196868896\n",
            "Epoch 49, Step 311, Loss: 0.5617040395736694\n",
            "Epoch 49, Step 312, Loss: 0.574349582195282\n",
            "Epoch 49 end, avg train loss: 0.49215875846890217\n",
            "Epoch 49 end, avg val loss: 0.5686401483378832, accuracy: 80.47%\n",
            "Epoch 50, Step 0, Loss: 0.678124725818634\n",
            "Epoch 50, Step 1, Loss: 0.449387788772583\n",
            "Epoch 50, Step 2, Loss: 0.4762980341911316\n",
            "Epoch 50, Step 3, Loss: 0.5786904692649841\n",
            "Epoch 50, Step 4, Loss: 0.5581814646720886\n",
            "Epoch 50, Step 5, Loss: 0.5303785800933838\n",
            "Epoch 50, Step 6, Loss: 0.4370124638080597\n",
            "Epoch 50, Step 7, Loss: 0.5786446928977966\n",
            "Epoch 50, Step 8, Loss: 0.41449660062789917\n",
            "Epoch 50, Step 9, Loss: 0.42981603741645813\n",
            "Epoch 50, Step 10, Loss: 0.5924438834190369\n",
            "Epoch 50, Step 11, Loss: 0.4655230939388275\n",
            "Epoch 50, Step 12, Loss: 0.4549133777618408\n",
            "Epoch 50, Step 13, Loss: 0.4616554081439972\n",
            "Epoch 50, Step 14, Loss: 0.40193402767181396\n",
            "Epoch 50, Step 15, Loss: 0.582796573638916\n",
            "Epoch 50, Step 16, Loss: 0.46264269948005676\n",
            "Epoch 50, Step 17, Loss: 0.4459213316440582\n",
            "Epoch 50, Step 18, Loss: 0.36097124218940735\n",
            "Epoch 50, Step 19, Loss: 0.4078104794025421\n",
            "Epoch 50, Step 20, Loss: 0.47198593616485596\n",
            "Epoch 50, Step 21, Loss: 0.5742600560188293\n",
            "Epoch 50, Step 22, Loss: 0.5298527479171753\n",
            "Epoch 50, Step 23, Loss: 0.4341968894004822\n",
            "Epoch 50, Step 24, Loss: 0.6433432698249817\n",
            "Epoch 50, Step 25, Loss: 0.47010135650634766\n",
            "Epoch 50, Step 26, Loss: 0.49825456738471985\n",
            "Epoch 50, Step 27, Loss: 0.6326667666435242\n",
            "Epoch 50, Step 28, Loss: 0.36381256580352783\n",
            "Epoch 50, Step 29, Loss: 0.4584827423095703\n",
            "Epoch 50, Step 30, Loss: 0.5615994334220886\n",
            "Epoch 50, Step 31, Loss: 0.4378849267959595\n",
            "Epoch 50, Step 32, Loss: 0.5341637134552002\n",
            "Epoch 50, Step 33, Loss: 0.5470957159996033\n",
            "Epoch 50, Step 34, Loss: 0.36823537945747375\n",
            "Epoch 50, Step 35, Loss: 0.644332766532898\n",
            "Epoch 50, Step 36, Loss: 0.5134810209274292\n",
            "Epoch 50, Step 37, Loss: 0.4470559358596802\n",
            "Epoch 50, Step 38, Loss: 0.5258505344390869\n",
            "Epoch 50, Step 39, Loss: 0.622402012348175\n",
            "Epoch 50, Step 40, Loss: 0.3773761987686157\n",
            "Epoch 50, Step 41, Loss: 0.557379961013794\n",
            "Epoch 50, Step 42, Loss: 0.49330371618270874\n",
            "Epoch 50, Step 43, Loss: 0.4796740412712097\n",
            "Epoch 50, Step 44, Loss: 0.492224782705307\n",
            "Epoch 50, Step 45, Loss: 0.5501284003257751\n",
            "Epoch 50, Step 46, Loss: 0.46792736649513245\n",
            "Epoch 50, Step 47, Loss: 0.5971161127090454\n",
            "Epoch 50, Step 48, Loss: 0.47708868980407715\n",
            "Epoch 50, Step 49, Loss: 0.47209352254867554\n",
            "Epoch 50, Step 50, Loss: 0.5399131178855896\n",
            "Epoch 50, Step 51, Loss: 0.5571773648262024\n",
            "Epoch 50, Step 52, Loss: 0.5615432262420654\n",
            "Epoch 50, Step 53, Loss: 0.46790874004364014\n",
            "Epoch 50, Step 54, Loss: 0.43527328968048096\n",
            "Epoch 50, Step 55, Loss: 0.4870007038116455\n",
            "Epoch 50, Step 56, Loss: 0.5734463334083557\n",
            "Epoch 50, Step 57, Loss: 0.4155576527118683\n",
            "Epoch 50, Step 58, Loss: 0.5582678914070129\n",
            "Epoch 50, Step 59, Loss: 0.5090759992599487\n",
            "Epoch 50, Step 60, Loss: 0.6729303002357483\n",
            "Epoch 50, Step 61, Loss: 0.5184929966926575\n",
            "Epoch 50, Step 62, Loss: 0.4267493188381195\n",
            "Epoch 50, Step 63, Loss: 0.6621914505958557\n",
            "Epoch 50, Step 64, Loss: 0.37158796191215515\n",
            "Epoch 50, Step 65, Loss: 0.4291825294494629\n",
            "Epoch 50, Step 66, Loss: 0.4300866425037384\n",
            "Epoch 50, Step 67, Loss: 0.6108845472335815\n",
            "Epoch 50, Step 68, Loss: 0.5000043511390686\n",
            "Epoch 50, Step 69, Loss: 0.4489733576774597\n",
            "Epoch 50, Step 70, Loss: 0.526898980140686\n",
            "Epoch 50, Step 71, Loss: 0.405343234539032\n",
            "Epoch 50, Step 72, Loss: 0.4409773349761963\n",
            "Epoch 50, Step 73, Loss: 0.5433995127677917\n",
            "Epoch 50, Step 74, Loss: 0.5836547613143921\n",
            "Epoch 50, Step 75, Loss: 0.4488343894481659\n",
            "Epoch 50, Step 76, Loss: 0.46991145610809326\n",
            "Epoch 50, Step 77, Loss: 0.49700459837913513\n",
            "Epoch 50, Step 78, Loss: 0.364437997341156\n",
            "Epoch 50, Step 79, Loss: 0.502032995223999\n",
            "Epoch 50, Step 80, Loss: 0.46012526750564575\n",
            "Epoch 50, Step 81, Loss: 0.4172123074531555\n",
            "Epoch 50, Step 82, Loss: 0.5238611102104187\n",
            "Epoch 50, Step 83, Loss: 0.4571292996406555\n",
            "Epoch 50, Step 84, Loss: 0.49139928817749023\n",
            "Epoch 50, Step 85, Loss: 0.41822338104248047\n",
            "Epoch 50, Step 86, Loss: 0.695277214050293\n",
            "Epoch 50, Step 87, Loss: 0.5472404360771179\n",
            "Epoch 50, Step 88, Loss: 0.3647248148918152\n",
            "Epoch 50, Step 89, Loss: 0.4440973997116089\n",
            "Epoch 50, Step 90, Loss: 0.3466007709503174\n",
            "Epoch 50, Step 91, Loss: 0.4548378884792328\n",
            "Epoch 50, Step 92, Loss: 0.4137473404407501\n",
            "Epoch 50, Step 93, Loss: 0.41810959577560425\n",
            "Epoch 50, Step 94, Loss: 0.34294992685317993\n",
            "Epoch 50, Step 95, Loss: 0.5248041152954102\n",
            "Epoch 50, Step 96, Loss: 0.5256443619728088\n",
            "Epoch 50, Step 97, Loss: 0.6118476390838623\n",
            "Epoch 50, Step 98, Loss: 0.4707928001880646\n",
            "Epoch 50, Step 99, Loss: 0.49172091484069824\n",
            "Epoch 50, Step 100, Loss: 0.5154327154159546\n",
            "Epoch 50, Step 101, Loss: 0.5344262719154358\n",
            "Epoch 50, Step 102, Loss: 0.5037174224853516\n",
            "Epoch 50, Step 103, Loss: 0.44469889998435974\n",
            "Epoch 50, Step 104, Loss: 0.4775542914867401\n",
            "Epoch 50, Step 105, Loss: 0.7377170920372009\n",
            "Epoch 50, Step 106, Loss: 0.5288742780685425\n",
            "Epoch 50, Step 107, Loss: 0.579485297203064\n",
            "Epoch 50, Step 108, Loss: 0.5383290648460388\n",
            "Epoch 50, Step 109, Loss: 0.3578481674194336\n",
            "Epoch 50, Step 110, Loss: 0.3223784565925598\n",
            "Epoch 50, Step 111, Loss: 0.3151947259902954\n",
            "Epoch 50, Step 112, Loss: 0.685110330581665\n",
            "Epoch 50, Step 113, Loss: 0.4806245267391205\n",
            "Epoch 50, Step 114, Loss: 0.6013665199279785\n",
            "Epoch 50, Step 115, Loss: 0.40322548151016235\n",
            "Epoch 50, Step 116, Loss: 0.3697899580001831\n",
            "Epoch 50, Step 117, Loss: 0.3774338662624359\n",
            "Epoch 50, Step 118, Loss: 0.3621368110179901\n",
            "Epoch 50, Step 119, Loss: 0.4859694242477417\n",
            "Epoch 50, Step 120, Loss: 0.5640752911567688\n",
            "Epoch 50, Step 121, Loss: 0.4768790900707245\n",
            "Epoch 50, Step 122, Loss: 0.46753746271133423\n",
            "Epoch 50, Step 123, Loss: 0.42636463046073914\n",
            "Epoch 50, Step 124, Loss: 0.5122473239898682\n",
            "Epoch 50, Step 125, Loss: 0.4310148358345032\n",
            "Epoch 50, Step 126, Loss: 0.5102447867393494\n",
            "Epoch 50, Step 127, Loss: 0.4533838629722595\n",
            "Epoch 50, Step 128, Loss: 0.539299488067627\n",
            "Epoch 50, Step 129, Loss: 0.5722405314445496\n",
            "Epoch 50, Step 130, Loss: 0.5558709502220154\n",
            "Epoch 50, Step 131, Loss: 0.5226386189460754\n",
            "Epoch 50, Step 132, Loss: 0.35666918754577637\n",
            "Epoch 50, Step 133, Loss: 0.5305032134056091\n",
            "Epoch 50, Step 134, Loss: 0.4804544746875763\n",
            "Epoch 50, Step 135, Loss: 0.4639728367328644\n",
            "Epoch 50, Step 136, Loss: 0.47441670298576355\n",
            "Epoch 50, Step 137, Loss: 0.5124923586845398\n",
            "Epoch 50, Step 138, Loss: 0.32204392552375793\n",
            "Epoch 50, Step 139, Loss: 0.529782772064209\n",
            "Epoch 50, Step 140, Loss: 0.5864967703819275\n",
            "Epoch 50, Step 141, Loss: 0.4344198703765869\n",
            "Epoch 50, Step 142, Loss: 0.46429702639579773\n",
            "Epoch 50, Step 143, Loss: 0.4303455948829651\n",
            "Epoch 50, Step 144, Loss: 0.6758986115455627\n",
            "Epoch 50, Step 145, Loss: 0.48146528005599976\n",
            "Epoch 50, Step 146, Loss: 0.5910191535949707\n",
            "Epoch 50, Step 147, Loss: 0.5062316656112671\n",
            "Epoch 50, Step 148, Loss: 0.440255731344223\n",
            "Epoch 50, Step 149, Loss: 0.4771152436733246\n",
            "Epoch 50, Step 150, Loss: 0.5333766937255859\n",
            "Epoch 50, Step 151, Loss: 0.4662008285522461\n",
            "Epoch 50, Step 152, Loss: 0.5372963547706604\n",
            "Epoch 50, Step 153, Loss: 0.343280166387558\n",
            "Epoch 50, Step 154, Loss: 0.38485050201416016\n",
            "Epoch 50, Step 155, Loss: 0.47448626160621643\n",
            "Epoch 50, Step 156, Loss: 0.5831755995750427\n",
            "Epoch 50, Step 157, Loss: 0.6833152770996094\n",
            "Epoch 50, Step 158, Loss: 0.6357106566429138\n",
            "Epoch 50, Step 159, Loss: 0.5608062744140625\n",
            "Epoch 50, Step 160, Loss: 0.4998027980327606\n",
            "Epoch 50, Step 161, Loss: 0.548186719417572\n",
            "Epoch 50, Step 162, Loss: 0.5805487036705017\n",
            "Epoch 50, Step 163, Loss: 0.42893069982528687\n",
            "Epoch 50, Step 164, Loss: 0.4844118058681488\n",
            "Epoch 50, Step 165, Loss: 0.5899128317832947\n",
            "Epoch 50, Step 166, Loss: 0.44381919503211975\n",
            "Epoch 50, Step 167, Loss: 0.46992751955986023\n",
            "Epoch 50, Step 168, Loss: 0.37800735235214233\n",
            "Epoch 50, Step 169, Loss: 0.42316532135009766\n",
            "Epoch 50, Step 170, Loss: 0.5532430410385132\n",
            "Epoch 50, Step 171, Loss: 0.5945931673049927\n",
            "Epoch 50, Step 172, Loss: 0.5487008690834045\n",
            "Epoch 50, Step 173, Loss: 0.5081517100334167\n",
            "Epoch 50, Step 174, Loss: 0.6833212971687317\n",
            "Epoch 50, Step 175, Loss: 0.594946026802063\n",
            "Epoch 50, Step 176, Loss: 0.477253258228302\n",
            "Epoch 50, Step 177, Loss: 0.3569002151489258\n",
            "Epoch 50, Step 178, Loss: 0.5480076670646667\n",
            "Epoch 50, Step 179, Loss: 0.5432681441307068\n",
            "Epoch 50, Step 180, Loss: 0.5512822866439819\n",
            "Epoch 50, Step 181, Loss: 0.5420395731925964\n",
            "Epoch 50, Step 182, Loss: 0.5267431735992432\n",
            "Epoch 50, Step 183, Loss: 0.44528210163116455\n",
            "Epoch 50, Step 184, Loss: 0.4818541705608368\n",
            "Epoch 50, Step 185, Loss: 0.45504555106163025\n",
            "Epoch 50, Step 186, Loss: 0.5484831929206848\n",
            "Epoch 50, Step 187, Loss: 0.544903039932251\n",
            "Epoch 50, Step 188, Loss: 0.5876764059066772\n",
            "Epoch 50, Step 189, Loss: 0.39690321683883667\n",
            "Epoch 50, Step 190, Loss: 0.44137585163116455\n",
            "Epoch 50, Step 191, Loss: 0.4973512589931488\n",
            "Epoch 50, Step 192, Loss: 0.4692642390727997\n",
            "Epoch 50, Step 193, Loss: 0.43501564860343933\n",
            "Epoch 50, Step 194, Loss: 0.4522019326686859\n",
            "Epoch 50, Step 195, Loss: 0.40803655982017517\n",
            "Epoch 50, Step 196, Loss: 0.4018264710903168\n",
            "Epoch 50, Step 197, Loss: 0.5218408703804016\n",
            "Epoch 50, Step 198, Loss: 0.4469648599624634\n",
            "Epoch 50, Step 199, Loss: 0.4455627501010895\n",
            "Epoch 50, Step 200, Loss: 0.42412421107292175\n",
            "Epoch 50, Step 201, Loss: 0.48089516162872314\n",
            "Epoch 50, Step 202, Loss: 0.5060787796974182\n",
            "Epoch 50, Step 203, Loss: 0.5616618394851685\n",
            "Epoch 50, Step 204, Loss: 0.4260846674442291\n",
            "Epoch 50, Step 205, Loss: 0.3152070939540863\n",
            "Epoch 50, Step 206, Loss: 0.4999852776527405\n",
            "Epoch 50, Step 207, Loss: 0.5177708864212036\n",
            "Epoch 50, Step 208, Loss: 0.556053876876831\n",
            "Epoch 50, Step 209, Loss: 0.3884202539920807\n",
            "Epoch 50, Step 210, Loss: 0.47389453649520874\n",
            "Epoch 50, Step 211, Loss: 0.38574865460395813\n",
            "Epoch 50, Step 212, Loss: 0.46243301033973694\n",
            "Epoch 50, Step 213, Loss: 0.38306620717048645\n",
            "Epoch 50, Step 214, Loss: 0.5389779210090637\n",
            "Epoch 50, Step 215, Loss: 0.39083725214004517\n",
            "Epoch 50, Step 216, Loss: 0.5542017817497253\n",
            "Epoch 50, Step 217, Loss: 0.5102187991142273\n",
            "Epoch 50, Step 218, Loss: 0.4972081184387207\n",
            "Epoch 50, Step 219, Loss: 0.3909097909927368\n",
            "Epoch 50, Step 220, Loss: 0.33673521876335144\n",
            "Epoch 50, Step 221, Loss: 0.4754032492637634\n",
            "Epoch 50, Step 222, Loss: 0.4189852476119995\n",
            "Epoch 50, Step 223, Loss: 0.3807624876499176\n",
            "Epoch 50, Step 224, Loss: 0.380260705947876\n",
            "Epoch 50, Step 225, Loss: 0.5752056241035461\n",
            "Epoch 50, Step 226, Loss: 0.5642157793045044\n",
            "Epoch 50, Step 227, Loss: 0.4424362778663635\n",
            "Epoch 50, Step 228, Loss: 0.5234947204589844\n",
            "Epoch 50, Step 229, Loss: 0.4018385708332062\n",
            "Epoch 50, Step 230, Loss: 0.46436551213264465\n",
            "Epoch 50, Step 231, Loss: 0.5108885169029236\n",
            "Epoch 50, Step 232, Loss: 0.4600788354873657\n",
            "Epoch 50, Step 233, Loss: 0.5407916307449341\n",
            "Epoch 50, Step 234, Loss: 0.42404982447624207\n",
            "Epoch 50, Step 235, Loss: 0.36419060826301575\n",
            "Epoch 50, Step 236, Loss: 0.4881817400455475\n",
            "Epoch 50, Step 237, Loss: 0.5732498168945312\n",
            "Epoch 50, Step 238, Loss: 0.5116599202156067\n",
            "Epoch 50, Step 239, Loss: 0.33091530203819275\n",
            "Epoch 50, Step 240, Loss: 0.5955958962440491\n",
            "Epoch 50, Step 241, Loss: 0.3654841482639313\n",
            "Epoch 50, Step 242, Loss: 0.5196376442909241\n",
            "Epoch 50, Step 243, Loss: 0.5453615188598633\n",
            "Epoch 50, Step 244, Loss: 0.6520044207572937\n",
            "Epoch 50, Step 245, Loss: 0.5328246355056763\n",
            "Epoch 50, Step 246, Loss: 0.5682703256607056\n",
            "Epoch 50, Step 247, Loss: 0.6129338145256042\n",
            "Epoch 50, Step 248, Loss: 0.4914567172527313\n",
            "Epoch 50, Step 249, Loss: 0.39374658465385437\n",
            "Epoch 50, Step 250, Loss: 0.49902647733688354\n",
            "Epoch 50, Step 251, Loss: 0.5841145515441895\n",
            "Epoch 50, Step 252, Loss: 0.5356649160385132\n",
            "Epoch 50, Step 253, Loss: 0.636461079120636\n",
            "Epoch 50, Step 254, Loss: 0.45567432045936584\n",
            "Epoch 50, Step 255, Loss: 0.46583062410354614\n",
            "Epoch 50, Step 256, Loss: 0.48957228660583496\n",
            "Epoch 50, Step 257, Loss: 0.5281026363372803\n",
            "Epoch 50, Step 258, Loss: 0.5806565284729004\n",
            "Epoch 50, Step 259, Loss: 0.34717872738838196\n",
            "Epoch 50, Step 260, Loss: 0.5455050468444824\n",
            "Epoch 50, Step 261, Loss: 0.4447864890098572\n",
            "Epoch 50, Step 262, Loss: 0.5346513986587524\n",
            "Epoch 50, Step 263, Loss: 0.46070775389671326\n",
            "Epoch 50, Step 264, Loss: 0.5747217535972595\n",
            "Epoch 50, Step 265, Loss: 0.4406566321849823\n",
            "Epoch 50, Step 266, Loss: 0.4247802495956421\n",
            "Epoch 50, Step 267, Loss: 0.5325050354003906\n",
            "Epoch 50, Step 268, Loss: 0.44890493154525757\n",
            "Epoch 50, Step 269, Loss: 0.5707407593727112\n",
            "Epoch 50, Step 270, Loss: 0.6064651608467102\n",
            "Epoch 50, Step 271, Loss: 0.3580608069896698\n",
            "Epoch 50, Step 272, Loss: 0.38458919525146484\n",
            "Epoch 50, Step 273, Loss: 0.3447033166885376\n",
            "Epoch 50, Step 274, Loss: 0.5055650472640991\n",
            "Epoch 50, Step 275, Loss: 0.48183995485305786\n",
            "Epoch 50, Step 276, Loss: 0.4711839258670807\n",
            "Epoch 50, Step 277, Loss: 0.4761490523815155\n",
            "Epoch 50, Step 278, Loss: 0.4491913914680481\n",
            "Epoch 50, Step 279, Loss: 0.49526283144950867\n",
            "Epoch 50, Step 280, Loss: 0.5328562259674072\n",
            "Epoch 50, Step 281, Loss: 0.39498332142829895\n",
            "Epoch 50, Step 282, Loss: 0.499104768037796\n",
            "Epoch 50, Step 283, Loss: 0.5225245952606201\n",
            "Epoch 50, Step 284, Loss: 0.5915708541870117\n",
            "Epoch 50, Step 285, Loss: 0.5115519165992737\n",
            "Epoch 50, Step 286, Loss: 0.5702570080757141\n",
            "Epoch 50, Step 287, Loss: 0.4654479920864105\n",
            "Epoch 50, Step 288, Loss: 0.6747303009033203\n",
            "Epoch 50, Step 289, Loss: 0.5958826541900635\n",
            "Epoch 50, Step 290, Loss: 0.4806135296821594\n",
            "Epoch 50, Step 291, Loss: 0.49602705240249634\n",
            "Epoch 50, Step 292, Loss: 0.49857479333877563\n",
            "Epoch 50, Step 293, Loss: 0.4146774709224701\n",
            "Epoch 50, Step 294, Loss: 0.507520854473114\n",
            "Epoch 50, Step 295, Loss: 0.48516082763671875\n",
            "Epoch 50, Step 296, Loss: 0.3685097396373749\n",
            "Epoch 50, Step 297, Loss: 0.37941598892211914\n",
            "Epoch 50, Step 298, Loss: 0.5511733889579773\n",
            "Epoch 50, Step 299, Loss: 0.41500240564346313\n",
            "Epoch 50, Step 300, Loss: 0.6024174690246582\n",
            "Epoch 50, Step 301, Loss: 0.5682430863380432\n",
            "Epoch 50, Step 302, Loss: 0.6055295467376709\n",
            "Epoch 50, Step 303, Loss: 0.4681536853313446\n",
            "Epoch 50, Step 304, Loss: 0.5574500560760498\n",
            "Epoch 50, Step 305, Loss: 0.5313202142715454\n",
            "Epoch 50, Step 306, Loss: 0.6473076939582825\n",
            "Epoch 50, Step 307, Loss: 0.5225729942321777\n",
            "Epoch 50, Step 308, Loss: 0.49681782722473145\n",
            "Epoch 50, Step 309, Loss: 0.6574455499649048\n",
            "Epoch 50, Step 310, Loss: 0.4491729736328125\n",
            "Epoch 50, Step 311, Loss: 0.5277937054634094\n",
            "Epoch 50, Step 312, Loss: 0.4538259506225586\n",
            "Epoch 50 end, avg train loss: 0.49292024522543715\n",
            "Epoch 50 end, avg val loss: 0.5472444095943547, accuracy: 80.97%\n",
            "GPU memory allocated: 0.34 GB\n",
            "GPU memory reserved: 0.44 GB\n",
            "Training complete.\n"
          ]
        }
      ],
      "source": [
        "ipsModel = PretrainedResNet18().to(device)\n",
        "ipsOptimizer = IPS(ipsModel.parameters(), lower_bound=0, T=epochs * (len(trainset)/batch_size))\n",
        "train(model=ipsModel, optimizer=ipsOptimizer, epochs=epochs)\n",
        "ipsModel = ipsModel.cpu()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(ipsModel, 'ips_cifar_vanilla.pth')"
      ],
      "metadata": {
        "id": "162B6FCIxWXV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "LZfWE11624O0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "b9c561f3-3c47-414d-9623-93909d5896b0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "models = [\n",
        "    (adaIpsModel, 'adaips'),\n",
        "    (adamModel, 'adam'),\n",
        "    # (adaIpsModel_, 'adaips per param optimizer'),\n",
        "\n",
        "    (ipsModel, 'ips optimizer')\n",
        "\n",
        "]\n",
        "exclude = []\n",
        "focus = [adaIpsModel]\n",
        "interval = 1\n",
        "for model, optimizer in models:\n",
        "    if model in exclude: continue\n",
        "    plt.plot(\n",
        "        [i for i, loss in enumerate(model.t_losses) if i % interval == 0],\n",
        "        [loss for i, loss in enumerate(model.t_losses) if i % interval == 0],\n",
        "        label=f\"{optimizer} training loss\",\n",
        "        alpha=0.5 if model not in focus else 1\n",
        "    )\n",
        "\n",
        "plt.title(\"Training loss CIFAR-10 dataset\")\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for model, optimizer in models:\n",
        "    if model in exclude: continue\n",
        "    plt.plot(\n",
        "        [i for i, loss in enumerate(model.v_losses) if i % interval == 0],\n",
        "        [loss for i, loss in enumerate(model.v_losses) if i % interval == 0],\n",
        "        label=f\"{optimizer} training loss\",\n",
        "        alpha=0.5 if model not in focus else 1\n",
        "    )\n",
        "\n",
        "plt.title(\"Training loss CIFAR-10 dataset\")\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "SpoCCuMxy3Ok",
        "outputId": "38368ddd-268b-4119-bae7-2ea8cc982eb3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for model, opt in models:\n",
        "    torch.save(model, f\"{opt.split(' ')[0]}_cifar_vanilla.pth\")"
      ],
      "metadata": {
        "id": "suaIdJjR7O6g"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(adaIpsModel, testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhmXgrpbI-KB",
        "outputId": "923103d7-39ee-4198-f443-0f044c8f62ef"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8876\n",
            "Precision: 0.8879\n",
            "Recall: 0.8876\n",
            "F1-score: 0.8869\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(adamModel, testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59-ZP6xyiSr0",
        "outputId": "1445dd78-d774-401b-d410-a56277825978"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9091\n",
            "Precision: 0.9101\n",
            "Recall: 0.9091\n",
            "F1-score: 0.9091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(ipsModel, testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piCdxzLTxkEE",
        "outputId": "e8d898d8-65a1-4fae-a32f-2403f0c47203"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8062\n",
            "Precision: 0.8071\n",
            "Recall: 0.8062\n",
            "F1-score: 0.8062\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}